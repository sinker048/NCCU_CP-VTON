{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# change directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ching\\cv\\final\\cp-vton\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\ching\\cv\\final\\cp-vton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geometric Matching Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=4, checkpoint='', checkpoint_dir='checkpoints', data_list='train_pairs.txt', datamode='train', dataroot='data', decay_step=100000, display_count=20, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, keep_step=100000, lr=0.0001, name='gmm_train_new', radius=5, save_count=5000, shuffle=True, stage='GMM', tensorboard_dir='tensorboard', workers=4)\n",
      "Start to train stage: GMM, named: gmm_train_new!\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n",
      "step:       20, time: 0.415, loss: 0.029373\n",
      "step:       40, time: 0.455, loss: 0.018272\n",
      "step:       60, time: 0.402, loss: 0.011971\n",
      "step:       80, time: 0.418, loss: 0.018203\n",
      "step:      100, time: 0.395, loss: 0.018490\n",
      "step:      120, time: 0.403, loss: 0.020803\n",
      "step:      140, time: 0.407, loss: 0.018822\n",
      "step:      160, time: 0.430, loss: 0.021278\n",
      "step:      180, time: 0.405, loss: 0.006290\n",
      "step:      200, time: 0.405, loss: 0.019304\n",
      "step:      220, time: 0.392, loss: 0.015386\n",
      "step:      240, time: 0.406, loss: 0.015079\n",
      "step:      260, time: 0.406, loss: 0.019312\n",
      "step:      280, time: 0.417, loss: 0.020717\n",
      "step:      300, time: 0.419, loss: 0.020708\n",
      "step:      320, time: 0.399, loss: 0.010802\n",
      "step:      340, time: 0.393, loss: 0.015857\n",
      "step:      360, time: 0.394, loss: 0.012555\n",
      "step:      380, time: 0.373, loss: 0.008216\n",
      "step:      400, time: 0.416, loss: 0.019768\n",
      "step:      420, time: 0.423, loss: 0.021373\n",
      "step:      440, time: 0.418, loss: 0.017984\n",
      "step:      460, time: 0.400, loss: 0.010673\n",
      "step:      480, time: 0.401, loss: 0.008123\n",
      "step:      500, time: 0.385, loss: 0.019646\n",
      "step:      520, time: 0.387, loss: 0.011964\n",
      "step:      540, time: 0.426, loss: 0.012921\n",
      "step:      560, time: 0.410, loss: 0.021867\n",
      "step:      580, time: 0.403, loss: 0.014226\n",
      "step:      600, time: 0.389, loss: 0.018523\n",
      "step:      620, time: 0.414, loss: 0.019136\n",
      "step:      640, time: 0.390, loss: 0.007744\n",
      "step:      660, time: 0.408, loss: 0.013814\n",
      "step:      680, time: 0.412, loss: 0.134676\n",
      "step:      700, time: 0.385, loss: 0.011385\n",
      "step:      720, time: 0.420, loss: 0.016097\n",
      "step:      740, time: 0.416, loss: 0.183723\n",
      "step:      760, time: 0.411, loss: 0.022052\n",
      "step:      780, time: 0.381, loss: 0.008766\n",
      "step:      800, time: 0.404, loss: 0.012469\n",
      "step:      820, time: 0.409, loss: 0.022775\n",
      "step:      840, time: 0.400, loss: 0.013927\n",
      "step:      860, time: 0.426, loss: 0.017198\n",
      "step:      880, time: 0.410, loss: 0.012578\n",
      "step:      900, time: 0.421, loss: 0.019964\n",
      "step:      920, time: 0.427, loss: 0.021581\n",
      "step:      940, time: 0.408, loss: 0.019684\n",
      "step:      960, time: 0.384, loss: 0.007401\n",
      "step:      980, time: 0.390, loss: 0.013085\n",
      "step:     1000, time: 0.398, loss: 0.018166\n",
      "step:     1020, time: 0.408, loss: 0.012941\n",
      "step:     1040, time: 0.405, loss: 0.016614\n",
      "step:     1060, time: 0.423, loss: 0.019348\n",
      "step:     1080, time: 0.389, loss: 0.020367\n",
      "step:     1100, time: 0.411, loss: 0.013275\n",
      "step:     1120, time: 0.421, loss: 0.014762\n",
      "step:     1140, time: 0.403, loss: 0.014346\n",
      "step:     1160, time: 0.435, loss: 0.015482\n",
      "step:     1180, time: 0.411, loss: 0.009809\n",
      "step:     1200, time: 0.422, loss: 0.013804\n",
      "step:     1220, time: 0.433, loss: 0.025105\n",
      "step:     1240, time: 0.444, loss: 0.013401\n",
      "step:     1260, time: 0.414, loss: 0.017515\n",
      "step:     1280, time: 0.397, loss: 0.017433\n",
      "step:     1300, time: 0.408, loss: 0.016533\n",
      "step:     1320, time: 0.416, loss: 0.023102\n",
      "step:     1340, time: 0.425, loss: 0.019009\n",
      "step:     1360, time: 0.411, loss: 0.021266\n",
      "step:     1380, time: 0.416, loss: 0.015698\n",
      "step:     1400, time: 0.375, loss: 0.014846\n",
      "step:     1420, time: 0.461, loss: 0.134832\n",
      "step:     1440, time: 0.401, loss: 0.017758\n",
      "step:     1460, time: 0.437, loss: 0.027397\n",
      "step:     1480, time: 0.387, loss: 0.010963\n",
      "step:     1500, time: 0.419, loss: 0.008218\n",
      "step:     1520, time: 0.420, loss: 0.014112\n",
      "step:     1540, time: 0.423, loss: 0.016713\n",
      "step:     1560, time: 0.413, loss: 0.018704\n",
      "step:     1580, time: 0.413, loss: 0.013081\n",
      "step:     1600, time: 0.417, loss: 0.018105\n",
      "step:     1620, time: 0.376, loss: 0.009740\n",
      "step:     1640, time: 0.438, loss: 0.016297\n",
      "step:     1660, time: 0.397, loss: 0.008082\n",
      "step:     1680, time: 0.438, loss: 0.019291\n",
      "step:     1700, time: 0.428, loss: 0.014520\n",
      "step:     1720, time: 0.402, loss: 0.012556\n",
      "step:     1740, time: 0.396, loss: 0.012204\n",
      "step:     1760, time: 0.403, loss: 0.029766\n",
      "step:     1780, time: 0.398, loss: 0.020456\n",
      "step:     1800, time: 0.401, loss: 0.009044\n",
      "step:     1820, time: 0.401, loss: 0.011497\n",
      "step:     1840, time: 0.430, loss: 0.008353\n",
      "step:     1860, time: 0.425, loss: 0.016999\n",
      "step:     1880, time: 0.405, loss: 0.008390\n",
      "step:     1900, time: 0.389, loss: 0.014583\n",
      "step:     1920, time: 0.419, loss: 0.022255\n",
      "step:     1940, time: 0.440, loss: 0.013899\n",
      "step:     1960, time: 0.390, loss: 0.011620\n",
      "step:     1980, time: 0.384, loss: 0.021528\n",
      "step:     2000, time: 0.411, loss: 0.021349\n",
      "step:     2020, time: 0.426, loss: 0.018402\n",
      "step:     2040, time: 0.376, loss: 0.013266\n",
      "step:     2060, time: 0.396, loss: 0.017742\n",
      "step:     2080, time: 0.403, loss: 0.014978\n",
      "step:     2100, time: 0.393, loss: 0.010597\n",
      "step:     2120, time: 0.400, loss: 0.018074\n",
      "step:     2140, time: 0.436, loss: 0.018423\n",
      "step:     2160, time: 0.410, loss: 0.018535\n",
      "step:     2180, time: 0.430, loss: 0.012100\n",
      "step:     2200, time: 0.407, loss: 0.013462\n",
      "step:     2220, time: 0.414, loss: 0.010924\n",
      "step:     2240, time: 0.409, loss: 0.022840\n",
      "step:     2260, time: 0.395, loss: 0.021810\n",
      "step:     2280, time: 0.400, loss: 0.008527\n",
      "step:     2300, time: 0.394, loss: 0.012202\n",
      "step:     2320, time: 0.394, loss: 0.011573\n",
      "step:     2340, time: 0.412, loss: 0.012293\n",
      "step:     2360, time: 0.410, loss: 0.015099\n",
      "step:     2380, time: 0.411, loss: 0.032436\n",
      "step:     2400, time: 0.415, loss: 0.016291\n",
      "step:     2420, time: 0.412, loss: 0.015873\n",
      "step:     2440, time: 0.407, loss: 0.004442\n",
      "step:     2460, time: 0.405, loss: 0.017248\n",
      "step:     2480, time: 0.397, loss: 0.009520\n",
      "step:     2500, time: 0.430, loss: 0.014648\n",
      "step:     2520, time: 0.385, loss: 0.019981\n",
      "step:     2540, time: 0.398, loss: 0.016550\n",
      "step:     2560, time: 0.436, loss: 0.018643\n",
      "step:     2580, time: 0.395, loss: 0.023743\n",
      "step:     2600, time: 0.395, loss: 0.019077\n",
      "step:     2620, time: 0.409, loss: 0.022262\n",
      "step:     2640, time: 0.391, loss: 0.008780\n",
      "step:     2660, time: 0.378, loss: 0.003006\n",
      "step:     2680, time: 0.395, loss: 0.021372\n",
      "step:     2700, time: 0.388, loss: 0.027260\n",
      "step:     2720, time: 0.376, loss: 0.008019\n",
      "step:     2740, time: 0.417, loss: 0.021779\n",
      "step:     2760, time: 0.392, loss: 0.015766\n",
      "step:     2780, time: 0.423, loss: 0.023075\n",
      "step:     2800, time: 0.420, loss: 0.023651\n",
      "step:     2820, time: 0.401, loss: 0.015690\n",
      "step:     2840, time: 0.428, loss: 0.014012\n",
      "step:     2860, time: 0.409, loss: 0.021295\n",
      "step:     2880, time: 0.430, loss: 0.015119\n",
      "step:     2900, time: 0.435, loss: 0.020226\n",
      "step:     2920, time: 0.421, loss: 0.009687\n",
      "step:     2940, time: 0.432, loss: 0.021754\n",
      "step:     2960, time: 0.374, loss: 0.007695\n",
      "step:     2980, time: 0.401, loss: 0.007289\n",
      "step:     3000, time: 0.427, loss: 0.015011\n",
      "step:     3020, time: 0.413, loss: 0.012583\n",
      "step:     3040, time: 0.433, loss: 0.015060\n",
      "step:     3060, time: 0.391, loss: 0.015071\n",
      "step:     3080, time: 0.395, loss: 0.019461\n",
      "step:     3100, time: 0.414, loss: 0.008240\n",
      "step:     3120, time: 0.392, loss: 0.009096\n",
      "step:     3140, time: 0.392, loss: 0.016266\n",
      "step:     3160, time: 0.398, loss: 0.018974\n",
      "step:     3180, time: 0.401, loss: 0.009028\n",
      "step:     3200, time: 0.394, loss: 0.008581\n",
      "step:     3220, time: 0.418, loss: 0.011292\n",
      "step:     3240, time: 0.410, loss: 0.010773\n",
      "step:     3260, time: 0.372, loss: 0.012605\n",
      "step:     3280, time: 0.426, loss: 0.023809\n",
      "step:     3300, time: 0.384, loss: 0.025154\n",
      "step:     3320, time: 0.411, loss: 0.014349\n",
      "step:     3340, time: 0.398, loss: 0.013909\n",
      "step:     3360, time: 0.398, loss: 0.015050\n",
      "step:     3380, time: 0.437, loss: 0.006306\n",
      "step:     3400, time: 0.403, loss: 0.011513\n",
      "step:     3420, time: 0.384, loss: 0.016192\n",
      "step:     3440, time: 0.434, loss: 0.012080\n",
      "step:     3460, time: 0.403, loss: 0.008156\n",
      "step:     3480, time: 0.450, loss: 0.023554\n",
      "step:     3500, time: 0.402, loss: 0.010539\n",
      "step:     3520, time: 0.418, loss: 0.015903\n",
      "step:     3540, time: 0.382, loss: 0.009548\n",
      "step:     3560, time: 0.420, loss: 0.150503\n",
      "step:     3580, time: 0.401, loss: 0.014725\n",
      "step:     3600, time: 0.395, loss: 0.006314\n",
      "step:     3620, time: 0.428, loss: 0.007730\n",
      "step:     3640, time: 0.410, loss: 0.014611\n",
      "step:     3660, time: 0.389, loss: 0.018176\n",
      "step:     3680, time: 0.394, loss: 0.017454\n",
      "step:     3700, time: 0.399, loss: 0.016800\n",
      "step:     3720, time: 0.387, loss: 0.011080\n",
      "step:     3740, time: 0.397, loss: 0.017786\n",
      "step:     3760, time: 0.382, loss: 0.015294\n",
      "step:     3780, time: 0.402, loss: 0.016903\n",
      "step:     3800, time: 0.379, loss: 0.020217\n",
      "step:     3820, time: 0.395, loss: 0.011611\n",
      "step:     3840, time: 0.379, loss: 0.014810\n",
      "step:     3860, time: 0.377, loss: 0.013466\n",
      "step:     3880, time: 0.401, loss: 0.015962\n",
      "step:     3900, time: 0.385, loss: 0.031267\n",
      "step:     3920, time: 0.408, loss: 0.020591\n",
      "step:     3940, time: 0.384, loss: 0.021621\n",
      "step:     3960, time: 0.408, loss: 0.021598\n",
      "step:     3980, time: 0.406, loss: 0.013037\n",
      "step:     4000, time: 0.393, loss: 0.017697\n",
      "step:     4020, time: 0.413, loss: 0.014797\n",
      "step:     4040, time: 0.399, loss: 0.010838\n",
      "step:     4060, time: 0.383, loss: 0.021642\n",
      "step:     4080, time: 0.397, loss: 0.019976\n",
      "step:     4100, time: 0.408, loss: 0.011954\n",
      "step:     4120, time: 0.381, loss: 0.012839\n",
      "step:     4140, time: 0.400, loss: 0.013420\n",
      "step:     4160, time: 0.367, loss: 0.020627\n",
      "step:     4180, time: 0.370, loss: 0.013279\n",
      "step:     4200, time: 0.378, loss: 0.012570\n",
      "step:     4220, time: 0.379, loss: 0.004627\n",
      "step:     4240, time: 0.392, loss: 0.012942\n",
      "step:     4260, time: 0.400, loss: 0.013896\n",
      "step:     4280, time: 0.412, loss: 0.013786\n",
      "step:     4300, time: 0.378, loss: 0.010353\n",
      "step:     4320, time: 0.416, loss: 0.021559\n",
      "step:     4340, time: 0.392, loss: 0.015728\n",
      "step:     4360, time: 0.412, loss: 0.016265\n",
      "step:     4380, time: 0.410, loss: 0.017877\n",
      "step:     4400, time: 0.400, loss: 0.027981\n",
      "step:     4420, time: 0.428, loss: 0.017920\n",
      "step:     4440, time: 0.383, loss: 0.009999\n",
      "step:     4460, time: 0.417, loss: 0.017891\n",
      "step:     4480, time: 0.381, loss: 0.030341\n",
      "step:     4500, time: 0.381, loss: 0.010633\n",
      "step:     4520, time: 0.371, loss: 0.006898\n",
      "step:     4540, time: 0.404, loss: 0.008749\n",
      "step:     4560, time: 0.410, loss: 0.015666\n",
      "step:     4580, time: 0.411, loss: 0.019138\n",
      "step:     4600, time: 0.411, loss: 0.018752\n",
      "step:     4620, time: 0.396, loss: 0.161944\n",
      "step:     4640, time: 0.382, loss: 0.016535\n",
      "step:     4660, time: 0.426, loss: 0.016295\n",
      "step:     4680, time: 0.402, loss: 0.022436\n",
      "step:     4700, time: 0.393, loss: 0.013959\n",
      "step:     4720, time: 0.413, loss: 0.015141\n",
      "step:     4740, time: 0.396, loss: 0.013370\n",
      "step:     4760, time: 0.415, loss: 0.018936\n",
      "step:     4780, time: 0.382, loss: 0.015663\n",
      "step:     4800, time: 0.406, loss: 0.013223\n",
      "step:     4820, time: 0.390, loss: 0.017688\n",
      "step:     4840, time: 0.414, loss: 0.018636\n",
      "step:     4860, time: 0.383, loss: 0.018646\n",
      "step:     4880, time: 0.420, loss: 0.026139\n",
      "step:     4900, time: 0.411, loss: 0.014682\n",
      "step:     4920, time: 0.409, loss: 0.022006\n",
      "step:     4940, time: 0.411, loss: 0.015776\n",
      "step:     4960, time: 0.408, loss: 0.014566\n",
      "step:     4980, time: 0.431, loss: 0.168421\n",
      "step:     5000, time: 0.395, loss: 0.009532\n",
      "step:     5020, time: 0.391, loss: 0.018471\n",
      "step:     5040, time: 0.392, loss: 0.007166\n",
      "step:     5060, time: 0.392, loss: 0.013188\n",
      "step:     5080, time: 0.395, loss: 0.019837\n",
      "step:     5100, time: 0.392, loss: 0.007751\n",
      "step:     5120, time: 0.403, loss: 0.012955\n",
      "step:     5140, time: 0.383, loss: 0.016323\n",
      "step:     5160, time: 0.381, loss: 0.016384\n",
      "step:     5180, time: 0.397, loss: 0.018731\n",
      "step:     5200, time: 0.378, loss: 0.016271\n",
      "step:     5220, time: 0.396, loss: 0.017799\n",
      "step:     5240, time: 0.386, loss: 0.020441\n",
      "step:     5260, time: 0.381, loss: 0.017300\n",
      "step:     5280, time: 0.387, loss: 0.013264\n",
      "step:     5300, time: 0.386, loss: 0.010926\n",
      "step:     5320, time: 0.414, loss: 0.014114\n",
      "step:     5340, time: 0.409, loss: 0.017712\n",
      "step:     5360, time: 0.409, loss: 0.016404\n",
      "step:     5380, time: 0.399, loss: 0.018146\n",
      "step:     5400, time: 0.398, loss: 0.009692\n",
      "step:     5420, time: 0.390, loss: 0.009093\n",
      "step:     5440, time: 0.396, loss: 0.009175\n",
      "step:     5460, time: 0.387, loss: 0.007770\n",
      "step:     5480, time: 0.366, loss: 0.002470\n",
      "step:     5500, time: 0.418, loss: 0.020012\n",
      "step:     5520, time: 0.391, loss: 0.024251\n",
      "step:     5540, time: 0.398, loss: 0.009429\n",
      "step:     5560, time: 0.381, loss: 0.004601\n",
      "step:     5580, time: 0.407, loss: 0.011129\n",
      "step:     5600, time: 0.394, loss: 0.008708\n",
      "step:     5620, time: 0.428, loss: 0.021025\n",
      "step:     5640, time: 0.421, loss: 0.018942\n",
      "step:     5660, time: 0.388, loss: 0.015040\n",
      "step:     5680, time: 0.391, loss: 0.013775\n",
      "step:     5700, time: 0.415, loss: 0.019081\n",
      "step:     5720, time: 0.384, loss: 0.024680\n",
      "step:     5740, time: 0.373, loss: 0.013733\n",
      "step:     5760, time: 0.425, loss: 0.012149\n",
      "step:     5780, time: 0.364, loss: 0.018618\n",
      "step:     5800, time: 0.449, loss: 0.014343\n",
      "step:     5820, time: 0.361, loss: 0.009434\n",
      "step:     5840, time: 0.391, loss: 0.011591\n",
      "step:     5860, time: 0.379, loss: 0.015298\n",
      "step:     5880, time: 0.392, loss: 0.018509\n",
      "step:     5900, time: 0.394, loss: 0.022424\n",
      "step:     5920, time: 0.380, loss: 0.009020\n",
      "step:     5940, time: 0.412, loss: 0.023789\n",
      "step:     5960, time: 0.430, loss: 0.018037\n",
      "step:     5980, time: 0.450, loss: 0.023764\n",
      "step:     6000, time: 0.413, loss: 0.017253\n",
      "step:     6020, time: 0.439, loss: 0.015205\n",
      "step:     6040, time: 0.410, loss: 0.012866\n",
      "step:     6060, time: 0.417, loss: 0.013982\n",
      "step:     6080, time: 0.404, loss: 0.021357\n",
      "step:     6100, time: 0.436, loss: 0.015836\n",
      "step:     6120, time: 0.428, loss: 0.012335\n",
      "step:     6140, time: 0.445, loss: 0.021970\n",
      "step:     6160, time: 0.424, loss: 0.019806\n",
      "step:     6180, time: 0.425, loss: 0.021998\n",
      "step:     6200, time: 0.414, loss: 0.018940\n",
      "step:     6220, time: 0.409, loss: 0.009048\n",
      "step:     6240, time: 0.418, loss: 0.020179\n",
      "step:     6260, time: 0.415, loss: 0.015598\n",
      "step:     6280, time: 0.431, loss: 0.014220\n",
      "step:     6300, time: 0.452, loss: 0.019182\n",
      "step:     6320, time: 0.475, loss: 0.013661\n",
      "step:     6340, time: 0.488, loss: 0.013646\n",
      "step:     6360, time: 0.456, loss: 0.014869\n",
      "step:     6380, time: 0.435, loss: 0.013916\n",
      "step:     6400, time: 0.458, loss: 0.018470\n",
      "step:     6420, time: 0.488, loss: 0.010744\n",
      "step:     6440, time: 0.430, loss: 0.021892\n",
      "step:     6460, time: 0.503, loss: 0.013655\n",
      "step:     6480, time: 0.441, loss: 0.016042\n",
      "step:     6500, time: 0.446, loss: 0.018948\n",
      "step:     6520, time: 0.460, loss: 0.026542\n",
      "step:     6540, time: 0.420, loss: 0.013979\n",
      "step:     6560, time: 0.512, loss: 0.011759\n",
      "step:     6580, time: 0.412, loss: 0.018267\n",
      "step:     6600, time: 0.415, loss: 0.014653\n",
      "step:     6620, time: 0.416, loss: 0.008143\n",
      "step:     6640, time: 0.441, loss: 0.013405\n",
      "step:     6660, time: 0.407, loss: 0.021819\n",
      "step:     6680, time: 0.439, loss: 0.016156\n",
      "step:     6700, time: 0.399, loss: 0.022305\n",
      "step:     6720, time: 0.422, loss: 0.011775\n",
      "step:     6740, time: 0.414, loss: 0.010912\n",
      "step:     6760, time: 0.393, loss: 0.018045\n",
      "step:     6780, time: 0.413, loss: 0.013323\n",
      "step:     6800, time: 0.425, loss: 0.023010\n",
      "step:     6820, time: 0.420, loss: 0.019151\n",
      "step:     6840, time: 0.404, loss: 0.018637\n",
      "step:     6860, time: 0.441, loss: 0.020376\n",
      "step:     6880, time: 0.395, loss: 0.017280\n",
      "step:     6900, time: 0.393, loss: 0.010374\n",
      "step:     6920, time: 0.410, loss: 0.015489\n",
      "step:     6940, time: 0.414, loss: 0.021345\n",
      "step:     6960, time: 0.409, loss: 0.008886\n",
      "step:     6980, time: 0.413, loss: 0.015864\n",
      "step:     7000, time: 0.413, loss: 0.017716\n",
      "step:     7020, time: 0.407, loss: 0.019593\n",
      "step:     7040, time: 0.396, loss: 0.003525\n",
      "step:     7060, time: 0.422, loss: 0.015379\n",
      "step:     7080, time: 0.424, loss: 0.014769\n",
      "step:     7100, time: 0.424, loss: 0.022567\n",
      "step:     7120, time: 0.416, loss: 0.016038\n",
      "step:     7140, time: 0.433, loss: 0.020288\n",
      "step:     7160, time: 0.407, loss: 0.018901\n",
      "step:     7180, time: 0.395, loss: 0.010411\n",
      "step:     7200, time: 0.404, loss: 0.023071\n",
      "step:     7220, time: 0.410, loss: 0.015142\n",
      "step:     7240, time: 0.388, loss: 0.008904\n",
      "step:     7260, time: 0.419, loss: 0.011268\n",
      "step:     7280, time: 0.379, loss: 0.015461\n",
      "step:     7300, time: 0.431, loss: 0.016656\n",
      "step:     7320, time: 0.422, loss: 0.020304\n",
      "step:     7340, time: 0.404, loss: 0.020220\n",
      "step:     7360, time: 0.424, loss: 0.014265\n",
      "step:     7380, time: 0.413, loss: 0.018273\n",
      "step:     7400, time: 0.416, loss: 0.014418\n",
      "step:     7420, time: 0.379, loss: 0.019596\n",
      "step:     7440, time: 0.408, loss: 0.010033\n",
      "step:     7460, time: 0.393, loss: 0.020519\n",
      "step:     7480, time: 0.393, loss: 0.024814\n",
      "step:     7500, time: 0.453, loss: 0.022848\n",
      "step:     7520, time: 0.387, loss: 0.013802\n",
      "step:     7540, time: 0.398, loss: 0.015067\n",
      "step:     7560, time: 0.395, loss: 0.013762\n",
      "step:     7580, time: 0.416, loss: 0.018442\n",
      "step:     7600, time: 0.387, loss: 0.022415\n",
      "step:     7620, time: 0.402, loss: 0.016346\n",
      "step:     7640, time: 0.422, loss: 0.013805\n",
      "step:     7660, time: 0.390, loss: 0.019345\n",
      "step:     7680, time: 0.386, loss: 0.017822\n",
      "step:     7700, time: 0.424, loss: 0.015318\n",
      "step:     7720, time: 0.382, loss: 0.013363\n",
      "step:     7740, time: 0.405, loss: 0.011376\n",
      "step:     7760, time: 0.403, loss: 0.027960\n",
      "step:     7780, time: 0.401, loss: 0.018749\n",
      "step:     7800, time: 0.444, loss: 0.291547\n",
      "step:     7820, time: 0.390, loss: 0.010129\n",
      "step:     7840, time: 0.384, loss: 0.004146\n",
      "step:     7860, time: 0.420, loss: 0.006114\n",
      "step:     7880, time: 0.415, loss: 0.019010\n",
      "step:     7900, time: 0.372, loss: 0.005731\n",
      "step:     7920, time: 0.423, loss: 0.019144\n",
      "step:     7940, time: 0.413, loss: 0.019867\n",
      "step:     7960, time: 0.416, loss: 0.026706\n",
      "step:     7980, time: 0.436, loss: 0.013249\n",
      "step:     8000, time: 0.405, loss: 0.010010\n",
      "step:     8020, time: 0.413, loss: 0.009867\n",
      "step:     8040, time: 0.417, loss: 0.018113\n",
      "step:     8060, time: 0.391, loss: 0.020745\n",
      "step:     8080, time: 0.403, loss: 0.018947\n",
      "step:     8100, time: 0.404, loss: 0.026519\n",
      "step:     8120, time: 0.414, loss: 0.011162\n",
      "step:     8140, time: 0.442, loss: 0.195947\n",
      "step:     8160, time: 0.414, loss: 0.009729\n",
      "step:     8180, time: 0.420, loss: 0.016982\n",
      "step:     8200, time: 0.405, loss: 0.018512\n",
      "step:     8220, time: 0.421, loss: 0.016218\n",
      "step:     8240, time: 0.429, loss: 0.016645\n",
      "step:     8260, time: 0.386, loss: 0.016954\n",
      "step:     8280, time: 0.393, loss: 0.018671\n",
      "step:     8300, time: 0.403, loss: 0.024109\n",
      "step:     8320, time: 0.419, loss: 0.021038\n",
      "step:     8340, time: 0.399, loss: 0.021609\n",
      "step:     8360, time: 0.393, loss: 0.037900\n",
      "step:     8380, time: 0.429, loss: 0.020884\n",
      "step:     8400, time: 0.421, loss: 0.013916\n",
      "step:     8420, time: 0.404, loss: 0.013530\n",
      "step:     8440, time: 0.389, loss: 0.014223\n",
      "step:     8460, time: 0.417, loss: 0.018841\n",
      "step:     8480, time: 0.412, loss: 0.019728\n",
      "step:     8500, time: 0.408, loss: 0.012993\n",
      "step:     8520, time: 0.377, loss: 0.018124\n",
      "step:     8540, time: 0.390, loss: 0.014076\n",
      "step:     8560, time: 0.410, loss: 0.020471\n",
      "step:     8580, time: 0.438, loss: 0.018885\n",
      "step:     8600, time: 0.414, loss: 0.015536\n",
      "step:     8620, time: 0.396, loss: 0.018425\n",
      "step:     8640, time: 0.394, loss: 0.011305\n",
      "step:     8660, time: 0.406, loss: 0.004501\n",
      "step:     8680, time: 0.372, loss: 0.013014\n",
      "step:     8700, time: 0.413, loss: 0.015853\n",
      "step:     8720, time: 0.385, loss: 0.015725\n",
      "step:     8740, time: 0.386, loss: 0.014481\n",
      "step:     8760, time: 0.398, loss: 0.014958\n",
      "step:     8780, time: 0.372, loss: 0.014659\n",
      "step:     8800, time: 0.396, loss: 0.012398\n",
      "step:     8820, time: 0.430, loss: 0.025225\n",
      "step:     8840, time: 0.396, loss: 0.008294\n",
      "step:     8860, time: 0.397, loss: 0.013611\n",
      "step:     8880, time: 0.404, loss: 0.022892\n",
      "step:     8900, time: 0.398, loss: 0.025688\n",
      "step:     8920, time: 0.390, loss: 0.007441\n",
      "step:     8940, time: 0.448, loss: 0.250229\n",
      "step:     8960, time: 0.420, loss: 0.026351\n",
      "step:     8980, time: 0.396, loss: 0.018595\n",
      "step:     9000, time: 0.397, loss: 0.011982\n",
      "step:     9020, time: 0.424, loss: 0.020849\n",
      "step:     9040, time: 0.406, loss: 0.016598\n",
      "step:     9060, time: 0.412, loss: 0.014650\n",
      "step:     9080, time: 0.382, loss: 0.014478\n",
      "step:     9100, time: 0.389, loss: 0.011357\n",
      "step:     9120, time: 0.401, loss: 0.020811\n",
      "step:     9140, time: 0.389, loss: 0.009673\n",
      "step:     9160, time: 0.398, loss: 0.011729\n",
      "step:     9180, time: 0.399, loss: 0.019883\n",
      "step:     9200, time: 0.397, loss: 0.016659\n",
      "step:     9220, time: 0.401, loss: 0.015501\n",
      "step:     9240, time: 0.374, loss: 0.009350\n",
      "step:     9260, time: 0.404, loss: 0.015009\n",
      "step:     9280, time: 0.436, loss: 0.025451\n",
      "step:     9300, time: 0.413, loss: 0.007467\n",
      "step:     9320, time: 0.398, loss: 0.010197\n",
      "step:     9340, time: 0.415, loss: 0.019178\n",
      "step:     9360, time: 0.391, loss: 0.008092\n",
      "step:     9380, time: 0.421, loss: 0.051039\n",
      "step:     9400, time: 0.397, loss: 0.019820\n",
      "step:     9420, time: 0.419, loss: 0.010406\n",
      "step:     9440, time: 0.429, loss: 0.016298\n",
      "step:     9460, time: 0.386, loss: 0.017022\n",
      "step:     9480, time: 0.393, loss: 0.016523\n",
      "step:     9500, time: 0.439, loss: 0.018316\n",
      "step:     9520, time: 0.412, loss: 0.018098\n",
      "step:     9540, time: 0.395, loss: 0.020109\n",
      "step:     9560, time: 0.431, loss: 0.022664\n",
      "step:     9580, time: 0.423, loss: 0.194801\n",
      "step:     9600, time: 0.415, loss: 0.018365\n",
      "step:     9620, time: 0.390, loss: 0.024656\n",
      "step:     9640, time: 0.411, loss: 0.011756\n",
      "step:     9660, time: 0.401, loss: 0.025355\n",
      "step:     9680, time: 0.417, loss: 0.016435\n",
      "step:     9700, time: 0.423, loss: 0.014919\n",
      "step:     9720, time: 0.385, loss: 0.015296\n",
      "step:     9740, time: 0.425, loss: 0.024605\n",
      "step:     9760, time: 0.407, loss: 0.020660\n",
      "step:     9780, time: 0.398, loss: 0.013389\n",
      "step:     9800, time: 0.436, loss: 0.013539\n",
      "step:     9820, time: 0.387, loss: 0.002698\n",
      "step:     9840, time: 0.391, loss: 0.016019\n",
      "step:     9860, time: 0.381, loss: 0.019642\n",
      "step:     9880, time: 0.414, loss: 0.021660\n",
      "step:     9900, time: 0.389, loss: 0.020833\n",
      "step:     9920, time: 0.381, loss: 0.009939\n",
      "step:     9940, time: 0.418, loss: 0.014869\n",
      "step:     9960, time: 0.407, loss: 0.011901"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:924] Warning: Mixed memory format inputs detected while calling the operator. The operator will output channels_last tensor even if some of the inputs are not in channels_last format. (function operator ())\n",
      "[W ..\\aten\\src\\ATen\\native\\TensorIterator.cpp:918] Warning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (function operator ())\n",
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:     9980, time: 0.415, loss: 0.012220\n",
      "step:    10000, time: 0.372, loss: 0.013965\n",
      "step:    10020, time: 0.382, loss: 0.010465\n",
      "step:    10040, time: 0.411, loss: 0.011920\n",
      "step:    10060, time: 0.397, loss: 0.009577\n",
      "step:    10080, time: 0.381, loss: 0.012878\n",
      "step:    10100, time: 0.412, loss: 0.018972\n",
      "step:    10120, time: 0.368, loss: 0.008423\n",
      "step:    10140, time: 0.390, loss: 0.017761\n",
      "step:    10160, time: 0.416, loss: 0.022266\n",
      "step:    10180, time: 0.392, loss: 0.011681\n",
      "step:    10200, time: 0.415, loss: 0.013273\n",
      "step:    10220, time: 0.414, loss: 0.011657\n",
      "step:    10240, time: 0.437, loss: 0.018013\n",
      "step:    10260, time: 0.406, loss: 0.009518\n",
      "step:    10280, time: 0.436, loss: 0.233083\n",
      "step:    10300, time: 0.392, loss: 0.012513\n",
      "step:    10320, time: 0.399, loss: 0.018801\n",
      "step:    10340, time: 0.420, loss: 0.012478\n",
      "step:    10360, time: 0.406, loss: 0.018973\n",
      "step:    10380, time: 0.406, loss: 0.015742\n",
      "step:    10400, time: 0.412, loss: 0.019450\n",
      "step:    10420, time: 0.400, loss: 0.015949\n",
      "step:    10440, time: 0.435, loss: 0.015862\n",
      "step:    10460, time: 0.391, loss: 0.021823\n",
      "step:    10480, time: 0.403, loss: 0.013728\n",
      "step:    10500, time: 0.393, loss: 0.018067\n",
      "step:    10520, time: 0.382, loss: 0.020048\n",
      "step:    10540, time: 0.386, loss: 0.016312\n",
      "step:    10560, time: 0.410, loss: 0.013553\n",
      "step:    10580, time: 0.411, loss: 0.015416\n",
      "step:    10600, time: 0.391, loss: 0.009903\n",
      "step:    10620, time: 0.442, loss: 0.014436\n",
      "step:    10640, time: 0.381, loss: 0.021014\n",
      "step:    10660, time: 0.410, loss: 0.018630\n",
      "step:    10680, time: 0.383, loss: 0.019327\n",
      "step:    10700, time: 0.374, loss: 0.014641\n",
      "step:    10720, time: 0.412, loss: 0.019315\n",
      "step:    10740, time: 0.371, loss: 0.018412\n",
      "step:    10760, time: 0.397, loss: 0.028146\n",
      "step:    10780, time: 0.384, loss: 0.022375\n",
      "step:    10800, time: 0.403, loss: 0.012962\n",
      "step:    10820, time: 0.384, loss: 0.021053\n",
      "step:    10840, time: 0.370, loss: 0.018129\n",
      "step:    10860, time: 0.387, loss: 0.017186\n",
      "step:    10880, time: 0.406, loss: 0.007822\n",
      "step:    10900, time: 0.389, loss: 0.010108\n",
      "step:    10920, time: 0.389, loss: 0.016004\n",
      "step:    10940, time: 0.389, loss: 0.017770\n",
      "step:    10960, time: 0.375, loss: 0.009995\n",
      "step:    10980, time: 0.409, loss: 0.017785\n",
      "step:    11000, time: 0.419, loss: 0.023645\n",
      "step:    11020, time: 0.396, loss: 0.024691\n",
      "step:    11040, time: 0.400, loss: 0.019936\n",
      "step:    11060, time: 0.400, loss: 0.016216\n",
      "step:    11080, time: 0.402, loss: 0.008923\n",
      "step:    11100, time: 0.394, loss: 0.007041\n",
      "step:    11120, time: 0.393, loss: 0.012299\n",
      "step:    11140, time: 0.408, loss: 0.006504\n",
      "step:    11160, time: 0.357, loss: 0.020141\n",
      "step:    11180, time: 0.392, loss: 0.016856\n",
      "step:    11200, time: 0.383, loss: 0.009769\n",
      "step:    11220, time: 0.417, loss: 0.019027\n",
      "step:    11240, time: 0.389, loss: 0.020419\n",
      "step:    11260, time: 0.392, loss: 0.025226\n",
      "step:    11280, time: 0.406, loss: 0.009919\n",
      "step:    11300, time: 0.374, loss: 0.013672\n",
      "step:    11320, time: 0.368, loss: 0.011908\n",
      "step:    11340, time: 0.390, loss: 0.012366\n",
      "step:    11360, time: 0.409, loss: 0.017217\n",
      "step:    11380, time: 0.358, loss: 0.015804\n",
      "step:    11400, time: 0.396, loss: 0.024241\n",
      "step:    11420, time: 0.408, loss: 0.010473\n",
      "step:    11440, time: 0.405, loss: 0.018652\n",
      "step:    11460, time: 0.399, loss: 0.012836\n",
      "step:    11480, time: 0.395, loss: 0.031441\n",
      "step:    11500, time: 0.389, loss: 0.018301\n",
      "step:    11520, time: 0.400, loss: 0.175340\n",
      "step:    11540, time: 0.407, loss: 0.009454\n",
      "step:    11560, time: 0.430, loss: 0.019292\n",
      "step:    11580, time: 0.383, loss: 0.020845\n",
      "step:    11600, time: 0.373, loss: 0.016532\n",
      "step:    11620, time: 0.401, loss: 0.019377\n",
      "step:    11640, time: 0.361, loss: 0.013344\n",
      "step:    11660, time: 0.379, loss: 0.013238\n",
      "step:    11680, time: 0.410, loss: 0.008543\n",
      "step:    11700, time: 0.420, loss: 0.019402\n",
      "step:    11720, time: 0.440, loss: 0.022793\n",
      "step:    11740, time: 0.401, loss: 0.015372\n",
      "step:    11760, time: 0.444, loss: 0.016040\n",
      "step:    11780, time: 0.396, loss: 0.010864\n",
      "step:    11800, time: 0.400, loss: 0.010744\n",
      "step:    11820, time: 0.386, loss: 0.018945\n",
      "step:    11840, time: 0.403, loss: 0.017457\n",
      "step:    11860, time: 0.403, loss: 0.028076\n",
      "step:    11880, time: 0.397, loss: 0.006660\n",
      "step:    11900, time: 0.405, loss: 0.014536\n",
      "step:    11920, time: 0.391, loss: 0.011527\n",
      "step:    11940, time: 0.377, loss: 0.011124\n",
      "step:    11960, time: 0.397, loss: 0.016923\n",
      "step:    11980, time: 0.394, loss: 0.016103\n",
      "step:    12000, time: 0.417, loss: 0.018433\n",
      "step:    12020, time: 0.402, loss: 0.018420\n",
      "step:    12040, time: 0.412, loss: 0.016392\n",
      "step:    12060, time: 0.389, loss: 0.008462\n",
      "step:    12080, time: 0.376, loss: 0.015955\n",
      "step:    12100, time: 0.408, loss: 0.007194\n",
      "step:    12120, time: 0.405, loss: 0.011982\n",
      "step:    12140, time: 0.404, loss: 0.020467\n",
      "step:    12160, time: 0.398, loss: 0.025096\n",
      "step:    12180, time: 0.399, loss: 0.014517\n",
      "step:    12200, time: 0.422, loss: 0.015975\n",
      "step:    12220, time: 0.401, loss: 0.017020\n",
      "step:    12240, time: 0.388, loss: 0.013081\n",
      "step:    12260, time: 0.381, loss: 0.021260\n",
      "step:    12280, time: 0.381, loss: 0.014705\n",
      "step:    12300, time: 0.397, loss: 0.017171\n",
      "step:    12320, time: 0.384, loss: 0.013449\n",
      "step:    12340, time: 0.377, loss: 0.011864\n",
      "step:    12360, time: 0.392, loss: 0.018070\n",
      "step:    12380, time: 0.427, loss: 0.018605\n",
      "step:    12400, time: 0.404, loss: 0.013738\n",
      "step:    12420, time: 0.399, loss: 0.017053\n",
      "step:    12440, time: 0.400, loss: 0.011977\n",
      "step:    12460, time: 0.429, loss: 0.213824\n",
      "step:    12480, time: 0.394, loss: 0.012439\n",
      "step:    12500, time: 0.388, loss: 0.020422\n",
      "step:    12520, time: 0.351, loss: 0.008466\n",
      "step:    12540, time: 0.400, loss: 0.013258\n",
      "step:    12560, time: 0.401, loss: 0.025526\n",
      "step:    12580, time: 0.408, loss: 0.017971\n",
      "step:    12600, time: 0.396, loss: 0.017844\n",
      "step:    12620, time: 0.403, loss: 0.019322\n",
      "step:    12640, time: 0.375, loss: 0.003444\n",
      "step:    12660, time: 0.419, loss: 0.247797\n",
      "step:    12680, time: 0.376, loss: 0.009630\n",
      "step:    12700, time: 0.382, loss: 0.018338\n",
      "step:    12720, time: 0.410, loss: 0.037479\n",
      "step:    12740, time: 0.369, loss: 0.012336\n",
      "step:    12760, time: 0.403, loss: 0.008681\n",
      "step:    12780, time: 0.413, loss: 0.014798\n",
      "step:    12800, time: 0.382, loss: 0.007614\n",
      "step:    12820, time: 0.399, loss: 0.016591\n",
      "step:    12840, time: 0.414, loss: 0.012986\n",
      "step:    12860, time: 0.375, loss: 0.018350\n",
      "step:    12880, time: 0.381, loss: 0.008713\n",
      "step:    12900, time: 0.405, loss: 0.019193\n",
      "step:    12920, time: 0.431, loss: 0.016102\n",
      "step:    12940, time: 0.402, loss: 0.010780\n",
      "step:    12960, time: 0.411, loss: 0.016004\n",
      "step:    12980, time: 0.392, loss: 0.012295\n",
      "step:    13000, time: 0.406, loss: 0.015743\n",
      "step:    13020, time: 0.454, loss: 0.015184\n",
      "step:    13040, time: 0.389, loss: 0.011992\n",
      "step:    13060, time: 0.385, loss: 0.026856\n",
      "step:    13080, time: 0.407, loss: 0.020970\n",
      "step:    13100, time: 0.408, loss: 0.037542\n",
      "step:    13120, time: 0.418, loss: 0.012414\n",
      "step:    13140, time: 0.394, loss: 0.011655\n",
      "step:    13160, time: 0.407, loss: 0.016962\n",
      "step:    13180, time: 0.377, loss: 0.007587\n",
      "step:    13200, time: 0.374, loss: 0.027062\n",
      "step:    13220, time: 0.423, loss: 0.012629\n",
      "step:    13240, time: 0.405, loss: 0.018542\n",
      "step:    13260, time: 0.395, loss: 0.028099\n",
      "step:    13280, time: 0.388, loss: 0.006017\n",
      "step:    13300, time: 0.381, loss: 0.020584\n",
      "step:    13320, time: 0.435, loss: 0.020787\n",
      "step:    13340, time: 0.409, loss: 0.011341\n",
      "step:    13360, time: 0.382, loss: 0.006591\n",
      "step:    13380, time: 0.384, loss: 0.018366\n",
      "step:    13400, time: 0.382, loss: 0.011143\n",
      "step:    13420, time: 0.381, loss: 0.009014\n",
      "step:    13440, time: 0.413, loss: 0.019141\n",
      "step:    13460, time: 0.442, loss: 0.013326\n",
      "step:    13480, time: 0.441, loss: 0.242882\n",
      "step:    13500, time: 0.406, loss: 0.014474\n",
      "step:    13520, time: 0.402, loss: 0.016865\n",
      "step:    13540, time: 0.420, loss: 0.169693\n",
      "step:    13560, time: 0.400, loss: 0.015394\n",
      "step:    13580, time: 0.395, loss: 0.009906\n",
      "step:    13600, time: 0.397, loss: 0.018560\n",
      "step:    13620, time: 0.404, loss: 0.017965\n",
      "step:    13640, time: 0.385, loss: 0.014258\n",
      "step:    13660, time: 0.432, loss: 0.016004\n",
      "step:    13680, time: 0.426, loss: 0.013474\n",
      "step:    13700, time: 0.396, loss: 0.005444\n",
      "step:    13720, time: 0.373, loss: 0.018812\n",
      "step:    13740, time: 0.420, loss: 0.017649\n",
      "step:    13760, time: 0.386, loss: 0.004558\n",
      "step:    13780, time: 0.392, loss: 0.015789\n",
      "step:    13800, time: 0.391, loss: 0.011267\n",
      "step:    13820, time: 0.383, loss: 0.018436\n",
      "step:    13840, time: 0.383, loss: 0.009743\n",
      "step:    13860, time: 0.379, loss: 0.010755\n",
      "step:    13880, time: 0.391, loss: 0.021675\n",
      "step:    13900, time: 0.402, loss: 0.018986\n",
      "step:    13920, time: 0.379, loss: 0.026212\n",
      "step:    13940, time: 0.382, loss: 0.020301\n",
      "step:    13960, time: 0.411, loss: 0.013074\n",
      "step:    13980, time: 0.406, loss: 0.013060\n",
      "step:    14000, time: 0.386, loss: 0.006975\n",
      "step:    14020, time: 0.361, loss: 0.018147\n",
      "step:    14040, time: 0.420, loss: 0.009321\n",
      "step:    14060, time: 0.405, loss: 0.022503\n",
      "step:    14080, time: 0.405, loss: 0.020024\n",
      "step:    14100, time: 0.387, loss: 0.005835\n",
      "step:    14120, time: 0.422, loss: 0.016360\n",
      "step:    14140, time: 0.391, loss: 0.017380\n",
      "step:    14160, time: 0.391, loss: 0.018056\n",
      "step:    14180, time: 0.379, loss: 0.009873\n",
      "step:    14200, time: 0.398, loss: 0.022358\n",
      "step:    14220, time: 0.400, loss: 0.022826\n",
      "step:    14240, time: 0.388, loss: 0.018263\n",
      "step:    14260, time: 0.411, loss: 0.020768\n",
      "step:    14280, time: 0.392, loss: 0.008725\n",
      "step:    14300, time: 0.420, loss: 0.019859\n",
      "step:    14320, time: 0.422, loss: 0.014357\n",
      "step:    14340, time: 0.409, loss: 0.015180\n",
      "step:    14360, time: 0.385, loss: 0.015614\n",
      "step:    14380, time: 0.382, loss: 0.015303\n",
      "step:    14400, time: 0.399, loss: 0.005359\n",
      "step:    14420, time: 0.416, loss: 0.017916\n",
      "step:    14440, time: 0.379, loss: 0.014400\n",
      "step:    14460, time: 0.402, loss: 0.011470\n",
      "step:    14480, time: 0.370, loss: 0.010339\n",
      "step:    14500, time: 0.397, loss: 0.013602\n",
      "step:    14520, time: 0.420, loss: 0.013288\n",
      "step:    14540, time: 0.392, loss: 0.017500\n",
      "step:    14560, time: 0.411, loss: 0.012228\n",
      "step:    14580, time: 0.419, loss: 0.017765\n",
      "step:    14600, time: 0.403, loss: 0.016078\n",
      "step:    14620, time: 0.445, loss: 0.010782\n",
      "step:    14640, time: 0.404, loss: 0.006224\n",
      "step:    14660, time: 0.431, loss: 0.023981\n",
      "step:    14680, time: 0.398, loss: 0.018500\n",
      "step:    14700, time: 0.395, loss: 0.018377\n",
      "step:    14720, time: 0.427, loss: 0.018781\n",
      "step:    14740, time: 0.396, loss: 0.006597\n",
      "step:    14760, time: 0.394, loss: 0.022989\n",
      "step:    14780, time: 0.398, loss: 0.008541\n",
      "step:    14800, time: 0.391, loss: 0.020608\n",
      "step:    14820, time: 0.381, loss: 0.016157\n",
      "step:    14840, time: 0.409, loss: 0.191320\n",
      "step:    14860, time: 0.388, loss: 0.013213\n",
      "step:    14880, time: 0.401, loss: 0.007532\n",
      "step:    14900, time: 0.421, loss: 0.013510\n",
      "step:    14920, time: 0.387, loss: 0.027869\n",
      "step:    14940, time: 0.387, loss: 0.008305\n",
      "step:    14960, time: 0.417, loss: 0.014986\n",
      "step:    14980, time: 0.434, loss: 0.023201\n",
      "step:    15000, time: 0.404, loss: 0.017731\n",
      "step:    15020, time: 0.387, loss: 0.010634\n",
      "step:    15040, time: 0.400, loss: 0.023369\n",
      "step:    15060, time: 0.371, loss: 0.015739\n",
      "step:    15080, time: 0.427, loss: 0.116520\n",
      "step:    15100, time: 0.389, loss: 0.009699\n",
      "step:    15120, time: 0.411, loss: 0.009454\n",
      "step:    15140, time: 0.398, loss: 0.007552\n",
      "step:    15160, time: 0.406, loss: 0.017024\n",
      "step:    15180, time: 0.378, loss: 0.013178\n",
      "step:    15200, time: 0.402, loss: 0.015393\n",
      "step:    15220, time: 0.395, loss: 0.017322\n",
      "step:    15240, time: 0.410, loss: 0.015010\n",
      "step:    15260, time: 0.416, loss: 0.017368\n",
      "step:    15280, time: 0.408, loss: 0.015837\n",
      "step:    15300, time: 0.373, loss: 0.020107\n",
      "step:    15320, time: 0.401, loss: 0.012731\n",
      "step:    15340, time: 0.418, loss: 0.020716\n",
      "step:    15360, time: 0.393, loss: 0.018047\n",
      "step:    15380, time: 0.382, loss: 0.014747\n",
      "step:    15400, time: 0.419, loss: 0.012441\n",
      "step:    15420, time: 0.394, loss: 0.008583\n",
      "step:    15440, time: 0.379, loss: 0.013391\n",
      "step:    15460, time: 0.398, loss: 0.002747\n",
      "step:    15480, time: 0.396, loss: 0.014902\n",
      "step:    15500, time: 0.404, loss: 0.027841\n",
      "step:    15520, time: 0.448, loss: 0.016306\n",
      "step:    15540, time: 0.391, loss: 0.019268\n",
      "step:    15560, time: 0.415, loss: 0.018442\n",
      "step:    15580, time: 0.396, loss: 0.014914\n",
      "step:    15600, time: 0.392, loss: 0.016395\n",
      "step:    15620, time: 0.383, loss: 0.024025\n",
      "step:    15640, time: 0.424, loss: 0.010328\n",
      "step:    15660, time: 0.421, loss: 0.011316\n",
      "step:    15680, time: 0.431, loss: 0.015970\n",
      "step:    15700, time: 0.397, loss: 0.018668\n",
      "step:    15720, time: 0.422, loss: 0.012889\n",
      "step:    15740, time: 0.420, loss: 0.013044\n",
      "step:    15760, time: 0.394, loss: 0.013963\n",
      "step:    15780, time: 0.399, loss: 0.007927\n",
      "step:    15800, time: 0.401, loss: 0.016791\n",
      "step:    15820, time: 0.432, loss: 0.014988\n",
      "step:    15840, time: 0.368, loss: 0.018238\n",
      "step:    15860, time: 0.388, loss: 0.019097\n",
      "step:    15880, time: 0.406, loss: 0.013453\n",
      "step:    15900, time: 0.370, loss: 0.022765\n",
      "step:    15920, time: 0.383, loss: 0.013186\n",
      "step:    15940, time: 0.425, loss: 0.016988\n",
      "step:    15960, time: 0.383, loss: 0.008575\n",
      "step:    15980, time: 0.402, loss: 0.016667\n",
      "step:    16000, time: 0.427, loss: 0.017622\n",
      "step:    16020, time: 0.401, loss: 0.016641\n",
      "step:    16040, time: 0.382, loss: 0.015636\n",
      "step:    16060, time: 0.417, loss: 0.016992\n",
      "step:    16080, time: 0.417, loss: 0.012169\n",
      "step:    16100, time: 0.367, loss: 0.004122\n",
      "step:    16120, time: 0.404, loss: 0.018702\n",
      "step:    16140, time: 0.375, loss: 0.013058\n",
      "step:    16160, time: 0.380, loss: 0.022272\n",
      "step:    16180, time: 0.398, loss: 0.019315\n",
      "step:    16200, time: 0.389, loss: 0.018047\n",
      "step:    16220, time: 0.402, loss: 0.010543\n",
      "step:    16240, time: 0.410, loss: 0.021903\n",
      "step:    16260, time: 0.409, loss: 0.013321\n",
      "step:    16280, time: 0.422, loss: 0.022177\n",
      "step:    16300, time: 0.397, loss: 0.006423\n",
      "step:    16320, time: 0.396, loss: 0.018747\n",
      "step:    16340, time: 0.383, loss: 0.017491\n",
      "step:    16360, time: 0.401, loss: 0.021749\n",
      "step:    16380, time: 0.405, loss: 0.018761\n",
      "step:    16400, time: 0.405, loss: 0.019707\n",
      "step:    16420, time: 0.380, loss: 0.017596\n",
      "step:    16440, time: 0.376, loss: 0.015825\n",
      "step:    16460, time: 0.376, loss: 0.012676\n",
      "step:    16480, time: 0.413, loss: 0.006582\n",
      "step:    16500, time: 0.377, loss: 0.017711\n",
      "step:    16520, time: 0.438, loss: 0.016257\n",
      "step:    16540, time: 0.409, loss: 0.007560\n",
      "step:    16560, time: 0.450, loss: 0.019754\n",
      "step:    16580, time: 0.411, loss: 0.022995\n",
      "step:    16600, time: 0.381, loss: 0.009470\n",
      "step:    16620, time: 0.387, loss: 0.015675\n",
      "step:    16640, time: 0.396, loss: 0.010408\n",
      "step:    16660, time: 0.427, loss: 0.018790\n",
      "step:    16680, time: 0.382, loss: 0.013938\n",
      "step:    16700, time: 0.401, loss: 0.023238\n",
      "step:    16720, time: 0.393, loss: 0.019367\n",
      "step:    16740, time: 0.389, loss: 0.019976\n",
      "step:    16760, time: 0.382, loss: 0.002569\n",
      "step:    16780, time: 0.371, loss: 0.007735\n",
      "step:    16800, time: 0.407, loss: 0.017180\n",
      "step:    16820, time: 0.378, loss: 0.013163\n",
      "step:    16840, time: 0.389, loss: 0.014214\n",
      "step:    16860, time: 0.380, loss: 0.012750\n",
      "step:    16880, time: 0.415, loss: 0.016588\n",
      "step:    16900, time: 0.410, loss: 0.013971\n",
      "step:    16920, time: 0.393, loss: 0.012486\n",
      "step:    16940, time: 0.425, loss: 0.019619\n",
      "step:    16960, time: 0.403, loss: 0.016080\n",
      "step:    16980, time: 0.412, loss: 0.008343\n",
      "step:    17000, time: 0.397, loss: 0.011288\n",
      "step:    17020, time: 0.369, loss: 0.018918\n",
      "step:    17040, time: 0.397, loss: 0.017543\n",
      "step:    17060, time: 0.398, loss: 0.010140\n",
      "step:    17080, time: 0.382, loss: 0.014055\n",
      "step:    17100, time: 0.412, loss: 0.012716\n",
      "step:    17120, time: 0.450, loss: 0.134596\n",
      "step:    17140, time: 0.389, loss: 0.014428\n",
      "step:    17160, time: 0.394, loss: 0.014933\n",
      "step:    17180, time: 0.401, loss: 0.016584\n",
      "step:    17200, time: 0.390, loss: 0.012269\n",
      "step:    17220, time: 0.378, loss: 0.015743\n",
      "step:    17240, time: 0.417, loss: 0.017691\n",
      "step:    17260, time: 0.378, loss: 0.018233\n",
      "step:    17280, time: 0.389, loss: 0.013614\n",
      "step:    17300, time: 0.439, loss: 0.014577\n",
      "step:    17320, time: 0.372, loss: 0.018378\n",
      "step:    17340, time: 0.388, loss: 0.008091\n",
      "step:    17360, time: 0.409, loss: 0.018044\n",
      "step:    17380, time: 0.386, loss: 0.020340\n",
      "step:    17400, time: 0.407, loss: 0.020733\n",
      "step:    17420, time: 0.401, loss: 0.016994\n",
      "step:    17440, time: 0.387, loss: 0.024775\n",
      "step:    17460, time: 0.401, loss: 0.006474\n",
      "step:    17480, time: 0.434, loss: 0.021502\n",
      "step:    17500, time: 0.404, loss: 0.005773\n",
      "step:    17520, time: 0.409, loss: 0.005613\n",
      "step:    17540, time: 0.387, loss: 0.007366\n",
      "step:    17560, time: 0.409, loss: 0.013410\n",
      "step:    17580, time: 0.383, loss: 0.010904\n",
      "step:    17600, time: 0.409, loss: 0.014262\n",
      "step:    17620, time: 0.430, loss: 0.022628\n",
      "step:    17640, time: 0.372, loss: 0.020491\n",
      "step:    17660, time: 0.387, loss: 0.014039\n",
      "step:    17680, time: 0.404, loss: 0.011146\n",
      "step:    17700, time: 0.406, loss: 0.011749\n",
      "step:    17720, time: 0.400, loss: 0.013158\n",
      "step:    17740, time: 0.409, loss: 0.022672\n",
      "step:    17760, time: 0.394, loss: 0.013957\n",
      "step:    17780, time: 0.116, loss: 0.022623\n",
      "step:    17800, time: 0.398, loss: 0.018004\n",
      "step:    17820, time: 0.400, loss: 0.020069\n",
      "step:    17840, time: 0.402, loss: 0.010409\n",
      "step:    17860, time: 0.398, loss: 0.014616\n",
      "step:    17880, time: 0.390, loss: 0.017812\n",
      "step:    17900, time: 0.413, loss: 0.016425\n",
      "step:    17920, time: 0.404, loss: 0.018305\n",
      "step:    17940, time: 0.383, loss: 0.016816\n",
      "step:    17960, time: 0.418, loss: 0.019475\n",
      "step:    17980, time: 0.405, loss: 0.009591\n",
      "step:    18000, time: 0.365, loss: 0.014788\n",
      "step:    18020, time: 0.420, loss: 0.018947\n",
      "step:    18040, time: 0.400, loss: 0.020677\n",
      "step:    18060, time: 0.396, loss: 0.011025\n",
      "step:    18080, time: 0.411, loss: 0.014662\n",
      "step:    18100, time: 0.398, loss: 0.007183\n",
      "step:    18120, time: 0.396, loss: 0.016012\n",
      "step:    18140, time: 0.421, loss: 0.014612\n",
      "step:    18160, time: 0.415, loss: 0.019785\n",
      "step:    18180, time: 0.405, loss: 0.009696\n",
      "step:    18200, time: 0.404, loss: 0.165843\n",
      "step:    18220, time: 0.419, loss: 0.010612\n",
      "step:    18240, time: 0.385, loss: 0.008371\n",
      "step:    18260, time: 0.384, loss: 0.015842\n",
      "step:    18280, time: 0.395, loss: 0.017527\n",
      "step:    18300, time: 0.406, loss: 0.010934\n",
      "step:    18320, time: 0.383, loss: 0.011643\n",
      "step:    18340, time: 0.407, loss: 0.023623\n",
      "step:    18360, time: 0.371, loss: 0.020626\n",
      "step:    18380, time: 0.404, loss: 0.018881\n",
      "step:    18400, time: 0.389, loss: 0.013471\n",
      "step:    18420, time: 0.375, loss: 0.016487\n",
      "step:    18440, time: 0.385, loss: 0.020702\n",
      "step:    18460, time: 0.365, loss: 0.018327\n",
      "step:    18480, time: 0.400, loss: 0.024233\n",
      "step:    18500, time: 0.415, loss: 0.020584\n",
      "step:    18520, time: 0.408, loss: 0.026472\n",
      "step:    18540, time: 0.413, loss: 0.021511\n",
      "step:    18560, time: 0.383, loss: 0.017497\n",
      "step:    18580, time: 0.376, loss: 0.015992\n",
      "step:    18600, time: 0.389, loss: 0.009915\n",
      "step:    18620, time: 0.381, loss: 0.014129\n",
      "step:    18640, time: 0.377, loss: 0.021749\n",
      "step:    18660, time: 0.376, loss: 0.016771\n",
      "step:    18680, time: 0.400, loss: 0.016082\n",
      "step:    18700, time: 0.406, loss: 0.012038\n",
      "step:    18720, time: 0.389, loss: 0.005527\n",
      "step:    18740, time: 0.396, loss: 0.019940\n",
      "step:    18760, time: 0.388, loss: 0.016863\n",
      "step:    18780, time: 0.401, loss: 0.021342\n",
      "step:    18800, time: 0.386, loss: 0.024194\n",
      "step:    18820, time: 0.413, loss: 0.018348\n",
      "step:    18840, time: 0.420, loss: 0.013781\n",
      "step:    18860, time: 0.392, loss: 0.186861\n",
      "step:    18880, time: 0.414, loss: 0.016213\n",
      "step:    18900, time: 0.376, loss: 0.011836\n",
      "step:    18920, time: 0.407, loss: 0.015524\n",
      "step:    18940, time: 0.415, loss: 0.010119\n",
      "step:    18960, time: 0.409, loss: 0.021765\n",
      "step:    18980, time: 0.412, loss: 0.018349\n",
      "step:    19000, time: 0.415, loss: 0.009859\n",
      "step:    19020, time: 0.410, loss: 0.015279\n",
      "step:    19040, time: 0.399, loss: 0.019761\n",
      "step:    19060, time: 0.389, loss: 0.023500\n",
      "step:    19080, time: 0.405, loss: 0.022106\n",
      "step:    19100, time: 0.401, loss: 0.015027\n",
      "step:    19120, time: 0.408, loss: 0.014592\n",
      "step:    19140, time: 0.381, loss: 0.023750\n",
      "step:    19160, time: 0.391, loss: 0.018566\n",
      "step:    19180, time: 0.366, loss: 0.008118\n",
      "step:    19200, time: 0.419, loss: 0.014893\n",
      "step:    19220, time: 0.383, loss: 0.006861\n",
      "step:    19240, time: 0.408, loss: 0.018050\n",
      "step:    19260, time: 0.413, loss: 0.018772\n",
      "step:    19280, time: 0.387, loss: 0.010679\n",
      "step:    19300, time: 0.389, loss: 0.015533\n",
      "step:    19320, time: 0.381, loss: 0.041488\n",
      "step:    19340, time: 0.369, loss: 0.007408\n",
      "step:    19360, time: 0.384, loss: 0.011746\n",
      "step:    19380, time: 0.424, loss: 0.013342\n",
      "step:    19400, time: 0.419, loss: 0.013423\n",
      "step:    19420, time: 0.380, loss: 0.022467\n",
      "step:    19440, time: 0.400, loss: 0.013328\n",
      "step:    19460, time: 0.398, loss: 0.015445\n",
      "step:    19480, time: 0.412, loss: 0.019457\n",
      "step:    19500, time: 0.411, loss: 0.024340\n",
      "step:    19520, time: 0.407, loss: 0.010679\n",
      "step:    19540, time: 0.386, loss: 0.014428\n",
      "step:    19560, time: 0.383, loss: 0.019217\n",
      "step:    19580, time: 0.392, loss: 0.020054\n",
      "step:    19600, time: 0.384, loss: 0.017178\n",
      "step:    19620, time: 0.422, loss: 0.019943\n",
      "step:    19640, time: 0.421, loss: 0.014303\n",
      "step:    19660, time: 0.388, loss: 0.016647\n",
      "step:    19680, time: 0.382, loss: 0.004504\n",
      "step:    19700, time: 0.410, loss: 0.018711\n",
      "step:    19720, time: 0.411, loss: 0.013084\n",
      "step:    19740, time: 0.366, loss: 0.019397\n",
      "step:    19760, time: 0.369, loss: 0.016278\n",
      "step:    19780, time: 0.384, loss: 0.014747\n",
      "step:    19800, time: 0.428, loss: 0.020459\n",
      "step:    19820, time: 0.428, loss: 0.010946\n",
      "step:    19840, time: 0.396, loss: 0.014406\n",
      "step:    19860, time: 0.401, loss: 0.024902\n",
      "step:    19880, time: 0.417, loss: 0.020344\n",
      "step:    19900, time: 0.385, loss: 0.017858\n",
      "step:    19920, time: 0.393, loss: 0.009797\n",
      "step:    19940, time: 0.407, loss: 0.013694\n",
      "step:    19960, time: 0.376, loss: 0.009733\n",
      "step:    19980, time: 0.422, loss: 0.012476\n",
      "step:    20000, time: 0.412, loss: 0.013681\n",
      "step:    20020, time: 0.422, loss: 0.019841\n",
      "step:    20040, time: 0.411, loss: 0.018530\n",
      "step:    20060, time: 0.448, loss: 0.019554\n",
      "step:    20080, time: 0.400, loss: 0.020739\n",
      "step:    20100, time: 0.411, loss: 0.010723\n",
      "step:    20120, time: 0.419, loss: 0.024301\n",
      "step:    20140, time: 0.419, loss: 0.020692\n",
      "step:    20160, time: 0.413, loss: 0.012033\n",
      "step:    20180, time: 0.421, loss: 0.009511\n",
      "step:    20200, time: 0.438, loss: 0.024149\n",
      "step:    20220, time: 0.424, loss: 0.020830\n",
      "step:    20240, time: 0.404, loss: 0.011745\n",
      "step:    20260, time: 0.390, loss: 0.013394\n",
      "step:    20280, time: 0.423, loss: 0.018900\n",
      "step:    20300, time: 0.416, loss: 0.031133\n",
      "step:    20320, time: 0.364, loss: 0.013652\n",
      "step:    20340, time: 0.416, loss: 0.014038\n",
      "step:    20360, time: 0.397, loss: 0.020799\n",
      "step:    20380, time: 0.401, loss: 0.014022\n",
      "step:    20400, time: 0.395, loss: 0.015970\n",
      "step:    20420, time: 0.393, loss: 0.010675\n",
      "step:    20440, time: 0.388, loss: 0.011719\n",
      "step:    20460, time: 0.412, loss: 0.015973\n",
      "step:    20480, time: 0.410, loss: 0.006541\n",
      "step:    20500, time: 0.409, loss: 0.019609\n",
      "step:    20520, time: 0.404, loss: 0.016331\n",
      "step:    20540, time: 0.460, loss: 0.025790\n",
      "step:    20560, time: 0.422, loss: 0.014513\n",
      "step:    20580, time: 0.398, loss: 0.016571\n",
      "step:    20600, time: 0.409, loss: 0.010091\n",
      "step:    20620, time: 0.402, loss: 0.013768\n",
      "step:    20640, time: 0.371, loss: 0.019344\n",
      "step:    20660, time: 0.399, loss: 0.012515\n",
      "step:    20680, time: 0.405, loss: 0.007029\n",
      "step:    20700, time: 0.413, loss: 0.018627\n",
      "step:    20720, time: 0.402, loss: 0.018970\n",
      "step:    20740, time: 0.429, loss: 0.020441\n",
      "step:    20760, time: 0.408, loss: 0.012742\n",
      "step:    20780, time: 0.438, loss: 0.173575\n",
      "step:    20800, time: 0.392, loss: 0.017673\n",
      "step:    20820, time: 0.403, loss: 0.010657\n",
      "step:    20840, time: 0.392, loss: 0.021465\n",
      "step:    20860, time: 0.416, loss: 0.019861\n",
      "step:    20880, time: 0.399, loss: 0.015698\n",
      "step:    20900, time: 0.399, loss: 0.008435\n",
      "step:    20920, time: 0.422, loss: 0.020801\n",
      "step:    20940, time: 0.379, loss: 0.022328\n",
      "step:    20960, time: 0.394, loss: 0.019136\n",
      "step:    20980, time: 0.379, loss: 0.005556\n",
      "step:    21000, time: 0.377, loss: 0.006937\n",
      "step:    21020, time: 0.413, loss: 0.017137\n",
      "step:    21040, time: 0.412, loss: 0.015537\n",
      "step:    21060, time: 0.388, loss: 0.013563\n",
      "step:    21080, time: 0.389, loss: 0.015968\n",
      "step:    21100, time: 0.384, loss: 0.002108\n",
      "step:    21120, time: 0.379, loss: 0.017335\n",
      "step:    21140, time: 0.365, loss: 0.009039\n",
      "step:    21160, time: 0.416, loss: 0.018434\n",
      "step:    21180, time: 0.381, loss: 0.013145\n",
      "step:    21200, time: 0.397, loss: 0.009583\n",
      "step:    21220, time: 0.425, loss: 0.018403\n",
      "step:    21240, time: 0.389, loss: 0.020317\n",
      "step:    21260, time: 0.373, loss: 0.022120\n",
      "step:    21280, time: 0.399, loss: 0.016007\n",
      "step:    21300, time: 0.392, loss: 0.013562\n",
      "step:    21320, time: 0.415, loss: 0.006190\n",
      "step:    21340, time: 0.390, loss: 0.016848\n",
      "step:    21360, time: 0.389, loss: 0.011080\n",
      "step:    21380, time: 0.413, loss: 0.019606\n",
      "step:    21400, time: 0.437, loss: 0.017729\n",
      "step:    21420, time: 0.408, loss: 0.019907\n",
      "step:    21440, time: 0.411, loss: 0.018418\n",
      "step:    21460, time: 0.443, loss: 0.013256\n",
      "step:    21480, time: 0.417, loss: 0.021549\n",
      "step:    21500, time: 0.449, loss: 0.043692\n",
      "step:    21520, time: 0.402, loss: 0.020570\n",
      "step:    21540, time: 0.453, loss: 0.039851\n",
      "step:    21560, time: 0.436, loss: 0.011042\n",
      "step:    21580, time: 0.392, loss: 0.011278\n",
      "step:    21600, time: 0.415, loss: 0.032258\n",
      "step:    21620, time: 0.370, loss: 0.022930\n",
      "step:    21640, time: 0.366, loss: 0.016126\n",
      "step:    21660, time: 0.370, loss: 0.011294\n",
      "step:    21680, time: 0.393, loss: 0.019347\n",
      "step:    21700, time: 0.388, loss: 0.008138\n",
      "step:    21720, time: 0.386, loss: 0.013985\n",
      "step:    21740, time: 0.388, loss: 0.010747\n",
      "step:    21760, time: 0.418, loss: 0.015874\n",
      "step:    21780, time: 0.384, loss: 0.013827\n",
      "step:    21800, time: 0.397, loss: 0.014877\n",
      "step:    21820, time: 0.396, loss: 0.009616\n",
      "step:    21840, time: 0.398, loss: 0.013541\n",
      "step:    21860, time: 0.387, loss: 0.020309\n",
      "step:    21880, time: 0.389, loss: 0.014410\n",
      "step:    21900, time: 0.371, loss: 0.007495\n",
      "step:    21920, time: 0.375, loss: 0.017434\n",
      "step:    21940, time: 0.380, loss: 0.015960\n",
      "step:    21960, time: 0.378, loss: 0.015014\n",
      "step:    21980, time: 0.401, loss: 0.007385\n",
      "step:    22000, time: 0.387, loss: 0.016044\n",
      "step:    22020, time: 0.381, loss: 0.025586\n",
      "step:    22040, time: 0.375, loss: 0.016004\n",
      "step:    22060, time: 0.407, loss: 0.019454\n",
      "step:    22080, time: 0.406, loss: 0.017887\n",
      "step:    22100, time: 0.409, loss: 0.017387\n",
      "step:    22120, time: 0.387, loss: 0.010842\n",
      "step:    22140, time: 0.405, loss: 0.016235\n",
      "step:    22160, time: 0.392, loss: 0.010427\n",
      "step:    22180, time: 0.373, loss: 0.008409\n",
      "step:    22200, time: 0.409, loss: 0.016436\n",
      "step:    22220, time: 0.422, loss: 0.013213\n",
      "step:    22240, time: 0.396, loss: 0.011480\n",
      "step:    22260, time: 0.377, loss: 0.021446\n",
      "step:    22280, time: 0.372, loss: 0.015200\n",
      "step:    22300, time: 0.378, loss: 0.011763\n",
      "step:    22320, time: 0.436, loss: 0.019149\n",
      "step:    22340, time: 0.398, loss: 0.007358\n",
      "step:    22360, time: 0.395, loss: 0.016248\n",
      "step:    22380, time: 0.394, loss: 0.013674\n",
      "step:    22400, time: 0.371, loss: 0.008424\n",
      "step:    22420, time: 0.390, loss: 0.034434\n",
      "step:    22440, time: 0.395, loss: 0.017434\n",
      "step:    22460, time: 0.416, loss: 0.017905\n",
      "step:    22480, time: 0.404, loss: 0.018651\n",
      "step:    22500, time: 0.412, loss: 0.022684\n",
      "step:    22520, time: 0.376, loss: 0.014118\n",
      "step:    22540, time: 0.399, loss: 0.015182\n",
      "step:    22560, time: 0.401, loss: 0.019843\n",
      "step:    22580, time: 0.402, loss: 0.020103\n",
      "step:    22600, time: 0.400, loss: 0.020018\n",
      "step:    22620, time: 0.416, loss: 0.022055\n",
      "step:    22640, time: 0.389, loss: 0.014626\n",
      "step:    22660, time: 0.406, loss: 0.015704\n",
      "step:    22680, time: 0.379, loss: 0.023098\n",
      "step:    22700, time: 0.411, loss: 0.021515\n",
      "step:    22720, time: 0.416, loss: 0.013974\n",
      "step:    22740, time: 0.418, loss: 0.018684\n",
      "step:    22760, time: 0.392, loss: 0.016501\n",
      "step:    22780, time: 0.416, loss: 0.014210\n",
      "step:    22800, time: 0.408, loss: 0.019885\n",
      "step:    22820, time: 0.389, loss: 0.008713\n",
      "step:    22840, time: 0.384, loss: 0.011574\n",
      "step:    22860, time: 0.390, loss: 0.009075\n",
      "step:    22880, time: 0.423, loss: 0.004130\n",
      "step:    22900, time: 0.385, loss: 0.013911\n",
      "step:    22920, time: 0.420, loss: 0.012146\n",
      "step:    22940, time: 0.408, loss: 0.005969\n",
      "step:    22960, time: 0.394, loss: 0.015530\n",
      "step:    22980, time: 0.393, loss: 0.003099\n",
      "step:    23000, time: 0.391, loss: 0.023117\n",
      "step:    23020, time: 0.379, loss: 0.015795\n",
      "step:    23040, time: 0.418, loss: 0.012519\n",
      "step:    23060, time: 0.401, loss: 0.010695\n",
      "step:    23080, time: 0.410, loss: 0.012883\n",
      "step:    23100, time: 0.391, loss: 0.014453\n",
      "step:    23120, time: 0.392, loss: 0.024769\n",
      "step:    23140, time: 0.416, loss: 0.012110\n",
      "step:    23160, time: 0.405, loss: 0.016802\n",
      "step:    23180, time: 0.412, loss: 0.008069\n",
      "step:    23200, time: 0.385, loss: 0.023834\n",
      "step:    23220, time: 0.409, loss: 0.019715\n",
      "step:    23240, time: 0.394, loss: 0.003437\n",
      "step:    23260, time: 0.412, loss: 0.023928\n",
      "step:    23280, time: 0.404, loss: 0.011158\n",
      "step:    23300, time: 0.405, loss: 0.012156\n",
      "step:    23320, time: 0.373, loss: 0.019887\n",
      "step:    23340, time: 0.405, loss: 0.009649\n",
      "step:    23360, time: 0.391, loss: 0.014335\n",
      "step:    23380, time: 0.401, loss: 0.009302\n",
      "step:    23400, time: 0.383, loss: 0.017779\n",
      "step:    23420, time: 0.387, loss: 0.023079\n",
      "step:    23440, time: 0.369, loss: 0.016429\n",
      "step:    23460, time: 0.423, loss: 0.140574\n",
      "step:    23480, time: 0.397, loss: 0.015758\n",
      "step:    23500, time: 0.381, loss: 0.023908\n",
      "step:    23520, time: 0.387, loss: 0.010103\n",
      "step:    23540, time: 0.392, loss: 0.012090\n",
      "step:    23560, time: 0.419, loss: 0.016159\n",
      "step:    23580, time: 0.406, loss: 0.014753\n",
      "step:    23600, time: 0.391, loss: 0.018763\n",
      "step:    23620, time: 0.405, loss: 0.016847\n",
      "step:    23640, time: 0.392, loss: 0.020344\n",
      "step:    23660, time: 0.389, loss: 0.010331\n",
      "step:    23680, time: 0.374, loss: 0.017480\n",
      "step:    23700, time: 0.382, loss: 0.032174\n",
      "step:    23720, time: 0.397, loss: 0.019797\n",
      "step:    23740, time: 0.401, loss: 0.014987\n",
      "step:    23760, time: 0.392, loss: 0.016550\n",
      "step:    23780, time: 0.406, loss: 0.023040\n",
      "step:    23800, time: 0.435, loss: 0.016200\n",
      "step:    23820, time: 0.403, loss: 0.015754\n",
      "step:    23840, time: 0.405, loss: 0.342630\n",
      "step:    23860, time: 0.378, loss: 0.009948\n",
      "step:    23880, time: 0.402, loss: 0.017255\n",
      "step:    23900, time: 0.395, loss: 0.012497\n",
      "step:    23920, time: 0.404, loss: 0.014531\n",
      "step:    23940, time: 0.400, loss: 0.009375\n",
      "step:    23960, time: 0.380, loss: 0.012956\n",
      "step:    23980, time: 0.420, loss: 0.013774\n",
      "step:    24000, time: 0.399, loss: 0.017454\n",
      "step:    24020, time: 0.400, loss: 0.025111\n",
      "step:    24040, time: 0.394, loss: 0.018306\n",
      "step:    24060, time: 0.414, loss: 0.032357\n",
      "step:    24080, time: 0.397, loss: 0.014903\n",
      "step:    24100, time: 0.387, loss: 0.014334\n",
      "step:    24120, time: 0.431, loss: 0.016972\n",
      "step:    24140, time: 0.410, loss: 0.017448\n",
      "step:    24160, time: 0.407, loss: 0.018824\n",
      "step:    24180, time: 0.427, loss: 0.017115\n",
      "step:    24200, time: 0.400, loss: 0.018734\n",
      "step:    24220, time: 0.411, loss: 0.019813\n",
      "step:    24240, time: 0.404, loss: 0.210275\n",
      "step:    24260, time: 0.389, loss: 0.019892\n",
      "step:    24280, time: 0.384, loss: 0.014413\n",
      "step:    24300, time: 0.399, loss: 0.199946\n",
      "step:    24320, time: 0.386, loss: 0.017273\n",
      "step:    24340, time: 0.382, loss: 0.008647\n",
      "step:    24360, time: 0.398, loss: 0.012729\n",
      "step:    24380, time: 0.396, loss: 0.015065\n",
      "step:    24400, time: 0.408, loss: 0.019730\n",
      "step:    24420, time: 0.413, loss: 0.021085\n",
      "step:    24440, time: 0.430, loss: 0.025284\n",
      "step:    24460, time: 0.390, loss: 0.013384\n",
      "step:    24480, time: 0.407, loss: 0.010578\n",
      "step:    24500, time: 0.405, loss: 0.004857\n",
      "step:    24520, time: 0.417, loss: 0.019576\n",
      "step:    24540, time: 0.411, loss: 0.016645\n",
      "step:    24560, time: 0.413, loss: 0.014418\n",
      "step:    24580, time: 0.405, loss: 0.012315\n",
      "step:    24600, time: 0.381, loss: 0.013040\n",
      "step:    24620, time: 0.434, loss: 0.179855\n",
      "step:    24640, time: 0.394, loss: 0.012830\n",
      "step:    24660, time: 0.380, loss: 0.014608\n",
      "step:    24680, time: 0.411, loss: 0.011580\n",
      "step:    24700, time: 0.416, loss: 0.014178\n",
      "step:    24720, time: 0.401, loss: 0.009141\n",
      "step:    24740, time: 0.413, loss: 0.011163\n",
      "step:    24760, time: 0.374, loss: 0.010280\n",
      "step:    24780, time: 0.406, loss: 0.005811\n",
      "step:    24800, time: 0.406, loss: 0.014134\n",
      "step:    24820, time: 0.396, loss: 0.010191\n",
      "step:    24840, time: 0.424, loss: 0.020228\n",
      "step:    24860, time: 0.392, loss: 0.019847\n",
      "step:    24880, time: 0.426, loss: 0.013789\n",
      "step:    24900, time: 0.406, loss: 0.015178\n",
      "step:    24920, time: 0.395, loss: 0.011511\n",
      "step:    24940, time: 0.377, loss: 0.013112\n",
      "step:    24960, time: 0.393, loss: 0.010873\n",
      "step:    24980, time: 0.387, loss: 0.023375\n",
      "step:    25000, time: 0.390, loss: 0.011418\n",
      "step:    25020, time: 0.392, loss: 0.022823\n",
      "step:    25040, time: 0.413, loss: 0.015688\n",
      "step:    25060, time: 0.391, loss: 0.022116\n",
      "step:    25080, time: 0.379, loss: 0.016138\n",
      "step:    25100, time: 0.389, loss: 0.017666\n",
      "step:    25120, time: 0.402, loss: 0.013278\n",
      "step:    25140, time: 0.375, loss: 0.009904\n",
      "step:    25160, time: 0.415, loss: 0.022091\n",
      "step:    25180, time: 0.400, loss: 0.010521\n",
      "step:    25200, time: 0.412, loss: 0.010787\n",
      "step:    25220, time: 0.415, loss: 0.022292\n",
      "step:    25240, time: 0.412, loss: 0.016816\n",
      "step:    25260, time: 0.401, loss: 0.012084\n",
      "step:    25280, time: 0.430, loss: 0.018087\n",
      "step:    25300, time: 0.393, loss: 0.009704\n",
      "step:    25320, time: 0.401, loss: 0.012354\n",
      "step:    25340, time: 0.387, loss: 0.011665\n",
      "step:    25360, time: 0.393, loss: 0.018339\n",
      "step:    25380, time: 0.443, loss: 0.018567\n",
      "step:    25400, time: 0.423, loss: 0.020673\n",
      "step:    25420, time: 0.414, loss: 0.012555\n",
      "step:    25440, time: 0.412, loss: 0.012496\n",
      "step:    25460, time: 0.370, loss: 0.008108\n",
      "step:    25480, time: 0.387, loss: 0.016289\n",
      "step:    25500, time: 0.407, loss: 0.013715\n",
      "step:    25520, time: 0.375, loss: 0.007490\n",
      "step:    25540, time: 0.399, loss: 0.015044\n",
      "step:    25560, time: 0.403, loss: 0.006780\n",
      "step:    25580, time: 0.403, loss: 0.020782\n",
      "step:    25600, time: 0.400, loss: 0.016969\n",
      "step:    25620, time: 0.379, loss: 0.019309\n",
      "step:    25640, time: 0.398, loss: 0.009221\n",
      "step:    25660, time: 0.398, loss: 0.025804\n",
      "step:    25680, time: 0.380, loss: 0.015711\n",
      "step:    25700, time: 0.368, loss: 0.015956\n",
      "step:    25720, time: 0.372, loss: 0.012794\n",
      "step:    25740, time: 0.430, loss: 0.015500\n",
      "step:    25760, time: 0.392, loss: 0.012607\n",
      "step:    25780, time: 0.361, loss: 0.008163\n",
      "step:    25800, time: 0.372, loss: 0.014776\n",
      "step:    25820, time: 0.403, loss: 0.031294\n",
      "step:    25840, time: 0.394, loss: 0.016255\n",
      "step:    25860, time: 0.421, loss: 0.013124\n",
      "step:    25880, time: 0.387, loss: 0.009464\n",
      "step:    25900, time: 0.397, loss: 0.015520\n",
      "step:    25920, time: 0.365, loss: 0.013001\n",
      "step:    25940, time: 0.432, loss: 0.017937\n",
      "step:    25960, time: 0.377, loss: 0.024966\n",
      "step:    25980, time: 0.405, loss: 0.011930\n",
      "step:    26000, time: 0.369, loss: 0.036073\n",
      "step:    26020, time: 0.405, loss: 0.039227\n",
      "step:    26040, time: 0.403, loss: 0.023247\n",
      "step:    26060, time: 0.413, loss: 0.013913\n",
      "step:    26080, time: 0.459, loss: 0.230639\n",
      "step:    26100, time: 0.394, loss: 0.008502\n",
      "step:    26120, time: 0.410, loss: 0.009357\n",
      "step:    26140, time: 0.390, loss: 0.010148\n",
      "step:    26160, time: 0.388, loss: 0.021775\n",
      "step:    26180, time: 0.395, loss: 0.013172\n",
      "step:    26200, time: 0.396, loss: 0.012090\n",
      "step:    26220, time: 0.370, loss: 0.011448\n",
      "step:    26240, time: 0.382, loss: 0.019797\n",
      "step:    26260, time: 0.382, loss: 0.035796\n",
      "step:    26280, time: 0.405, loss: 0.020836\n",
      "step:    26300, time: 0.378, loss: 0.004060\n",
      "step:    26320, time: 0.392, loss: 0.016248\n",
      "step:    26340, time: 0.393, loss: 0.009407\n",
      "step:    26360, time: 0.377, loss: 0.019695\n",
      "step:    26380, time: 0.387, loss: 0.017690\n",
      "step:    26400, time: 0.411, loss: 0.016643\n",
      "step:    26420, time: 0.387, loss: 0.020010\n",
      "step:    26440, time: 0.400, loss: 0.006865\n",
      "step:    26460, time: 0.401, loss: 0.016105\n",
      "step:    26480, time: 0.407, loss: 0.012932\n",
      "step:    26500, time: 0.397, loss: 0.021065\n",
      "step:    26520, time: 0.373, loss: 0.015056\n",
      "step:    26540, time: 0.373, loss: 0.013355\n",
      "step:    26560, time: 0.376, loss: 0.010400\n",
      "step:    26580, time: 0.388, loss: 0.014318\n",
      "step:    26600, time: 0.404, loss: 0.022709\n",
      "step:    26620, time: 0.403, loss: 0.015709\n",
      "step:    26640, time: 0.394, loss: 0.016906\n",
      "step:    26660, time: 0.411, loss: 0.023232\n",
      "step:    26680, time: 0.421, loss: 0.010512\n",
      "step:    26700, time: 0.406, loss: 0.019386\n",
      "step:    26720, time: 0.406, loss: 0.022114\n",
      "step:    26740, time: 0.382, loss: 0.019487\n",
      "step:    26760, time: 0.400, loss: 0.014783\n",
      "step:    26780, time: 0.380, loss: 0.005928\n",
      "step:    26800, time: 0.371, loss: 0.012981\n",
      "step:    26820, time: 0.420, loss: 0.019913\n",
      "step:    26840, time: 0.370, loss: 0.014648\n",
      "step:    26860, time: 0.421, loss: 0.009220\n",
      "step:    26880, time: 0.425, loss: 0.012602\n",
      "step:    26900, time: 0.405, loss: 0.024082\n",
      "step:    26920, time: 0.405, loss: 0.014069\n",
      "step:    26940, time: 0.375, loss: 0.014775\n",
      "step:    26960, time: 0.367, loss: 0.019610\n",
      "step:    26980, time: 0.365, loss: 0.011543\n",
      "step:    27000, time: 0.405, loss: 0.015857\n",
      "step:    27020, time: 0.385, loss: 0.013372\n",
      "step:    27040, time: 0.400, loss: 0.009431\n",
      "step:    27060, time: 0.397, loss: 0.014794\n",
      "step:    27080, time: 0.386, loss: 0.013362\n",
      "step:    27100, time: 0.365, loss: 0.008810\n",
      "step:    27120, time: 0.412, loss: 0.016266\n",
      "step:    27140, time: 0.396, loss: 0.012362\n",
      "step:    27160, time: 0.401, loss: 0.018397\n",
      "step:    27180, time: 0.405, loss: 0.014645\n",
      "step:    27200, time: 0.382, loss: 0.021558\n",
      "step:    27220, time: 0.406, loss: 0.019102\n",
      "step:    27240, time: 0.424, loss: 0.017358\n",
      "step:    27260, time: 0.408, loss: 0.013564\n",
      "step:    27280, time: 0.399, loss: 0.014812\n",
      "step:    27300, time: 0.398, loss: 0.008567\n",
      "step:    27320, time: 0.370, loss: 0.012770\n",
      "step:    27340, time: 0.396, loss: 0.015813\n",
      "step:    27360, time: 0.400, loss: 0.006214\n",
      "step:    27380, time: 0.421, loss: 0.014395\n",
      "step:    27400, time: 0.405, loss: 0.003799\n",
      "step:    27420, time: 0.446, loss: 0.017649\n",
      "step:    27440, time: 0.411, loss: 0.012940\n",
      "step:    27460, time: 0.389, loss: 0.012054\n",
      "step:    27480, time: 0.394, loss: 0.019977\n",
      "step:    27500, time: 0.394, loss: 0.008538\n",
      "step:    27520, time: 0.394, loss: 0.014539\n",
      "step:    27540, time: 0.387, loss: 0.006357\n",
      "step:    27560, time: 0.392, loss: 0.019638\n",
      "step:    27580, time: 0.380, loss: 0.015720\n",
      "step:    27600, time: 0.388, loss: 0.016652\n",
      "step:    27620, time: 0.378, loss: 0.013080\n",
      "step:    27640, time: 0.376, loss: 0.007947\n",
      "step:    27660, time: 0.374, loss: 0.014076\n",
      "step:    27680, time: 0.395, loss: 0.016229\n",
      "step:    27700, time: 0.403, loss: 0.009875\n",
      "step:    27720, time: 0.414, loss: 0.026342\n",
      "step:    27740, time: 0.375, loss: 0.013626\n",
      "step:    27760, time: 0.395, loss: 0.014120\n",
      "step:    27780, time: 0.383, loss: 0.008010\n",
      "step:    27800, time: 0.374, loss: 0.012940\n",
      "step:    27820, time: 0.376, loss: 0.022844\n",
      "step:    27840, time: 0.380, loss: 0.013383\n",
      "step:    27860, time: 0.389, loss: 0.014350\n",
      "step:    27880, time: 0.382, loss: 0.021284\n",
      "step:    27900, time: 0.383, loss: 0.022285\n",
      "step:    27920, time: 0.405, loss: 0.016525\n",
      "step:    27940, time: 0.372, loss: 0.010641\n",
      "step:    27960, time: 0.395, loss: 0.005446\n",
      "step:    27980, time: 0.432, loss: 0.012658\n",
      "step:    28000, time: 0.360, loss: 0.019091\n",
      "step:    28020, time: 0.392, loss: 0.015520\n",
      "step:    28040, time: 0.414, loss: 0.012672\n",
      "step:    28060, time: 0.413, loss: 0.028976\n",
      "step:    28080, time: 0.401, loss: 0.021927\n",
      "step:    28100, time: 0.382, loss: 0.009075\n",
      "step:    28120, time: 0.397, loss: 0.019591\n",
      "step:    28140, time: 0.415, loss: 0.013806\n",
      "step:    28160, time: 0.411, loss: 0.019969\n",
      "step:    28180, time: 0.385, loss: 0.010385\n",
      "step:    28200, time: 0.401, loss: 0.021483\n",
      "step:    28220, time: 0.402, loss: 0.017176\n",
      "step:    28240, time: 0.412, loss: 0.015237\n",
      "step:    28260, time: 0.424, loss: 0.014072\n",
      "step:    28280, time: 0.411, loss: 0.011558\n",
      "step:    28300, time: 0.414, loss: 0.020505\n",
      "step:    28320, time: 0.404, loss: 0.016561\n",
      "step:    28340, time: 0.437, loss: 0.015694\n",
      "step:    28360, time: 0.413, loss: 0.013464\n",
      "step:    28380, time: 0.419, loss: 0.018444\n",
      "step:    28400, time: 0.397, loss: 0.011869\n",
      "step:    28420, time: 0.399, loss: 0.012702\n",
      "step:    28440, time: 0.377, loss: 0.009059\n",
      "step:    28460, time: 0.388, loss: 0.020416\n",
      "step:    28480, time: 0.393, loss: 0.010026\n",
      "step:    28500, time: 0.376, loss: 0.016350\n",
      "step:    28520, time: 0.405, loss: 0.142953\n",
      "step:    28540, time: 0.394, loss: 0.018533\n",
      "step:    28560, time: 0.416, loss: 0.011955\n",
      "step:    28580, time: 0.392, loss: 0.017758\n",
      "step:    28600, time: 0.380, loss: 0.008964\n",
      "step:    28620, time: 0.395, loss: 0.012036\n",
      "step:    28640, time: 0.394, loss: 0.007636\n",
      "step:    28660, time: 0.397, loss: 0.017447\n",
      "step:    28680, time: 0.395, loss: 0.017032\n",
      "step:    28700, time: 0.402, loss: 0.013931\n",
      "step:    28720, time: 0.414, loss: 0.020436\n",
      "step:    28740, time: 0.385, loss: 0.010292\n",
      "step:    28760, time: 0.399, loss: 0.015693\n",
      "step:    28780, time: 0.378, loss: 0.016012\n",
      "step:    28800, time: 0.393, loss: 0.014091\n",
      "step:    28820, time: 0.391, loss: 0.021774\n",
      "step:    28840, time: 0.402, loss: 0.014630\n",
      "step:    28860, time: 0.376, loss: 0.015393\n",
      "step:    28880, time: 0.391, loss: 0.013897\n",
      "step:    28900, time: 0.400, loss: 0.012496\n",
      "step:    28920, time: 0.388, loss: 0.009207\n",
      "step:    28940, time: 0.418, loss: 0.016932\n",
      "step:    28960, time: 0.373, loss: 0.017865\n",
      "step:    28980, time: 0.392, loss: 0.022474\n",
      "step:    29000, time: 0.438, loss: 0.025937\n",
      "step:    29020, time: 0.415, loss: 0.017858\n",
      "step:    29040, time: 0.400, loss: 0.018188\n",
      "step:    29060, time: 0.402, loss: 0.016423\n",
      "step:    29080, time: 0.396, loss: 0.007509\n",
      "step:    29100, time: 0.389, loss: 0.018796\n",
      "step:    29120, time: 0.403, loss: 0.017839\n",
      "step:    29140, time: 0.388, loss: 0.020858\n",
      "step:    29160, time: 0.397, loss: 0.019309\n",
      "step:    29180, time: 0.381, loss: 0.015993\n",
      "step:    29200, time: 0.397, loss: 0.019410\n",
      "step:    29220, time: 0.395, loss: 0.013170\n",
      "step:    29240, time: 0.423, loss: 0.021814\n",
      "step:    29260, time: 0.365, loss: 0.018385\n",
      "step:    29280, time: 0.396, loss: 0.008248\n",
      "step:    29300, time: 0.373, loss: 0.016248\n",
      "step:    29320, time: 0.369, loss: 0.013537\n",
      "step:    29340, time: 0.420, loss: 0.017757\n",
      "step:    29360, time: 0.387, loss: 0.015498\n",
      "step:    29380, time: 0.425, loss: 0.013779\n",
      "step:    29400, time: 0.400, loss: 0.016659\n",
      "step:    29420, time: 0.410, loss: 0.015407\n",
      "step:    29440, time: 0.383, loss: 0.010491\n",
      "step:    29460, time: 0.398, loss: 0.011008\n",
      "step:    29480, time: 0.377, loss: 0.012054\n",
      "step:    29500, time: 0.404, loss: 0.020368\n",
      "step:    29520, time: 0.434, loss: 0.019739\n",
      "step:    29540, time: 0.397, loss: 0.010831\n",
      "step:    29560, time: 0.413, loss: 0.015439\n",
      "step:    29580, time: 0.388, loss: 0.010238\n",
      "step:    29600, time: 0.397, loss: 0.015004\n",
      "step:    29620, time: 0.395, loss: 0.017256\n",
      "step:    29640, time: 0.402, loss: 0.007227\n",
      "step:    29660, time: 0.417, loss: 0.007679\n",
      "step:    29680, time: 0.395, loss: 0.008963\n",
      "step:    29700, time: 0.400, loss: 0.010073\n",
      "step:    29720, time: 0.398, loss: 0.016285\n",
      "step:    29740, time: 0.401, loss: 0.014529\n",
      "step:    29760, time: 0.402, loss: 0.014003\n",
      "step:    29780, time: 0.401, loss: 0.018410\n",
      "step:    29800, time: 0.400, loss: 0.017740\n",
      "step:    29820, time: 0.394, loss: 0.008033\n",
      "step:    29840, time: 0.386, loss: 0.015708\n",
      "step:    29860, time: 0.403, loss: 0.018068\n",
      "step:    29880, time: 0.395, loss: 0.015309\n",
      "step:    29900, time: 0.409, loss: 0.013245\n",
      "step:    29920, time: 0.383, loss: 0.010551\n",
      "step:    29940, time: 0.389, loss: 0.009530\n",
      "step:    29960, time: 0.409, loss: 0.025850\n",
      "step:    29980, time: 0.398, loss: 0.016994\n",
      "step:    30000, time: 0.380, loss: 0.014678\n",
      "step:    30020, time: 0.388, loss: 0.019992\n",
      "step:    30040, time: 0.403, loss: 0.015588\n",
      "step:    30060, time: 0.434, loss: 0.015913\n",
      "step:    30080, time: 0.376, loss: 0.016675\n",
      "step:    30100, time: 0.417, loss: 0.019093\n",
      "step:    30120, time: 0.409, loss: 0.022633\n",
      "step:    30140, time: 0.443, loss: 0.020229\n",
      "step:    30160, time: 0.422, loss: 0.014434\n",
      "step:    30180, time: 0.400, loss: 0.016255\n",
      "step:    30200, time: 0.395, loss: 0.019121\n",
      "step:    30220, time: 0.399, loss: 0.013469\n",
      "step:    30240, time: 0.420, loss: 0.023595\n",
      "step:    30260, time: 0.381, loss: 0.017331\n",
      "step:    30280, time: 0.415, loss: 0.019664\n",
      "step:    30300, time: 0.432, loss: 0.019746\n",
      "step:    30320, time: 0.388, loss: 0.046590\n",
      "step:    30340, time: 0.390, loss: 0.014553\n",
      "step:    30360, time: 0.369, loss: 0.009317\n",
      "step:    30380, time: 0.375, loss: 0.018736\n",
      "step:    30400, time: 0.392, loss: 0.017763\n",
      "step:    30420, time: 0.403, loss: 0.027104\n",
      "step:    30440, time: 0.382, loss: 0.021508\n",
      "step:    30460, time: 0.402, loss: 0.012358\n",
      "step:    30480, time: 0.403, loss: 0.009979\n",
      "step:    30500, time: 0.393, loss: 0.007301\n",
      "step:    30520, time: 0.407, loss: 0.011747\n",
      "step:    30540, time: 0.396, loss: 0.016578\n",
      "step:    30560, time: 0.423, loss: 0.013012\n",
      "step:    30580, time: 0.390, loss: 0.015561\n",
      "step:    30600, time: 0.407, loss: 0.014499\n",
      "step:    30620, time: 0.395, loss: 0.013918\n",
      "step:    30640, time: 0.386, loss: 0.025184\n",
      "step:    30660, time: 0.421, loss: 0.026968\n",
      "step:    30680, time: 0.391, loss: 0.007616\n",
      "step:    30700, time: 0.376, loss: 0.023592\n",
      "step:    30720, time: 0.379, loss: 0.015358\n",
      "step:    30740, time: 0.381, loss: 0.003890\n",
      "step:    30760, time: 0.446, loss: 0.214392\n",
      "step:    30780, time: 0.392, loss: 0.016398\n",
      "step:    30800, time: 0.368, loss: 0.008288\n",
      "step:    30820, time: 0.408, loss: 0.010165\n",
      "step:    30840, time: 0.381, loss: 0.011046\n",
      "step:    30860, time: 0.402, loss: 0.021800\n",
      "step:    30880, time: 0.418, loss: 0.014888\n",
      "step:    30900, time: 0.384, loss: 0.022028\n",
      "step:    30920, time: 0.409, loss: 0.174683\n",
      "step:    30940, time: 0.389, loss: 0.017419\n",
      "step:    30960, time: 0.384, loss: 0.014953\n",
      "step:    30980, time: 0.397, loss: 0.018527\n",
      "step:    31000, time: 0.412, loss: 0.018593\n",
      "step:    31020, time: 0.398, loss: 0.015513\n",
      "step:    31040, time: 0.408, loss: 0.012662\n",
      "step:    31060, time: 0.408, loss: 0.016916\n",
      "step:    31080, time: 0.402, loss: 0.014529\n",
      "step:    31100, time: 0.391, loss: 0.017183\n",
      "step:    31120, time: 0.402, loss: 0.015823\n",
      "step:    31140, time: 0.392, loss: 0.026562\n",
      "step:    31160, time: 0.394, loss: 0.019261\n",
      "step:    31180, time: 0.386, loss: 0.013043\n",
      "step:    31200, time: 0.403, loss: 0.023942\n",
      "step:    31220, time: 0.389, loss: 0.009889\n",
      "step:    31240, time: 0.419, loss: 0.012571\n",
      "step:    31260, time: 0.395, loss: 0.008572\n",
      "step:    31280, time: 0.413, loss: 0.014955\n",
      "step:    31300, time: 0.430, loss: 0.019650\n",
      "step:    31320, time: 0.400, loss: 0.017176\n",
      "step:    31340, time: 0.384, loss: 0.021414\n",
      "step:    31360, time: 0.399, loss: 0.010792\n",
      "step:    31380, time: 0.407, loss: 0.020182\n",
      "step:    31400, time: 0.402, loss: 0.022843\n",
      "step:    31420, time: 0.392, loss: 0.024575\n",
      "step:    31440, time: 0.418, loss: 0.012382\n",
      "step:    31460, time: 0.403, loss: 0.012212\n",
      "step:    31480, time: 0.422, loss: 0.014947\n",
      "step:    31500, time: 0.391, loss: 0.011665\n",
      "step:    31520, time: 0.403, loss: 0.015956\n",
      "step:    31540, time: 0.399, loss: 0.015814\n",
      "step:    31560, time: 0.408, loss: 0.019723\n",
      "step:    31580, time: 0.410, loss: 0.015712\n",
      "step:    31600, time: 0.424, loss: 0.022512\n",
      "step:    31620, time: 0.418, loss: 0.208851\n",
      "step:    31640, time: 0.391, loss: 0.017973\n",
      "step:    31660, time: 0.395, loss: 0.020899\n",
      "step:    31680, time: 0.413, loss: 0.012550\n",
      "step:    31700, time: 0.404, loss: 0.006909\n",
      "step:    31720, time: 0.410, loss: 0.015355\n",
      "step:    31740, time: 0.373, loss: 0.010875\n",
      "step:    31760, time: 0.423, loss: 0.011863\n",
      "step:    31780, time: 0.405, loss: 0.013694\n",
      "step:    31800, time: 0.377, loss: 0.009816\n",
      "step:    31820, time: 0.404, loss: 0.022237\n",
      "step:    31840, time: 0.431, loss: 0.015950\n",
      "step:    31860, time: 0.375, loss: 0.015434\n",
      "step:    31880, time: 0.407, loss: 0.012144\n",
      "step:    31900, time: 0.401, loss: 0.018341\n",
      "step:    31920, time: 0.378, loss: 0.017592\n",
      "step:    31940, time: 0.405, loss: 0.018380\n",
      "step:    31960, time: 0.402, loss: 0.013440\n",
      "step:    31980, time: 0.401, loss: 0.020023\n",
      "step:    32000, time: 0.381, loss: 0.014117\n",
      "step:    32020, time: 0.404, loss: 0.020782\n",
      "step:    32040, time: 0.417, loss: 0.009313\n",
      "step:    32060, time: 0.402, loss: 0.009907\n",
      "step:    32080, time: 0.415, loss: 0.015172\n",
      "step:    32100, time: 0.400, loss: 0.013305\n",
      "step:    32120, time: 0.388, loss: 0.014612\n",
      "step:    32140, time: 0.412, loss: 0.017448\n",
      "step:    32160, time: 0.395, loss: 0.010514\n",
      "step:    32180, time: 0.381, loss: 0.017909\n",
      "step:    32200, time: 0.389, loss: 0.011482\n",
      "step:    32220, time: 0.400, loss: 0.013931\n",
      "step:    32240, time: 0.428, loss: 0.016640\n",
      "step:    32260, time: 0.390, loss: 0.009014\n",
      "step:    32280, time: 0.423, loss: 0.019869\n",
      "step:    32300, time: 0.404, loss: 0.015666\n",
      "step:    32320, time: 0.398, loss: 0.009351\n",
      "step:    32340, time: 0.384, loss: 0.009422\n",
      "step:    32360, time: 0.392, loss: 0.018420\n",
      "step:    32380, time: 0.390, loss: 0.014877\n",
      "step:    32400, time: 0.377, loss: 0.017564\n",
      "step:    32420, time: 0.380, loss: 0.015196\n",
      "step:    32440, time: 0.375, loss: 0.015366\n",
      "step:    32460, time: 0.402, loss: 0.040506\n",
      "step:    32480, time: 0.395, loss: 0.014063\n",
      "step:    32500, time: 0.375, loss: 0.015086\n",
      "step:    32520, time: 0.406, loss: 0.015537\n",
      "step:    32540, time: 0.386, loss: 0.016754\n",
      "step:    32560, time: 0.381, loss: 0.020888\n",
      "step:    32580, time: 0.398, loss: 0.015253\n",
      "step:    32600, time: 0.407, loss: 0.008615\n",
      "step:    32620, time: 0.442, loss: 0.012559\n",
      "step:    32640, time: 0.393, loss: 0.008711\n",
      "step:    32660, time: 0.390, loss: 0.007496\n",
      "step:    32680, time: 0.384, loss: 0.020286\n",
      "step:    32700, time: 0.374, loss: 0.012308\n",
      "step:    32720, time: 0.394, loss: 0.019253\n",
      "step:    32740, time: 0.386, loss: 0.024696\n",
      "step:    32760, time: 0.408, loss: 0.015782\n",
      "step:    32780, time: 0.387, loss: 0.005154\n",
      "step:    32800, time: 0.433, loss: 0.018640\n",
      "step:    32820, time: 0.416, loss: 0.025247\n",
      "step:    32840, time: 0.395, loss: 0.012807\n",
      "step:    32860, time: 0.408, loss: 0.018985\n",
      "step:    32880, time: 0.386, loss: 0.019444\n",
      "step:    32900, time: 0.386, loss: 0.018037\n",
      "step:    32920, time: 0.403, loss: 0.011657\n",
      "step:    32940, time: 0.405, loss: 0.021617\n",
      "step:    32960, time: 0.387, loss: 0.015083\n",
      "step:    32980, time: 0.405, loss: 0.030642\n",
      "step:    33000, time: 0.399, loss: 0.019824\n",
      "step:    33020, time: 0.375, loss: 0.008359\n",
      "step:    33040, time: 0.409, loss: 0.010129\n",
      "step:    33060, time: 0.403, loss: 0.021344\n",
      "step:    33080, time: 0.401, loss: 0.016409\n",
      "step:    33100, time: 0.422, loss: 0.242223\n",
      "step:    33120, time: 0.396, loss: 0.017524\n",
      "step:    33140, time: 0.379, loss: 0.018268\n",
      "step:    33160, time: 0.423, loss: 0.011468\n",
      "step:    33180, time: 0.411, loss: 0.015041\n",
      "step:    33200, time: 0.389, loss: 0.016401\n",
      "step:    33220, time: 0.398, loss: 0.010506\n",
      "step:    33240, time: 0.394, loss: 0.018260\n",
      "step:    33260, time: 0.383, loss: 0.015068\n",
      "step:    33280, time: 0.414, loss: 0.023870\n",
      "step:    33300, time: 0.406, loss: 0.018860\n",
      "step:    33320, time: 0.384, loss: 0.013927\n",
      "step:    33340, time: 0.398, loss: 0.016204\n",
      "step:    33360, time: 0.413, loss: 0.018232\n",
      "step:    33380, time: 0.400, loss: 0.014166\n",
      "step:    33400, time: 0.396, loss: 0.019958\n",
      "step:    33420, time: 0.396, loss: 0.011566\n",
      "step:    33440, time: 0.390, loss: 0.019338\n",
      "step:    33460, time: 0.385, loss: 0.019930\n",
      "step:    33480, time: 0.396, loss: 0.009808\n",
      "step:    33500, time: 0.404, loss: 0.014090\n",
      "step:    33520, time: 0.401, loss: 0.014403\n",
      "step:    33540, time: 0.422, loss: 0.012535\n",
      "step:    33560, time: 0.388, loss: 0.009615\n",
      "step:    33580, time: 0.390, loss: 0.010278\n",
      "step:    33600, time: 0.397, loss: 0.026608\n",
      "step:    33620, time: 0.405, loss: 0.011228\n",
      "step:    33640, time: 0.413, loss: 0.012521\n",
      "step:    33660, time: 0.421, loss: 0.015282\n",
      "step:    33680, time: 0.384, loss: 0.006201\n",
      "step:    33700, time: 0.383, loss: 0.018666\n",
      "step:    33720, time: 0.412, loss: 0.018494\n",
      "step:    33740, time: 0.405, loss: 0.013081\n",
      "step:    33760, time: 0.413, loss: 0.014307\n",
      "step:    33780, time: 0.388, loss: 0.003944\n",
      "step:    33800, time: 0.393, loss: 0.012438\n",
      "step:    33820, time: 0.383, loss: 0.009635\n",
      "step:    33840, time: 0.402, loss: 0.015797\n",
      "step:    33860, time: 0.408, loss: 0.014935\n",
      "step:    33880, time: 0.425, loss: 0.019582\n",
      "step:    33900, time: 0.395, loss: 0.018867\n",
      "step:    33920, time: 0.408, loss: 0.015889\n",
      "step:    33940, time: 0.377, loss: 0.021817\n",
      "step:    33960, time: 0.399, loss: 0.013521\n",
      "step:    33980, time: 0.363, loss: 0.012958\n",
      "step:    34000, time: 0.400, loss: 0.017536\n",
      "step:    34020, time: 0.403, loss: 0.020712\n",
      "step:    34040, time: 0.386, loss: 0.018154\n",
      "step:    34060, time: 0.401, loss: 0.014561\n",
      "step:    34080, time: 0.409, loss: 0.014703\n",
      "step:    34100, time: 0.404, loss: 0.013890\n",
      "step:    34120, time: 0.402, loss: 0.005772\n",
      "step:    34140, time: 0.409, loss: 0.015673\n",
      "step:    34160, time: 0.383, loss: 0.016094\n",
      "step:    34180, time: 0.419, loss: 0.010781\n",
      "step:    34200, time: 0.400, loss: 0.009613\n",
      "step:    34220, time: 0.385, loss: 0.015842\n",
      "step:    34240, time: 0.419, loss: 0.015516\n",
      "step:    34260, time: 0.372, loss: 0.012904\n",
      "step:    34280, time: 0.432, loss: 0.019618\n",
      "step:    34300, time: 0.382, loss: 0.017008\n",
      "step:    34320, time: 0.401, loss: 0.009588\n",
      "step:    34340, time: 0.368, loss: 0.006197\n",
      "step:    34360, time: 0.411, loss: 0.017958\n",
      "step:    34380, time: 0.405, loss: 0.021524\n",
      "step:    34400, time: 0.392, loss: 0.010676\n",
      "step:    34420, time: 0.418, loss: 0.022604\n",
      "step:    34440, time: 0.367, loss: 0.018474\n",
      "step:    34460, time: 0.415, loss: 0.007117\n",
      "step:    34480, time: 0.394, loss: 0.018304\n",
      "step:    34500, time: 0.400, loss: 0.012289\n",
      "step:    34520, time: 0.393, loss: 0.015435\n",
      "step:    34540, time: 0.410, loss: 0.017623\n",
      "step:    34560, time: 0.368, loss: 0.012321\n",
      "step:    34580, time: 0.387, loss: 0.032964\n",
      "step:    34600, time: 0.392, loss: 0.017276\n",
      "step:    34620, time: 0.414, loss: 0.022942\n",
      "step:    34640, time: 0.407, loss: 0.013847\n",
      "step:    34660, time: 0.396, loss: 0.020916\n",
      "step:    34680, time: 0.406, loss: 0.020447\n",
      "step:    34700, time: 0.379, loss: 0.015830\n",
      "step:    34720, time: 0.410, loss: 0.020933\n",
      "step:    34740, time: 0.397, loss: 0.013376\n",
      "step:    34760, time: 0.404, loss: 0.011061\n",
      "step:    34780, time: 0.415, loss: 0.020504\n",
      "step:    34800, time: 0.397, loss: 0.018859\n",
      "step:    34820, time: 0.407, loss: 0.015549\n",
      "step:    34840, time: 0.411, loss: 0.022869\n",
      "step:    34860, time: 0.421, loss: 0.015754\n",
      "step:    34880, time: 0.405, loss: 0.012873\n",
      "step:    34900, time: 0.401, loss: 0.013245\n",
      "step:    34920, time: 0.412, loss: 0.016817\n",
      "step:    34940, time: 0.407, loss: 0.012254\n",
      "step:    34960, time: 0.396, loss: 0.013423\n",
      "step:    34980, time: 0.412, loss: 0.014666\n",
      "step:    35000, time: 0.422, loss: 0.025688\n",
      "step:    35020, time: 0.442, loss: 0.015720\n",
      "step:    35040, time: 0.423, loss: 0.028728\n",
      "step:    35060, time: 0.436, loss: 0.049560\n",
      "step:    35080, time: 0.400, loss: 0.017400\n",
      "step:    35100, time: 0.403, loss: 0.015266\n",
      "step:    35120, time: 0.446, loss: 0.020395\n",
      "step:    35140, time: 0.412, loss: 0.014395\n",
      "step:    35160, time: 0.375, loss: 0.023083\n",
      "step:    35180, time: 0.398, loss: 0.009291\n",
      "step:    35200, time: 0.412, loss: 0.026726\n",
      "step:    35220, time: 0.379, loss: 0.012563\n",
      "step:    35240, time: 0.389, loss: 0.012821\n",
      "step:    35260, time: 0.412, loss: 0.011234\n",
      "step:    35280, time: 0.402, loss: 0.020302\n",
      "step:    35300, time: 0.378, loss: 0.017169\n",
      "step:    35320, time: 0.402, loss: 0.013118\n",
      "step:    35340, time: 0.384, loss: 0.015697\n",
      "step:    35360, time: 0.388, loss: 0.008582\n",
      "step:    35380, time: 0.413, loss: 0.017781\n",
      "step:    35400, time: 0.422, loss: 0.012293\n",
      "step:    35420, time: 0.387, loss: 0.018256\n",
      "step:    35440, time: 0.419, loss: 0.012158\n",
      "step:    35460, time: 0.379, loss: 0.013864\n",
      "step:    35480, time: 0.395, loss: 0.016002\n",
      "step:    35500, time: 0.400, loss: 0.019142\n",
      "step:    35520, time: 0.383, loss: 0.013488\n",
      "step:    35540, time: 0.384, loss: 0.018862\n",
      "step:    35560, time: 0.115, loss: 0.009088\n",
      "step:    35580, time: 0.385, loss: 0.008176\n",
      "step:    35600, time: 0.388, loss: 0.020605\n",
      "step:    35620, time: 0.378, loss: 0.024637\n",
      "step:    35640, time: 0.398, loss: 0.019390\n",
      "step:    35660, time: 0.413, loss: 0.011673\n",
      "step:    35680, time: 0.404, loss: 0.018044\n",
      "step:    35700, time: 0.404, loss: 0.023184\n",
      "step:    35720, time: 0.410, loss: 0.011589\n",
      "step:    35740, time: 0.395, loss: 0.007972\n",
      "step:    35760, time: 0.401, loss: 0.014020\n",
      "step:    35780, time: 0.388, loss: 0.014537\n",
      "step:    35800, time: 0.400, loss: 0.013303\n",
      "step:    35820, time: 0.393, loss: 0.009700\n",
      "step:    35840, time: 0.428, loss: 0.018363\n",
      "step:    35860, time: 0.387, loss: 0.007160\n",
      "step:    35880, time: 0.399, loss: 0.019989\n",
      "step:    35900, time: 0.424, loss: 0.015270\n",
      "step:    35920, time: 0.393, loss: 0.016457\n",
      "step:    35940, time: 0.398, loss: 0.013133\n",
      "step:    35960, time: 0.397, loss: 0.009852\n",
      "step:    35980, time: 0.385, loss: 0.018632\n",
      "step:    36000, time: 0.402, loss: 0.010541\n",
      "step:    36020, time: 0.420, loss: 0.013131\n",
      "step:    36040, time: 0.418, loss: 0.025643\n",
      "step:    36060, time: 0.361, loss: 0.004397\n",
      "step:    36080, time: 0.403, loss: 0.006958\n",
      "step:    36100, time: 0.388, loss: 0.007278\n",
      "step:    36120, time: 0.411, loss: 0.020750\n",
      "step:    36140, time: 0.396, loss: 0.024422\n",
      "step:    36160, time: 0.404, loss: 0.019352\n",
      "step:    36180, time: 0.418, loss: 0.017743\n",
      "step:    36200, time: 0.395, loss: 0.012324\n",
      "step:    36220, time: 0.384, loss: 0.012529\n",
      "step:    36240, time: 0.419, loss: 0.012052\n",
      "step:    36260, time: 0.393, loss: 0.005075\n",
      "step:    36280, time: 0.372, loss: 0.023804\n",
      "step:    36300, time: 0.419, loss: 0.012740\n",
      "step:    36320, time: 0.388, loss: 0.014314\n",
      "step:    36340, time: 0.426, loss: 0.019540\n",
      "step:    36360, time: 0.419, loss: 0.019166\n",
      "step:    36380, time: 0.396, loss: 0.012545\n",
      "step:    36400, time: 0.419, loss: 0.011284\n",
      "step:    36420, time: 0.434, loss: 0.019115\n",
      "step:    36440, time: 0.406, loss: 0.010338\n",
      "step:    36460, time: 0.391, loss: 0.017952\n",
      "step:    36480, time: 0.387, loss: 0.020899\n",
      "step:    36500, time: 0.405, loss: 0.009452\n",
      "step:    36520, time: 0.394, loss: 0.017653\n",
      "step:    36540, time: 0.403, loss: 0.063861\n",
      "step:    36560, time: 0.390, loss: 0.017638\n",
      "step:    36580, time: 0.384, loss: 0.022447\n",
      "step:    36600, time: 0.414, loss: 0.019529\n",
      "step:    36620, time: 0.391, loss: 0.015971\n",
      "step:    36640, time: 0.403, loss: 0.025039\n",
      "step:    36660, time: 0.423, loss: 0.011014\n",
      "step:    36680, time: 0.414, loss: 0.017996\n",
      "step:    36700, time: 0.420, loss: 0.021793\n",
      "step:    36720, time: 0.426, loss: 0.013377\n",
      "step:    36740, time: 0.383, loss: 0.008401\n",
      "step:    36760, time: 0.367, loss: 0.013257\n",
      "step:    36780, time: 0.456, loss: 0.014501\n",
      "step:    36800, time: 0.420, loss: 0.014118\n",
      "step:    36820, time: 0.394, loss: 0.008672\n",
      "step:    36840, time: 0.389, loss: 0.015842\n",
      "step:    36860, time: 0.407, loss: 0.015762\n",
      "step:    36880, time: 0.397, loss: 0.021443\n",
      "step:    36900, time: 0.409, loss: 0.014188\n",
      "step:    36920, time: 0.405, loss: 0.010247\n",
      "step:    36940, time: 0.418, loss: 0.015188\n",
      "step:    36960, time: 0.398, loss: 0.011100\n",
      "step:    36980, time: 0.376, loss: 0.006649\n",
      "step:    37000, time: 0.403, loss: 0.018415\n",
      "step:    37020, time: 0.394, loss: 0.021704\n",
      "step:    37040, time: 0.400, loss: 0.014178\n",
      "step:    37060, time: 0.384, loss: 0.012669\n",
      "step:    37080, time: 0.413, loss: 0.035450\n",
      "step:    37100, time: 0.394, loss: 0.021916\n",
      "step:    37120, time: 0.389, loss: 0.007495\n",
      "step:    37140, time: 0.387, loss: 0.009391\n",
      "step:    37160, time: 0.403, loss: 0.007348\n",
      "step:    37180, time: 0.397, loss: 0.008638\n",
      "step:    37200, time: 0.398, loss: 0.013169\n",
      "step:    37220, time: 0.403, loss: 0.016661\n",
      "step:    37240, time: 0.405, loss: 0.013394\n",
      "step:    37260, time: 0.393, loss: 0.019631\n",
      "step:    37280, time: 0.418, loss: 0.011293\n",
      "step:    37300, time: 0.386, loss: 0.008565\n",
      "step:    37320, time: 0.384, loss: 0.019276\n",
      "step:    37340, time: 0.423, loss: 0.017713\n",
      "step:    37360, time: 0.394, loss: 0.018572\n",
      "step:    37380, time: 0.383, loss: 0.013426\n",
      "step:    37400, time: 0.379, loss: 0.122768\n",
      "step:    37420, time: 0.438, loss: 0.021499\n",
      "step:    37440, time: 0.403, loss: 0.024993\n",
      "step:    37460, time: 0.407, loss: 0.013315\n",
      "step:    37480, time: 0.374, loss: 0.013914\n",
      "step:    37500, time: 0.404, loss: 0.017717\n",
      "step:    37520, time: 0.401, loss: 0.014051\n",
      "step:    37540, time: 0.377, loss: 0.019443\n",
      "step:    37560, time: 0.393, loss: 0.022439\n",
      "step:    37580, time: 0.399, loss: 0.016446\n",
      "step:    37600, time: 0.385, loss: 0.021309\n",
      "step:    37620, time: 0.426, loss: 0.012420\n",
      "step:    37640, time: 0.388, loss: 0.009825\n",
      "step:    37660, time: 0.388, loss: 0.014825\n",
      "step:    37680, time: 0.381, loss: 0.013809\n",
      "step:    37700, time: 0.414, loss: 0.015488\n",
      "step:    37720, time: 0.402, loss: 0.012928\n",
      "step:    37740, time: 0.415, loss: 0.015632\n",
      "step:    37760, time: 0.419, loss: 0.019207\n",
      "step:    37780, time: 0.396, loss: 0.015519\n",
      "step:    37800, time: 0.394, loss: 0.010379\n",
      "step:    37820, time: 0.430, loss: 0.014093\n",
      "step:    37840, time: 0.407, loss: 0.025930\n",
      "step:    37860, time: 0.409, loss: 0.008709\n",
      "step:    37880, time: 0.402, loss: 0.019192\n",
      "step:    37900, time: 0.413, loss: 0.018502\n",
      "step:    37920, time: 0.392, loss: 0.015764\n",
      "step:    37940, time: 0.415, loss: 0.017220\n",
      "step:    37960, time: 0.384, loss: 0.019921\n",
      "step:    37980, time: 0.411, loss: 0.132356\n",
      "step:    38000, time: 0.385, loss: 0.019539\n",
      "step:    38020, time: 0.399, loss: 0.019769\n",
      "step:    38040, time: 0.406, loss: 0.007346\n",
      "step:    38060, time: 0.398, loss: 0.012053\n",
      "step:    38080, time: 0.429, loss: 0.020268\n",
      "step:    38100, time: 0.400, loss: 0.012861\n",
      "step:    38120, time: 0.382, loss: 0.005829\n",
      "step:    38140, time: 0.380, loss: 0.015917\n",
      "step:    38160, time: 0.376, loss: 0.014039\n",
      "step:    38180, time: 0.392, loss: 0.016683\n",
      "step:    38200, time: 0.400, loss: 0.016490\n",
      "step:    38220, time: 0.391, loss: 0.021704\n",
      "step:    38240, time: 0.409, loss: 0.016332\n",
      "step:    38260, time: 0.455, loss: 0.021130\n",
      "step:    38280, time: 0.406, loss: 0.009127\n",
      "step:    38300, time: 0.388, loss: 0.007960\n",
      "step:    38320, time: 0.403, loss: 0.009383\n",
      "step:    38340, time: 0.384, loss: 0.022255\n",
      "step:    38360, time: 0.394, loss: 0.012195\n",
      "step:    38380, time: 0.380, loss: 0.026191\n",
      "step:    38400, time: 0.406, loss: 0.016036\n",
      "step:    38420, time: 0.385, loss: 0.012381\n",
      "step:    38440, time: 0.418, loss: 0.019197\n",
      "step:    38460, time: 0.389, loss: 0.008577\n",
      "step:    38480, time: 0.426, loss: 0.010613\n",
      "step:    38500, time: 0.392, loss: 0.019746\n",
      "step:    38520, time: 0.404, loss: 0.013491\n",
      "step:    38540, time: 0.416, loss: 0.014215\n",
      "step:    38560, time: 0.445, loss: 0.014777\n",
      "step:    38580, time: 0.397, loss: 0.016063\n",
      "step:    38600, time: 0.410, loss: 0.010170\n",
      "step:    38620, time: 0.381, loss: 0.007681\n",
      "step:    38640, time: 0.395, loss: 0.018933\n",
      "step:    38660, time: 0.423, loss: 0.017182\n",
      "step:    38680, time: 0.380, loss: 0.018238\n",
      "step:    38700, time: 0.394, loss: 0.020637\n",
      "step:    38720, time: 0.404, loss: 0.014858\n",
      "step:    38740, time: 0.408, loss: 0.023066\n",
      "step:    38760, time: 0.396, loss: 0.009600\n",
      "step:    38780, time: 0.387, loss: 0.015972\n",
      "step:    38800, time: 0.378, loss: 0.020045\n",
      "step:    38820, time: 0.420, loss: 0.019482\n",
      "step:    38840, time: 0.396, loss: 0.016886\n",
      "step:    38860, time: 0.413, loss: 0.020338\n",
      "step:    38880, time: 0.394, loss: 0.004733\n",
      "step:    38900, time: 0.418, loss: 0.015983\n",
      "step:    38920, time: 0.400, loss: 0.016929\n",
      "step:    38940, time: 0.407, loss: 0.020498\n",
      "step:    38960, time: 0.401, loss: 0.012555\n",
      "step:    38980, time: 0.381, loss: 0.016302\n",
      "step:    39000, time: 0.403, loss: 0.023406\n",
      "step:    39020, time: 0.376, loss: 0.002400\n",
      "step:    39040, time: 0.409, loss: 0.013054\n",
      "step:    39060, time: 0.394, loss: 0.017299\n",
      "step:    39080, time: 0.396, loss: 0.025874\n",
      "step:    39100, time: 0.397, loss: 0.021757\n",
      "step:    39120, time: 0.398, loss: 0.015849\n",
      "step:    39140, time: 0.395, loss: 0.014242\n",
      "step:    39160, time: 0.405, loss: 0.012639\n",
      "step:    39180, time: 0.390, loss: 0.009945\n",
      "step:    39200, time: 0.406, loss: 0.022614\n",
      "step:    39220, time: 0.393, loss: 0.012533\n",
      "step:    39240, time: 0.414, loss: 0.018538\n",
      "step:    39260, time: 0.389, loss: 0.012393\n",
      "step:    39280, time: 0.389, loss: 0.006030\n",
      "step:    39300, time: 0.409, loss: 0.023877\n",
      "step:    39320, time: 0.382, loss: 0.008285\n",
      "step:    39340, time: 0.413, loss: 0.011978\n",
      "step:    39360, time: 0.402, loss: 0.009754\n",
      "step:    39380, time: 0.373, loss: 0.007635\n",
      "step:    39400, time: 0.401, loss: 0.017676\n",
      "step:    39420, time: 0.429, loss: 0.014054\n",
      "step:    39440, time: 0.419, loss: 0.005671\n",
      "step:    39460, time: 0.393, loss: 0.251683\n",
      "step:    39480, time: 0.417, loss: 0.009172\n",
      "step:    39500, time: 0.377, loss: 0.010905\n",
      "step:    39520, time: 0.428, loss: 0.013048\n",
      "step:    39540, time: 0.408, loss: 0.005096\n",
      "step:    39560, time: 0.397, loss: 0.020202\n",
      "step:    39580, time: 0.398, loss: 0.017889\n",
      "step:    39600, time: 0.396, loss: 0.015604\n",
      "step:    39620, time: 0.402, loss: 0.020108\n",
      "step:    39640, time: 0.416, loss: 0.012058\n",
      "step:    39660, time: 0.430, loss: 0.018033\n",
      "step:    39680, time: 0.380, loss: 0.010155\n",
      "step:    39700, time: 0.400, loss: 0.022242\n",
      "step:    39720, time: 0.408, loss: 0.015815\n",
      "step:    39740, time: 0.387, loss: 0.020325\n",
      "step:    39760, time: 0.385, loss: 0.009755\n",
      "step:    39780, time: 0.398, loss: 0.015116\n",
      "step:    39800, time: 0.406, loss: 0.018483\n",
      "step:    39820, time: 0.376, loss: 0.006978\n",
      "step:    39840, time: 0.395, loss: 0.015661\n",
      "step:    39860, time: 0.381, loss: 0.020019\n",
      "step:    39880, time: 0.414, loss: 0.013439\n",
      "step:    39900, time: 0.407, loss: 0.023050\n",
      "step:    39920, time: 0.383, loss: 0.016470\n",
      "step:    39940, time: 0.393, loss: 0.225886\n",
      "step:    39960, time: 0.392, loss: 0.012702\n",
      "step:    39980, time: 0.390, loss: 0.022579\n",
      "step:    40000, time: 0.381, loss: 0.020440\n",
      "step:    40020, time: 0.384, loss: 0.016446\n",
      "step:    40040, time: 0.404, loss: 0.009570\n",
      "step:    40060, time: 0.383, loss: 0.019485\n",
      "step:    40080, time: 0.409, loss: 0.012862\n",
      "step:    40100, time: 0.418, loss: 0.018329\n",
      "step:    40120, time: 0.426, loss: 0.017351\n",
      "step:    40140, time: 0.396, loss: 0.004623\n",
      "step:    40160, time: 0.375, loss: 0.013400\n",
      "step:    40180, time: 0.406, loss: 0.017944\n",
      "step:    40200, time: 0.383, loss: 0.012626\n",
      "step:    40220, time: 0.437, loss: 0.157522\n",
      "step:    40240, time: 0.412, loss: 0.021671\n",
      "step:    40260, time: 0.409, loss: 0.020274\n",
      "step:    40280, time: 0.392, loss: 0.018692\n",
      "step:    40300, time: 0.396, loss: 0.019360\n",
      "step:    40320, time: 0.410, loss: 0.023944\n",
      "step:    40340, time: 0.411, loss: 0.015518\n",
      "step:    40360, time: 0.364, loss: 0.019076\n",
      "step:    40380, time: 0.406, loss: 0.017147\n",
      "step:    40400, time: 0.390, loss: 0.013095\n",
      "step:    40420, time: 0.389, loss: 0.012123\n",
      "step:    40440, time: 0.388, loss: 0.009961\n",
      "step:    40460, time: 0.407, loss: 0.013328\n",
      "step:    40480, time: 0.434, loss: 0.014461\n",
      "step:    40500, time: 0.416, loss: 0.013657\n",
      "step:    40520, time: 0.395, loss: 0.017931\n",
      "step:    40540, time: 0.387, loss: 0.021799\n",
      "step:    40560, time: 0.425, loss: 0.004318\n",
      "step:    40580, time: 0.425, loss: 0.012934\n",
      "step:    40600, time: 0.398, loss: 0.014268\n",
      "step:    40620, time: 0.380, loss: 0.015761\n",
      "step:    40640, time: 0.394, loss: 0.015005\n",
      "step:    40660, time: 0.384, loss: 0.012839\n",
      "step:    40680, time: 0.402, loss: 0.020678\n",
      "step:    40700, time: 0.396, loss: 0.011331\n",
      "step:    40720, time: 0.399, loss: 0.019952\n",
      "step:    40740, time: 0.383, loss: 0.019000\n",
      "step:    40760, time: 0.415, loss: 0.014836\n",
      "step:    40780, time: 0.398, loss: 0.009777\n",
      "step:    40800, time: 0.392, loss: 0.028504\n",
      "step:    40820, time: 0.412, loss: 0.012018\n",
      "step:    40840, time: 0.395, loss: 0.006378\n",
      "step:    40860, time: 0.394, loss: 0.023686\n",
      "step:    40880, time: 0.399, loss: 0.009760\n",
      "step:    40900, time: 0.401, loss: 0.025816\n",
      "step:    40920, time: 0.403, loss: 0.013622\n",
      "step:    40940, time: 0.422, loss: 0.021289\n",
      "step:    40960, time: 0.414, loss: 0.013818\n",
      "step:    40980, time: 0.410, loss: 0.009787\n",
      "step:    41000, time: 0.414, loss: 0.016075\n",
      "step:    41020, time: 0.409, loss: 0.019516\n",
      "step:    41040, time: 0.427, loss: 0.023287\n",
      "step:    41060, time: 0.430, loss: 0.014060\n",
      "step:    41080, time: 0.392, loss: 0.021637\n",
      "step:    41100, time: 0.407, loss: 0.013876\n",
      "step:    41120, time: 0.407, loss: 0.015950\n",
      "step:    41140, time: 0.416, loss: 0.006411\n",
      "step:    41160, time: 0.437, loss: 0.019249\n",
      "step:    41180, time: 0.410, loss: 0.014448\n",
      "step:    41200, time: 0.397, loss: 0.017955\n",
      "step:    41220, time: 0.410, loss: 0.017264\n",
      "step:    41240, time: 0.382, loss: 0.014736\n",
      "step:    41260, time: 0.402, loss: 0.016297\n",
      "step:    41280, time: 0.394, loss: 0.010456\n",
      "step:    41300, time: 0.393, loss: 0.013796\n",
      "step:    41320, time: 0.415, loss: 0.012360\n",
      "step:    41340, time: 0.387, loss: 0.014653\n",
      "step:    41360, time: 0.381, loss: 0.013959\n",
      "step:    41380, time: 0.407, loss: 0.009112\n",
      "step:    41400, time: 0.422, loss: 0.017255\n",
      "step:    41420, time: 0.379, loss: 0.012008\n",
      "step:    41440, time: 0.390, loss: 0.009878\n",
      "step:    41460, time: 0.416, loss: 0.023271\n",
      "step:    41480, time: 0.400, loss: 0.016257\n",
      "step:    41500, time: 0.408, loss: 0.015833\n",
      "step:    41520, time: 0.414, loss: 0.016244\n",
      "step:    41540, time: 0.368, loss: 0.012146\n",
      "step:    41560, time: 0.395, loss: 0.024029\n",
      "step:    41580, time: 0.399, loss: 0.017981\n",
      "step:    41600, time: 0.387, loss: 0.012463\n",
      "step:    41620, time: 0.379, loss: 0.008946\n",
      "step:    41640, time: 0.398, loss: 0.016294\n",
      "step:    41660, time: 0.394, loss: 0.020261\n",
      "step:    41680, time: 0.416, loss: 0.011143\n",
      "step:    41700, time: 0.385, loss: 0.013262\n",
      "step:    41720, time: 0.388, loss: 0.009109\n",
      "step:    41740, time: 0.384, loss: 0.026495\n",
      "step:    41760, time: 0.394, loss: 0.016895\n",
      "step:    41780, time: 0.418, loss: 0.020469\n",
      "step:    41800, time: 0.418, loss: 0.019046\n",
      "step:    41820, time: 0.402, loss: 0.014790\n",
      "step:    41840, time: 0.404, loss: 0.007700\n",
      "step:    41860, time: 0.409, loss: 0.013807\n",
      "step:    41880, time: 0.428, loss: 0.019039\n",
      "step:    41900, time: 0.404, loss: 0.011479\n",
      "step:    41920, time: 0.408, loss: 0.014924\n",
      "step:    41940, time: 0.428, loss: 0.013366\n",
      "step:    41960, time: 0.388, loss: 0.012210\n",
      "step:    41980, time: 0.412, loss: 0.016797\n",
      "step:    42000, time: 0.430, loss: 0.014347\n",
      "step:    42020, time: 0.375, loss: 0.022927\n",
      "step:    42040, time: 0.413, loss: 0.158787\n",
      "step:    42060, time: 0.408, loss: 0.017122\n",
      "step:    42080, time: 0.397, loss: 0.020644\n",
      "step:    42100, time: 0.417, loss: 0.014146\n",
      "step:    42120, time: 0.422, loss: 0.021869\n",
      "step:    42140, time: 0.378, loss: 0.012159\n",
      "step:    42160, time: 0.384, loss: 0.006061\n",
      "step:    42180, time: 0.417, loss: 0.043562\n",
      "step:    42200, time: 0.390, loss: 0.020766\n",
      "step:    42220, time: 0.388, loss: 0.027009\n",
      "step:    42240, time: 0.402, loss: 0.012268\n",
      "step:    42260, time: 0.398, loss: 0.017106\n",
      "step:    42280, time: 0.379, loss: 0.017068\n",
      "step:    42300, time: 0.400, loss: 0.015751\n",
      "step:    42320, time: 0.430, loss: 0.012207\n",
      "step:    42340, time: 0.397, loss: 0.016930\n",
      "step:    42360, time: 0.386, loss: 0.018748\n",
      "step:    42380, time: 0.425, loss: 0.022602\n",
      "step:    42400, time: 0.380, loss: 0.015431\n",
      "step:    42420, time: 0.438, loss: 0.015377\n",
      "step:    42440, time: 0.406, loss: 0.008118\n",
      "step:    42460, time: 0.408, loss: 0.027136\n",
      "step:    42480, time: 0.403, loss: 0.015927\n",
      "step:    42500, time: 0.391, loss: 0.005523\n",
      "step:    42520, time: 0.410, loss: 0.014151\n",
      "step:    42540, time: 0.425, loss: 0.019684\n",
      "step:    42560, time: 0.388, loss: 0.015064\n",
      "step:    42580, time: 0.403, loss: 0.022422\n",
      "step:    42600, time: 0.405, loss: 0.012037\n",
      "step:    42620, time: 0.391, loss: 0.014129\n",
      "step:    42640, time: 0.423, loss: 0.024406\n",
      "step:    42660, time: 0.395, loss: 0.018994\n",
      "step:    42680, time: 0.398, loss: 0.005381\n",
      "step:    42700, time: 0.374, loss: 0.017805\n",
      "step:    42720, time: 0.381, loss: 0.008143\n",
      "step:    42740, time: 0.406, loss: 0.058692\n",
      "step:    42760, time: 0.397, loss: 0.009718\n",
      "step:    42780, time: 0.405, loss: 0.013828\n",
      "step:    42800, time: 0.404, loss: 0.023881\n",
      "step:    42820, time: 0.406, loss: 0.011546\n",
      "step:    42840, time: 0.408, loss: 0.014305\n",
      "step:    42860, time: 0.397, loss: 0.014813\n",
      "step:    42880, time: 0.397, loss: 0.014753\n",
      "step:    42900, time: 0.409, loss: 0.019375\n",
      "step:    42920, time: 0.388, loss: 0.014904\n",
      "step:    42940, time: 0.407, loss: 0.014936\n",
      "step:    42960, time: 0.386, loss: 0.030075\n",
      "step:    42980, time: 0.396, loss: 0.018797\n",
      "step:    43000, time: 0.383, loss: 0.006743\n",
      "step:    43020, time: 0.391, loss: 0.011882\n",
      "step:    43040, time: 0.393, loss: 0.013590\n",
      "step:    43060, time: 0.397, loss: 0.013448\n",
      "step:    43080, time: 0.435, loss: 0.016050\n",
      "step:    43100, time: 0.385, loss: 0.009618\n",
      "step:    43120, time: 0.388, loss: 0.015411\n",
      "step:    43140, time: 0.394, loss: 0.018270\n",
      "step:    43160, time: 0.386, loss: 0.014920\n",
      "step:    43180, time: 0.397, loss: 0.015920\n",
      "step:    43200, time: 0.412, loss: 0.011836\n",
      "step:    43220, time: 0.413, loss: 0.006103\n",
      "step:    43240, time: 0.395, loss: 0.018959\n",
      "step:    43260, time: 0.415, loss: 0.016797\n",
      "step:    43280, time: 0.407, loss: 0.014581\n",
      "step:    43300, time: 0.400, loss: 0.009483\n",
      "step:    43320, time: 0.397, loss: 0.015987\n",
      "step:    43340, time: 0.380, loss: 0.009854\n",
      "step:    43360, time: 0.411, loss: 0.015078\n",
      "step:    43380, time: 0.410, loss: 0.011192\n",
      "step:    43400, time: 0.403, loss: 0.017463\n",
      "step:    43420, time: 0.380, loss: 0.011954\n",
      "step:    43440, time: 0.431, loss: 0.019999\n",
      "step:    43460, time: 0.406, loss: 0.014165\n",
      "step:    43480, time: 0.386, loss: 0.008782\n",
      "step:    43500, time: 0.388, loss: 0.008603\n",
      "step:    43520, time: 0.411, loss: 0.020598\n",
      "step:    43540, time: 0.384, loss: 0.012714\n",
      "step:    43560, time: 0.402, loss: 0.014615\n",
      "step:    43580, time: 0.387, loss: 0.011154\n",
      "step:    43600, time: 0.395, loss: 0.012955\n",
      "step:    43620, time: 0.384, loss: 0.022932\n",
      "step:    43640, time: 0.405, loss: 0.017268\n",
      "step:    43660, time: 0.401, loss: 0.007743\n",
      "step:    43680, time: 0.401, loss: 0.020443\n",
      "step:    43700, time: 0.385, loss: 0.017501\n",
      "step:    43720, time: 0.413, loss: 0.018112\n",
      "step:    43740, time: 0.387, loss: 0.010904\n",
      "step:    43760, time: 0.402, loss: 0.022924\n",
      "step:    43780, time: 0.391, loss: 0.007446\n",
      "step:    43800, time: 0.398, loss: 0.018516\n",
      "step:    43820, time: 0.409, loss: 0.009539\n",
      "step:    43840, time: 0.398, loss: 0.012831\n",
      "step:    43860, time: 0.399, loss: 0.008112\n",
      "step:    43880, time: 0.418, loss: 0.011761\n",
      "step:    43900, time: 0.424, loss: 0.024273\n",
      "step:    43920, time: 0.422, loss: 0.025183\n",
      "step:    43940, time: 0.387, loss: 0.020149\n",
      "step:    43960, time: 0.399, loss: 0.010076\n",
      "step:    43980, time: 0.409, loss: 0.022098\n",
      "step:    44000, time: 0.393, loss: 0.017984\n",
      "step:    44020, time: 0.404, loss: 0.015541\n",
      "step:    44040, time: 0.422, loss: 0.008790\n",
      "step:    44060, time: 0.420, loss: 0.014703\n",
      "step:    44080, time: 0.404, loss: 0.016393\n",
      "step:    44100, time: 0.402, loss: 0.017061\n",
      "step:    44120, time: 0.402, loss: 0.016286\n",
      "step:    44140, time: 0.417, loss: 0.016423\n",
      "step:    44160, time: 0.386, loss: 0.009571\n",
      "step:    44180, time: 0.409, loss: 0.013066\n",
      "step:    44200, time: 0.411, loss: 0.007420\n",
      "step:    44220, time: 0.404, loss: 0.012483\n",
      "step:    44240, time: 0.403, loss: 0.014112\n",
      "step:    44260, time: 0.429, loss: 0.011296\n",
      "step:    44280, time: 0.383, loss: 0.009936\n",
      "step:    44300, time: 0.395, loss: 0.020426\n",
      "step:    44320, time: 0.415, loss: 0.016389\n",
      "step:    44340, time: 0.413, loss: 0.020175\n",
      "step:    44360, time: 0.388, loss: 0.016265\n",
      "step:    44380, time: 0.437, loss: 0.014457\n",
      "step:    44400, time: 0.385, loss: 0.014071\n",
      "step:    44420, time: 0.374, loss: 0.019200\n",
      "step:    44440, time: 0.413, loss: 0.016483\n",
      "step:    44460, time: 0.397, loss: 0.021502\n",
      "step:    44480, time: 0.393, loss: 0.020977\n",
      "step:    44500, time: 0.402, loss: 0.015239\n",
      "step:    44520, time: 0.377, loss: 0.021711\n",
      "step:    44540, time: 0.373, loss: 0.008393\n",
      "step:    44560, time: 0.406, loss: 0.017874\n",
      "step:    44580, time: 0.373, loss: 0.013820\n",
      "step:    44600, time: 0.416, loss: 0.010742\n",
      "step:    44620, time: 0.417, loss: 0.006479\n",
      "step:    44640, time: 0.397, loss: 0.018146\n",
      "step:    44660, time: 0.392, loss: 0.026061\n",
      "step:    44680, time: 0.410, loss: 0.012064\n",
      "step:    44700, time: 0.398, loss: 0.017335\n",
      "step:    44720, time: 0.399, loss: 0.014796\n",
      "step:    44740, time: 0.416, loss: 0.006298\n",
      "step:    44760, time: 0.415, loss: 0.012776\n",
      "step:    44780, time: 0.411, loss: 0.019035\n",
      "step:    44800, time: 0.421, loss: 0.020182\n",
      "step:    44820, time: 0.408, loss: 0.014619\n",
      "step:    44840, time: 0.401, loss: 0.015651\n",
      "step:    44860, time: 0.417, loss: 0.010644\n",
      "step:    44880, time: 0.399, loss: 0.017243\n",
      "step:    44900, time: 0.413, loss: 0.015627\n",
      "step:    44920, time: 0.421, loss: 0.014945\n",
      "step:    44940, time: 0.416, loss: 0.009705\n",
      "step:    44960, time: 0.396, loss: 0.012946\n",
      "step:    44980, time: 0.394, loss: 0.011450\n",
      "step:    45000, time: 0.396, loss: 0.006980\n",
      "step:    45020, time: 0.402, loss: 0.010462\n",
      "step:    45040, time: 0.399, loss: 0.010201\n",
      "step:    45060, time: 0.431, loss: 0.020405\n",
      "step:    45080, time: 0.405, loss: 0.008256\n",
      "step:    45100, time: 0.409, loss: 0.015373\n",
      "step:    45120, time: 0.382, loss: 0.010379\n",
      "step:    45140, time: 0.402, loss: 0.010720\n",
      "step:    45160, time: 0.387, loss: 0.023954\n",
      "step:    45180, time: 0.398, loss: 0.012732\n",
      "step:    45200, time: 0.392, loss: 0.019852\n",
      "step:    45220, time: 0.389, loss: 0.014198\n",
      "step:    45240, time: 0.386, loss: 0.018768\n",
      "step:    45260, time: 0.435, loss: 0.017053\n",
      "step:    45280, time: 0.396, loss: 0.038126\n",
      "step:    45300, time: 0.399, loss: 0.012011\n",
      "step:    45320, time: 0.403, loss: 0.014244\n",
      "step:    45340, time: 0.361, loss: 0.016652\n",
      "step:    45360, time: 0.419, loss: 0.021487\n",
      "step:    45380, time: 0.391, loss: 0.017905\n",
      "step:    45400, time: 0.394, loss: 0.015257\n",
      "step:    45420, time: 0.401, loss: 0.013703\n",
      "step:    45440, time: 0.387, loss: 0.009871\n",
      "step:    45460, time: 0.382, loss: 0.011016\n",
      "step:    45480, time: 0.462, loss: 0.016311\n",
      "step:    45500, time: 0.409, loss: 0.015506\n",
      "step:    45520, time: 0.417, loss: 0.008304\n",
      "step:    45540, time: 0.400, loss: 0.016031\n",
      "step:    45560, time: 0.405, loss: 0.019468\n",
      "step:    45580, time: 0.390, loss: 0.018310\n",
      "step:    45600, time: 0.408, loss: 0.013038\n",
      "step:    45620, time: 0.390, loss: 0.019025\n",
      "step:    45640, time: 0.418, loss: 0.017414\n",
      "step:    45660, time: 0.456, loss: 0.013784\n",
      "step:    45680, time: 0.383, loss: 0.006868\n",
      "step:    45700, time: 0.396, loss: 0.011748\n",
      "step:    45720, time: 0.401, loss: 0.014397\n",
      "step:    45740, time: 0.408, loss: 0.013216\n",
      "step:    45760, time: 0.419, loss: 0.062932\n",
      "step:    45780, time: 0.373, loss: 0.015345\n",
      "step:    45800, time: 0.402, loss: 0.016342\n",
      "step:    45820, time: 0.391, loss: 0.019283\n",
      "step:    45840, time: 0.408, loss: 0.012934\n",
      "step:    45860, time: 0.406, loss: 0.014454\n",
      "step:    45880, time: 0.415, loss: 0.013479\n",
      "step:    45900, time: 0.392, loss: 0.010941\n",
      "step:    45920, time: 0.396, loss: 0.010091\n",
      "step:    45940, time: 0.396, loss: 0.015713\n",
      "step:    45960, time: 0.428, loss: 0.015322\n",
      "step:    45980, time: 0.391, loss: 0.009704\n",
      "step:    46000, time: 0.428, loss: 0.117854\n",
      "step:    46020, time: 0.397, loss: 0.021414\n",
      "step:    46040, time: 0.393, loss: 0.022713\n",
      "step:    46060, time: 0.380, loss: 0.015386\n",
      "step:    46080, time: 0.401, loss: 0.021453\n",
      "step:    46100, time: 0.387, loss: 0.009435\n",
      "step:    46120, time: 0.394, loss: 0.009606\n",
      "step:    46140, time: 0.398, loss: 0.018491\n",
      "step:    46160, time: 0.418, loss: 0.014542\n",
      "step:    46180, time: 0.390, loss: 0.027676\n",
      "step:    46200, time: 0.394, loss: 0.016243\n",
      "step:    46220, time: 0.395, loss: 0.016406\n",
      "step:    46240, time: 0.402, loss: 0.017148\n",
      "step:    46260, time: 0.390, loss: 0.016642\n",
      "step:    46280, time: 0.386, loss: 0.011767\n",
      "step:    46300, time: 0.407, loss: 0.019056\n",
      "step:    46320, time: 0.384, loss: 0.001865\n",
      "step:    46340, time: 0.396, loss: 0.019228\n",
      "step:    46360, time: 0.403, loss: 0.015500\n",
      "step:    46380, time: 0.373, loss: 0.004365\n",
      "step:    46400, time: 0.399, loss: 0.010153\n",
      "step:    46420, time: 0.374, loss: 0.021080\n",
      "step:    46440, time: 0.406, loss: 0.024012\n",
      "step:    46460, time: 0.397, loss: 0.019054\n",
      "step:    46480, time: 0.403, loss: 0.016067\n",
      "step:    46500, time: 0.406, loss: 0.016428\n",
      "step:    46520, time: 0.417, loss: 0.025446\n",
      "step:    46540, time: 0.370, loss: 0.006138\n",
      "step:    46560, time: 0.394, loss: 0.014355\n",
      "step:    46580, time: 0.379, loss: 0.016651\n",
      "step:    46600, time: 0.426, loss: 0.023520\n",
      "step:    46620, time: 0.378, loss: 0.022493\n",
      "step:    46640, time: 0.423, loss: 0.023081\n",
      "step:    46660, time: 0.394, loss: 0.018522\n",
      "step:    46680, time: 0.401, loss: 0.009349\n",
      "step:    46700, time: 0.386, loss: 0.014155\n",
      "step:    46720, time: 0.399, loss: 0.012366\n",
      "step:    46740, time: 0.397, loss: 0.013743\n",
      "step:    46760, time: 0.384, loss: 0.014482\n",
      "step:    46780, time: 0.402, loss: 0.019832\n",
      "step:    46800, time: 0.402, loss: 0.011561\n",
      "step:    46820, time: 0.389, loss: 0.006397\n",
      "step:    46840, time: 0.378, loss: 0.013545\n",
      "step:    46860, time: 0.400, loss: 0.020251\n",
      "step:    46880, time: 0.382, loss: 0.007507\n",
      "step:    46900, time: 0.398, loss: 0.006543\n",
      "step:    46920, time: 0.433, loss: 0.150350\n",
      "step:    46940, time: 0.400, loss: 0.021642\n",
      "step:    46960, time: 0.400, loss: 0.024343\n",
      "step:    46980, time: 0.416, loss: 0.019413\n",
      "step:    47000, time: 0.399, loss: 0.019755\n",
      "step:    47020, time: 0.380, loss: 0.020774\n",
      "step:    47040, time: 0.428, loss: 0.020384\n",
      "step:    47060, time: 0.403, loss: 0.013027\n",
      "step:    47080, time: 0.412, loss: 0.013583\n",
      "step:    47100, time: 0.403, loss: 0.011755\n",
      "step:    47120, time: 0.401, loss: 0.021503\n",
      "step:    47140, time: 0.416, loss: 0.013133\n",
      "step:    47160, time: 0.395, loss: 0.016212\n",
      "step:    47180, time: 0.398, loss: 0.013334\n",
      "step:    47200, time: 0.381, loss: 0.009692\n",
      "step:    47220, time: 0.395, loss: 0.013187\n",
      "step:    47240, time: 0.417, loss: 0.012114\n",
      "step:    47260, time: 0.408, loss: 0.017922\n",
      "step:    47280, time: 0.398, loss: 0.018558\n",
      "step:    47300, time: 0.382, loss: 0.006815\n",
      "step:    47320, time: 0.392, loss: 0.007507\n",
      "step:    47340, time: 0.378, loss: 0.009706\n",
      "step:    47360, time: 0.373, loss: 0.011068\n",
      "step:    47380, time: 0.409, loss: 0.013424\n",
      "step:    47400, time: 0.379, loss: 0.016137\n",
      "step:    47420, time: 0.418, loss: 0.009244\n",
      "step:    47440, time: 0.418, loss: 0.018049\n",
      "step:    47460, time: 0.399, loss: 0.011083\n",
      "step:    47480, time: 0.401, loss: 0.020726\n",
      "step:    47500, time: 0.400, loss: 0.015030\n",
      "step:    47520, time: 0.384, loss: 0.008599\n",
      "step:    47540, time: 0.402, loss: 0.021716\n",
      "step:    47560, time: 0.402, loss: 0.008084\n",
      "step:    47580, time: 0.405, loss: 0.014957\n",
      "step:    47600, time: 0.398, loss: 0.008138\n",
      "step:    47620, time: 0.388, loss: 0.017803\n",
      "step:    47640, time: 0.422, loss: 0.010544\n",
      "step:    47660, time: 0.391, loss: 0.016830\n",
      "step:    47680, time: 0.412, loss: 0.013780\n",
      "step:    47700, time: 0.387, loss: 0.010693\n",
      "step:    47720, time: 0.392, loss: 0.016125\n",
      "step:    47740, time: 0.408, loss: 0.015415\n",
      "step:    47760, time: 0.404, loss: 0.013826\n",
      "step:    47780, time: 0.376, loss: 0.013008\n",
      "step:    47800, time: 0.416, loss: 0.012282\n",
      "step:    47820, time: 0.377, loss: 0.013440\n",
      "step:    47840, time: 0.396, loss: 0.010387\n",
      "step:    47860, time: 0.391, loss: 0.009728\n",
      "step:    47880, time: 0.409, loss: 0.014691\n",
      "step:    47900, time: 0.420, loss: 0.021714\n",
      "step:    47920, time: 0.367, loss: 0.010622\n",
      "step:    47940, time: 0.420, loss: 0.017524\n",
      "step:    47960, time: 0.381, loss: 0.014502\n",
      "step:    47980, time: 0.412, loss: 0.012669\n",
      "step:    48000, time: 0.389, loss: 0.012780\n",
      "step:    48020, time: 0.379, loss: 0.012904\n",
      "step:    48040, time: 0.385, loss: 0.013835\n",
      "step:    48060, time: 0.406, loss: 0.020905\n",
      "step:    48080, time: 0.406, loss: 0.014057\n",
      "step:    48100, time: 0.404, loss: 0.015856\n",
      "step:    48120, time: 0.380, loss: 0.021871\n",
      "step:    48140, time: 0.387, loss: 0.018496\n",
      "step:    48160, time: 0.398, loss: 0.005297\n",
      "step:    48180, time: 0.411, loss: 0.014201\n",
      "step:    48200, time: 0.395, loss: 0.013728\n",
      "step:    48220, time: 0.379, loss: 0.021690\n",
      "step:    48240, time: 0.380, loss: 0.012690\n",
      "step:    48260, time: 0.413, loss: 0.020299\n",
      "step:    48280, time: 0.391, loss: 0.012683\n",
      "step:    48300, time: 0.404, loss: 0.015807\n",
      "step:    48320, time: 0.392, loss: 0.021610\n",
      "step:    48340, time: 0.440, loss: 0.019935\n",
      "step:    48360, time: 0.370, loss: 0.012495\n",
      "step:    48380, time: 0.377, loss: 0.018439\n",
      "step:    48400, time: 0.393, loss: 0.015802\n",
      "step:    48420, time: 0.401, loss: 0.010648\n",
      "step:    48440, time: 0.379, loss: 0.007808\n",
      "step:    48460, time: 0.400, loss: 0.015903\n",
      "step:    48480, time: 0.400, loss: 0.010340\n",
      "step:    48500, time: 0.417, loss: 0.012562\n",
      "step:    48520, time: 0.425, loss: 0.008691\n",
      "step:    48540, time: 0.457, loss: 0.012372\n",
      "step:    48560, time: 0.422, loss: 0.014580\n",
      "step:    48580, time: 0.404, loss: 0.013510\n",
      "step:    48600, time: 0.413, loss: 0.022889\n",
      "step:    48620, time: 0.393, loss: 0.011199\n",
      "step:    48640, time: 0.419, loss: 0.023916\n",
      "step:    48660, time: 0.424, loss: 0.014743\n",
      "step:    48680, time: 0.390, loss: 0.020600\n",
      "step:    48700, time: 0.411, loss: 0.019893\n",
      "step:    48720, time: 0.431, loss: 0.014927\n",
      "step:    48740, time: 0.389, loss: 0.009065\n",
      "step:    48760, time: 0.427, loss: 0.019397\n",
      "step:    48780, time: 0.383, loss: 0.021882\n",
      "step:    48800, time: 0.421, loss: 0.017017\n",
      "step:    48820, time: 0.419, loss: 0.017980\n",
      "step:    48840, time: 0.397, loss: 0.010577\n",
      "step:    48860, time: 0.372, loss: 0.023777\n",
      "step:    48880, time: 0.410, loss: 0.015079\n",
      "step:    48900, time: 0.427, loss: 0.010390\n",
      "step:    48920, time: 0.387, loss: 0.022427\n",
      "step:    48940, time: 0.379, loss: 0.020864\n",
      "step:    48960, time: 0.390, loss: 0.011391\n",
      "step:    48980, time: 0.399, loss: 0.022985\n",
      "step:    49000, time: 0.406, loss: 0.016797\n",
      "step:    49020, time: 0.411, loss: 0.004147\n",
      "step:    49040, time: 0.422, loss: 0.014954\n",
      "step:    49060, time: 0.388, loss: 0.008508\n",
      "step:    49080, time: 0.414, loss: 0.011684\n",
      "step:    49100, time: 0.396, loss: 0.015634\n",
      "step:    49120, time: 0.404, loss: 0.016543\n",
      "step:    49140, time: 0.385, loss: 0.008719\n",
      "step:    49160, time: 0.403, loss: 0.005228\n",
      "step:    49180, time: 0.396, loss: 0.024239\n",
      "step:    49200, time: 0.406, loss: 0.024106\n",
      "step:    49220, time: 0.397, loss: 0.018863\n",
      "step:    49240, time: 0.383, loss: 0.013946\n",
      "step:    49260, time: 0.439, loss: 0.012220\n",
      "step:    49280, time: 0.403, loss: 0.011718\n",
      "step:    49300, time: 0.401, loss: 0.016245\n",
      "step:    49320, time: 0.418, loss: 0.016065\n",
      "step:    49340, time: 0.404, loss: 0.018980\n",
      "step:    49360, time: 0.409, loss: 0.021971\n",
      "step:    49380, time: 0.413, loss: 0.013733\n",
      "step:    49400, time: 0.427, loss: 0.018276\n",
      "step:    49420, time: 0.427, loss: 0.101966\n",
      "step:    49440, time: 0.387, loss: 0.017405\n",
      "step:    49460, time: 0.390, loss: 0.003651\n",
      "step:    49480, time: 0.407, loss: 0.013612\n",
      "step:    49500, time: 0.400, loss: 0.015690\n",
      "step:    49520, time: 0.397, loss: 0.026067\n",
      "step:    49540, time: 0.405, loss: 0.012542\n",
      "step:    49560, time: 0.392, loss: 0.012561\n",
      "step:    49580, time: 0.404, loss: 0.020222\n",
      "step:    49600, time: 0.399, loss: 0.004700\n",
      "step:    49620, time: 0.388, loss: 0.019208\n",
      "step:    49640, time: 0.407, loss: 0.021839\n",
      "step:    49660, time: 0.410, loss: 0.021517\n",
      "step:    49680, time: 0.409, loss: 0.012391\n",
      "step:    49700, time: 0.386, loss: 0.020404\n",
      "step:    49720, time: 0.410, loss: 0.014648\n",
      "step:    49740, time: 0.403, loss: 0.017955\n",
      "step:    49760, time: 0.375, loss: 0.013292\n",
      "step:    49780, time: 0.378, loss: 0.009237\n",
      "step:    49800, time: 0.389, loss: 0.010738\n",
      "step:    49820, time: 0.418, loss: 0.016982\n",
      "step:    49840, time: 0.377, loss: 0.018583\n",
      "step:    49860, time: 0.396, loss: 0.021220\n",
      "step:    49880, time: 0.378, loss: 0.014267\n",
      "step:    49900, time: 0.388, loss: 0.016006\n",
      "step:    49920, time: 0.420, loss: 0.010345\n",
      "step:    49940, time: 0.393, loss: 0.022121\n",
      "step:    49960, time: 0.399, loss: 0.012010\n",
      "step:    49980, time: 0.385, loss: 0.017915\n",
      "step:    50000, time: 0.392, loss: 0.015710\n",
      "step:    50020, time: 0.400, loss: 0.023077\n",
      "step:    50040, time: 0.398, loss: 0.014325\n",
      "step:    50060, time: 0.385, loss: 0.013799\n",
      "step:    50080, time: 0.383, loss: 0.011039\n",
      "step:    50100, time: 0.426, loss: 0.015213\n",
      "step:    50120, time: 0.386, loss: 0.011988\n",
      "step:    50140, time: 0.381, loss: 0.015437\n",
      "step:    50160, time: 0.390, loss: 0.016451\n",
      "step:    50180, time: 0.400, loss: 0.012091\n",
      "step:    50200, time: 0.400, loss: 0.016143\n",
      "step:    50220, time: 0.396, loss: 0.027326\n",
      "step:    50240, time: 0.364, loss: 0.013937\n",
      "step:    50260, time: 0.389, loss: 0.011795\n",
      "step:    50280, time: 0.376, loss: 0.008207\n",
      "step:    50300, time: 0.401, loss: 0.021227\n",
      "step:    50320, time: 0.398, loss: 0.010050\n",
      "step:    50340, time: 0.393, loss: 0.008074\n",
      "step:    50360, time: 0.383, loss: 0.017126\n",
      "step:    50380, time: 0.431, loss: 0.035061\n",
      "step:    50400, time: 0.395, loss: 0.009179\n",
      "step:    50420, time: 0.400, loss: 0.011547\n",
      "step:    50440, time: 0.380, loss: 0.023306\n",
      "step:    50460, time: 0.379, loss: 0.011846\n",
      "step:    50480, time: 0.375, loss: 0.010614\n",
      "step:    50500, time: 0.380, loss: 0.009882\n",
      "step:    50520, time: 0.384, loss: 0.013994\n",
      "step:    50540, time: 0.416, loss: 0.007776\n",
      "step:    50560, time: 0.385, loss: 0.017595\n",
      "step:    50580, time: 0.387, loss: 0.015298\n",
      "step:    50600, time: 0.425, loss: 0.021334\n",
      "step:    50620, time: 0.404, loss: 0.022645\n",
      "step:    50640, time: 0.397, loss: 0.024599\n",
      "step:    50660, time: 0.436, loss: 0.009483\n",
      "step:    50680, time: 0.375, loss: 0.015088\n",
      "step:    50700, time: 0.388, loss: 0.007103\n",
      "step:    50720, time: 0.406, loss: 0.020836\n",
      "step:    50740, time: 0.389, loss: 0.008560\n",
      "step:    50760, time: 0.385, loss: 0.009900\n",
      "step:    50780, time: 0.416, loss: 0.008777\n",
      "step:    50800, time: 0.386, loss: 0.012791\n",
      "step:    50820, time: 0.418, loss: 0.013900\n",
      "step:    50840, time: 0.406, loss: 0.019644\n",
      "step:    50860, time: 0.422, loss: 0.020521\n",
      "step:    50880, time: 0.402, loss: 0.010876\n",
      "step:    50900, time: 0.416, loss: 0.014929\n",
      "step:    50920, time: 0.395, loss: 0.016822\n",
      "step:    50940, time: 0.402, loss: 0.012006\n",
      "step:    50960, time: 0.399, loss: 0.015591\n",
      "step:    50980, time: 0.394, loss: 0.020966\n",
      "step:    51000, time: 0.378, loss: 0.018025\n",
      "step:    51020, time: 0.399, loss: 0.012570\n",
      "step:    51040, time: 0.416, loss: 0.017870\n",
      "step:    51060, time: 0.390, loss: 0.020251\n",
      "step:    51080, time: 0.429, loss: 0.021006\n",
      "step:    51100, time: 0.385, loss: 0.009071\n",
      "step:    51120, time: 0.430, loss: 0.133995\n",
      "step:    51140, time: 0.422, loss: 0.012942\n",
      "step:    51160, time: 0.377, loss: 0.028168\n",
      "step:    51180, time: 0.408, loss: 0.023078\n",
      "step:    51200, time: 0.397, loss: 0.016069\n",
      "step:    51220, time: 0.417, loss: 0.016219\n",
      "step:    51240, time: 0.380, loss: 0.016278\n",
      "step:    51260, time: 0.372, loss: 0.017473\n",
      "step:    51280, time: 0.402, loss: 0.020838\n",
      "step:    51300, time: 0.418, loss: 0.014416\n",
      "step:    51320, time: 0.411, loss: 0.015353\n",
      "step:    51340, time: 0.410, loss: 0.135236\n",
      "step:    51360, time: 0.402, loss: 0.019005\n",
      "step:    51380, time: 0.360, loss: 0.005525\n",
      "step:    51400, time: 0.426, loss: 0.016740\n",
      "step:    51420, time: 0.368, loss: 0.012617\n",
      "step:    51440, time: 0.400, loss: 0.014407\n",
      "step:    51460, time: 0.399, loss: 0.013495\n",
      "step:    51480, time: 0.395, loss: 0.010160\n",
      "step:    51500, time: 0.406, loss: 0.016088\n",
      "step:    51520, time: 0.380, loss: 0.018725\n",
      "step:    51540, time: 0.411, loss: 0.018679\n",
      "step:    51560, time: 0.395, loss: 0.012937\n",
      "step:    51580, time: 0.398, loss: 0.009295\n",
      "step:    51600, time: 0.406, loss: 0.015254\n",
      "step:    51620, time: 0.404, loss: 0.017724\n",
      "step:    51640, time: 0.411, loss: 0.015970\n",
      "step:    51660, time: 0.400, loss: 0.019118\n",
      "step:    51680, time: 0.388, loss: 0.008292\n",
      "step:    51700, time: 0.420, loss: 0.009314\n",
      "step:    51720, time: 0.412, loss: 0.017340\n",
      "step:    51740, time: 0.407, loss: 0.022038\n",
      "step:    51760, time: 0.388, loss: 0.014455\n",
      "step:    51780, time: 0.396, loss: 0.017897\n",
      "step:    51800, time: 0.410, loss: 0.018107\n",
      "step:    51820, time: 0.370, loss: 0.012146\n",
      "step:    51840, time: 0.433, loss: 0.128948\n",
      "step:    51860, time: 0.404, loss: 0.015580\n",
      "step:    51880, time: 0.424, loss: 0.020022\n",
      "step:    51900, time: 0.381, loss: 0.006708\n",
      "step:    51920, time: 0.380, loss: 0.011085\n",
      "step:    51940, time: 0.438, loss: 0.183925\n",
      "step:    51960, time: 0.413, loss: 0.015895\n",
      "step:    51980, time: 0.396, loss: 0.021298\n",
      "step:    52000, time: 0.376, loss: 0.008876\n",
      "step:    52020, time: 0.410, loss: 0.016690\n",
      "step:    52040, time: 0.392, loss: 0.029043\n",
      "step:    52060, time: 0.396, loss: 0.006690\n",
      "step:    52080, time: 0.412, loss: 0.015429\n",
      "step:    52100, time: 0.419, loss: 0.009450\n",
      "step:    52120, time: 0.426, loss: 0.019154\n",
      "step:    52140, time: 0.434, loss: 0.023647\n",
      "step:    52160, time: 0.411, loss: 0.012594\n",
      "step:    52180, time: 0.396, loss: 0.017869\n",
      "step:    52200, time: 0.372, loss: 0.008993\n",
      "step:    52220, time: 0.408, loss: 0.014029\n",
      "step:    52240, time: 0.392, loss: 0.012360\n",
      "step:    52260, time: 0.407, loss: 0.010605\n",
      "step:    52280, time: 0.389, loss: 0.015802\n",
      "step:    52300, time: 0.417, loss: 0.012373\n",
      "step:    52320, time: 0.416, loss: 0.013984\n",
      "step:    52340, time: 0.441, loss: 0.010124\n",
      "step:    52360, time: 0.411, loss: 0.011578\n",
      "step:    52380, time: 0.410, loss: 0.016342\n",
      "step:    52400, time: 0.397, loss: 0.014917\n",
      "step:    52420, time: 0.431, loss: 0.013330\n",
      "step:    52440, time: 0.409, loss: 0.019767\n",
      "step:    52460, time: 0.388, loss: 0.019943\n",
      "step:    52480, time: 0.399, loss: 0.016382\n",
      "step:    52500, time: 0.396, loss: 0.015622\n",
      "step:    52520, time: 0.411, loss: 0.013956\n",
      "step:    52540, time: 0.403, loss: 0.023403\n",
      "step:    52560, time: 0.407, loss: 0.008498\n",
      "step:    52580, time: 0.388, loss: 0.015156\n",
      "step:    52600, time: 0.381, loss: 0.007316\n",
      "step:    52620, time: 0.380, loss: 0.009659\n",
      "step:    52640, time: 0.385, loss: 0.018808\n",
      "step:    52660, time: 0.390, loss: 0.011223\n",
      "step:    52680, time: 0.418, loss: 0.022761\n",
      "step:    52700, time: 0.384, loss: 0.015238\n",
      "step:    52720, time: 0.381, loss: 0.016090\n",
      "step:    52740, time: 0.407, loss: 0.010992\n",
      "step:    52760, time: 0.406, loss: 0.020027\n",
      "step:    52780, time: 0.409, loss: 0.006831\n",
      "step:    52800, time: 0.405, loss: 0.007157\n",
      "step:    52820, time: 0.410, loss: 0.014771\n",
      "step:    52840, time: 0.388, loss: 0.012005\n",
      "step:    52860, time: 0.385, loss: 0.005474\n",
      "step:    52880, time: 0.410, loss: 0.010126\n",
      "step:    52900, time: 0.425, loss: 0.015617\n",
      "step:    52920, time: 0.373, loss: 0.012062\n",
      "step:    52940, time: 0.391, loss: 0.012093\n",
      "step:    52960, time: 0.382, loss: 0.017373\n",
      "step:    52980, time: 0.415, loss: 0.019728\n",
      "step:    53000, time: 0.394, loss: 0.012386\n",
      "step:    53020, time: 0.422, loss: 0.015267\n",
      "step:    53040, time: 0.405, loss: 0.017839\n",
      "step:    53060, time: 0.484, loss: 0.093381\n",
      "step:    53080, time: 0.403, loss: 0.021131\n",
      "step:    53100, time: 0.395, loss: 0.020051\n",
      "step:    53120, time: 0.432, loss: 0.021086\n",
      "step:    53140, time: 0.384, loss: 0.018766\n",
      "step:    53160, time: 0.415, loss: 0.013585\n",
      "step:    53180, time: 0.405, loss: 0.033633\n",
      "step:    53200, time: 0.404, loss: 0.011814\n",
      "step:    53220, time: 0.406, loss: 0.011363\n",
      "step:    53240, time: 0.434, loss: 0.015247\n",
      "step:    53260, time: 0.406, loss: 0.019894\n",
      "step:    53280, time: 0.403, loss: 0.016228\n",
      "step:    53300, time: 0.374, loss: 0.020918\n",
      "step:    53320, time: 0.408, loss: 0.018146\n",
      "step:    53340, time: 0.115, loss: 0.005986\n",
      "step:    53360, time: 0.389, loss: 0.020364\n",
      "step:    53380, time: 0.380, loss: 0.009332\n",
      "step:    53400, time: 0.412, loss: 0.008361\n",
      "step:    53420, time: 0.433, loss: 0.102556\n",
      "step:    53440, time: 0.389, loss: 0.013209\n",
      "step:    53460, time: 0.377, loss: 0.018504\n",
      "step:    53480, time: 0.405, loss: 0.019610\n",
      "step:    53500, time: 0.383, loss: 0.021386\n",
      "step:    53520, time: 0.403, loss: 0.014806\n",
      "step:    53540, time: 0.412, loss: 0.013644\n",
      "step:    53560, time: 0.426, loss: 0.016589\n",
      "step:    53580, time: 0.362, loss: 0.011247\n",
      "step:    53600, time: 0.384, loss: 0.023172\n",
      "step:    53620, time: 0.389, loss: 0.012962\n",
      "step:    53640, time: 0.390, loss: 0.015867\n",
      "step:    53660, time: 0.420, loss: 0.014878\n",
      "step:    53680, time: 0.397, loss: 0.014841\n",
      "step:    53700, time: 0.394, loss: 0.007887\n",
      "step:    53720, time: 0.440, loss: 0.013350\n",
      "step:    53740, time: 0.394, loss: 0.015887\n",
      "step:    53760, time: 0.397, loss: 0.017229\n",
      "step:    53780, time: 0.390, loss: 0.018793\n",
      "step:    53800, time: 0.383, loss: 0.018096\n",
      "step:    53820, time: 0.382, loss: 0.015135\n",
      "step:    53840, time: 0.384, loss: 0.013695\n",
      "step:    53860, time: 0.389, loss: 0.012095\n",
      "step:    53880, time: 0.385, loss: 0.013952\n",
      "step:    53900, time: 0.432, loss: 0.022286\n",
      "step:    53920, time: 0.403, loss: 0.016378\n",
      "step:    53940, time: 0.403, loss: 0.017760\n",
      "step:    53960, time: 0.384, loss: 0.008676\n",
      "step:    53980, time: 0.397, loss: 0.017606\n",
      "step:    54000, time: 0.391, loss: 0.009901\n",
      "step:    54020, time: 0.409, loss: 0.014624\n",
      "step:    54040, time: 0.372, loss: 0.007796\n",
      "step:    54060, time: 0.409, loss: 0.016145\n",
      "step:    54080, time: 0.395, loss: 0.014715\n",
      "step:    54100, time: 0.407, loss: 0.017563\n",
      "step:    54120, time: 0.381, loss: 0.015057\n",
      "step:    54140, time: 0.399, loss: 0.012913\n",
      "step:    54160, time: 0.398, loss: 0.023041\n",
      "step:    54180, time: 0.407, loss: 0.025011\n",
      "step:    54200, time: 0.414, loss: 0.010209\n",
      "step:    54220, time: 0.403, loss: 0.015875\n",
      "step:    54240, time: 0.383, loss: 0.010654\n",
      "step:    54260, time: 0.411, loss: 0.011683\n",
      "step:    54280, time: 0.401, loss: 0.016942\n",
      "step:    54300, time: 0.425, loss: 0.018182\n",
      "step:    54320, time: 0.399, loss: 0.027447\n",
      "step:    54340, time: 0.406, loss: 0.020376\n",
      "step:    54360, time: 0.392, loss: 0.016431\n",
      "step:    54380, time: 0.418, loss: 0.019216\n",
      "step:    54400, time: 0.400, loss: 0.158000\n",
      "step:    54420, time: 0.429, loss: 0.013244\n",
      "step:    54440, time: 0.395, loss: 0.017759\n",
      "step:    54460, time: 0.416, loss: 0.013003\n",
      "step:    54480, time: 0.436, loss: 0.019190\n",
      "step:    54500, time: 0.409, loss: 0.019399\n",
      "step:    54520, time: 0.414, loss: 0.013267\n",
      "step:    54540, time: 0.384, loss: 0.011005\n",
      "step:    54560, time: 0.399, loss: 0.015316\n",
      "step:    54580, time: 0.383, loss: 0.018359\n",
      "step:    54600, time: 0.395, loss: 0.018716\n",
      "step:    54620, time: 0.402, loss: 0.014783\n",
      "step:    54640, time: 0.438, loss: 0.016044\n",
      "step:    54660, time: 0.386, loss: 0.005412\n",
      "step:    54680, time: 0.425, loss: 0.006640\n",
      "step:    54700, time: 0.402, loss: 0.009520\n",
      "step:    54720, time: 0.404, loss: 0.009318\n",
      "step:    54740, time: 0.417, loss: 0.008313\n",
      "step:    54760, time: 0.367, loss: 0.007197\n",
      "step:    54780, time: 0.380, loss: 0.013580\n",
      "step:    54800, time: 0.451, loss: 0.018203\n",
      "step:    54820, time: 0.388, loss: 0.007090\n",
      "step:    54840, time: 0.400, loss: 0.006112\n",
      "step:    54860, time: 0.400, loss: 0.019851\n",
      "step:    54880, time: 0.394, loss: 0.012564\n",
      "step:    54900, time: 0.377, loss: 0.005814\n",
      "step:    54920, time: 0.407, loss: 0.015120\n",
      "step:    54940, time: 0.400, loss: 0.017727\n",
      "step:    54960, time: 0.365, loss: 0.013112\n",
      "step:    54980, time: 0.414, loss: 0.014962\n",
      "step:    55000, time: 0.399, loss: 0.013835\n",
      "step:    55020, time: 0.372, loss: 0.010629\n",
      "step:    55040, time: 0.389, loss: 0.016625\n",
      "step:    55060, time: 0.398, loss: 0.017501\n",
      "step:    55080, time: 0.387, loss: 0.021959\n",
      "step:    55100, time: 0.417, loss: 0.019519\n",
      "step:    55120, time: 0.412, loss: 0.013384\n",
      "step:    55140, time: 0.401, loss: 0.007484\n",
      "step:    55160, time: 0.389, loss: 0.011841\n",
      "step:    55180, time: 0.390, loss: 0.018764\n",
      "step:    55200, time: 0.417, loss: 0.012229\n",
      "step:    55220, time: 0.425, loss: 0.021879\n",
      "step:    55240, time: 0.384, loss: 0.009245\n",
      "step:    55260, time: 0.372, loss: 0.021534\n",
      "step:    55280, time: 0.424, loss: 0.014352\n",
      "step:    55300, time: 0.441, loss: 0.019751\n",
      "step:    55320, time: 0.446, loss: 0.021309\n",
      "step:    55340, time: 0.419, loss: 0.006733\n",
      "step:    55360, time: 0.425, loss: 0.017081\n",
      "step:    55380, time: 0.424, loss: 0.020294\n",
      "step:    55400, time: 0.457, loss: 0.015965\n",
      "step:    55420, time: 0.392, loss: 0.016839\n",
      "step:    55440, time: 0.377, loss: 0.021552\n",
      "step:    55460, time: 0.374, loss: 0.012843\n",
      "step:    55480, time: 0.361, loss: 0.040258\n",
      "step:    55500, time: 0.401, loss: 0.007172\n",
      "step:    55520, time: 0.402, loss: 0.011483\n",
      "step:    55540, time: 0.402, loss: 0.015168\n",
      "step:    55560, time: 0.430, loss: 0.019589\n",
      "step:    55580, time: 0.401, loss: 0.008979\n",
      "step:    55600, time: 0.375, loss: 0.016170\n",
      "step:    55620, time: 0.390, loss: 0.005730\n",
      "step:    55640, time: 0.404, loss: 0.016708\n",
      "step:    55660, time: 0.388, loss: 0.026113\n",
      "step:    55680, time: 0.395, loss: 0.022371\n",
      "step:    55700, time: 0.412, loss: 0.021234\n",
      "step:    55720, time: 0.408, loss: 0.010912\n",
      "step:    55740, time: 0.420, loss: 0.015166\n",
      "step:    55760, time: 0.411, loss: 0.011993\n",
      "step:    55780, time: 0.391, loss: 0.015550\n",
      "step:    55800, time: 0.411, loss: 0.013104\n",
      "step:    55820, time: 0.423, loss: 0.013700\n",
      "step:    55840, time: 0.383, loss: 0.019233\n",
      "step:    55860, time: 0.388, loss: 0.008956\n",
      "step:    55880, time: 0.394, loss: 0.014137\n",
      "step:    55900, time: 0.362, loss: 0.018506\n",
      "step:    55920, time: 0.391, loss: 0.012132\n",
      "step:    55940, time: 0.387, loss: 0.019853\n",
      "step:    55960, time: 0.408, loss: 0.015595\n",
      "step:    55980, time: 0.423, loss: 0.018533\n",
      "step:    56000, time: 0.394, loss: 0.020931\n",
      "step:    56020, time: 0.384, loss: 0.019199\n",
      "step:    56040, time: 0.389, loss: 0.015652\n",
      "step:    56060, time: 0.409, loss: 0.012792\n",
      "step:    56080, time: 0.398, loss: 0.015980\n",
      "step:    56100, time: 0.423, loss: 0.014278\n",
      "step:    56120, time: 0.426, loss: 0.027160\n",
      "step:    56140, time: 0.388, loss: 0.016340\n",
      "step:    56160, time: 0.386, loss: 0.005800\n",
      "step:    56180, time: 0.406, loss: 0.019944\n",
      "step:    56200, time: 0.407, loss: 0.020821\n",
      "step:    56220, time: 0.435, loss: 0.012671\n",
      "step:    56240, time: 0.425, loss: 0.015700\n",
      "step:    56260, time: 0.423, loss: 0.019124\n",
      "step:    56280, time: 0.401, loss: 0.014739\n",
      "step:    56300, time: 0.416, loss: 0.018564\n",
      "step:    56320, time: 0.386, loss: 0.011995\n",
      "step:    56340, time: 0.420, loss: 0.019876\n",
      "step:    56360, time: 0.413, loss: 0.017018\n",
      "step:    56380, time: 0.420, loss: 0.013177\n",
      "step:    56400, time: 0.422, loss: 0.024110\n",
      "step:    56420, time: 0.382, loss: 0.019358\n",
      "step:    56440, time: 0.399, loss: 0.008851\n",
      "step:    56460, time: 0.418, loss: 0.018321\n",
      "step:    56480, time: 0.457, loss: 0.012332\n",
      "step:    56500, time: 0.411, loss: 0.014595\n",
      "step:    56520, time: 0.390, loss: 0.009781\n",
      "step:    56540, time: 0.450, loss: 0.015447\n",
      "step:    56560, time: 0.415, loss: 0.010348\n",
      "step:    56580, time: 0.402, loss: 0.016896\n",
      "step:    56600, time: 0.378, loss: 0.009161\n",
      "step:    56620, time: 0.405, loss: 0.082308\n",
      "step:    56640, time: 0.372, loss: 0.013733\n",
      "step:    56660, time: 0.422, loss: 0.013827\n",
      "step:    56680, time: 0.399, loss: 0.015189\n",
      "step:    56700, time: 0.395, loss: 0.009676\n",
      "step:    56720, time: 0.391, loss: 0.024033\n",
      "step:    56740, time: 0.416, loss: 0.059199\n",
      "step:    56760, time: 0.414, loss: 0.015115\n",
      "step:    56780, time: 0.389, loss: 0.022040\n",
      "step:    56800, time: 0.396, loss: 0.014584\n",
      "step:    56820, time: 0.389, loss: 0.012966\n",
      "step:    56840, time: 0.418, loss: 0.016613\n",
      "step:    56860, time: 0.398, loss: 0.012303\n",
      "step:    56880, time: 0.403, loss: 0.021906\n",
      "step:    56900, time: 0.389, loss: 0.011997\n",
      "step:    56920, time: 0.381, loss: 0.011205\n",
      "step:    56940, time: 0.394, loss: 0.018678\n",
      "step:    56960, time: 0.403, loss: 0.018270\n",
      "step:    56980, time: 0.422, loss: 0.020962\n",
      "step:    57000, time: 0.409, loss: 0.017539\n",
      "step:    57020, time: 0.390, loss: 0.017934\n",
      "step:    57040, time: 0.402, loss: 0.018263\n",
      "step:    57060, time: 0.427, loss: 0.021229\n",
      "step:    57080, time: 0.375, loss: 0.003903\n",
      "step:    57100, time: 0.401, loss: 0.020321\n",
      "step:    57120, time: 0.384, loss: 0.018694\n",
      "step:    57140, time: 0.427, loss: 0.021171\n",
      "step:    57160, time: 0.367, loss: 0.024101\n",
      "step:    57180, time: 0.409, loss: 0.015905\n",
      "step:    57200, time: 0.394, loss: 0.015743\n",
      "step:    57220, time: 0.441, loss: 0.015227\n",
      "step:    57240, time: 0.415, loss: 0.020077\n",
      "step:    57260, time: 0.378, loss: 0.013377\n",
      "step:    57280, time: 0.413, loss: 0.021671\n",
      "step:    57300, time: 0.409, loss: 0.014969\n",
      "step:    57320, time: 0.432, loss: 0.013370\n",
      "step:    57340, time: 0.381, loss: 0.015678\n",
      "step:    57360, time: 0.398, loss: 0.011709\n",
      "step:    57380, time: 0.400, loss: 0.019565\n",
      "step:    57400, time: 0.394, loss: 0.011582\n",
      "step:    57420, time: 0.385, loss: 0.017379\n",
      "step:    57440, time: 0.389, loss: 0.005903\n",
      "step:    57460, time: 0.430, loss: 0.020433\n",
      "step:    57480, time: 0.405, loss: 0.017192\n",
      "step:    57500, time: 0.457, loss: 0.016313\n",
      "step:    57520, time: 0.393, loss: 0.017570\n",
      "step:    57540, time: 0.402, loss: 0.017242\n",
      "step:    57560, time: 0.402, loss: 0.011554\n",
      "step:    57580, time: 0.411, loss: 0.022938\n",
      "step:    57600, time: 0.391, loss: 0.014949\n",
      "step:    57620, time: 0.393, loss: 0.018578\n",
      "step:    57640, time: 0.392, loss: 0.007646\n",
      "step:    57660, time: 0.391, loss: 0.013663\n",
      "step:    57680, time: 0.434, loss: 0.014655\n",
      "step:    57700, time: 0.428, loss: 0.137654\n",
      "step:    57720, time: 0.389, loss: 0.025187\n",
      "step:    57740, time: 0.384, loss: 0.012666\n",
      "step:    57760, time: 0.398, loss: 0.013196\n",
      "step:    57780, time: 0.403, loss: 0.022653\n",
      "step:    57800, time: 0.379, loss: 0.013216\n",
      "step:    57820, time: 0.410, loss: 0.020521\n",
      "step:    57840, time: 0.365, loss: 0.020908\n",
      "step:    57860, time: 0.399, loss: 0.006981\n",
      "step:    57880, time: 0.382, loss: 0.009469\n",
      "step:    57900, time: 0.366, loss: 0.015558\n",
      "step:    57920, time: 0.447, loss: 0.021690\n",
      "step:    57940, time: 0.384, loss: 0.015614\n",
      "step:    57960, time: 0.400, loss: 0.014907\n",
      "step:    57980, time: 0.404, loss: 0.012328\n",
      "step:    58000, time: 0.399, loss: 0.017736\n",
      "step:    58020, time: 0.392, loss: 0.013787\n",
      "step:    58040, time: 0.397, loss: 0.013877\n",
      "step:    58060, time: 0.398, loss: 0.015277\n",
      "step:    58080, time: 0.381, loss: 0.005417\n",
      "step:    58100, time: 0.397, loss: 0.011923\n",
      "step:    58120, time: 0.410, loss: 0.013302\n",
      "step:    58140, time: 0.376, loss: 0.003538\n",
      "step:    58160, time: 0.406, loss: 0.021282\n",
      "step:    58180, time: 0.429, loss: 0.075410\n",
      "step:    58200, time: 0.391, loss: 0.015815\n",
      "step:    58220, time: 0.389, loss: 0.013997\n",
      "step:    58240, time: 0.427, loss: 0.015651\n",
      "step:    58260, time: 0.390, loss: 0.012921\n",
      "step:    58280, time: 0.399, loss: 0.014518\n",
      "step:    58300, time: 0.395, loss: 0.015691\n",
      "step:    58320, time: 0.407, loss: 0.018212\n",
      "step:    58340, time: 0.377, loss: 0.007635\n",
      "step:    58360, time: 0.392, loss: 0.014441\n",
      "step:    58380, time: 0.420, loss: 0.007191\n",
      "step:    58400, time: 0.423, loss: 0.022611\n",
      "step:    58420, time: 0.444, loss: 0.017822\n",
      "step:    58440, time: 0.388, loss: 0.015399\n",
      "step:    58460, time: 0.402, loss: 0.023687\n",
      "step:    58480, time: 0.400, loss: 0.016950\n",
      "step:    58500, time: 0.371, loss: 0.025301\n",
      "step:    58520, time: 0.386, loss: 0.022772\n",
      "step:    58540, time: 0.381, loss: 0.012167\n",
      "step:    58560, time: 0.427, loss: 0.021275\n",
      "step:    58580, time: 0.386, loss: 0.012788\n",
      "step:    58600, time: 0.431, loss: 0.015875\n",
      "step:    58620, time: 0.395, loss: 0.017127\n",
      "step:    58640, time: 0.379, loss: 0.019508\n",
      "step:    58660, time: 0.402, loss: 0.012531\n",
      "step:    58680, time: 0.379, loss: 0.017515\n",
      "step:    58700, time: 0.386, loss: 0.020740\n",
      "step:    58720, time: 0.397, loss: 0.009221\n",
      "step:    58740, time: 0.393, loss: 0.021076\n",
      "step:    58760, time: 0.401, loss: 0.015320\n",
      "step:    58780, time: 0.374, loss: 0.012368\n",
      "step:    58800, time: 0.424, loss: 0.018692\n",
      "step:    58820, time: 0.408, loss: 0.022478\n",
      "step:    58840, time: 0.418, loss: 0.019171\n",
      "step:    58860, time: 0.400, loss: 0.033977\n",
      "step:    58880, time: 0.412, loss: 0.014983\n",
      "step:    58900, time: 0.427, loss: 0.015734\n",
      "step:    58920, time: 0.384, loss: 0.018586\n",
      "step:    58940, time: 0.393, loss: 0.007199\n",
      "step:    58960, time: 0.405, loss: 0.009213\n",
      "step:    58980, time: 0.386, loss: 0.015339\n",
      "step:    59000, time: 0.390, loss: 0.018916\n",
      "step:    59020, time: 0.394, loss: 0.013471\n",
      "step:    59040, time: 0.418, loss: 0.016897\n",
      "step:    59060, time: 0.382, loss: 0.011186\n",
      "step:    59080, time: 0.382, loss: 0.020919\n",
      "step:    59100, time: 0.395, loss: 0.018500\n",
      "step:    59120, time: 0.397, loss: 0.010692\n",
      "step:    59140, time: 0.406, loss: 0.011882\n",
      "step:    59160, time: 0.412, loss: 0.015145\n",
      "step:    59180, time: 0.396, loss: 0.019008\n",
      "step:    59200, time: 0.376, loss: 0.010867\n",
      "step:    59220, time: 0.390, loss: 0.012169\n",
      "step:    59240, time: 0.394, loss: 0.024271\n",
      "step:    59260, time: 0.410, loss: 0.017414\n",
      "step:    59280, time: 0.391, loss: 0.013330\n",
      "step:    59300, time: 0.433, loss: 0.018742\n",
      "step:    59320, time: 0.384, loss: 0.012537\n",
      "step:    59340, time: 0.419, loss: 0.025143\n",
      "step:    59360, time: 0.382, loss: 0.012009\n",
      "step:    59380, time: 0.392, loss: 0.015788\n",
      "step:    59400, time: 0.400, loss: 0.024960\n",
      "step:    59420, time: 0.415, loss: 0.009407\n",
      "step:    59440, time: 0.408, loss: 0.017388\n",
      "step:    59460, time: 0.391, loss: 0.012752\n",
      "step:    59480, time: 0.394, loss: 0.016990\n",
      "step:    59500, time: 0.387, loss: 0.018590\n",
      "step:    59520, time: 0.365, loss: 0.019378\n",
      "step:    59540, time: 0.435, loss: 0.013298\n",
      "step:    59560, time: 0.397, loss: 0.015028\n",
      "step:    59580, time: 0.376, loss: 0.011880\n",
      "step:    59600, time: 0.396, loss: 0.015518\n",
      "step:    59620, time: 0.379, loss: 0.006742\n",
      "step:    59640, time: 0.385, loss: 0.016804\n",
      "step:    59660, time: 0.424, loss: 0.017443\n",
      "step:    59680, time: 0.390, loss: 0.009912\n",
      "step:    59700, time: 0.414, loss: 0.008670\n",
      "step:    59720, time: 0.427, loss: 0.012688\n",
      "step:    59740, time: 0.415, loss: 0.015432\n",
      "step:    59760, time: 0.386, loss: 0.013800\n",
      "step:    59780, time: 0.431, loss: 0.016038\n",
      "step:    59800, time: 0.391, loss: 0.004490\n",
      "step:    59820, time: 0.418, loss: 0.013431\n",
      "step:    59840, time: 0.420, loss: 0.010680\n",
      "step:    59860, time: 0.382, loss: 0.014224\n",
      "step:    59880, time: 0.390, loss: 0.024570\n",
      "step:    59900, time: 0.404, loss: 0.014000\n",
      "step:    59920, time: 0.419, loss: 0.017432\n",
      "step:    59940, time: 0.386, loss: 0.010653\n",
      "step:    59960, time: 0.421, loss: 0.009897\n",
      "step:    59980, time: 0.378, loss: 0.022499\n",
      "step:    60000, time: 0.393, loss: 0.023931\n",
      "step:    60020, time: 0.411, loss: 0.011329\n",
      "step:    60040, time: 0.400, loss: 0.024261\n",
      "step:    60060, time: 0.394, loss: 0.014479\n",
      "step:    60080, time: 0.384, loss: 0.012244\n",
      "step:    60100, time: 0.383, loss: 0.013960\n",
      "step:    60120, time: 0.391, loss: 0.015353\n",
      "step:    60140, time: 0.411, loss: 0.008616\n",
      "step:    60160, time: 0.381, loss: 0.013991\n",
      "step:    60180, time: 0.398, loss: 0.013253\n",
      "step:    60200, time: 0.408, loss: 0.014266\n",
      "step:    60220, time: 0.382, loss: 0.012135\n",
      "step:    60240, time: 0.397, loss: 0.008480\n",
      "step:    60260, time: 0.416, loss: 0.009149\n",
      "step:    60280, time: 0.395, loss: 0.014271\n",
      "step:    60300, time: 0.399, loss: 0.016949\n",
      "step:    60320, time: 0.388, loss: 0.009164\n",
      "step:    60340, time: 0.413, loss: 0.011849\n",
      "step:    60360, time: 0.371, loss: 0.009668\n",
      "step:    60380, time: 0.412, loss: 0.009128\n",
      "step:    60400, time: 0.387, loss: 0.011215\n",
      "step:    60420, time: 0.402, loss: 0.008877\n",
      "step:    60440, time: 0.405, loss: 0.010191\n",
      "step:    60460, time: 0.389, loss: 0.111720\n",
      "step:    60480, time: 0.387, loss: 0.014350\n",
      "step:    60500, time: 0.429, loss: 0.013504\n",
      "step:    60520, time: 0.390, loss: 0.022185\n",
      "step:    60540, time: 0.406, loss: 0.009430\n",
      "step:    60560, time: 0.394, loss: 0.013192\n",
      "step:    60580, time: 0.398, loss: 0.013348\n",
      "step:    60600, time: 0.424, loss: 0.019541\n",
      "step:    60620, time: 0.385, loss: 0.014515\n",
      "step:    60640, time: 0.384, loss: 0.010889\n",
      "step:    60660, time: 0.402, loss: 0.016273\n",
      "step:    60680, time: 0.401, loss: 0.018139\n",
      "step:    60700, time: 0.405, loss: 0.015693\n",
      "step:    60720, time: 0.389, loss: 0.022094\n",
      "step:    60740, time: 0.423, loss: 0.011520\n",
      "step:    60760, time: 0.415, loss: 0.013660\n",
      "step:    60780, time: 0.391, loss: 0.010575\n",
      "step:    60800, time: 0.415, loss: 0.015241\n",
      "step:    60820, time: 0.419, loss: 0.011627\n",
      "step:    60840, time: 0.382, loss: 0.005961\n",
      "step:    60860, time: 0.389, loss: 0.022328\n",
      "step:    60880, time: 0.407, loss: 0.022926\n",
      "step:    60900, time: 0.410, loss: 0.014641\n",
      "step:    60920, time: 0.379, loss: 0.015157\n",
      "step:    60940, time: 0.385, loss: 0.011753\n",
      "step:    60960, time: 0.400, loss: 0.009162\n",
      "step:    60980, time: 0.406, loss: 0.017519\n",
      "step:    61000, time: 0.370, loss: 0.022105\n",
      "step:    61020, time: 0.400, loss: 0.021296\n",
      "step:    61040, time: 0.398, loss: 0.015896\n",
      "step:    61060, time: 0.410, loss: 0.007706\n",
      "step:    61080, time: 0.412, loss: 0.015967\n",
      "step:    61100, time: 0.413, loss: 0.023282\n",
      "step:    61120, time: 0.387, loss: 0.018579\n",
      "step:    61140, time: 0.386, loss: 0.020607\n",
      "step:    61160, time: 0.388, loss: 0.023028\n",
      "step:    61180, time: 0.398, loss: 0.014480\n",
      "step:    61200, time: 0.389, loss: 0.011196\n",
      "step:    61220, time: 0.381, loss: 0.013289\n",
      "step:    61240, time: 0.395, loss: 0.021750\n",
      "step:    61260, time: 0.410, loss: 0.017086\n",
      "step:    61280, time: 0.410, loss: 0.015796\n",
      "step:    61300, time: 0.440, loss: 0.018507\n",
      "step:    61320, time: 0.378, loss: 0.019729\n",
      "step:    61340, time: 0.403, loss: 0.018747\n",
      "step:    61360, time: 0.362, loss: 0.002990\n",
      "step:    61380, time: 0.372, loss: 0.009252\n",
      "step:    61400, time: 0.392, loss: 0.014699\n",
      "step:    61420, time: 0.409, loss: 0.022330\n",
      "step:    61440, time: 0.425, loss: 0.010795\n",
      "step:    61460, time: 0.383, loss: 0.007134\n",
      "step:    61480, time: 0.424, loss: 0.014092\n",
      "step:    61500, time: 0.423, loss: 0.010829\n",
      "step:    61520, time: 0.400, loss: 0.012897\n",
      "step:    61540, time: 0.371, loss: 0.009337\n",
      "step:    61560, time: 0.398, loss: 0.016029\n",
      "step:    61580, time: 0.406, loss: 0.016103\n",
      "step:    61600, time: 0.402, loss: 0.015062\n",
      "step:    61620, time: 0.362, loss: 0.012923\n",
      "step:    61640, time: 0.390, loss: 0.017472\n",
      "step:    61660, time: 0.391, loss: 0.017148\n",
      "step:    61680, time: 0.419, loss: 0.021897\n",
      "step:    61700, time: 0.395, loss: 0.016496\n",
      "step:    61720, time: 0.415, loss: 0.019200\n",
      "step:    61740, time: 0.399, loss: 0.011874\n",
      "step:    61760, time: 0.440, loss: 0.016986\n",
      "step:    61780, time: 0.421, loss: 0.013246\n",
      "step:    61800, time: 0.399, loss: 0.012878\n",
      "step:    61820, time: 0.408, loss: 0.009814\n",
      "step:    61840, time: 0.433, loss: 0.010855\n",
      "step:    61860, time: 0.430, loss: 0.020883\n",
      "step:    61880, time: 0.400, loss: 0.005688\n",
      "step:    61900, time: 0.397, loss: 0.014660\n",
      "step:    61920, time: 0.406, loss: 0.013890\n",
      "step:    61940, time: 0.406, loss: 0.016529\n",
      "step:    61960, time: 0.400, loss: 0.018733\n",
      "step:    61980, time: 0.400, loss: 0.012889\n",
      "step:    62000, time: 0.455, loss: 0.013604\n",
      "step:    62020, time: 0.426, loss: 0.019157\n",
      "step:    62040, time: 0.446, loss: 0.006016\n",
      "step:    62060, time: 0.425, loss: 0.022328\n",
      "step:    62080, time: 0.440, loss: 0.012916\n",
      "step:    62100, time: 0.425, loss: 0.008345\n",
      "step:    62120, time: 0.427, loss: 0.016315\n",
      "step:    62140, time: 0.394, loss: 0.009274\n",
      "step:    62160, time: 0.418, loss: 0.023135\n",
      "step:    62180, time: 0.372, loss: 0.014102\n",
      "step:    62200, time: 0.435, loss: 0.016151\n",
      "step:    62220, time: 0.405, loss: 0.023129\n",
      "step:    62240, time: 0.390, loss: 0.017107\n",
      "step:    62260, time: 0.405, loss: 0.014826\n",
      "step:    62280, time: 0.440, loss: 0.007591\n",
      "step:    62300, time: 0.393, loss: 0.016517\n",
      "step:    62320, time: 0.399, loss: 0.015656\n",
      "step:    62340, time: 0.387, loss: 0.011846\n",
      "step:    62360, time: 0.395, loss: 0.017618\n",
      "step:    62380, time: 0.426, loss: 0.016876\n",
      "step:    62400, time: 0.440, loss: 0.018018\n",
      "step:    62420, time: 0.372, loss: 0.010152\n",
      "step:    62440, time: 0.422, loss: 0.013615\n",
      "step:    62460, time: 0.387, loss: 0.022938\n",
      "step:    62480, time: 0.392, loss: 0.012940\n",
      "step:    62500, time: 0.385, loss: 0.013881\n",
      "step:    62520, time: 0.398, loss: 0.015110\n",
      "step:    62540, time: 0.422, loss: 0.016206\n",
      "step:    62560, time: 0.396, loss: 0.018360\n",
      "step:    62580, time: 0.409, loss: 0.005166\n",
      "step:    62600, time: 0.384, loss: 0.007592\n",
      "step:    62620, time: 0.395, loss: 0.014902\n",
      "step:    62640, time: 0.384, loss: 0.020277\n",
      "step:    62660, time: 0.410, loss: 0.013850\n",
      "step:    62680, time: 0.386, loss: 0.006566\n",
      "step:    62700, time: 0.400, loss: 0.012640\n",
      "step:    62720, time: 0.393, loss: 0.013819\n",
      "step:    62740, time: 0.389, loss: 0.010193\n",
      "step:    62760, time: 0.402, loss: 0.008977\n",
      "step:    62780, time: 0.406, loss: 0.019491\n",
      "step:    62800, time: 0.390, loss: 0.226218\n",
      "step:    62820, time: 0.396, loss: 0.015592\n",
      "step:    62840, time: 0.415, loss: 0.015525\n",
      "step:    62860, time: 0.390, loss: 0.017401\n",
      "step:    62880, time: 0.442, loss: 0.016860\n",
      "step:    62900, time: 0.416, loss: 0.016778\n",
      "step:    62920, time: 0.420, loss: 0.017042\n",
      "step:    62940, time: 0.416, loss: 0.013785\n",
      "step:    62960, time: 0.417, loss: 0.015417\n",
      "step:    62980, time: 0.403, loss: 0.007547\n",
      "step:    63000, time: 0.379, loss: 0.017792\n",
      "step:    63020, time: 0.414, loss: 0.023046\n",
      "step:    63040, time: 0.389, loss: 0.017858\n",
      "step:    63060, time: 0.418, loss: 0.021244\n",
      "step:    63080, time: 0.380, loss: 0.015899\n",
      "step:    63100, time: 0.402, loss: 0.011651\n",
      "step:    63120, time: 0.405, loss: 0.011749\n",
      "step:    63140, time: 0.421, loss: 0.013001\n",
      "step:    63160, time: 0.387, loss: 0.018918\n",
      "step:    63180, time: 0.397, loss: 0.016702\n",
      "step:    63200, time: 0.410, loss: 0.022605\n",
      "step:    63220, time: 0.389, loss: 0.010025\n",
      "step:    63240, time: 0.384, loss: 0.013770\n",
      "step:    63260, time: 0.392, loss: 0.019824\n",
      "step:    63280, time: 0.398, loss: 0.012199\n",
      "step:    63300, time: 0.413, loss: 0.025556\n",
      "step:    63320, time: 0.413, loss: 0.008627\n",
      "step:    63340, time: 0.393, loss: 0.018758\n",
      "step:    63360, time: 0.395, loss: 0.016497\n",
      "step:    63380, time: 0.385, loss: 0.012964\n",
      "step:    63400, time: 0.411, loss: 0.016438\n",
      "step:    63420, time: 0.404, loss: 0.011641\n",
      "step:    63440, time: 0.403, loss: 0.007402\n",
      "step:    63460, time: 0.392, loss: 0.016190\n",
      "step:    63480, time: 0.383, loss: 0.017903\n",
      "step:    63500, time: 0.384, loss: 0.013315\n",
      "step:    63520, time: 0.378, loss: 0.038798\n",
      "step:    63540, time: 0.389, loss: 0.009680\n",
      "step:    63560, time: 0.395, loss: 0.021782\n",
      "step:    63580, time: 0.402, loss: 0.009471\n",
      "step:    63600, time: 0.406, loss: 0.017247\n",
      "step:    63620, time: 0.402, loss: 0.025138\n",
      "step:    63640, time: 0.392, loss: 0.019324\n",
      "step:    63660, time: 0.390, loss: 0.024029\n",
      "step:    63680, time: 0.409, loss: 0.015383\n",
      "step:    63700, time: 0.415, loss: 0.016286\n",
      "step:    63720, time: 0.384, loss: 0.012189\n",
      "step:    63740, time: 0.393, loss: 0.008527\n",
      "step:    63760, time: 0.413, loss: 0.014623\n",
      "step:    63780, time: 0.423, loss: 0.015319\n",
      "step:    63800, time: 0.406, loss: 0.008627\n",
      "step:    63820, time: 0.391, loss: 0.022254\n",
      "step:    63840, time: 0.433, loss: 0.014019\n",
      "step:    63860, time: 0.383, loss: 0.010682\n",
      "step:    63880, time: 0.420, loss: 0.010280\n",
      "step:    63900, time: 0.373, loss: 0.007571\n",
      "step:    63920, time: 0.397, loss: 0.017046\n",
      "step:    63940, time: 0.416, loss: 0.016027\n",
      "step:    63960, time: 0.376, loss: 0.012035\n",
      "step:    63980, time: 0.422, loss: 0.018694\n",
      "step:    64000, time: 0.385, loss: 0.028052\n",
      "step:    64020, time: 0.385, loss: 0.012717\n",
      "step:    64040, time: 0.419, loss: 0.128967\n",
      "step:    64060, time: 0.367, loss: 0.014484\n",
      "step:    64080, time: 0.401, loss: 0.010023\n",
      "step:    64100, time: 0.392, loss: 0.013690\n",
      "step:    64120, time: 0.403, loss: 0.018111\n",
      "step:    64140, time: 0.411, loss: 0.015124\n",
      "step:    64160, time: 0.450, loss: 0.015615\n",
      "step:    64180, time: 0.384, loss: 0.018747\n",
      "step:    64200, time: 0.426, loss: 0.023174\n",
      "step:    64220, time: 0.386, loss: 0.012686\n",
      "step:    64240, time: 0.418, loss: 0.013663\n",
      "step:    64260, time: 0.399, loss: 0.012908\n",
      "step:    64280, time: 0.390, loss: 0.017479\n",
      "step:    64300, time: 0.424, loss: 0.013683\n",
      "step:    64320, time: 0.371, loss: 0.015457\n",
      "step:    64340, time: 0.395, loss: 0.016197\n",
      "step:    64360, time: 0.378, loss: 0.010611\n",
      "step:    64380, time: 0.389, loss: 0.014119\n",
      "step:    64400, time: 0.386, loss: 0.014047\n",
      "step:    64420, time: 0.403, loss: 0.057525\n",
      "step:    64440, time: 0.390, loss: 0.018421\n",
      "step:    64460, time: 0.394, loss: 0.011551\n",
      "step:    64480, time: 0.416, loss: 0.015265\n",
      "step:    64500, time: 0.406, loss: 0.019691\n",
      "step:    64520, time: 0.389, loss: 0.010588\n",
      "step:    64540, time: 0.402, loss: 0.020926\n",
      "step:    64560, time: 0.415, loss: 0.017984\n",
      "step:    64580, time: 0.390, loss: 0.018986\n",
      "step:    64600, time: 0.392, loss: 0.005765\n",
      "step:    64620, time: 0.411, loss: 0.018100\n",
      "step:    64640, time: 0.429, loss: 0.020354\n",
      "step:    64660, time: 0.394, loss: 0.014530\n",
      "step:    64680, time: 0.398, loss: 0.019541\n",
      "step:    64700, time: 0.394, loss: 0.015976\n",
      "step:    64720, time: 0.404, loss: 0.012993\n",
      "step:    64740, time: 0.375, loss: 0.020000\n",
      "step:    64760, time: 0.382, loss: 0.018706\n",
      "step:    64780, time: 0.406, loss: 0.013908\n",
      "step:    64800, time: 0.407, loss: 0.019994\n",
      "step:    64820, time: 0.403, loss: 0.014898\n",
      "step:    64840, time: 0.399, loss: 0.016729\n",
      "step:    64860, time: 0.389, loss: 0.006631\n",
      "step:    64880, time: 0.433, loss: 0.012807\n",
      "step:    64900, time: 0.450, loss: 0.022861\n",
      "step:    64920, time: 0.374, loss: 0.008450\n",
      "step:    64940, time: 0.395, loss: 0.015960\n",
      "step:    64960, time: 0.400, loss: 0.011368\n",
      "step:    64980, time: 0.391, loss: 0.024857\n",
      "step:    65000, time: 0.394, loss: 0.015998\n",
      "step:    65020, time: 0.398, loss: 0.009737\n",
      "step:    65040, time: 0.396, loss: 0.020645\n",
      "step:    65060, time: 0.402, loss: 0.013280\n",
      "step:    65080, time: 0.421, loss: 0.016605\n",
      "step:    65100, time: 0.374, loss: 0.015695\n",
      "step:    65120, time: 0.396, loss: 0.017771\n",
      "step:    65140, time: 0.399, loss: 0.015764\n",
      "step:    65160, time: 0.386, loss: 0.339497\n",
      "step:    65180, time: 0.397, loss: 0.017737\n",
      "step:    65200, time: 0.423, loss: 0.019986\n",
      "step:    65220, time: 0.406, loss: 0.012257\n",
      "step:    65240, time: 0.404, loss: 0.009938\n",
      "step:    65260, time: 0.407, loss: 0.007800\n",
      "step:    65280, time: 0.394, loss: 0.006892\n",
      "step:    65300, time: 0.403, loss: 0.012942\n",
      "step:    65320, time: 0.385, loss: 0.009140\n",
      "step:    65340, time: 0.392, loss: 0.007624\n",
      "step:    65360, time: 0.393, loss: 0.011875\n",
      "step:    65380, time: 0.398, loss: 0.011513\n",
      "step:    65400, time: 0.395, loss: 0.014540\n",
      "step:    65420, time: 0.383, loss: 0.014477\n",
      "step:    65440, time: 0.386, loss: 0.016668\n",
      "step:    65460, time: 0.432, loss: 0.005706\n",
      "step:    65480, time: 0.373, loss: 0.018482\n",
      "step:    65500, time: 0.373, loss: 0.007560\n",
      "step:    65520, time: 0.365, loss: 0.005997\n",
      "step:    65540, time: 0.390, loss: 0.012406\n",
      "step:    65560, time: 0.413, loss: 0.015316\n",
      "step:    65580, time: 0.413, loss: 0.019659\n",
      "step:    65600, time: 0.373, loss: 0.009519\n",
      "step:    65620, time: 0.390, loss: 0.012522\n",
      "step:    65640, time: 0.411, loss: 0.013149\n",
      "step:    65660, time: 0.407, loss: 0.199590\n",
      "step:    65680, time: 0.422, loss: 0.018009\n",
      "step:    65700, time: 0.421, loss: 0.015364\n",
      "step:    65720, time: 0.394, loss: 0.017981\n",
      "step:    65740, time: 0.384, loss: 0.017941\n",
      "step:    65760, time: 0.414, loss: 0.018542\n",
      "step:    65780, time: 0.388, loss: 0.014378\n",
      "step:    65800, time: 0.383, loss: 0.006931\n",
      "step:    65820, time: 0.393, loss: 0.013674\n",
      "step:    65840, time: 0.441, loss: 0.016365\n",
      "step:    65860, time: 0.397, loss: 0.019655\n",
      "step:    65880, time: 0.383, loss: 0.016730\n",
      "step:    65900, time: 0.412, loss: 0.129869\n",
      "step:    65920, time: 0.388, loss: 0.008705\n",
      "step:    65940, time: 0.415, loss: 0.011546\n",
      "step:    65960, time: 0.362, loss: 0.012841\n",
      "step:    65980, time: 0.383, loss: 0.008604\n",
      "step:    66000, time: 0.411, loss: 0.019473\n",
      "step:    66020, time: 0.435, loss: 0.018231\n",
      "step:    66040, time: 0.402, loss: 0.010461\n",
      "step:    66060, time: 0.387, loss: 0.019496\n",
      "step:    66080, time: 0.394, loss: 0.020275\n",
      "step:    66100, time: 0.384, loss: 0.014836\n",
      "step:    66120, time: 0.371, loss: 0.013462\n",
      "step:    66140, time: 0.412, loss: 0.012844\n",
      "step:    66160, time: 0.391, loss: 0.021762\n",
      "step:    66180, time: 0.396, loss: 0.012693\n",
      "step:    66200, time: 0.436, loss: 0.016466\n",
      "step:    66220, time: 0.400, loss: 0.023172\n",
      "step:    66240, time: 0.382, loss: 0.013229\n",
      "step:    66260, time: 0.393, loss: 0.008242\n",
      "step:    66280, time: 0.442, loss: 0.017373\n",
      "step:    66300, time: 0.394, loss: 0.010298\n",
      "step:    66320, time: 0.374, loss: 0.025213\n",
      "step:    66340, time: 0.425, loss: 0.012421\n",
      "step:    66360, time: 0.425, loss: 0.020048\n",
      "step:    66380, time: 0.427, loss: 0.019463\n",
      "step:    66400, time: 0.403, loss: 0.015466\n",
      "step:    66420, time: 0.390, loss: 0.012160\n",
      "step:    66440, time: 0.414, loss: 0.014995\n",
      "step:    66460, time: 0.409, loss: 0.017079\n",
      "step:    66480, time: 0.393, loss: 0.008576\n",
      "step:    66500, time: 0.420, loss: 0.016514\n",
      "step:    66520, time: 0.399, loss: 0.016822\n",
      "step:    66540, time: 0.428, loss: 0.124827\n",
      "step:    66560, time: 0.381, loss: 0.011234\n",
      "step:    66580, time: 0.387, loss: 0.007233\n",
      "step:    66600, time: 0.391, loss: 0.017728\n",
      "step:    66620, time: 0.401, loss: 0.015686\n",
      "step:    66640, time: 0.414, loss: 0.021750\n",
      "step:    66660, time: 0.385, loss: 0.012834\n",
      "step:    66680, time: 0.408, loss: 0.010873\n",
      "step:    66700, time: 0.373, loss: 0.021773\n",
      "step:    66720, time: 0.389, loss: 0.024486\n",
      "step:    66740, time: 0.413, loss: 0.017976\n",
      "step:    66760, time: 0.407, loss: 0.013576\n",
      "step:    66780, time: 0.414, loss: 0.016531\n",
      "step:    66800, time: 0.402, loss: 0.012791\n",
      "step:    66820, time: 0.412, loss: 0.012979\n",
      "step:    66840, time: 0.386, loss: 0.011337\n",
      "step:    66860, time: 0.397, loss: 0.023339\n",
      "step:    66880, time: 0.397, loss: 0.023005\n",
      "step:    66900, time: 0.363, loss: 0.023231\n",
      "step:    66920, time: 0.389, loss: 0.016374\n",
      "step:    66940, time: 0.413, loss: 0.012554\n",
      "step:    66960, time: 0.386, loss: 0.017654\n",
      "step:    66980, time: 0.394, loss: 0.015556\n",
      "step:    67000, time: 0.387, loss: 0.014994\n",
      "step:    67020, time: 0.425, loss: 0.014891\n",
      "step:    67040, time: 0.376, loss: 0.007341\n",
      "step:    67060, time: 0.377, loss: 0.016700\n",
      "step:    67080, time: 0.386, loss: 0.013292\n",
      "step:    67100, time: 0.392, loss: 0.017937\n",
      "step:    67120, time: 0.398, loss: 0.005085\n",
      "step:    67140, time: 0.385, loss: 0.010713\n",
      "step:    67160, time: 0.417, loss: 0.019369\n",
      "step:    67180, time: 0.409, loss: 0.015779\n",
      "step:    67200, time: 0.419, loss: 0.023672\n",
      "step:    67220, time: 0.453, loss: 0.019950\n",
      "step:    67240, time: 0.431, loss: 0.023599\n",
      "step:    67260, time: 0.381, loss: 0.020014\n",
      "step:    67280, time: 0.405, loss: 0.013350\n",
      "step:    67300, time: 0.424, loss: 0.017310\n",
      "step:    67320, time: 0.402, loss: 0.017391\n",
      "step:    67340, time: 0.394, loss: 0.010185\n",
      "step:    67360, time: 0.397, loss: 0.017378\n",
      "step:    67380, time: 0.392, loss: 0.020500\n",
      "step:    67400, time: 0.383, loss: 0.008801\n",
      "step:    67420, time: 0.402, loss: 0.010408\n",
      "step:    67440, time: 0.415, loss: 0.018215\n",
      "step:    67460, time: 0.437, loss: 0.369236\n",
      "step:    67480, time: 0.387, loss: 0.024536\n",
      "step:    67500, time: 0.393, loss: 0.013444\n",
      "step:    67520, time: 0.387, loss: 0.015597\n",
      "step:    67540, time: 0.404, loss: 0.019229\n",
      "step:    67560, time: 0.377, loss: 0.017173\n",
      "step:    67580, time: 0.394, loss: 0.017637\n",
      "step:    67600, time: 0.395, loss: 0.019398\n",
      "step:    67620, time: 0.389, loss: 0.014849\n",
      "step:    67640, time: 0.391, loss: 0.015534\n",
      "step:    67660, time: 0.404, loss: 0.009418\n",
      "step:    67680, time: 0.387, loss: 0.018228\n",
      "step:    67700, time: 0.406, loss: 0.027427\n",
      "step:    67720, time: 0.375, loss: 0.013067\n",
      "step:    67740, time: 0.389, loss: 0.011802\n",
      "step:    67760, time: 0.409, loss: 0.011734\n",
      "step:    67780, time: 0.427, loss: 0.008488\n",
      "step:    67800, time: 0.402, loss: 0.012868\n",
      "step:    67820, time: 0.395, loss: 0.013192\n",
      "step:    67840, time: 0.392, loss: 0.015932\n",
      "step:    67860, time: 0.397, loss: 0.024774\n",
      "step:    67880, time: 0.382, loss: 0.018154\n",
      "step:    67900, time: 0.391, loss: 0.019405\n",
      "step:    67920, time: 0.411, loss: 0.013920\n",
      "step:    67940, time: 0.406, loss: 0.020831\n",
      "step:    67960, time: 0.390, loss: 0.002892\n",
      "step:    67980, time: 0.394, loss: 0.082510\n",
      "step:    68000, time: 0.392, loss: 0.015585\n",
      "step:    68020, time: 0.409, loss: 0.005113\n",
      "step:    68040, time: 0.393, loss: 0.014686\n",
      "step:    68060, time: 0.406, loss: 0.015469\n",
      "step:    68080, time: 0.399, loss: 0.018866\n",
      "step:    68100, time: 0.412, loss: 0.015888\n",
      "step:    68120, time: 0.396, loss: 0.007543\n",
      "step:    68140, time: 0.391, loss: 0.005411\n",
      "step:    68160, time: 0.421, loss: 0.185608\n",
      "step:    68180, time: 0.389, loss: 0.009730\n",
      "step:    68200, time: 0.397, loss: 0.017911\n",
      "step:    68220, time: 0.375, loss: 0.012961\n",
      "step:    68240, time: 0.410, loss: 0.024575\n",
      "step:    68260, time: 0.422, loss: 0.023092\n",
      "step:    68280, time: 0.393, loss: 0.015753\n",
      "step:    68300, time: 0.408, loss: 0.017984\n",
      "step:    68320, time: 0.363, loss: 0.016848\n",
      "step:    68340, time: 0.413, loss: 0.011228\n",
      "step:    68360, time: 0.389, loss: 0.006114\n",
      "step:    68380, time: 0.400, loss: 0.014908\n",
      "step:    68400, time: 0.390, loss: 0.021474\n",
      "step:    68420, time: 0.403, loss: 0.010921\n",
      "step:    68440, time: 0.390, loss: 0.017424\n",
      "step:    68460, time: 0.400, loss: 0.012613\n",
      "step:    68480, time: 0.409, loss: 0.017694\n",
      "step:    68500, time: 0.404, loss: 0.015175\n",
      "step:    68520, time: 0.423, loss: 0.022022\n",
      "step:    68540, time: 0.363, loss: 0.023307\n",
      "step:    68560, time: 0.379, loss: 0.011000\n",
      "step:    68580, time: 0.388, loss: 0.011073\n",
      "step:    68600, time: 0.431, loss: 0.020793\n",
      "step:    68620, time: 0.380, loss: 0.013847\n",
      "step:    68640, time: 0.394, loss: 0.015627\n",
      "step:    68660, time: 0.426, loss: 0.016857\n",
      "step:    68680, time: 0.416, loss: 0.012040\n",
      "step:    68700, time: 0.417, loss: 0.015116\n",
      "step:    68720, time: 0.409, loss: 0.011099\n",
      "step:    68740, time: 0.404, loss: 0.014398\n",
      "step:    68760, time: 0.387, loss: 0.027390\n",
      "step:    68780, time: 0.430, loss: 0.012407\n",
      "step:    68800, time: 0.407, loss: 0.129957\n",
      "step:    68820, time: 0.411, loss: 0.013832\n",
      "step:    68840, time: 0.390, loss: 0.007554\n",
      "step:    68860, time: 0.429, loss: 0.015007\n",
      "step:    68880, time: 0.437, loss: 0.017870\n",
      "step:    68900, time: 0.422, loss: 0.028859\n",
      "step:    68920, time: 0.383, loss: 0.004251\n",
      "step:    68940, time: 0.389, loss: 0.014006\n",
      "step:    68960, time: 0.397, loss: 0.006966\n",
      "step:    68980, time: 0.416, loss: 0.020350\n",
      "step:    69000, time: 0.382, loss: 0.010565\n",
      "step:    69020, time: 0.389, loss: 0.016425\n",
      "step:    69040, time: 0.406, loss: 0.015297\n",
      "step:    69060, time: 0.400, loss: 0.018614\n",
      "step:    69080, time: 0.402, loss: 0.019410\n",
      "step:    69100, time: 0.394, loss: 0.023917\n",
      "step:    69120, time: 0.405, loss: 0.016758\n",
      "step:    69140, time: 0.371, loss: 0.020078\n",
      "step:    69160, time: 0.362, loss: 0.008573\n",
      "step:    69180, time: 0.384, loss: 0.010308\n",
      "step:    69200, time: 0.422, loss: 0.121201\n",
      "step:    69220, time: 0.406, loss: 0.012490\n",
      "step:    69240, time: 0.396, loss: 0.006633\n",
      "step:    69260, time: 0.412, loss: 0.021347\n",
      "step:    69280, time: 0.415, loss: 0.012372\n",
      "step:    69300, time: 0.403, loss: 0.012021\n",
      "step:    69320, time: 0.401, loss: 0.020104\n",
      "step:    69340, time: 0.395, loss: 0.014692\n",
      "step:    69360, time: 0.382, loss: 0.012690\n",
      "step:    69380, time: 0.408, loss: 0.004910\n",
      "step:    69400, time: 0.424, loss: 0.012680\n",
      "step:    69420, time: 0.408, loss: 0.008650\n",
      "step:    69440, time: 0.457, loss: 0.021433\n",
      "step:    69460, time: 0.380, loss: 0.010314\n",
      "step:    69480, time: 0.388, loss: 0.009973\n",
      "step:    69500, time: 0.393, loss: 0.011827\n",
      "step:    69520, time: 0.394, loss: 0.009585\n",
      "step:    69540, time: 0.409, loss: 0.009656\n",
      "step:    69560, time: 0.386, loss: 0.008685\n",
      "step:    69580, time: 0.395, loss: 0.012766\n",
      "step:    69600, time: 0.384, loss: 0.017571\n",
      "step:    69620, time: 0.418, loss: 0.016576\n",
      "step:    69640, time: 0.385, loss: 0.018894\n",
      "step:    69660, time: 0.396, loss: 0.005119\n",
      "step:    69680, time: 0.394, loss: 0.009491\n",
      "step:    69700, time: 0.379, loss: 0.011567\n",
      "step:    69720, time: 0.408, loss: 0.014806\n",
      "step:    69740, time: 0.396, loss: 0.017912\n",
      "step:    69760, time: 0.403, loss: 0.011350\n",
      "step:    69780, time: 0.401, loss: 0.019460\n",
      "step:    69800, time: 0.423, loss: 0.012880\n",
      "step:    69820, time: 0.382, loss: 0.015300\n",
      "step:    69840, time: 0.394, loss: 0.016921\n",
      "step:    69860, time: 0.385, loss: 0.017102\n",
      "step:    69880, time: 0.435, loss: 0.021625\n",
      "step:    69900, time: 0.407, loss: 0.011015\n",
      "step:    69920, time: 0.413, loss: 0.023454\n",
      "step:    69940, time: 0.389, loss: 0.025273\n",
      "step:    69960, time: 0.394, loss: 0.012736\n",
      "step:    69980, time: 0.396, loss: 0.022919\n",
      "step:    70000, time: 0.413, loss: 0.013291\n",
      "step:    70020, time: 0.400, loss: 0.014786\n",
      "step:    70040, time: 0.382, loss: 0.011195\n",
      "step:    70060, time: 0.402, loss: 0.018486\n",
      "step:    70080, time: 0.399, loss: 0.016773\n",
      "step:    70100, time: 0.386, loss: 0.014703\n",
      "step:    70120, time: 0.425, loss: 0.364838\n",
      "step:    70140, time: 0.405, loss: 0.020662\n",
      "step:    70160, time: 0.386, loss: 0.015893\n",
      "step:    70180, time: 0.411, loss: 0.023811\n",
      "step:    70200, time: 0.421, loss: 0.198020\n",
      "step:    70220, time: 0.396, loss: 0.024047\n",
      "step:    70240, time: 0.370, loss: 0.015400\n",
      "step:    70260, time: 0.404, loss: 0.016851\n",
      "step:    70280, time: 0.391, loss: 0.019041\n",
      "step:    70300, time: 0.433, loss: 0.010268\n",
      "step:    70320, time: 0.396, loss: 0.015652\n",
      "step:    70340, time: 0.444, loss: 0.023578\n",
      "step:    70360, time: 0.421, loss: 0.014639\n",
      "step:    70380, time: 0.442, loss: 0.016438\n",
      "step:    70400, time: 0.373, loss: 0.012294\n",
      "step:    70420, time: 0.410, loss: 0.107360\n",
      "step:    70440, time: 0.434, loss: 0.013457\n",
      "step:    70460, time: 0.401, loss: 0.005042\n",
      "step:    70480, time: 0.387, loss: 0.003048\n",
      "step:    70500, time: 0.401, loss: 0.010279\n",
      "step:    70520, time: 0.399, loss: 0.018976\n",
      "step:    70540, time: 0.421, loss: 0.017696\n",
      "step:    70560, time: 0.385, loss: 0.011598\n",
      "step:    70580, time: 0.390, loss: 0.017221\n",
      "step:    70600, time: 0.407, loss: 0.019688\n",
      "step:    70620, time: 0.391, loss: 0.011205\n",
      "step:    70640, time: 0.400, loss: 0.012173\n",
      "step:    70660, time: 0.394, loss: 0.014309\n",
      "step:    70680, time: 0.395, loss: 0.014732\n",
      "step:    70700, time: 0.401, loss: 0.012081\n",
      "step:    70720, time: 0.421, loss: 0.015242\n",
      "step:    70740, time: 0.389, loss: 0.008282\n",
      "step:    70760, time: 0.370, loss: 0.009196\n",
      "step:    70780, time: 0.378, loss: 0.010615\n",
      "step:    70800, time: 0.387, loss: 0.021936\n",
      "step:    70820, time: 0.422, loss: 0.018369\n",
      "step:    70840, time: 0.380, loss: 0.014068\n",
      "step:    70860, time: 0.417, loss: 0.016947\n",
      "step:    70880, time: 0.371, loss: 0.021519\n",
      "step:    70900, time: 0.378, loss: 0.008844\n",
      "step:    70920, time: 0.395, loss: 0.008288\n",
      "step:    70940, time: 0.366, loss: 0.016211\n",
      "step:    70960, time: 0.387, loss: 0.019844\n",
      "step:    70980, time: 0.386, loss: 0.021120\n",
      "step:    71000, time: 0.402, loss: 0.012938\n",
      "step:    71020, time: 0.404, loss: 0.018273\n",
      "step:    71040, time: 0.411, loss: 0.023738\n",
      "step:    71060, time: 0.409, loss: 0.024350\n",
      "step:    71080, time: 0.399, loss: 0.017129\n",
      "step:    71100, time: 0.424, loss: 0.026389\n",
      "step:    71120, time: 0.112, loss: 0.002628\n",
      "step:    71140, time: 0.406, loss: 0.007682\n",
      "step:    71160, time: 0.395, loss: 0.009277\n",
      "step:    71180, time: 0.453, loss: 0.019734\n",
      "step:    71200, time: 0.434, loss: 0.011711\n",
      "step:    71220, time: 0.392, loss: 0.007517\n",
      "step:    71240, time: 0.425, loss: 0.200183\n",
      "step:    71260, time: 0.388, loss: 0.021805\n",
      "step:    71280, time: 0.434, loss: 0.016203\n",
      "step:    71300, time: 0.388, loss: 0.013304\n",
      "step:    71320, time: 0.422, loss: 0.022723\n",
      "step:    71340, time: 0.422, loss: 0.026032\n",
      "step:    71360, time: 0.373, loss: 0.023800\n",
      "step:    71380, time: 0.449, loss: 0.061218\n",
      "step:    71400, time: 0.436, loss: 0.012338\n",
      "step:    71420, time: 0.416, loss: 0.016010\n",
      "step:    71440, time: 0.392, loss: 0.016516\n",
      "step:    71460, time: 0.391, loss: 0.011397\n",
      "step:    71480, time: 0.389, loss: 0.017983\n",
      "step:    71500, time: 0.388, loss: 0.014107\n",
      "step:    71520, time: 0.436, loss: 0.021870\n",
      "step:    71540, time: 0.403, loss: 0.012305\n",
      "step:    71560, time: 0.380, loss: 0.020235\n",
      "step:    71580, time: 0.401, loss: 0.010526\n",
      "step:    71600, time: 0.393, loss: 0.008875\n",
      "step:    71620, time: 0.372, loss: 0.010129\n",
      "step:    71640, time: 0.399, loss: 0.021664\n",
      "step:    71660, time: 0.424, loss: 0.016159\n",
      "step:    71680, time: 0.388, loss: 0.007877\n",
      "step:    71700, time: 0.403, loss: 0.015452\n",
      "step:    71720, time: 0.404, loss: 0.005232\n",
      "step:    71740, time: 0.404, loss: 0.007846\n",
      "step:    71760, time: 0.395, loss: 0.020179\n",
      "step:    71780, time: 0.395, loss: 0.012752\n",
      "step:    71800, time: 0.400, loss: 0.017684\n",
      "step:    71820, time: 0.418, loss: 0.015213\n",
      "step:    71840, time: 0.402, loss: 0.024294\n",
      "step:    71860, time: 0.400, loss: 0.021144\n",
      "step:    71880, time: 0.402, loss: 0.013719\n",
      "step:    71900, time: 0.431, loss: 0.019071\n",
      "step:    71920, time: 0.387, loss: 0.010496\n",
      "step:    71940, time: 0.444, loss: 0.009559\n",
      "step:    71960, time: 0.417, loss: 0.217408\n",
      "step:    71980, time: 0.434, loss: 0.017982\n",
      "step:    72000, time: 0.393, loss: 0.012362\n",
      "step:    72020, time: 0.389, loss: 0.021477\n",
      "step:    72040, time: 0.393, loss: 0.012906\n",
      "step:    72060, time: 0.419, loss: 0.016894\n",
      "step:    72080, time: 0.410, loss: 0.014845\n",
      "step:    72100, time: 0.394, loss: 0.019452\n",
      "step:    72120, time: 0.425, loss: 0.016782\n",
      "step:    72140, time: 0.394, loss: 0.024224\n",
      "step:    72160, time: 0.389, loss: 0.012491\n",
      "step:    72180, time: 0.399, loss: 0.011976\n",
      "step:    72200, time: 0.372, loss: 0.024622\n",
      "step:    72220, time: 0.393, loss: 0.012787\n",
      "step:    72240, time: 0.404, loss: 0.012675\n",
      "step:    72260, time: 0.417, loss: 0.055549\n",
      "step:    72280, time: 0.382, loss: 0.014399\n",
      "step:    72300, time: 0.439, loss: 0.012591\n",
      "step:    72320, time: 0.396, loss: 0.020669\n",
      "step:    72340, time: 0.396, loss: 0.021082\n",
      "step:    72360, time: 0.409, loss: 0.022290\n",
      "step:    72380, time: 0.385, loss: 0.012048\n",
      "step:    72400, time: 0.419, loss: 0.020660\n",
      "step:    72420, time: 0.387, loss: 0.012070\n",
      "step:    72440, time: 0.373, loss: 0.007833\n",
      "step:    72460, time: 0.390, loss: 0.007217\n",
      "step:    72480, time: 0.384, loss: 0.013210\n",
      "step:    72500, time: 0.410, loss: 0.016230\n",
      "step:    72520, time: 0.397, loss: 0.018928\n",
      "step:    72540, time: 0.401, loss: 0.018376\n",
      "step:    72560, time: 0.421, loss: 0.015102\n",
      "step:    72580, time: 0.430, loss: 0.019034\n",
      "step:    72600, time: 0.394, loss: 0.018401\n",
      "step:    72620, time: 0.432, loss: 0.020290\n",
      "step:    72640, time: 0.426, loss: 0.014725\n",
      "step:    72660, time: 0.390, loss: 0.018944\n",
      "step:    72680, time: 0.398, loss: 0.011059\n",
      "step:    72700, time: 0.383, loss: 0.002544\n",
      "step:    72720, time: 0.412, loss: 0.008532\n",
      "step:    72740, time: 0.411, loss: 0.014214\n",
      "step:    72760, time: 0.398, loss: 0.015767\n",
      "step:    72780, time: 0.400, loss: 0.018643\n",
      "step:    72800, time: 0.421, loss: 0.019045\n",
      "step:    72820, time: 0.390, loss: 0.011526\n",
      "step:    72840, time: 0.401, loss: 0.017227\n",
      "step:    72860, time: 0.414, loss: 0.022300\n",
      "step:    72880, time: 0.413, loss: 0.019082\n",
      "step:    72900, time: 0.390, loss: 0.009773\n",
      "step:    72920, time: 0.386, loss: 0.017994\n",
      "step:    72940, time: 0.412, loss: 0.020660\n",
      "step:    72960, time: 0.400, loss: 0.020504\n",
      "step:    72980, time: 0.406, loss: 0.017021\n",
      "step:    73000, time: 0.390, loss: 0.023846\n",
      "step:    73020, time: 0.380, loss: 0.011749\n",
      "step:    73040, time: 0.394, loss: 0.014671\n",
      "step:    73060, time: 0.424, loss: 0.020331\n",
      "step:    73080, time: 0.423, loss: 0.013078\n",
      "step:    73100, time: 0.391, loss: 0.012156\n",
      "step:    73120, time: 0.406, loss: 0.014457\n",
      "step:    73140, time: 0.376, loss: 0.009268\n",
      "step:    73160, time: 0.378, loss: 0.022038\n",
      "step:    73180, time: 0.390, loss: 0.019804\n",
      "step:    73200, time: 0.426, loss: 0.015039\n",
      "step:    73220, time: 0.398, loss: 0.017129\n",
      "step:    73240, time: 0.388, loss: 0.012157\n",
      "step:    73260, time: 0.396, loss: 0.010038\n",
      "step:    73280, time: 0.375, loss: 0.006290\n",
      "step:    73300, time: 0.401, loss: 0.009610\n",
      "step:    73320, time: 0.376, loss: 0.010141\n",
      "step:    73340, time: 0.430, loss: 0.014231\n",
      "step:    73360, time: 0.406, loss: 0.018332\n",
      "step:    73380, time: 0.391, loss: 0.018329\n",
      "step:    73400, time: 0.410, loss: 0.017248\n",
      "step:    73420, time: 0.422, loss: 0.017562\n",
      "step:    73440, time: 0.407, loss: 0.022855\n",
      "step:    73460, time: 0.407, loss: 0.022886\n",
      "step:    73480, time: 0.392, loss: 0.012437\n",
      "step:    73500, time: 0.399, loss: 0.012343\n",
      "step:    73520, time: 0.413, loss: 0.014683\n",
      "step:    73540, time: 0.408, loss: 0.024394\n",
      "step:    73560, time: 0.375, loss: 0.016274\n",
      "step:    73580, time: 0.413, loss: 0.013063\n",
      "step:    73600, time: 0.413, loss: 0.017836\n",
      "step:    73620, time: 0.407, loss: 0.027154\n",
      "step:    73640, time: 0.393, loss: 0.013680\n",
      "step:    73660, time: 0.399, loss: 0.026108\n",
      "step:    73680, time: 0.390, loss: 0.010318\n",
      "step:    73700, time: 0.376, loss: 0.017833\n",
      "step:    73720, time: 0.393, loss: 0.014709\n",
      "step:    73740, time: 0.410, loss: 0.014385\n",
      "step:    73760, time: 0.437, loss: 0.015917\n",
      "step:    73780, time: 0.424, loss: 0.021776\n",
      "step:    73800, time: 0.406, loss: 0.017058\n",
      "step:    73820, time: 0.410, loss: 0.014511\n",
      "step:    73840, time: 0.388, loss: 0.005547\n",
      "step:    73860, time: 0.396, loss: 0.006788\n",
      "step:    73880, time: 0.386, loss: 0.005851\n",
      "step:    73900, time: 0.392, loss: 0.026415\n",
      "step:    73920, time: 0.387, loss: 0.013758\n",
      "step:    73940, time: 0.417, loss: 0.011107\n",
      "step:    73960, time: 0.393, loss: 0.013125\n",
      "step:    73980, time: 0.404, loss: 0.015066\n",
      "step:    74000, time: 0.406, loss: 0.015866\n",
      "step:    74020, time: 0.418, loss: 0.021706\n",
      "step:    74040, time: 0.414, loss: 0.015364\n",
      "step:    74060, time: 0.386, loss: 0.018619\n",
      "step:    74080, time: 0.404, loss: 0.014025\n",
      "step:    74100, time: 0.405, loss: 0.022466\n",
      "step:    74120, time: 0.397, loss: 0.016368\n",
      "step:    74140, time: 0.436, loss: 0.015112\n",
      "step:    74160, time: 0.418, loss: 0.020569\n",
      "step:    74180, time: 0.388, loss: 0.013248\n",
      "step:    74200, time: 0.396, loss: 0.010697\n",
      "step:    74220, time: 0.395, loss: 0.018472\n",
      "step:    74240, time: 0.427, loss: 0.106706\n",
      "step:    74260, time: 0.396, loss: 0.006105\n",
      "step:    74280, time: 0.403, loss: 0.015879\n",
      "step:    74300, time: 0.397, loss: 0.011843\n",
      "step:    74320, time: 0.440, loss: 0.225534\n",
      "step:    74340, time: 0.380, loss: 0.008131\n",
      "step:    74360, time: 0.369, loss: 0.008985\n",
      "step:    74380, time: 0.414, loss: 0.020177\n",
      "step:    74400, time: 0.424, loss: 0.017544\n",
      "step:    74420, time: 0.378, loss: 0.021103\n",
      "step:    74440, time: 0.390, loss: 0.017539\n",
      "step:    74460, time: 0.419, loss: 0.010856\n",
      "step:    74480, time: 0.374, loss: 0.013863\n",
      "step:    74500, time: 0.418, loss: 0.172712\n",
      "step:    74520, time: 0.433, loss: 0.020893\n",
      "step:    74540, time: 0.380, loss: 0.021879\n",
      "step:    74560, time: 0.404, loss: 0.014909\n",
      "step:    74580, time: 0.433, loss: 0.018941\n",
      "step:    74600, time: 0.407, loss: 0.011291\n",
      "step:    74620, time: 0.408, loss: 0.008983\n",
      "step:    74640, time: 0.390, loss: 0.010632\n",
      "step:    74660, time: 0.392, loss: 0.015472\n",
      "step:    74680, time: 0.403, loss: 0.021138\n",
      "step:    74700, time: 0.384, loss: 0.010978\n",
      "step:    74720, time: 0.407, loss: 0.018143\n",
      "step:    74740, time: 0.408, loss: 0.118135\n",
      "step:    74760, time: 0.384, loss: 0.018881\n",
      "step:    74780, time: 0.413, loss: 0.018376\n",
      "step:    74800, time: 0.393, loss: 0.011321\n",
      "step:    74820, time: 0.376, loss: 0.011939\n",
      "step:    74840, time: 0.392, loss: 0.009158\n",
      "step:    74860, time: 0.395, loss: 0.012868\n",
      "step:    74880, time: 0.393, loss: 0.019411\n",
      "step:    74900, time: 0.394, loss: 0.015538\n",
      "step:    74920, time: 0.397, loss: 0.012613\n",
      "step:    74940, time: 0.383, loss: 0.010989\n",
      "step:    74960, time: 0.388, loss: 0.008021\n",
      "step:    74980, time: 0.400, loss: 0.009686\n",
      "step:    75000, time: 0.399, loss: 0.012905\n",
      "step:    75020, time: 0.382, loss: 0.015920\n",
      "step:    75040, time: 0.427, loss: 0.010999\n",
      "step:    75060, time: 0.421, loss: 0.019986\n",
      "step:    75080, time: 0.393, loss: 0.015178\n",
      "step:    75100, time: 0.387, loss: 0.014807\n",
      "step:    75120, time: 0.390, loss: 0.009638\n",
      "step:    75140, time: 0.359, loss: 0.014509\n",
      "step:    75160, time: 0.407, loss: 0.021899\n",
      "step:    75180, time: 0.421, loss: 0.018803\n",
      "step:    75200, time: 0.401, loss: 0.021747\n",
      "step:    75220, time: 0.397, loss: 0.019316\n",
      "step:    75240, time: 0.405, loss: 0.016329\n",
      "step:    75260, time: 0.392, loss: 0.011480\n",
      "step:    75280, time: 0.386, loss: 0.017023\n",
      "step:    75300, time: 0.408, loss: 0.016467\n",
      "step:    75320, time: 0.413, loss: 0.017965\n",
      "step:    75340, time: 0.418, loss: 0.022792\n",
      "step:    75360, time: 0.421, loss: 0.016035\n",
      "step:    75380, time: 0.411, loss: 0.009182\n",
      "step:    75400, time: 0.391, loss: 0.022118\n",
      "step:    75420, time: 0.404, loss: 0.015968\n",
      "step:    75440, time: 0.385, loss: 0.013975\n",
      "step:    75460, time: 0.390, loss: 0.021205\n",
      "step:    75480, time: 0.379, loss: 0.017509\n",
      "step:    75500, time: 0.394, loss: 0.017522\n",
      "step:    75520, time: 0.409, loss: 0.012461\n",
      "step:    75540, time: 0.419, loss: 0.014338\n",
      "step:    75560, time: 0.433, loss: 0.018072\n",
      "step:    75580, time: 0.427, loss: 0.005222\n",
      "step:    75600, time: 0.415, loss: 0.023083\n",
      "step:    75620, time: 0.408, loss: 0.025502\n",
      "step:    75640, time: 0.414, loss: 0.015319\n",
      "step:    75660, time: 0.390, loss: 0.025238\n",
      "step:    75680, time: 0.398, loss: 0.011308\n",
      "step:    75700, time: 0.395, loss: 0.014486\n",
      "step:    75720, time: 0.398, loss: 0.007289\n",
      "step:    75740, time: 0.411, loss: 0.010686\n",
      "step:    75760, time: 0.390, loss: 0.014908\n",
      "step:    75780, time: 0.421, loss: 0.020810\n",
      "step:    75800, time: 0.390, loss: 0.011187\n",
      "step:    75820, time: 0.430, loss: 0.007740\n",
      "step:    75840, time: 0.398, loss: 0.004548\n",
      "step:    75860, time: 0.382, loss: 0.010221\n",
      "step:    75880, time: 0.394, loss: 0.015785\n",
      "step:    75900, time: 0.427, loss: 0.014998\n",
      "step:    75920, time: 0.402, loss: 0.008553\n",
      "step:    75940, time: 0.366, loss: 0.013683\n",
      "step:    75960, time: 0.406, loss: 0.178888\n",
      "step:    75980, time: 0.389, loss: 0.004286\n",
      "step:    76000, time: 0.391, loss: 0.010936\n",
      "step:    76020, time: 0.411, loss: 0.013892\n",
      "step:    76040, time: 0.412, loss: 0.017749\n",
      "step:    76060, time: 0.378, loss: 0.009023\n",
      "step:    76080, time: 0.396, loss: 0.018838\n",
      "step:    76100, time: 0.411, loss: 0.008878\n",
      "step:    76120, time: 0.426, loss: 0.015420\n",
      "step:    76140, time: 0.390, loss: 0.013174\n",
      "step:    76160, time: 0.399, loss: 0.011364\n",
      "step:    76180, time: 0.394, loss: 0.013463\n",
      "step:    76200, time: 0.393, loss: 0.015402\n",
      "step:    76220, time: 0.396, loss: 0.018973\n",
      "step:    76240, time: 0.407, loss: 0.014191\n",
      "step:    76260, time: 0.423, loss: 0.013616\n",
      "step:    76280, time: 0.417, loss: 0.018444\n",
      "step:    76300, time: 0.411, loss: 0.016242\n",
      "step:    76320, time: 0.399, loss: 0.014009\n",
      "step:    76340, time: 0.374, loss: 0.012523\n",
      "step:    76360, time: 0.411, loss: 0.011653\n",
      "step:    76380, time: 0.409, loss: 0.012037\n",
      "step:    76400, time: 0.408, loss: 0.020525\n",
      "step:    76420, time: 0.387, loss: 0.038131\n",
      "step:    76440, time: 0.376, loss: 0.016834\n",
      "step:    76460, time: 0.402, loss: 0.017075\n",
      "step:    76480, time: 0.370, loss: 0.021374\n",
      "step:    76500, time: 0.415, loss: 0.021679\n",
      "step:    76520, time: 0.412, loss: 0.016575\n",
      "step:    76540, time: 0.390, loss: 0.010745\n",
      "step:    76560, time: 0.399, loss: 0.017026\n",
      "step:    76580, time: 0.386, loss: 0.012947\n",
      "step:    76600, time: 0.408, loss: 0.016856\n",
      "step:    76620, time: 0.410, loss: 0.018873\n",
      "step:    76640, time: 0.393, loss: 0.007630\n",
      "step:    76660, time: 0.421, loss: 0.011264\n",
      "step:    76680, time: 0.410, loss: 0.013431\n",
      "step:    76700, time: 0.388, loss: 0.014182\n",
      "step:    76720, time: 0.404, loss: 0.036242\n",
      "step:    76740, time: 0.404, loss: 0.010988\n",
      "step:    76760, time: 0.414, loss: 0.012772\n",
      "step:    76780, time: 0.410, loss: 0.022497\n",
      "step:    76800, time: 0.388, loss: 0.013615\n",
      "step:    76820, time: 0.386, loss: 0.010146\n",
      "step:    76840, time: 0.428, loss: 0.022442\n",
      "step:    76860, time: 0.400, loss: 0.015995\n",
      "step:    76880, time: 0.406, loss: 0.016244\n",
      "step:    76900, time: 0.392, loss: 0.011641\n",
      "step:    76920, time: 0.383, loss: 0.013646\n",
      "step:    76940, time: 0.399, loss: 0.027147\n",
      "step:    76960, time: 0.389, loss: 0.011764\n",
      "step:    76980, time: 0.408, loss: 0.018586\n",
      "step:    77000, time: 0.401, loss: 0.030580\n",
      "step:    77020, time: 0.397, loss: 0.005672\n",
      "step:    77040, time: 0.386, loss: 0.009857\n",
      "step:    77060, time: 0.418, loss: 0.015972\n",
      "step:    77080, time: 0.395, loss: 0.014693\n",
      "step:    77100, time: 0.366, loss: 0.009114\n",
      "step:    77120, time: 0.386, loss: 0.019271\n",
      "step:    77140, time: 0.391, loss: 0.016356\n",
      "step:    77160, time: 0.386, loss: 0.010674\n",
      "step:    77180, time: 0.388, loss: 0.006010\n",
      "step:    77200, time: 0.388, loss: 0.013455\n",
      "step:    77220, time: 0.402, loss: 0.014150\n",
      "step:    77240, time: 0.378, loss: 0.013153\n",
      "step:    77260, time: 0.391, loss: 0.009589\n",
      "step:    77280, time: 0.417, loss: 0.011596\n",
      "step:    77300, time: 0.412, loss: 0.018818\n",
      "step:    77320, time: 0.384, loss: 0.016380\n",
      "step:    77340, time: 0.400, loss: 0.006072\n",
      "step:    77360, time: 0.398, loss: 0.014980\n",
      "step:    77380, time: 0.383, loss: 0.009415\n",
      "step:    77400, time: 0.422, loss: 0.016296\n",
      "step:    77420, time: 0.380, loss: 0.007976\n",
      "step:    77440, time: 0.386, loss: 0.008171\n",
      "step:    77460, time: 0.383, loss: 0.008376\n",
      "step:    77480, time: 0.425, loss: 0.016701\n",
      "step:    77500, time: 0.410, loss: 0.020752\n",
      "step:    77520, time: 0.391, loss: 0.015089\n",
      "step:    77540, time: 0.384, loss: 0.005931\n",
      "step:    77560, time: 0.400, loss: 0.011051\n",
      "step:    77580, time: 0.430, loss: 0.019925\n",
      "step:    77600, time: 0.380, loss: 0.018339\n",
      "step:    77620, time: 0.404, loss: 0.024556\n",
      "step:    77640, time: 0.375, loss: 0.004119\n",
      "step:    77660, time: 0.404, loss: 0.018338\n",
      "step:    77680, time: 0.424, loss: 0.014337\n",
      "step:    77700, time: 0.388, loss: 0.010915\n",
      "step:    77720, time: 0.423, loss: 0.016760\n",
      "step:    77740, time: 0.387, loss: 0.013235\n",
      "step:    77760, time: 0.430, loss: 0.018821\n",
      "step:    77780, time: 0.423, loss: 0.022179\n",
      "step:    77800, time: 0.404, loss: 0.021337\n",
      "step:    77820, time: 0.411, loss: 0.021115\n",
      "step:    77840, time: 0.388, loss: 0.020060\n",
      "step:    77860, time: 0.397, loss: 0.020247\n",
      "step:    77880, time: 0.398, loss: 0.018901\n",
      "step:    77900, time: 0.397, loss: 0.018132\n",
      "step:    77920, time: 0.413, loss: 0.008252\n",
      "step:    77940, time: 0.413, loss: 0.014711\n",
      "step:    77960, time: 0.424, loss: 0.244817\n",
      "step:    77980, time: 0.430, loss: 0.009187\n",
      "step:    78000, time: 0.395, loss: 0.018994\n",
      "step:    78020, time: 0.411, loss: 0.015524\n",
      "step:    78040, time: 0.392, loss: 0.018822\n",
      "step:    78060, time: 0.395, loss: 0.020113\n",
      "step:    78080, time: 0.385, loss: 0.010159\n",
      "step:    78100, time: 0.407, loss: 0.018334\n",
      "step:    78120, time: 0.403, loss: 0.020324\n",
      "step:    78140, time: 0.366, loss: 0.013213\n",
      "step:    78160, time: 0.393, loss: 0.013778\n",
      "step:    78180, time: 0.387, loss: 0.002944\n",
      "step:    78200, time: 0.392, loss: 0.012559\n",
      "step:    78220, time: 0.390, loss: 0.013111\n",
      "step:    78240, time: 0.422, loss: 0.018810\n",
      "step:    78260, time: 0.407, loss: 0.014077\n",
      "step:    78280, time: 0.398, loss: 0.007372\n",
      "step:    78300, time: 0.422, loss: 0.009733\n",
      "step:    78320, time: 0.420, loss: 0.088508\n",
      "step:    78340, time: 0.379, loss: 0.013730\n",
      "step:    78360, time: 0.384, loss: 0.016825\n",
      "step:    78380, time: 0.407, loss: 0.020718\n",
      "step:    78400, time: 0.409, loss: 0.012191\n",
      "step:    78420, time: 0.410, loss: 0.033455\n",
      "step:    78440, time: 0.423, loss: 0.008621\n",
      "step:    78460, time: 0.403, loss: 0.016038\n",
      "step:    78480, time: 0.392, loss: 0.006123\n",
      "step:    78500, time: 0.415, loss: 0.015444\n",
      "step:    78520, time: 0.380, loss: 0.008882\n",
      "step:    78540, time: 0.404, loss: 0.014338\n",
      "step:    78560, time: 0.384, loss: 0.013339\n",
      "step:    78580, time: 0.398, loss: 0.017144\n",
      "step:    78600, time: 0.413, loss: 0.014634\n",
      "step:    78620, time: 0.405, loss: 0.017185\n",
      "step:    78640, time: 0.374, loss: 0.015424\n",
      "step:    78660, time: 0.392, loss: 0.012241\n",
      "step:    78680, time: 0.395, loss: 0.016214\n",
      "step:    78700, time: 0.404, loss: 0.004766\n",
      "step:    78720, time: 0.407, loss: 0.017935\n",
      "step:    78740, time: 0.417, loss: 0.017475\n",
      "step:    78760, time: 0.358, loss: 0.009362\n",
      "step:    78780, time: 0.403, loss: 0.060439\n",
      "step:    78800, time: 0.411, loss: 0.021961\n",
      "step:    78820, time: 0.417, loss: 0.019276\n",
      "step:    78840, time: 0.413, loss: 0.015387\n",
      "step:    78860, time: 0.405, loss: 0.015689\n",
      "step:    78880, time: 0.411, loss: 0.006672\n",
      "step:    78900, time: 0.384, loss: 0.014102\n",
      "step:    78920, time: 0.402, loss: 0.013906\n",
      "step:    78940, time: 0.411, loss: 0.010067\n",
      "step:    78960, time: 0.392, loss: 0.022162\n",
      "step:    78980, time: 0.415, loss: 0.018495\n",
      "step:    79000, time: 0.409, loss: 0.017752\n",
      "step:    79020, time: 0.403, loss: 0.012450\n",
      "step:    79040, time: 0.396, loss: 0.014835\n",
      "step:    79060, time: 0.380, loss: 0.019704\n",
      "step:    79080, time: 0.390, loss: 0.016515\n",
      "step:    79100, time: 0.397, loss: 0.007140\n",
      "step:    79120, time: 0.410, loss: 0.016873\n",
      "step:    79140, time: 0.381, loss: 0.019049\n",
      "step:    79160, time: 0.418, loss: 0.014734\n",
      "step:    79180, time: 0.410, loss: 0.018023\n",
      "step:    79200, time: 0.379, loss: 0.015389\n",
      "step:    79220, time: 0.391, loss: 0.013874\n",
      "step:    79240, time: 0.376, loss: 0.007089\n",
      "step:    79260, time: 0.421, loss: 0.016253\n",
      "step:    79280, time: 0.404, loss: 0.012104\n",
      "step:    79300, time: 0.398, loss: 0.014299\n",
      "step:    79320, time: 0.396, loss: 0.016780\n",
      "step:    79340, time: 0.429, loss: 0.006353\n",
      "step:    79360, time: 0.381, loss: 0.015130\n",
      "step:    79380, time: 0.388, loss: 0.008422\n",
      "step:    79400, time: 0.405, loss: 0.019155\n",
      "step:    79420, time: 0.376, loss: 0.018484\n",
      "step:    79440, time: 0.383, loss: 0.020561\n",
      "step:    79460, time: 0.409, loss: 0.016696\n",
      "step:    79480, time: 0.409, loss: 0.016894\n",
      "step:    79500, time: 0.383, loss: 0.021285\n",
      "step:    79520, time: 0.419, loss: 0.008884\n",
      "step:    79540, time: 0.381, loss: 0.008471\n",
      "step:    79560, time: 0.378, loss: 0.012039\n",
      "step:    79580, time: 0.400, loss: 0.018176\n",
      "step:    79600, time: 0.393, loss: 0.013124\n",
      "step:    79620, time: 0.388, loss: 0.012834\n",
      "step:    79640, time: 0.405, loss: 0.017035\n",
      "step:    79660, time: 0.393, loss: 0.018834\n",
      "step:    79680, time: 0.400, loss: 0.008414\n",
      "step:    79700, time: 0.389, loss: 0.016101\n",
      "step:    79720, time: 0.407, loss: 0.016722\n",
      "step:    79740, time: 0.406, loss: 0.023145\n",
      "step:    79760, time: 0.420, loss: 0.022173\n",
      "step:    79780, time: 0.406, loss: 0.013422\n",
      "step:    79800, time: 0.437, loss: 0.012618\n",
      "step:    79820, time: 0.419, loss: 0.019331\n",
      "step:    79840, time: 0.378, loss: 0.015978\n",
      "step:    79860, time: 0.414, loss: 0.014834\n",
      "step:    79880, time: 0.404, loss: 0.011960\n",
      "step:    79900, time: 0.395, loss: 0.011078\n",
      "step:    79920, time: 0.416, loss: 0.019269\n",
      "step:    79940, time: 0.408, loss: 0.005885\n",
      "step:    79960, time: 0.447, loss: 0.114830\n",
      "step:    79980, time: 0.415, loss: 0.017018\n",
      "step:    80000, time: 0.422, loss: 0.016647\n",
      "step:    80020, time: 0.406, loss: 0.011696\n",
      "step:    80040, time: 0.404, loss: 0.011167\n",
      "step:    80060, time: 0.377, loss: 0.017867\n",
      "step:    80080, time: 0.409, loss: 0.009668\n",
      "step:    80100, time: 0.367, loss: 0.012465\n",
      "step:    80120, time: 0.391, loss: 0.018604\n",
      "step:    80140, time: 0.393, loss: 0.023302\n",
      "step:    80160, time: 0.383, loss: 0.010458\n",
      "step:    80180, time: 0.387, loss: 0.015348\n",
      "step:    80200, time: 0.390, loss: 0.010759\n",
      "step:    80220, time: 0.379, loss: 0.014276\n",
      "step:    80240, time: 0.396, loss: 0.011885\n",
      "step:    80260, time: 0.402, loss: 0.012674\n",
      "step:    80280, time: 0.406, loss: 0.014928\n",
      "step:    80300, time: 0.382, loss: 0.012973\n",
      "step:    80320, time: 0.393, loss: 0.014673\n",
      "step:    80340, time: 0.420, loss: 0.019608\n",
      "step:    80360, time: 0.398, loss: 0.008998\n",
      "step:    80380, time: 0.400, loss: 0.025069\n",
      "step:    80400, time: 0.405, loss: 0.014574\n",
      "step:    80420, time: 0.394, loss: 0.020644\n",
      "step:    80440, time: 0.440, loss: 0.017394\n",
      "step:    80460, time: 0.416, loss: 0.018271\n",
      "step:    80480, time: 0.395, loss: 0.012277\n",
      "step:    80500, time: 0.399, loss: 0.009349\n",
      "step:    80520, time: 0.447, loss: 0.265712\n",
      "step:    80540, time: 0.414, loss: 0.013435\n",
      "step:    80560, time: 0.407, loss: 0.014355\n",
      "step:    80580, time: 0.393, loss: 0.010251\n",
      "step:    80600, time: 0.413, loss: 0.013168\n",
      "step:    80620, time: 0.415, loss: 0.013137\n",
      "step:    80640, time: 0.390, loss: 0.012125\n",
      "step:    80660, time: 0.386, loss: 0.012596\n",
      "step:    80680, time: 0.426, loss: 0.010181\n",
      "step:    80700, time: 0.397, loss: 0.011767\n",
      "step:    80720, time: 0.414, loss: 0.014074\n",
      "step:    80740, time: 0.426, loss: 0.017393\n",
      "step:    80760, time: 0.397, loss: 0.013222\n",
      "step:    80780, time: 0.401, loss: 0.017391\n",
      "step:    80800, time: 0.395, loss: 0.014921\n",
      "step:    80820, time: 0.414, loss: 0.005969\n",
      "step:    80840, time: 0.394, loss: 0.024189\n",
      "step:    80860, time: 0.398, loss: 0.005543\n",
      "step:    80880, time: 0.407, loss: 0.011015\n",
      "step:    80900, time: 0.380, loss: 0.014803\n",
      "step:    80920, time: 0.392, loss: 0.019456\n",
      "step:    80940, time: 0.397, loss: 0.009069\n",
      "step:    80960, time: 0.402, loss: 0.023957\n",
      "step:    80980, time: 0.412, loss: 0.012759\n",
      "step:    81000, time: 0.434, loss: 0.014938\n",
      "step:    81020, time: 0.393, loss: 0.007844\n",
      "step:    81040, time: 0.389, loss: 0.016538\n",
      "step:    81060, time: 0.416, loss: 0.012094\n",
      "step:    81080, time: 0.380, loss: 0.016619\n",
      "step:    81100, time: 0.414, loss: 0.009006\n",
      "step:    81120, time: 0.386, loss: 0.012938\n",
      "step:    81140, time: 0.414, loss: 0.020732\n",
      "step:    81160, time: 0.419, loss: 0.009445\n",
      "step:    81180, time: 0.419, loss: 0.008258\n",
      "step:    81200, time: 0.395, loss: 0.008630\n",
      "step:    81220, time: 0.401, loss: 0.009568\n",
      "step:    81240, time: 0.391, loss: 0.003814\n",
      "step:    81260, time: 0.418, loss: 0.016819\n",
      "step:    81280, time: 0.401, loss: 0.013213\n",
      "step:    81300, time: 0.396, loss: 0.020141\n",
      "step:    81320, time: 0.404, loss: 0.021221\n",
      "step:    81340, time: 0.400, loss: 0.017917\n",
      "step:    81360, time: 0.426, loss: 0.022487\n",
      "step:    81380, time: 0.402, loss: 0.008287\n",
      "step:    81400, time: 0.379, loss: 0.016075\n",
      "step:    81420, time: 0.406, loss: 0.016977\n",
      "step:    81440, time: 0.409, loss: 0.006451\n",
      "step:    81460, time: 0.400, loss: 0.011256\n",
      "step:    81480, time: 0.398, loss: 0.014744\n",
      "step:    81500, time: 0.401, loss: 0.021395\n",
      "step:    81520, time: 0.402, loss: 0.018432\n",
      "step:    81540, time: 0.400, loss: 0.017985\n",
      "step:    81560, time: 0.391, loss: 0.014852\n",
      "step:    81580, time: 0.401, loss: 0.016805\n",
      "step:    81600, time: 0.397, loss: 0.014289\n",
      "step:    81620, time: 0.415, loss: 0.012813\n",
      "step:    81640, time: 0.385, loss: 0.009524\n",
      "step:    81660, time: 0.386, loss: 0.017229\n",
      "step:    81680, time: 0.399, loss: 0.015886\n",
      "step:    81700, time: 0.386, loss: 0.012734\n",
      "step:    81720, time: 0.384, loss: 0.017881\n",
      "step:    81740, time: 0.393, loss: 0.009449\n",
      "step:    81760, time: 0.399, loss: 0.018450\n",
      "step:    81780, time: 0.387, loss: 0.009856\n",
      "step:    81800, time: 0.399, loss: 0.015814\n",
      "step:    81820, time: 0.371, loss: 0.008566\n",
      "step:    81840, time: 0.401, loss: 0.011838\n",
      "step:    81860, time: 0.396, loss: 0.024604\n",
      "step:    81880, time: 0.401, loss: 0.011391\n",
      "step:    81900, time: 0.381, loss: 0.019097\n",
      "step:    81920, time: 0.402, loss: 0.016578\n",
      "step:    81940, time: 0.410, loss: 0.012495\n",
      "step:    81960, time: 0.391, loss: 0.003584\n",
      "step:    81980, time: 0.384, loss: 0.012753\n",
      "step:    82000, time: 0.383, loss: 0.017739\n",
      "step:    82020, time: 0.452, loss: 0.010990\n",
      "step:    82040, time: 0.403, loss: 0.014485\n",
      "step:    82060, time: 0.375, loss: 0.018434\n",
      "step:    82080, time: 0.396, loss: 0.017817\n",
      "step:    82100, time: 0.385, loss: 0.021464\n",
      "step:    82120, time: 0.426, loss: 0.018495\n",
      "step:    82140, time: 0.400, loss: 0.017904\n",
      "step:    82160, time: 0.390, loss: 0.013778\n",
      "step:    82180, time: 0.397, loss: 0.008128\n",
      "step:    82200, time: 0.400, loss: 0.008526\n",
      "step:    82220, time: 0.387, loss: 0.017136\n",
      "step:    82240, time: 0.393, loss: 0.010285\n",
      "step:    82260, time: 0.400, loss: 0.016934\n",
      "step:    82280, time: 0.406, loss: 0.016401\n",
      "step:    82300, time: 0.408, loss: 0.012536\n",
      "step:    82320, time: 0.421, loss: 0.006190\n",
      "step:    82340, time: 0.401, loss: 0.018895\n",
      "step:    82360, time: 0.432, loss: 0.012888\n",
      "step:    82380, time: 0.440, loss: 0.022104\n",
      "step:    82400, time: 0.450, loss: 0.008578\n",
      "step:    82420, time: 0.402, loss: 0.008917\n",
      "step:    82440, time: 0.391, loss: 0.022264\n",
      "step:    82460, time: 0.389, loss: 0.017734\n",
      "step:    82480, time: 0.392, loss: 0.038782\n",
      "step:    82500, time: 0.370, loss: 0.013300\n",
      "step:    82520, time: 0.388, loss: 0.027056\n",
      "step:    82540, time: 0.381, loss: 0.008644\n",
      "step:    82560, time: 0.415, loss: 0.015390\n",
      "step:    82580, time: 0.395, loss: 0.009502\n",
      "step:    82600, time: 0.386, loss: 0.013045\n",
      "step:    82620, time: 0.402, loss: 0.015529\n",
      "step:    82640, time: 0.391, loss: 0.017401\n",
      "step:    82660, time: 0.432, loss: 0.015913\n",
      "step:    82680, time: 0.421, loss: 0.011385\n",
      "step:    82700, time: 0.441, loss: 0.021948\n",
      "step:    82720, time: 0.400, loss: 0.016586\n",
      "step:    82740, time: 0.410, loss: 0.021305\n",
      "step:    82760, time: 0.417, loss: 0.011436\n",
      "step:    82780, time: 0.390, loss: 0.017483\n",
      "step:    82800, time: 0.403, loss: 0.009171\n",
      "step:    82820, time: 0.434, loss: 0.014184\n",
      "step:    82840, time: 0.448, loss: 0.017755\n",
      "step:    82860, time: 0.381, loss: 0.012741\n",
      "step:    82880, time: 0.410, loss: 0.017637\n",
      "step:    82900, time: 0.408, loss: 0.009392\n",
      "step:    82920, time: 0.424, loss: 0.016019\n",
      "step:    82940, time: 0.399, loss: 0.007859\n",
      "step:    82960, time: 0.420, loss: 0.014013\n",
      "step:    82980, time: 0.422, loss: 0.019136\n",
      "step:    83000, time: 0.414, loss: 0.013721\n",
      "step:    83020, time: 0.396, loss: 0.016970\n",
      "step:    83040, time: 0.413, loss: 0.013548\n",
      "step:    83060, time: 0.408, loss: 0.014514\n",
      "step:    83080, time: 0.390, loss: 0.045359\n",
      "step:    83100, time: 0.415, loss: 0.015838\n",
      "step:    83120, time: 0.409, loss: 0.013960\n",
      "step:    83140, time: 0.395, loss: 0.019079\n",
      "step:    83160, time: 0.402, loss: 0.007980\n",
      "step:    83180, time: 0.387, loss: 0.011849\n",
      "step:    83200, time: 0.406, loss: 0.015404\n",
      "step:    83220, time: 0.395, loss: 0.014012\n",
      "step:    83240, time: 0.394, loss: 0.016304\n",
      "step:    83260, time: 0.387, loss: 0.013801\n",
      "step:    83280, time: 0.413, loss: 0.015517\n",
      "step:    83300, time: 0.419, loss: 0.016224\n",
      "step:    83320, time: 0.376, loss: 0.015665\n",
      "step:    83340, time: 0.389, loss: 0.012293\n",
      "step:    83360, time: 0.415, loss: 0.012425\n",
      "step:    83380, time: 0.407, loss: 0.014268\n",
      "step:    83400, time: 0.406, loss: 0.007189\n",
      "step:    83420, time: 0.411, loss: 0.009735\n",
      "step:    83440, time: 0.376, loss: 0.002993\n",
      "step:    83460, time: 0.420, loss: 0.012859\n",
      "step:    83480, time: 0.375, loss: 0.016638\n",
      "step:    83500, time: 0.429, loss: 0.006831\n",
      "step:    83520, time: 0.381, loss: 0.013433\n",
      "step:    83540, time: 0.384, loss: 0.018387\n",
      "step:    83560, time: 0.399, loss: 0.013846\n",
      "step:    83580, time: 0.386, loss: 0.013364\n",
      "step:    83600, time: 0.394, loss: 0.024504\n",
      "step:    83620, time: 0.384, loss: 0.007926\n",
      "step:    83640, time: 0.386, loss: 0.017856\n",
      "step:    83660, time: 0.423, loss: 0.006081\n",
      "step:    83680, time: 0.405, loss: 0.025180\n",
      "step:    83700, time: 0.380, loss: 0.013007\n",
      "step:    83720, time: 0.411, loss: 0.014218\n",
      "step:    83740, time: 0.392, loss: 0.006801\n",
      "step:    83760, time: 0.371, loss: 0.014118\n",
      "step:    83780, time: 0.413, loss: 0.015299\n",
      "step:    83800, time: 0.402, loss: 0.015670\n",
      "step:    83820, time: 0.392, loss: 0.015163\n",
      "step:    83840, time: 0.406, loss: 0.016191\n",
      "step:    83860, time: 0.422, loss: 0.008127\n",
      "step:    83880, time: 0.429, loss: 0.014865\n",
      "step:    83900, time: 0.367, loss: 0.007823\n",
      "step:    83920, time: 0.412, loss: 0.011186\n",
      "step:    83940, time: 0.390, loss: 0.008039\n",
      "step:    83960, time: 0.402, loss: 0.018598\n",
      "step:    83980, time: 0.385, loss: 0.010165\n",
      "step:    84000, time: 0.397, loss: 0.012439\n",
      "step:    84020, time: 0.371, loss: 0.015052\n",
      "step:    84040, time: 0.422, loss: 0.023400\n",
      "step:    84060, time: 0.414, loss: 0.018100\n",
      "step:    84080, time: 0.390, loss: 0.010920\n",
      "step:    84100, time: 0.440, loss: 0.018063\n",
      "step:    84120, time: 0.388, loss: 0.017653\n",
      "step:    84140, time: 0.403, loss: 0.007887\n",
      "step:    84160, time: 0.386, loss: 0.010293\n",
      "step:    84180, time: 0.395, loss: 0.010161\n",
      "step:    84200, time: 0.402, loss: 0.012304\n",
      "step:    84220, time: 0.397, loss: 0.019204\n",
      "step:    84240, time: 0.394, loss: 0.011155\n",
      "step:    84260, time: 0.361, loss: 0.008623\n",
      "step:    84280, time: 0.393, loss: 0.011464\n",
      "step:    84300, time: 0.398, loss: 0.017687\n",
      "step:    84320, time: 0.380, loss: 0.011046\n",
      "step:    84340, time: 0.403, loss: 0.023540\n",
      "step:    84360, time: 0.400, loss: 0.020153\n",
      "step:    84380, time: 0.396, loss: 0.017549\n",
      "step:    84400, time: 0.399, loss: 0.015982\n",
      "step:    84420, time: 0.406, loss: 0.019388\n",
      "step:    84440, time: 0.394, loss: 0.008874\n",
      "step:    84460, time: 0.410, loss: 0.021170\n",
      "step:    84480, time: 0.409, loss: 0.012382\n",
      "step:    84500, time: 0.410, loss: 0.022198\n",
      "step:    84520, time: 0.422, loss: 0.024497\n",
      "step:    84540, time: 0.391, loss: 0.013656\n",
      "step:    84560, time: 0.407, loss: 0.021916\n",
      "step:    84580, time: 0.392, loss: 0.015097\n",
      "step:    84600, time: 0.398, loss: 0.010651\n",
      "step:    84620, time: 0.393, loss: 0.019451\n",
      "step:    84640, time: 0.365, loss: 0.014995\n",
      "step:    84660, time: 0.372, loss: 0.013496\n",
      "step:    84680, time: 0.401, loss: 0.018854\n",
      "step:    84700, time: 0.375, loss: 0.007398\n",
      "step:    84720, time: 0.406, loss: 0.016086\n",
      "step:    84740, time: 0.399, loss: 0.014518\n",
      "step:    84760, time: 0.395, loss: 0.014515\n",
      "step:    84780, time: 0.426, loss: 0.014295\n",
      "step:    84800, time: 0.411, loss: 0.023116\n",
      "step:    84820, time: 0.406, loss: 0.018964\n",
      "step:    84840, time: 0.443, loss: 0.016095\n",
      "step:    84860, time: 0.396, loss: 0.010090\n",
      "step:    84880, time: 0.379, loss: 0.011634\n",
      "step:    84900, time: 0.396, loss: 0.026315\n",
      "step:    84920, time: 0.398, loss: 0.008496\n",
      "step:    84940, time: 0.407, loss: 0.012342\n",
      "step:    84960, time: 0.417, loss: 0.019714\n",
      "step:    84980, time: 0.391, loss: 0.025565\n",
      "step:    85000, time: 0.413, loss: 0.013202\n",
      "step:    85020, time: 0.408, loss: 0.020171\n",
      "step:    85040, time: 0.391, loss: 0.013801\n",
      "step:    85060, time: 0.372, loss: 0.010184\n",
      "step:    85080, time: 0.392, loss: 0.005424\n",
      "step:    85100, time: 0.392, loss: 0.010096\n",
      "step:    85120, time: 0.406, loss: 0.016974\n",
      "step:    85140, time: 0.379, loss: 0.020621\n",
      "step:    85160, time: 0.396, loss: 0.018650\n",
      "step:    85180, time: 0.391, loss: 0.011573\n",
      "step:    85200, time: 0.422, loss: 0.023222\n",
      "step:    85220, time: 0.387, loss: 0.016609\n",
      "step:    85240, time: 0.382, loss: 0.012871\n",
      "step:    85260, time: 0.386, loss: 0.019455\n",
      "step:    85280, time: 0.406, loss: 0.017950\n",
      "step:    85300, time: 0.390, loss: 0.003937\n",
      "step:    85320, time: 0.410, loss: 0.015673\n",
      "step:    85340, time: 0.403, loss: 0.013732\n",
      "step:    85360, time: 0.365, loss: 0.018804\n",
      "step:    85380, time: 0.384, loss: 0.015875\n",
      "step:    85400, time: 0.413, loss: 0.009719\n",
      "step:    85420, time: 0.435, loss: 0.020509\n",
      "step:    85440, time: 0.409, loss: 0.013238\n",
      "step:    85460, time: 0.400, loss: 0.016471\n",
      "step:    85480, time: 0.409, loss: 0.019211\n",
      "step:    85500, time: 0.397, loss: 0.008747\n",
      "step:    85520, time: 0.406, loss: 0.012540\n",
      "step:    85540, time: 0.384, loss: 0.006865\n",
      "step:    85560, time: 0.394, loss: 0.010392\n",
      "step:    85580, time: 0.407, loss: 0.015541\n",
      "step:    85600, time: 0.398, loss: 0.005911\n",
      "step:    85620, time: 0.432, loss: 0.015612\n",
      "step:    85640, time: 0.406, loss: 0.015962\n",
      "step:    85660, time: 0.391, loss: 0.012275\n",
      "step:    85680, time: 0.405, loss: 0.024072\n",
      "step:    85700, time: 0.439, loss: 0.015213\n",
      "step:    85720, time: 0.420, loss: 0.012484\n",
      "step:    85740, time: 0.394, loss: 0.009511\n",
      "step:    85760, time: 0.423, loss: 0.017331\n",
      "step:    85780, time: 0.403, loss: 0.005230\n",
      "step:    85800, time: 0.421, loss: 0.012960\n",
      "step:    85820, time: 0.406, loss: 0.012379\n",
      "step:    85840, time: 0.448, loss: 0.006200\n",
      "step:    85860, time: 0.390, loss: 0.003058\n",
      "step:    85880, time: 0.385, loss: 0.014673\n",
      "step:    85900, time: 0.402, loss: 0.011979\n",
      "step:    85920, time: 0.398, loss: 0.012438\n",
      "step:    85940, time: 0.389, loss: 0.006971\n",
      "step:    85960, time: 0.386, loss: 0.019185\n",
      "step:    85980, time: 0.451, loss: 0.015465\n",
      "step:    86000, time: 0.374, loss: 0.010431\n",
      "step:    86020, time: 0.400, loss: 0.011237\n",
      "step:    86040, time: 0.403, loss: 0.016970\n",
      "step:    86060, time: 0.391, loss: 0.013450\n",
      "step:    86080, time: 0.377, loss: 0.012193\n",
      "step:    86100, time: 0.379, loss: 0.017727\n",
      "step:    86120, time: 0.396, loss: 0.009206\n",
      "step:    86140, time: 0.415, loss: 0.013416\n",
      "step:    86160, time: 0.392, loss: 0.010607\n",
      "step:    86180, time: 0.387, loss: 0.015362\n",
      "step:    86200, time: 0.390, loss: 0.008604\n",
      "step:    86220, time: 0.415, loss: 0.114194\n",
      "step:    86240, time: 0.397, loss: 0.011611\n",
      "step:    86260, time: 0.390, loss: 0.007011\n",
      "step:    86280, time: 0.409, loss: 0.014344\n",
      "step:    86300, time: 0.400, loss: 0.010443\n",
      "step:    86320, time: 0.426, loss: 0.010174\n",
      "step:    86340, time: 0.396, loss: 0.014685\n",
      "step:    86360, time: 0.416, loss: 0.007023\n",
      "step:    86380, time: 0.429, loss: 0.010557\n",
      "step:    86400, time: 0.391, loss: 0.008637\n",
      "step:    86420, time: 0.399, loss: 0.015780\n",
      "step:    86440, time: 0.408, loss: 0.008126\n",
      "step:    86460, time: 0.395, loss: 0.011856\n",
      "step:    86480, time: 0.401, loss: 0.015154\n",
      "step:    86500, time: 0.397, loss: 0.008337\n",
      "step:    86520, time: 0.421, loss: 0.012616\n",
      "step:    86540, time: 0.430, loss: 0.018582\n",
      "step:    86560, time: 0.438, loss: 0.012662\n",
      "step:    86580, time: 0.386, loss: 0.012824\n",
      "step:    86600, time: 0.377, loss: 0.010676\n",
      "step:    86620, time: 0.410, loss: 0.015528\n",
      "step:    86640, time: 0.404, loss: 0.014586\n",
      "step:    86660, time: 0.393, loss: 0.009659\n",
      "step:    86680, time: 0.415, loss: 0.021774\n",
      "step:    86700, time: 0.398, loss: 0.016461\n",
      "step:    86720, time: 0.436, loss: 0.008181\n",
      "step:    86740, time: 0.390, loss: 0.019239\n",
      "step:    86760, time: 0.418, loss: 0.017990\n",
      "step:    86780, time: 0.400, loss: 0.019542\n",
      "step:    86800, time: 0.395, loss: 0.023463\n",
      "step:    86820, time: 0.412, loss: 0.020740\n",
      "step:    86840, time: 0.382, loss: 0.010810\n",
      "step:    86860, time: 0.387, loss: 0.008198\n",
      "step:    86880, time: 0.412, loss: 0.014502\n",
      "step:    86900, time: 0.392, loss: 0.015194\n",
      "step:    86920, time: 0.384, loss: 0.018791\n",
      "step:    86940, time: 0.398, loss: 0.020461\n",
      "step:    86960, time: 0.408, loss: 0.018405\n",
      "step:    86980, time: 0.372, loss: 0.017222\n",
      "step:    87000, time: 0.402, loss: 0.012405\n",
      "step:    87020, time: 0.402, loss: 0.006264\n",
      "step:    87040, time: 0.407, loss: 0.020875\n",
      "step:    87060, time: 0.408, loss: 0.008308\n",
      "step:    87080, time: 0.400, loss: 0.023824\n",
      "step:    87100, time: 0.423, loss: 0.020749\n",
      "step:    87120, time: 0.408, loss: 0.012979\n",
      "step:    87140, time: 0.374, loss: 0.008144\n",
      "step:    87160, time: 0.403, loss: 0.014592\n",
      "step:    87180, time: 0.396, loss: 0.011920\n",
      "step:    87200, time: 0.411, loss: 0.016027\n",
      "step:    87220, time: 0.400, loss: 0.009024\n",
      "step:    87240, time: 0.410, loss: 0.013096\n",
      "step:    87260, time: 0.406, loss: 0.010261\n",
      "step:    87280, time: 0.431, loss: 0.021960\n",
      "step:    87300, time: 0.385, loss: 0.007084\n",
      "step:    87320, time: 0.398, loss: 0.017505\n",
      "step:    87340, time: 0.404, loss: 0.012524\n",
      "step:    87360, time: 0.415, loss: 0.009767\n",
      "step:    87380, time: 0.391, loss: 0.018235\n",
      "step:    87400, time: 0.402, loss: 0.024046\n",
      "step:    87420, time: 0.364, loss: 0.017016\n",
      "step:    87440, time: 0.420, loss: 0.016100\n",
      "step:    87460, time: 0.429, loss: 0.006271\n",
      "step:    87480, time: 0.376, loss: 0.011481\n",
      "step:    87500, time: 0.394, loss: 0.011753\n",
      "step:    87520, time: 0.382, loss: 0.010462\n",
      "step:    87540, time: 0.405, loss: 0.026759\n",
      "step:    87560, time: 0.416, loss: 0.016089\n",
      "step:    87580, time: 0.388, loss: 0.019089\n",
      "step:    87600, time: 0.396, loss: 0.007419\n",
      "step:    87620, time: 0.412, loss: 0.018526\n",
      "step:    87640, time: 0.407, loss: 0.023336\n",
      "step:    87660, time: 0.401, loss: 0.009534\n",
      "step:    87680, time: 0.417, loss: 0.010789\n",
      "step:    87700, time: 0.412, loss: 0.004933\n",
      "step:    87720, time: 0.389, loss: 0.017843\n",
      "step:    87740, time: 0.384, loss: 0.015166\n",
      "step:    87760, time: 0.411, loss: 0.015345\n",
      "step:    87780, time: 0.418, loss: 0.013884\n",
      "step:    87800, time: 0.386, loss: 0.007856\n",
      "step:    87820, time: 0.390, loss: 0.018944\n",
      "step:    87840, time: 0.391, loss: 0.007162\n",
      "step:    87860, time: 0.421, loss: 0.011977\n",
      "step:    87880, time: 0.402, loss: 0.020503\n",
      "step:    87900, time: 0.411, loss: 0.010563\n",
      "step:    87920, time: 0.405, loss: 0.021384\n",
      "step:    87940, time: 0.432, loss: 0.171547\n",
      "step:    87960, time: 0.395, loss: 0.016097\n",
      "step:    87980, time: 0.406, loss: 0.017484\n",
      "step:    88000, time: 0.439, loss: 0.116454\n",
      "step:    88020, time: 0.415, loss: 0.010382\n",
      "step:    88040, time: 0.397, loss: 0.015922\n",
      "step:    88060, time: 0.397, loss: 0.021441\n",
      "step:    88080, time: 0.392, loss: 0.011922\n",
      "step:    88100, time: 0.390, loss: 0.015065\n",
      "step:    88120, time: 0.431, loss: 0.021850\n",
      "step:    88140, time: 0.421, loss: 0.013574\n",
      "step:    88160, time: 0.396, loss: 0.021231\n",
      "step:    88180, time: 0.397, loss: 0.016032\n",
      "step:    88200, time: 0.397, loss: 0.020787\n",
      "step:    88220, time: 0.408, loss: 0.010579\n",
      "step:    88240, time: 0.420, loss: 0.018096\n",
      "step:    88260, time: 0.423, loss: 0.016607\n",
      "step:    88280, time: 0.427, loss: 0.016859\n",
      "step:    88300, time: 0.408, loss: 0.017672\n",
      "step:    88320, time: 0.385, loss: 0.013604\n",
      "step:    88340, time: 0.412, loss: 0.007749\n",
      "step:    88360, time: 0.397, loss: 0.016465\n",
      "step:    88380, time: 0.415, loss: 0.016529\n",
      "step:    88400, time: 0.427, loss: 0.015005\n",
      "step:    88420, time: 0.383, loss: 0.006656\n",
      "step:    88440, time: 0.398, loss: 0.014134\n",
      "step:    88460, time: 0.443, loss: 0.017385\n",
      "step:    88480, time: 0.393, loss: 0.021394\n",
      "step:    88500, time: 0.415, loss: 0.020932\n",
      "step:    88520, time: 0.419, loss: 0.020757\n",
      "step:    88540, time: 0.396, loss: 0.017790\n",
      "step:    88560, time: 0.446, loss: 0.173308\n",
      "step:    88580, time: 0.419, loss: 0.015162\n",
      "step:    88600, time: 0.436, loss: 0.019350\n",
      "step:    88620, time: 0.405, loss: 0.016017\n",
      "step:    88640, time: 0.390, loss: 0.017372\n",
      "step:    88660, time: 0.424, loss: 0.344163\n",
      "step:    88680, time: 0.416, loss: 0.011946\n",
      "step:    88700, time: 0.388, loss: 0.013951\n",
      "step:    88720, time: 0.385, loss: 0.011170\n",
      "step:    88740, time: 0.417, loss: 0.031482\n",
      "step:    88760, time: 0.398, loss: 0.007679\n",
      "step:    88780, time: 0.396, loss: 0.026337\n",
      "step:    88800, time: 0.387, loss: 0.012487\n",
      "step:    88820, time: 0.394, loss: 0.013408\n",
      "step:    88840, time: 0.382, loss: 0.012149\n",
      "step:    88860, time: 0.401, loss: 0.021976\n",
      "step:    88880, time: 0.391, loss: 0.014168\n",
      "step:    88900, time: 0.116, loss: 0.007681\n",
      "step:    88920, time: 0.387, loss: 0.010370\n",
      "step:    88940, time: 0.369, loss: 0.022522\n",
      "step:    88960, time: 0.422, loss: 0.025254\n",
      "step:    88980, time: 0.395, loss: 0.013583\n",
      "step:    89000, time: 0.391, loss: 0.016967\n",
      "step:    89020, time: 0.403, loss: 0.013188\n",
      "step:    89040, time: 0.402, loss: 0.015684\n",
      "step:    89060, time: 0.384, loss: 0.012281\n",
      "step:    89080, time: 0.432, loss: 0.028456\n",
      "step:    89100, time: 0.408, loss: 0.020557\n",
      "step:    89120, time: 0.444, loss: 0.010576\n",
      "step:    89140, time: 0.390, loss: 0.008321\n",
      "step:    89160, time: 0.398, loss: 0.018816\n",
      "step:    89180, time: 0.424, loss: 0.023507\n",
      "step:    89200, time: 0.383, loss: 0.015308\n",
      "step:    89220, time: 0.410, loss: 0.008793\n",
      "step:    89240, time: 0.401, loss: 0.009429\n",
      "step:    89260, time: 0.393, loss: 0.015126\n",
      "step:    89280, time: 0.374, loss: 0.012122\n",
      "step:    89300, time: 0.386, loss: 0.014109\n",
      "step:    89320, time: 0.424, loss: 0.009623\n",
      "step:    89340, time: 0.394, loss: 0.022768\n",
      "step:    89360, time: 0.390, loss: 0.009462\n",
      "step:    89380, time: 0.387, loss: 0.019031\n",
      "step:    89400, time: 0.406, loss: 0.017739\n",
      "step:    89420, time: 0.409, loss: 0.015022\n",
      "step:    89440, time: 0.406, loss: 0.019376\n",
      "step:    89460, time: 0.388, loss: 0.008193\n",
      "step:    89480, time: 0.412, loss: 0.013117\n",
      "step:    89500, time: 0.373, loss: 0.017286\n",
      "step:    89520, time: 0.387, loss: 0.021773\n",
      "step:    89540, time: 0.408, loss: 0.020757\n",
      "step:    89560, time: 0.388, loss: 0.012529\n",
      "step:    89580, time: 0.401, loss: 0.016948\n",
      "step:    89600, time: 0.399, loss: 0.011792\n",
      "step:    89620, time: 0.385, loss: 0.022106\n",
      "step:    89640, time: 0.421, loss: 0.014076\n",
      "step:    89660, time: 0.441, loss: 0.263946\n",
      "step:    89680, time: 0.374, loss: 0.009935\n",
      "step:    89700, time: 0.406, loss: 0.026937\n",
      "step:    89720, time: 0.376, loss: 0.022253\n",
      "step:    89740, time: 0.395, loss: 0.016900\n",
      "step:    89760, time: 0.407, loss: 0.007223\n",
      "step:    89780, time: 0.394, loss: 0.013962\n",
      "step:    89800, time: 0.378, loss: 0.017679\n",
      "step:    89820, time: 0.402, loss: 0.012611\n",
      "step:    89840, time: 0.379, loss: 0.021936\n",
      "step:    89860, time: 0.405, loss: 0.016604\n",
      "step:    89880, time: 0.406, loss: 0.013243\n",
      "step:    89900, time: 0.404, loss: 0.012215\n",
      "step:    89920, time: 0.392, loss: 0.015075\n",
      "step:    89940, time: 0.377, loss: 0.009545\n",
      "step:    89960, time: 0.422, loss: 0.014995\n",
      "step:    89980, time: 0.381, loss: 0.013507\n",
      "step:    90000, time: 0.400, loss: 0.022864\n",
      "step:    90020, time: 0.376, loss: 0.009147\n",
      "step:    90040, time: 0.383, loss: 0.022270\n",
      "step:    90060, time: 0.416, loss: 0.013034\n",
      "step:    90080, time: 0.403, loss: 0.021733\n",
      "step:    90100, time: 0.378, loss: 0.015847\n",
      "step:    90120, time: 0.398, loss: 0.009289\n",
      "step:    90140, time: 0.421, loss: 0.010826\n",
      "step:    90160, time: 0.412, loss: 0.013742\n",
      "step:    90180, time: 0.406, loss: 0.010001\n",
      "step:    90200, time: 0.400, loss: 0.017931\n",
      "step:    90220, time: 0.433, loss: 0.016593\n",
      "step:    90240, time: 0.387, loss: 0.016673\n",
      "step:    90260, time: 0.392, loss: 0.014435\n",
      "step:    90280, time: 0.408, loss: 0.020078\n",
      "step:    90300, time: 0.397, loss: 0.010078\n",
      "step:    90320, time: 0.403, loss: 0.014445\n",
      "step:    90340, time: 0.414, loss: 0.014651\n",
      "step:    90360, time: 0.410, loss: 0.011545\n",
      "step:    90380, time: 0.375, loss: 0.013427\n",
      "step:    90400, time: 0.412, loss: 0.018817\n",
      "step:    90420, time: 0.372, loss: 0.019309\n",
      "step:    90440, time: 0.412, loss: 0.016182\n",
      "step:    90460, time: 0.414, loss: 0.020356\n",
      "step:    90480, time: 0.407, loss: 0.009630\n",
      "step:    90500, time: 0.406, loss: 0.008120\n",
      "step:    90520, time: 0.391, loss: 0.019581\n",
      "step:    90540, time: 0.393, loss: 0.014177\n",
      "step:    90560, time: 0.389, loss: 0.012840\n",
      "step:    90580, time: 0.377, loss: 0.010207\n",
      "step:    90600, time: 0.399, loss: 0.009239\n",
      "step:    90620, time: 0.413, loss: 0.018605\n",
      "step:    90640, time: 0.414, loss: 0.015186\n",
      "step:    90660, time: 0.422, loss: 0.021087\n",
      "step:    90680, time: 0.383, loss: 0.009432\n",
      "step:    90700, time: 0.414, loss: 0.018813\n",
      "step:    90720, time: 0.379, loss: 0.012945\n",
      "step:    90740, time: 0.392, loss: 0.013166\n",
      "step:    90760, time: 0.414, loss: 0.027556\n",
      "step:    90780, time: 0.395, loss: 0.016043\n",
      "step:    90800, time: 0.367, loss: 0.008900\n",
      "step:    90820, time: 0.375, loss: 0.012419\n",
      "step:    90840, time: 0.426, loss: 0.152934\n",
      "step:    90860, time: 0.383, loss: 0.014375\n",
      "step:    90880, time: 0.400, loss: 0.007189\n",
      "step:    90900, time: 0.380, loss: 0.008920\n",
      "step:    90920, time: 0.432, loss: 0.014672\n",
      "step:    90940, time: 0.424, loss: 0.015446\n",
      "step:    90960, time: 0.387, loss: 0.019249\n",
      "step:    90980, time: 0.400, loss: 0.010548\n",
      "step:    91000, time: 0.397, loss: 0.021524\n",
      "step:    91020, time: 0.391, loss: 0.010593\n",
      "step:    91040, time: 0.407, loss: 0.010005\n",
      "step:    91060, time: 0.436, loss: 0.017169\n",
      "step:    91080, time: 0.411, loss: 0.017426\n",
      "step:    91100, time: 0.387, loss: 0.018101\n",
      "step:    91120, time: 0.386, loss: 0.015056\n",
      "step:    91140, time: 0.402, loss: 0.018002\n",
      "step:    91160, time: 0.388, loss: 0.015890\n",
      "step:    91180, time: 0.408, loss: 0.015430\n",
      "step:    91200, time: 0.392, loss: 0.009906\n",
      "step:    91220, time: 0.379, loss: 0.015607\n",
      "step:    91240, time: 0.383, loss: 0.007566\n",
      "step:    91260, time: 0.401, loss: 0.021019\n",
      "step:    91280, time: 0.408, loss: 0.018703\n",
      "step:    91300, time: 0.407, loss: 0.027441\n",
      "step:    91320, time: 0.368, loss: 0.014130\n",
      "step:    91340, time: 0.388, loss: 0.013969\n",
      "step:    91360, time: 0.403, loss: 0.018838\n",
      "step:    91380, time: 0.397, loss: 0.018381\n",
      "step:    91400, time: 0.390, loss: 0.020727\n",
      "step:    91420, time: 0.376, loss: 0.015239\n",
      "step:    91440, time: 0.402, loss: 0.006363\n",
      "step:    91460, time: 0.378, loss: 0.013390\n",
      "step:    91480, time: 0.397, loss: 0.025014\n",
      "step:    91500, time: 0.400, loss: 0.011195\n",
      "step:    91520, time: 0.406, loss: 0.021094\n",
      "step:    91540, time: 0.423, loss: 0.022439\n",
      "step:    91560, time: 0.386, loss: 0.026903\n",
      "step:    91580, time: 0.381, loss: 0.019523\n",
      "step:    91600, time: 0.404, loss: 0.015525\n",
      "step:    91620, time: 0.424, loss: 0.011392\n",
      "step:    91640, time: 0.387, loss: 0.018838\n",
      "step:    91660, time: 0.400, loss: 0.016121\n",
      "step:    91680, time: 0.415, loss: 0.015486\n",
      "step:    91700, time: 0.389, loss: 0.015978\n",
      "step:    91720, time: 0.427, loss: 0.014065\n",
      "step:    91740, time: 0.415, loss: 0.012974\n",
      "step:    91760, time: 0.400, loss: 0.017456\n",
      "step:    91780, time: 0.395, loss: 0.021276\n",
      "step:    91800, time: 0.406, loss: 0.010560\n",
      "step:    91820, time: 0.396, loss: 0.008226\n",
      "step:    91840, time: 0.392, loss: 0.018902\n",
      "step:    91860, time: 0.408, loss: 0.011639\n",
      "step:    91880, time: 0.393, loss: 0.016305\n",
      "step:    91900, time: 0.396, loss: 0.019241\n",
      "step:    91920, time: 0.388, loss: 0.009156\n",
      "step:    91940, time: 0.406, loss: 0.014097\n",
      "step:    91960, time: 0.382, loss: 0.010053\n",
      "step:    91980, time: 0.390, loss: 0.013109\n",
      "step:    92000, time: 0.403, loss: 0.007937\n",
      "step:    92020, time: 0.420, loss: 0.022467\n",
      "step:    92040, time: 0.412, loss: 0.009520\n",
      "step:    92060, time: 0.390, loss: 0.012068\n",
      "step:    92080, time: 0.388, loss: 0.013982\n",
      "step:    92100, time: 0.401, loss: 0.011358\n",
      "step:    92120, time: 0.398, loss: 0.013883\n",
      "step:    92140, time: 0.403, loss: 0.008441\n",
      "step:    92160, time: 0.382, loss: 0.015176\n",
      "step:    92180, time: 0.418, loss: 0.009393\n",
      "step:    92200, time: 0.390, loss: 0.025613\n",
      "step:    92220, time: 0.409, loss: 0.024539\n",
      "step:    92240, time: 0.446, loss: 0.012588\n",
      "step:    92260, time: 0.399, loss: 0.014036\n",
      "step:    92280, time: 0.411, loss: 0.004835\n",
      "step:    92300, time: 0.399, loss: 0.015573\n",
      "step:    92320, time: 0.380, loss: 0.009768\n",
      "step:    92340, time: 0.428, loss: 0.014393\n",
      "step:    92360, time: 0.391, loss: 0.014385\n",
      "step:    92380, time: 0.422, loss: 0.012785\n",
      "step:    92400, time: 0.391, loss: 0.009809\n",
      "step:    92420, time: 0.406, loss: 0.028009\n",
      "step:    92440, time: 0.402, loss: 0.023174\n",
      "step:    92460, time: 0.419, loss: 0.012095\n",
      "step:    92480, time: 0.395, loss: 0.012512\n",
      "step:    92500, time: 0.397, loss: 0.014008\n",
      "step:    92520, time: 0.421, loss: 0.024551\n",
      "step:    92540, time: 0.409, loss: 0.008078\n",
      "step:    92560, time: 0.397, loss: 0.015161\n",
      "step:    92580, time: 0.423, loss: 0.019874\n",
      "step:    92600, time: 0.396, loss: 0.016590\n",
      "step:    92620, time: 0.408, loss: 0.011382\n",
      "step:    92640, time: 0.454, loss: 0.004613\n",
      "step:    92660, time: 0.385, loss: 0.011934\n",
      "step:    92680, time: 0.409, loss: 0.014847\n",
      "step:    92700, time: 0.399, loss: 0.014098\n",
      "step:    92720, time: 0.388, loss: 0.018610\n",
      "step:    92740, time: 0.382, loss: 0.013637\n",
      "step:    92760, time: 0.394, loss: 0.006781\n",
      "step:    92780, time: 0.403, loss: 0.005543\n",
      "step:    92800, time: 0.394, loss: 0.011871\n",
      "step:    92820, time: 0.415, loss: 0.012262\n",
      "step:    92840, time: 0.399, loss: 0.013924\n",
      "step:    92860, time: 0.420, loss: 0.016250\n",
      "step:    92880, time: 0.387, loss: 0.022420\n",
      "step:    92900, time: 0.381, loss: 0.014714\n",
      "step:    92920, time: 0.389, loss: 0.010829\n",
      "step:    92940, time: 0.398, loss: 0.019706\n",
      "step:    92960, time: 0.403, loss: 0.004110\n",
      "step:    92980, time: 0.403, loss: 0.016625\n",
      "step:    93000, time: 0.396, loss: 0.016462\n",
      "step:    93020, time: 0.387, loss: 0.012995\n",
      "step:    93040, time: 0.422, loss: 0.015509\n",
      "step:    93060, time: 0.416, loss: 0.014039\n",
      "step:    93080, time: 0.368, loss: 0.007715\n",
      "step:    93100, time: 0.425, loss: 0.010057\n",
      "step:    93120, time: 0.415, loss: 0.007954\n",
      "step:    93140, time: 0.397, loss: 0.012564\n",
      "step:    93160, time: 0.402, loss: 0.016913\n",
      "step:    93180, time: 0.396, loss: 0.017493\n",
      "step:    93200, time: 0.377, loss: 0.005322\n",
      "step:    93220, time: 0.398, loss: 0.017222\n",
      "step:    93240, time: 0.400, loss: 0.012635\n",
      "step:    93260, time: 0.402, loss: 0.022550\n",
      "step:    93280, time: 0.457, loss: 0.013486\n",
      "step:    93300, time: 0.426, loss: 0.009968\n",
      "step:    93320, time: 0.388, loss: 0.015325\n",
      "step:    93340, time: 0.384, loss: 0.021250\n",
      "step:    93360, time: 0.415, loss: 0.015097\n",
      "step:    93380, time: 0.431, loss: 0.012396\n",
      "step:    93400, time: 0.393, loss: 0.021616\n",
      "step:    93420, time: 0.390, loss: 0.007778\n",
      "step:    93440, time: 0.385, loss: 0.018994\n",
      "step:    93460, time: 0.393, loss: 0.011592\n",
      "step:    93480, time: 0.382, loss: 0.013047\n",
      "step:    93500, time: 0.400, loss: 0.007864\n",
      "step:    93520, time: 0.416, loss: 0.023028\n",
      "step:    93540, time: 0.411, loss: 0.016049\n",
      "step:    93560, time: 0.426, loss: 0.019002\n",
      "step:    93580, time: 0.406, loss: 0.015895\n",
      "step:    93600, time: 0.387, loss: 0.009840\n",
      "step:    93620, time: 0.371, loss: 0.012257\n",
      "step:    93640, time: 0.380, loss: 0.010517\n",
      "step:    93660, time: 0.416, loss: 0.009050\n",
      "step:    93680, time: 0.408, loss: 0.023817\n",
      "step:    93700, time: 0.382, loss: 0.019120\n",
      "step:    93720, time: 0.392, loss: 0.007685\n",
      "step:    93740, time: 0.404, loss: 0.016899\n",
      "step:    93760, time: 0.409, loss: 0.006114\n",
      "step:    93780, time: 0.375, loss: 0.016816\n",
      "step:    93800, time: 0.374, loss: 0.027524\n",
      "step:    93820, time: 0.403, loss: 0.005519\n",
      "step:    93840, time: 0.422, loss: 0.016228\n",
      "step:    93860, time: 0.389, loss: 0.011362\n",
      "step:    93880, time: 0.389, loss: 0.014127\n",
      "step:    93900, time: 0.377, loss: 0.012176\n",
      "step:    93920, time: 0.395, loss: 0.017709\n",
      "step:    93940, time: 0.404, loss: 0.020985\n",
      "step:    93960, time: 0.368, loss: 0.012366\n",
      "step:    93980, time: 0.388, loss: 0.013742\n",
      "step:    94000, time: 0.411, loss: 0.016306\n",
      "step:    94020, time: 0.375, loss: 0.014828\n",
      "step:    94040, time: 0.381, loss: 0.015787\n",
      "step:    94060, time: 0.384, loss: 0.020877\n",
      "step:    94080, time: 0.368, loss: 0.009574\n",
      "step:    94100, time: 0.425, loss: 0.013219\n",
      "step:    94120, time: 0.428, loss: 0.015569\n",
      "step:    94140, time: 0.417, loss: 0.020653\n",
      "step:    94160, time: 0.388, loss: 0.011738\n",
      "step:    94180, time: 0.408, loss: 0.011282\n",
      "step:    94200, time: 0.439, loss: 0.019876\n",
      "step:    94220, time: 0.412, loss: 0.009327\n",
      "step:    94240, time: 0.371, loss: 0.015962\n",
      "step:    94260, time: 0.415, loss: 0.011352\n",
      "step:    94280, time: 0.388, loss: 0.014654\n",
      "step:    94300, time: 0.406, loss: 0.010318\n",
      "step:    94320, time: 0.394, loss: 0.016733\n",
      "step:    94340, time: 0.401, loss: 0.015141\n",
      "step:    94360, time: 0.384, loss: 0.016001\n",
      "step:    94380, time: 0.408, loss: 0.019193\n",
      "step:    94400, time: 0.391, loss: 0.019285\n",
      "step:    94420, time: 0.433, loss: 0.016560\n",
      "step:    94440, time: 0.392, loss: 0.012784\n",
      "step:    94460, time: 0.392, loss: 0.016859\n",
      "step:    94480, time: 0.406, loss: 0.008849\n",
      "step:    94500, time: 0.404, loss: 0.014695\n",
      "step:    94520, time: 0.411, loss: 0.020790\n",
      "step:    94540, time: 0.386, loss: 0.005148\n",
      "step:    94560, time: 0.388, loss: 0.011333\n",
      "step:    94580, time: 0.378, loss: 0.027826\n",
      "step:    94600, time: 0.403, loss: 0.010045\n",
      "step:    94620, time: 0.389, loss: 0.024030\n",
      "step:    94640, time: 0.392, loss: 0.012630\n",
      "step:    94660, time: 0.395, loss: 0.017321\n",
      "step:    94680, time: 0.401, loss: 0.014562\n",
      "step:    94700, time: 0.419, loss: 0.008518\n",
      "step:    94720, time: 0.418, loss: 0.021207\n",
      "step:    94740, time: 0.382, loss: 0.016467\n",
      "step:    94760, time: 0.391, loss: 0.012587\n",
      "step:    94780, time: 0.397, loss: 0.015833\n",
      "step:    94800, time: 0.403, loss: 0.007614\n",
      "step:    94820, time: 0.418, loss: 0.014113\n",
      "step:    94840, time: 0.403, loss: 0.014708\n",
      "step:    94860, time: 0.435, loss: 0.014659\n",
      "step:    94880, time: 0.397, loss: 0.016833\n",
      "step:    94900, time: 0.396, loss: 0.007926\n",
      "step:    94920, time: 0.385, loss: 0.021813\n",
      "step:    94940, time: 0.413, loss: 0.020404\n",
      "step:    94960, time: 0.406, loss: 0.021379\n",
      "step:    94980, time: 0.424, loss: 0.012441\n",
      "step:    95000, time: 0.410, loss: 0.016393\n",
      "step:    95020, time: 0.375, loss: 0.022105\n",
      "step:    95040, time: 0.413, loss: 0.014488\n",
      "step:    95060, time: 0.406, loss: 0.016166\n",
      "step:    95080, time: 0.400, loss: 0.021361\n",
      "step:    95100, time: 0.396, loss: 0.008873\n",
      "step:    95120, time: 0.411, loss: 0.013952\n",
      "step:    95140, time: 0.399, loss: 0.015082\n",
      "step:    95160, time: 0.378, loss: 0.014876\n",
      "step:    95180, time: 0.395, loss: 0.012677\n",
      "step:    95200, time: 0.388, loss: 0.022047\n",
      "step:    95220, time: 0.415, loss: 0.017606\n",
      "step:    95240, time: 0.423, loss: 0.016552\n",
      "step:    95260, time: 0.376, loss: 0.013306\n",
      "step:    95280, time: 0.387, loss: 0.009420\n",
      "step:    95300, time: 0.378, loss: 0.018597\n",
      "step:    95320, time: 0.394, loss: 0.015535\n",
      "step:    95340, time: 0.385, loss: 0.014178\n",
      "step:    95360, time: 0.440, loss: 0.018491\n",
      "step:    95380, time: 0.389, loss: 0.009530\n",
      "step:    95400, time: 0.376, loss: 0.025563\n",
      "step:    95420, time: 0.368, loss: 0.012752\n",
      "step:    95440, time: 0.388, loss: 0.018540\n",
      "step:    95460, time: 0.447, loss: 0.020058\n",
      "step:    95480, time: 0.411, loss: 0.021621\n",
      "step:    95500, time: 0.391, loss: 0.011578\n",
      "step:    95520, time: 0.405, loss: 0.013158\n",
      "step:    95540, time: 0.407, loss: 0.011460\n",
      "step:    95560, time: 0.391, loss: 0.008894\n",
      "step:    95580, time: 0.399, loss: 0.011132\n",
      "step:    95600, time: 0.415, loss: 0.012738\n",
      "step:    95620, time: 0.373, loss: 0.009542\n",
      "step:    95640, time: 0.421, loss: 0.019605\n",
      "step:    95660, time: 0.418, loss: 0.016376\n",
      "step:    95680, time: 0.432, loss: 0.014992\n",
      "step:    95700, time: 0.426, loss: 0.012700\n",
      "step:    95720, time: 0.420, loss: 0.018019\n",
      "step:    95740, time: 0.388, loss: 0.006681\n",
      "step:    95760, time: 0.395, loss: 0.021067\n",
      "step:    95780, time: 0.424, loss: 0.023044\n",
      "step:    95800, time: 0.413, loss: 0.023788\n",
      "step:    95820, time: 0.384, loss: 0.009216\n",
      "step:    95840, time: 0.400, loss: 0.018219\n",
      "step:    95860, time: 0.413, loss: 0.017306\n",
      "step:    95880, time: 0.486, loss: 0.019710\n",
      "step:    95900, time: 0.425, loss: 0.009984\n",
      "step:    95920, time: 0.428, loss: 0.014330\n",
      "step:    95940, time: 0.427, loss: 0.014802\n",
      "step:    95960, time: 0.459, loss: 0.020083\n",
      "step:    95980, time: 0.452, loss: 0.016190\n",
      "step:    96000, time: 0.385, loss: 0.023752\n",
      "step:    96020, time: 0.429, loss: 0.019889\n",
      "step:    96040, time: 0.373, loss: 0.015252\n",
      "step:    96060, time: 0.402, loss: 0.009072\n",
      "step:    96080, time: 0.393, loss: 0.019509\n",
      "step:    96100, time: 0.397, loss: 0.014467\n",
      "step:    96120, time: 0.392, loss: 0.005728\n",
      "step:    96140, time: 0.387, loss: 0.018922\n",
      "step:    96160, time: 0.394, loss: 0.018341\n",
      "step:    96180, time: 0.385, loss: 0.006650\n",
      "step:    96200, time: 0.395, loss: 0.012888\n",
      "step:    96220, time: 0.428, loss: 0.013209\n",
      "step:    96240, time: 0.397, loss: 0.017520\n",
      "step:    96260, time: 0.389, loss: 0.015620\n",
      "step:    96280, time: 0.397, loss: 0.010527\n",
      "step:    96300, time: 0.426, loss: 0.017206\n",
      "step:    96320, time: 0.410, loss: 0.012824\n",
      "step:    96340, time: 0.405, loss: 0.014468\n",
      "step:    96360, time: 0.393, loss: 0.019352\n",
      "step:    96380, time: 0.397, loss: 0.011063\n",
      "step:    96400, time: 0.416, loss: 0.020521\n",
      "step:    96420, time: 0.406, loss: 0.010388\n",
      "step:    96440, time: 0.395, loss: 0.009759\n",
      "step:    96460, time: 0.405, loss: 0.012505\n",
      "step:    96480, time: 0.404, loss: 0.010735\n",
      "step:    96500, time: 0.416, loss: 0.017462\n",
      "step:    96520, time: 0.383, loss: 0.019266\n",
      "step:    96540, time: 0.389, loss: 0.018971\n",
      "step:    96560, time: 0.399, loss: 0.013225\n",
      "step:    96580, time: 0.402, loss: 0.013839\n",
      "step:    96600, time: 0.407, loss: 0.008549\n",
      "step:    96620, time: 0.412, loss: 0.014546\n",
      "step:    96640, time: 0.406, loss: 0.009083\n",
      "step:    96660, time: 0.422, loss: 0.012993\n",
      "step:    96680, time: 0.395, loss: 0.016292\n",
      "step:    96700, time: 0.394, loss: 0.025681\n",
      "step:    96720, time: 0.377, loss: 0.020265\n",
      "step:    96740, time: 0.399, loss: 0.014431\n",
      "step:    96760, time: 0.390, loss: 0.006366\n",
      "step:    96780, time: 0.396, loss: 0.011079\n",
      "step:    96800, time: 0.401, loss: 0.012311\n",
      "step:    96820, time: 0.390, loss: 0.013286\n",
      "step:    96840, time: 0.393, loss: 0.007011\n",
      "step:    96860, time: 0.389, loss: 0.005183\n",
      "step:    96880, time: 0.398, loss: 0.010751\n",
      "step:    96900, time: 0.395, loss: 0.015298\n",
      "step:    96920, time: 0.396, loss: 0.018367\n",
      "step:    96940, time: 0.389, loss: 0.013531\n",
      "step:    96960, time: 0.396, loss: 0.015786\n",
      "step:    96980, time: 0.393, loss: 0.016003\n",
      "step:    97000, time: 0.423, loss: 0.016659\n",
      "step:    97020, time: 0.379, loss: 0.017795\n",
      "step:    97040, time: 0.396, loss: 0.019941\n",
      "step:    97060, time: 0.388, loss: 0.017674\n",
      "step:    97080, time: 0.408, loss: 0.006758\n",
      "step:    97100, time: 0.398, loss: 0.017723\n",
      "step:    97120, time: 0.398, loss: 0.010868\n",
      "step:    97140, time: 0.406, loss: 0.016995\n",
      "step:    97160, time: 0.399, loss: 0.013809\n",
      "step:    97180, time: 0.442, loss: 0.112004\n",
      "step:    97200, time: 0.381, loss: 0.014565\n",
      "step:    97220, time: 0.420, loss: 0.025339\n",
      "step:    97240, time: 0.435, loss: 0.013584\n",
      "step:    97260, time: 0.398, loss: 0.012394\n",
      "step:    97280, time: 0.381, loss: 0.011161\n",
      "step:    97300, time: 0.403, loss: 0.014272\n",
      "step:    97320, time: 0.407, loss: 0.021150\n",
      "step:    97340, time: 0.384, loss: 0.018694\n",
      "step:    97360, time: 0.407, loss: 0.008225\n",
      "step:    97380, time: 0.400, loss: 0.014185\n",
      "step:    97400, time: 0.391, loss: 0.017960\n",
      "step:    97420, time: 0.380, loss: 0.023570\n",
      "step:    97440, time: 0.399, loss: 0.104483\n",
      "step:    97460, time: 0.411, loss: 0.039736\n",
      "step:    97480, time: 0.389, loss: 0.012782\n",
      "step:    97500, time: 0.387, loss: 0.018091\n",
      "step:    97520, time: 0.404, loss: 0.013845\n",
      "step:    97540, time: 0.407, loss: 0.016725\n",
      "step:    97560, time: 0.394, loss: 0.020017\n",
      "step:    97580, time: 0.380, loss: 0.015114\n",
      "step:    97600, time: 0.395, loss: 0.012753\n",
      "step:    97620, time: 0.418, loss: 0.017227\n",
      "step:    97640, time: 0.415, loss: 0.015572\n",
      "step:    97660, time: 0.400, loss: 0.012296\n",
      "step:    97680, time: 0.406, loss: 0.013057\n",
      "step:    97700, time: 0.401, loss: 0.018336\n",
      "step:    97720, time: 0.411, loss: 0.021247\n",
      "step:    97740, time: 0.380, loss: 0.020708\n",
      "step:    97760, time: 0.386, loss: 0.016032\n",
      "step:    97780, time: 0.404, loss: 0.019893\n",
      "step:    97800, time: 0.398, loss: 0.008641\n",
      "step:    97820, time: 0.387, loss: 0.010072\n",
      "step:    97840, time: 0.387, loss: 0.006054\n",
      "step:    97860, time: 0.435, loss: 0.014584\n",
      "step:    97880, time: 0.401, loss: 0.013937\n",
      "step:    97900, time: 0.440, loss: 0.013676\n",
      "step:    97920, time: 0.393, loss: 0.013209\n",
      "step:    97940, time: 0.387, loss: 0.007838\n",
      "step:    97960, time: 0.425, loss: 0.019002\n",
      "step:    97980, time: 0.393, loss: 0.021700\n",
      "step:    98000, time: 0.416, loss: 0.018218\n",
      "step:    98020, time: 0.395, loss: 0.012111\n",
      "step:    98040, time: 0.406, loss: 0.010488\n",
      "step:    98060, time: 0.393, loss: 0.016569\n",
      "step:    98080, time: 0.391, loss: 0.011287\n",
      "step:    98100, time: 0.393, loss: 0.007418\n",
      "step:    98120, time: 0.411, loss: 0.017487\n",
      "step:    98140, time: 0.380, loss: 0.014223\n",
      "step:    98160, time: 0.385, loss: 0.014051\n",
      "step:    98180, time: 0.412, loss: 0.012799\n",
      "step:    98200, time: 0.400, loss: 0.021493\n",
      "step:    98220, time: 0.416, loss: 0.014083\n",
      "step:    98240, time: 0.398, loss: 0.014727\n",
      "step:    98260, time: 0.409, loss: 0.015092\n",
      "step:    98280, time: 0.422, loss: 0.014568\n",
      "step:    98300, time: 0.407, loss: 0.010769\n",
      "step:    98320, time: 0.371, loss: 0.008630\n",
      "step:    98340, time: 0.396, loss: 0.009356\n",
      "step:    98360, time: 0.396, loss: 0.013834\n",
      "step:    98380, time: 0.388, loss: 0.015770\n",
      "step:    98400, time: 0.390, loss: 0.013821\n",
      "step:    98420, time: 0.452, loss: 0.111707\n",
      "step:    98440, time: 0.425, loss: 0.021437\n",
      "step:    98460, time: 0.401, loss: 0.038322\n",
      "step:    98480, time: 0.434, loss: 0.013064\n",
      "step:    98500, time: 0.380, loss: 0.012419\n",
      "step:    98520, time: 0.407, loss: 0.017946\n",
      "step:    98540, time: 0.403, loss: 0.008808\n",
      "step:    98560, time: 0.410, loss: 0.016074\n",
      "step:    98580, time: 0.381, loss: 0.010679\n",
      "step:    98600, time: 0.381, loss: 0.008624\n",
      "step:    98620, time: 0.376, loss: 0.021336\n",
      "step:    98640, time: 0.401, loss: 0.012351\n",
      "step:    98660, time: 0.395, loss: 0.016789\n",
      "step:    98680, time: 0.408, loss: 0.010704\n",
      "step:    98700, time: 0.408, loss: 0.014071\n",
      "step:    98720, time: 0.407, loss: 0.008889\n",
      "step:    98740, time: 0.376, loss: 0.019005\n",
      "step:    98760, time: 0.416, loss: 0.010160\n",
      "step:    98780, time: 0.380, loss: 0.012745\n",
      "step:    98800, time: 0.395, loss: 0.020745\n",
      "step:    98820, time: 0.384, loss: 0.006683\n",
      "step:    98840, time: 0.403, loss: 0.018579\n",
      "step:    98860, time: 0.385, loss: 0.014490\n",
      "step:    98880, time: 0.406, loss: 0.010732\n",
      "step:    98900, time: 0.381, loss: 0.013208\n",
      "step:    98920, time: 0.381, loss: 0.023205\n",
      "step:    98940, time: 0.384, loss: 0.016545\n",
      "step:    98960, time: 0.402, loss: 0.009492\n",
      "step:    98980, time: 0.406, loss: 0.017188\n",
      "step:    99000, time: 0.397, loss: 0.012959\n",
      "step:    99020, time: 0.438, loss: 0.016441\n",
      "step:    99040, time: 0.410, loss: 0.015330\n",
      "step:    99060, time: 0.410, loss: 0.016948\n",
      "step:    99080, time: 0.397, loss: 0.024000\n",
      "step:    99100, time: 0.388, loss: 0.011557\n",
      "step:    99120, time: 0.375, loss: 0.017684\n",
      "step:    99140, time: 0.413, loss: 0.015458\n",
      "step:    99160, time: 0.405, loss: 0.009151\n",
      "step:    99180, time: 0.393, loss: 0.012243\n",
      "step:    99200, time: 0.388, loss: 0.024047\n",
      "step:    99220, time: 0.393, loss: 0.007896\n",
      "step:    99240, time: 0.441, loss: 0.182844\n",
      "step:    99260, time: 0.406, loss: 0.022575\n",
      "step:    99280, time: 0.402, loss: 0.017776\n",
      "step:    99300, time: 0.393, loss: 0.008824\n",
      "step:    99320, time: 0.402, loss: 0.007953\n",
      "step:    99340, time: 0.391, loss: 0.342147\n",
      "step:    99360, time: 0.399, loss: 0.011723\n",
      "step:    99380, time: 0.383, loss: 0.005454\n",
      "step:    99400, time: 0.406, loss: 0.012855\n",
      "step:    99420, time: 0.402, loss: 0.006834\n",
      "step:    99440, time: 0.426, loss: 0.014817\n",
      "step:    99460, time: 0.414, loss: 0.011199\n",
      "step:    99480, time: 0.393, loss: 0.015473\n",
      "step:    99500, time: 0.394, loss: 0.015368\n",
      "step:    99520, time: 0.422, loss: 0.018408\n",
      "step:    99540, time: 0.397, loss: 0.013548\n",
      "step:    99560, time: 0.387, loss: 0.013152\n",
      "step:    99580, time: 0.382, loss: 0.010898\n",
      "step:    99600, time: 0.421, loss: 0.009912\n",
      "step:    99620, time: 0.397, loss: 0.018576\n",
      "step:    99640, time: 0.375, loss: 0.015165\n",
      "step:    99660, time: 0.385, loss: 0.007465\n",
      "step:    99680, time: 0.422, loss: 0.011454\n",
      "step:    99700, time: 0.448, loss: 0.020249\n",
      "step:    99720, time: 0.408, loss: 0.019952\n",
      "step:    99740, time: 0.372, loss: 0.004858\n",
      "step:    99760, time: 0.382, loss: 0.019009\n",
      "step:    99780, time: 0.407, loss: 0.025210\n",
      "step:    99800, time: 0.457, loss: 0.017536\n",
      "step:    99820, time: 0.396, loss: 0.014982\n",
      "step:    99840, time: 0.393, loss: 0.006816\n",
      "step:    99860, time: 0.428, loss: 0.017187\n",
      "step:    99880, time: 0.393, loss: 0.020881\n",
      "step:    99900, time: 0.423, loss: 0.012420\n",
      "step:    99920, time: 0.408, loss: 0.013866\n",
      "step:    99940, time: 0.404, loss: 0.007041\n",
      "step:    99960, time: 0.383, loss: 0.007930\n",
      "step:    99980, time: 0.385, loss: 0.006935\n",
      "step:   100000, time: 0.390, loss: 0.007243\n",
      "step:   100020, time: 0.404, loss: 0.014874\n",
      "step:   100040, time: 0.413, loss: 0.018629\n",
      "step:   100060, time: 0.443, loss: 0.021922\n",
      "step:   100080, time: 0.436, loss: 0.016463\n",
      "step:   100100, time: 0.396, loss: 0.008230\n",
      "step:   100120, time: 0.367, loss: 0.018318\n",
      "step:   100140, time: 0.396, loss: 0.009534\n",
      "step:   100160, time: 0.380, loss: 0.015262\n",
      "step:   100180, time: 0.405, loss: 0.022917\n",
      "step:   100200, time: 0.410, loss: 0.012267\n",
      "step:   100220, time: 0.411, loss: 0.013364\n",
      "step:   100240, time: 0.380, loss: 0.019196\n",
      "step:   100260, time: 0.395, loss: 0.015097\n",
      "step:   100280, time: 0.422, loss: 0.017753\n",
      "step:   100300, time: 0.422, loss: 0.021750\n",
      "step:   100320, time: 0.404, loss: 0.021040\n",
      "step:   100340, time: 0.440, loss: 0.152950\n",
      "step:   100360, time: 0.394, loss: 0.102140\n",
      "step:   100380, time: 0.398, loss: 0.024744\n",
      "step:   100400, time: 0.421, loss: 0.017652\n",
      "step:   100420, time: 0.429, loss: 0.022405\n",
      "step:   100440, time: 0.396, loss: 0.018219\n",
      "step:   100460, time: 0.407, loss: 0.012812\n",
      "step:   100480, time: 0.408, loss: 0.018692\n",
      "step:   100500, time: 0.446, loss: 0.019441\n",
      "step:   100520, time: 0.405, loss: 0.009901\n",
      "step:   100540, time: 0.396, loss: 0.012377\n",
      "step:   100560, time: 0.403, loss: 0.012290\n",
      "step:   100580, time: 0.403, loss: 0.019171\n",
      "step:   100600, time: 0.418, loss: 0.012327\n",
      "step:   100620, time: 0.400, loss: 0.008662\n",
      "step:   100640, time: 0.406, loss: 0.017492\n",
      "step:   100660, time: 0.427, loss: 0.010752\n",
      "step:   100680, time: 0.419, loss: 0.015826\n",
      "step:   100700, time: 0.428, loss: 0.007284\n",
      "step:   100720, time: 0.394, loss: 0.016603\n",
      "step:   100740, time: 0.396, loss: 0.011832\n",
      "step:   100760, time: 0.421, loss: 0.023595\n",
      "step:   100780, time: 0.404, loss: 0.018455\n",
      "step:   100800, time: 0.395, loss: 0.010830\n",
      "step:   100820, time: 0.418, loss: 0.010454\n",
      "step:   100840, time: 0.386, loss: 0.016691\n",
      "step:   100860, time: 0.392, loss: 0.008147\n",
      "step:   100880, time: 0.381, loss: 0.018675\n",
      "step:   100900, time: 0.388, loss: 0.021241\n",
      "step:   100920, time: 0.386, loss: 0.013040\n",
      "step:   100940, time: 0.406, loss: 0.015960\n",
      "step:   100960, time: 0.373, loss: 0.016169\n",
      "step:   100980, time: 0.426, loss: 0.017477\n",
      "step:   101000, time: 0.418, loss: 0.020505\n",
      "step:   101020, time: 0.435, loss: 0.019383\n",
      "step:   101040, time: 0.405, loss: 0.018409\n",
      "step:   101060, time: 0.391, loss: 0.019650\n",
      "step:   101080, time: 0.409, loss: 0.022913\n",
      "step:   101100, time: 0.402, loss: 0.013408\n",
      "step:   101120, time: 0.393, loss: 0.012440\n",
      "step:   101140, time: 0.381, loss: 0.009316\n",
      "step:   101160, time: 0.386, loss: 0.016323\n",
      "step:   101180, time: 0.402, loss: 0.013958\n",
      "step:   101200, time: 0.405, loss: 0.015427\n",
      "step:   101220, time: 0.409, loss: 0.007349\n",
      "step:   101240, time: 0.407, loss: 0.030202\n",
      "step:   101260, time: 0.379, loss: 0.015125\n",
      "step:   101280, time: 0.396, loss: 0.010829\n",
      "step:   101300, time: 0.390, loss: 0.011912\n",
      "step:   101320, time: 0.383, loss: 0.012986\n",
      "step:   101340, time: 0.445, loss: 0.018599\n",
      "step:   101360, time: 0.390, loss: 0.018108\n",
      "step:   101380, time: 0.394, loss: 0.008196\n",
      "step:   101400, time: 0.390, loss: 0.019207\n",
      "step:   101420, time: 0.416, loss: 0.017001\n",
      "step:   101440, time: 0.418, loss: 0.119443\n",
      "step:   101460, time: 0.421, loss: 0.014223\n",
      "step:   101480, time: 0.409, loss: 0.021282\n",
      "step:   101500, time: 0.400, loss: 0.016142\n",
      "step:   101520, time: 0.416, loss: 0.008319\n",
      "step:   101540, time: 0.389, loss: 0.016605\n",
      "step:   101560, time: 0.409, loss: 0.024053\n",
      "step:   101580, time: 0.395, loss: 0.006772\n",
      "step:   101600, time: 0.388, loss: 0.025850\n",
      "step:   101620, time: 0.408, loss: 0.017333\n",
      "step:   101640, time: 0.398, loss: 0.019152\n",
      "step:   101660, time: 0.384, loss: 0.008007\n",
      "step:   101680, time: 0.404, loss: 0.017569\n",
      "step:   101700, time: 0.370, loss: 0.017013\n",
      "step:   101720, time: 0.397, loss: 0.011526\n",
      "step:   101740, time: 0.394, loss: 0.006694\n",
      "step:   101760, time: 0.406, loss: 0.011792\n",
      "step:   101780, time: 0.391, loss: 0.021316\n",
      "step:   101800, time: 0.390, loss: 0.013501\n",
      "step:   101820, time: 0.419, loss: 0.020679\n",
      "step:   101840, time: 0.384, loss: 0.015685\n",
      "step:   101860, time: 0.404, loss: 0.012782\n",
      "step:   101880, time: 0.393, loss: 0.022841\n",
      "step:   101900, time: 0.399, loss: 0.017425\n",
      "step:   101920, time: 0.376, loss: 0.012441\n",
      "step:   101940, time: 0.410, loss: 0.012932\n",
      "step:   101960, time: 0.395, loss: 0.020527\n",
      "step:   101980, time: 0.386, loss: 0.007701\n",
      "step:   102000, time: 0.393, loss: 0.011829\n",
      "step:   102020, time: 0.387, loss: 0.018183\n",
      "step:   102040, time: 0.427, loss: 0.009430\n",
      "step:   102060, time: 0.412, loss: 0.012850\n",
      "step:   102080, time: 0.412, loss: 0.010876\n",
      "step:   102100, time: 0.398, loss: 0.012257\n",
      "step:   102120, time: 0.373, loss: 0.017871\n",
      "step:   102140, time: 0.377, loss: 0.009778\n",
      "step:   102160, time: 0.396, loss: 0.010075\n",
      "step:   102180, time: 0.406, loss: 0.008330\n",
      "step:   102200, time: 0.421, loss: 0.020109\n",
      "step:   102220, time: 0.383, loss: 0.008314\n",
      "step:   102240, time: 0.385, loss: 0.011296\n",
      "step:   102260, time: 0.413, loss: 0.019644\n",
      "step:   102280, time: 0.404, loss: 0.004743\n",
      "step:   102300, time: 0.394, loss: 0.017902\n",
      "step:   102320, time: 0.396, loss: 0.015818\n",
      "step:   102340, time: 0.378, loss: 0.012191\n",
      "step:   102360, time: 0.379, loss: 0.015197\n",
      "step:   102380, time: 0.417, loss: 0.009894\n",
      "step:   102400, time: 0.397, loss: 0.012608\n",
      "step:   102420, time: 0.388, loss: 0.017333\n",
      "step:   102440, time: 0.391, loss: 0.014614\n",
      "step:   102460, time: 0.377, loss: 0.017046\n",
      "step:   102480, time: 0.397, loss: 0.015846\n",
      "step:   102500, time: 0.423, loss: 0.022268\n",
      "step:   102520, time: 0.396, loss: 0.014665\n",
      "step:   102540, time: 0.412, loss: 0.019031\n",
      "step:   102560, time: 0.407, loss: 0.018289\n",
      "step:   102580, time: 0.392, loss: 0.016186\n",
      "step:   102600, time: 0.419, loss: 0.014205\n",
      "step:   102620, time: 0.426, loss: 0.014770\n",
      "step:   102640, time: 0.447, loss: 0.024535\n",
      "step:   102660, time: 0.399, loss: 0.019416\n",
      "step:   102680, time: 0.431, loss: 0.013771\n",
      "step:   102700, time: 0.408, loss: 0.014612\n",
      "step:   102720, time: 0.393, loss: 0.012458\n",
      "step:   102740, time: 0.441, loss: 0.020094\n",
      "step:   102760, time: 0.395, loss: 0.020933\n",
      "step:   102780, time: 0.412, loss: 0.011683\n",
      "step:   102800, time: 0.416, loss: 0.020437\n",
      "step:   102820, time: 0.419, loss: 0.017793\n",
      "step:   102840, time: 0.397, loss: 0.012965\n",
      "step:   102860, time: 0.402, loss: 0.021913\n",
      "step:   102880, time: 0.411, loss: 0.017055\n",
      "step:   102900, time: 0.413, loss: 0.013689\n",
      "step:   102920, time: 0.416, loss: 0.015567\n",
      "step:   102940, time: 0.394, loss: 0.016957\n",
      "step:   102960, time: 0.387, loss: 0.013992\n",
      "step:   102980, time: 0.412, loss: 0.011906\n",
      "step:   103000, time: 0.419, loss: 0.010574\n",
      "step:   103020, time: 0.398, loss: 0.015680\n",
      "step:   103040, time: 0.391, loss: 0.012285\n",
      "step:   103060, time: 0.377, loss: 0.009752\n",
      "step:   103080, time: 0.419, loss: 0.015975\n",
      "step:   103100, time: 0.401, loss: 0.009205\n",
      "step:   103120, time: 0.373, loss: 0.010797\n",
      "step:   103140, time: 0.403, loss: 0.012738\n",
      "step:   103160, time: 0.401, loss: 0.019089\n",
      "step:   103180, time: 0.408, loss: 0.021637\n",
      "step:   103200, time: 0.408, loss: 0.016928\n",
      "step:   103220, time: 0.390, loss: 0.020165\n",
      "step:   103240, time: 0.407, loss: 0.014987\n",
      "step:   103260, time: 0.462, loss: 0.171364\n",
      "step:   103280, time: 0.429, loss: 0.020561\n",
      "step:   103300, time: 0.413, loss: 0.012808\n",
      "step:   103320, time: 0.382, loss: 0.014698\n",
      "step:   103340, time: 0.385, loss: 0.009932\n",
      "step:   103360, time: 0.377, loss: 0.012166\n",
      "step:   103380, time: 0.389, loss: 0.009236\n",
      "step:   103400, time: 0.419, loss: 0.024573\n",
      "step:   103420, time: 0.377, loss: 0.015329\n",
      "step:   103440, time: 0.395, loss: 0.010964\n",
      "step:   103460, time: 0.408, loss: 0.019399\n",
      "step:   103480, time: 0.394, loss: 0.014454\n",
      "step:   103500, time: 0.399, loss: 0.023754\n",
      "step:   103520, time: 0.382, loss: 0.014929\n",
      "step:   103540, time: 0.393, loss: 0.020424\n",
      "step:   103560, time: 0.396, loss: 0.014009\n",
      "step:   103580, time: 0.415, loss: 0.007350\n",
      "step:   103600, time: 0.446, loss: 0.103533\n",
      "step:   103620, time: 0.393, loss: 0.015643\n",
      "step:   103640, time: 0.417, loss: 0.009956\n",
      "step:   103660, time: 0.436, loss: 0.019174\n",
      "step:   103680, time: 0.437, loss: 0.006647\n",
      "step:   103700, time: 0.415, loss: 0.017954\n",
      "step:   103720, time: 0.409, loss: 0.008060\n",
      "step:   103740, time: 0.409, loss: 0.013633\n",
      "step:   103760, time: 0.387, loss: 0.009139\n",
      "step:   103780, time: 0.430, loss: 0.008324\n",
      "step:   103800, time: 0.390, loss: 0.014436\n",
      "step:   103820, time: 0.399, loss: 0.008753\n",
      "step:   103840, time: 0.443, loss: 0.014585\n",
      "step:   103860, time: 0.442, loss: 0.013789\n",
      "step:   103880, time: 0.390, loss: 0.014915\n",
      "step:   103900, time: 0.403, loss: 0.011291\n",
      "step:   103920, time: 0.404, loss: 0.010493\n",
      "step:   103940, time: 0.439, loss: 0.011764\n",
      "step:   103960, time: 0.419, loss: 0.014271\n",
      "step:   103980, time: 0.411, loss: 0.023237\n",
      "step:   104000, time: 0.408, loss: 0.014325\n",
      "step:   104020, time: 0.409, loss: 0.046644\n",
      "step:   104040, time: 0.389, loss: 0.015734\n",
      "step:   104060, time: 0.390, loss: 0.016702\n",
      "step:   104080, time: 0.392, loss: 0.008936\n",
      "step:   104100, time: 0.407, loss: 0.007863\n",
      "step:   104120, time: 0.418, loss: 0.020758\n",
      "step:   104140, time: 0.403, loss: 0.013879\n",
      "step:   104160, time: 0.421, loss: 0.013457\n",
      "step:   104180, time: 0.406, loss: 0.010543\n",
      "step:   104200, time: 0.433, loss: 0.017876\n",
      "step:   104220, time: 0.382, loss: 0.011480\n",
      "step:   104240, time: 0.397, loss: 0.014627\n",
      "step:   104260, time: 0.394, loss: 0.017682\n",
      "step:   104280, time: 0.424, loss: 0.013624\n",
      "step:   104300, time: 0.400, loss: 0.018585\n",
      "step:   104320, time: 0.421, loss: 0.022527\n",
      "step:   104340, time: 0.440, loss: 0.134784\n",
      "step:   104360, time: 0.383, loss: 0.006312\n",
      "step:   104380, time: 0.438, loss: 0.167918\n",
      "step:   104400, time: 0.405, loss: 0.021770\n",
      "step:   104420, time: 0.427, loss: 0.015239\n",
      "step:   104440, time: 0.413, loss: 0.011007\n",
      "step:   104460, time: 0.390, loss: 0.016525\n",
      "step:   104480, time: 0.417, loss: 0.014470\n",
      "step:   104500, time: 0.396, loss: 0.015681\n",
      "step:   104520, time: 0.401, loss: 0.014627\n",
      "step:   104540, time: 0.406, loss: 0.014317\n",
      "step:   104560, time: 0.433, loss: 0.016303\n",
      "step:   104580, time: 0.385, loss: 0.025029\n",
      "step:   104600, time: 0.387, loss: 0.020825\n",
      "step:   104620, time: 0.394, loss: 0.011224\n",
      "step:   104640, time: 0.405, loss: 0.031061\n",
      "step:   104660, time: 0.406, loss: 0.012048\n",
      "step:   104680, time: 0.393, loss: 0.013781\n",
      "step:   104700, time: 0.389, loss: 0.012251\n",
      "step:   104720, time: 0.417, loss: 0.015167\n",
      "step:   104740, time: 0.382, loss: 0.010790\n",
      "step:   104760, time: 0.393, loss: 0.013489\n",
      "step:   104780, time: 0.398, loss: 0.015756\n",
      "step:   104800, time: 0.387, loss: 0.012177\n",
      "step:   104820, time: 0.427, loss: 0.018490\n",
      "step:   104840, time: 0.432, loss: 0.007485\n",
      "step:   104860, time: 0.400, loss: 0.011522\n",
      "step:   104880, time: 0.394, loss: 0.129104\n",
      "step:   104900, time: 0.393, loss: 0.013685\n",
      "step:   104920, time: 0.405, loss: 0.016707\n",
      "step:   104940, time: 0.426, loss: 0.016655\n",
      "step:   104960, time: 0.394, loss: 0.014481\n",
      "step:   104980, time: 0.386, loss: 0.017785\n",
      "step:   105000, time: 0.399, loss: 0.010165\n",
      "step:   105020, time: 0.392, loss: 0.012711\n",
      "step:   105040, time: 0.401, loss: 0.011287\n",
      "step:   105060, time: 0.394, loss: 0.008276\n",
      "step:   105080, time: 0.390, loss: 0.015125\n",
      "step:   105100, time: 0.428, loss: 0.010427\n",
      "step:   105120, time: 0.390, loss: 0.019269\n",
      "step:   105140, time: 0.409, loss: 0.026901\n",
      "step:   105160, time: 0.390, loss: 0.015823\n",
      "step:   105180, time: 0.405, loss: 0.014146\n",
      "step:   105200, time: 0.409, loss: 0.016038\n",
      "step:   105220, time: 0.395, loss: 0.012668\n",
      "step:   105240, time: 0.393, loss: 0.015148\n",
      "step:   105260, time: 0.416, loss: 0.022357\n",
      "step:   105280, time: 0.400, loss: 0.013681\n",
      "step:   105300, time: 0.422, loss: 0.012598\n",
      "step:   105320, time: 0.404, loss: 0.012652\n",
      "step:   105340, time: 0.384, loss: 0.022973\n",
      "step:   105360, time: 0.396, loss: 0.011847\n",
      "step:   105380, time: 0.410, loss: 0.015939\n",
      "step:   105400, time: 0.394, loss: 0.011784\n",
      "step:   105420, time: 0.397, loss: 0.018261\n",
      "step:   105440, time: 0.359, loss: 0.014624\n",
      "step:   105460, time: 0.399, loss: 0.010466\n",
      "step:   105480, time: 0.428, loss: 0.012346\n",
      "step:   105500, time: 0.418, loss: 0.014944\n",
      "step:   105520, time: 0.383, loss: 0.018885\n",
      "step:   105540, time: 0.403, loss: 0.014204\n",
      "step:   105560, time: 0.390, loss: 0.015983\n",
      "step:   105580, time: 0.380, loss: 0.022659\n",
      "step:   105600, time: 0.412, loss: 0.016658\n",
      "step:   105620, time: 0.387, loss: 0.011977\n",
      "step:   105640, time: 0.369, loss: 0.004835\n",
      "step:   105660, time: 0.398, loss: 0.012919\n",
      "step:   105680, time: 0.413, loss: 0.019240\n",
      "step:   105700, time: 0.415, loss: 0.017033\n",
      "step:   105720, time: 0.392, loss: 0.013070\n",
      "step:   105740, time: 0.441, loss: 0.014925\n",
      "step:   105760, time: 0.402, loss: 0.009087\n",
      "step:   105780, time: 0.421, loss: 0.014571\n",
      "step:   105800, time: 0.403, loss: 0.011398\n",
      "step:   105820, time: 0.419, loss: 0.016284\n",
      "step:   105840, time: 0.399, loss: 0.012402\n",
      "step:   105860, time: 0.380, loss: 0.017316\n",
      "step:   105880, time: 0.405, loss: 0.022077\n",
      "step:   105900, time: 0.383, loss: 0.015128\n",
      "step:   105920, time: 0.402, loss: 0.014575\n",
      "step:   105940, time: 0.402, loss: 0.025413\n",
      "step:   105960, time: 0.391, loss: 0.013179\n",
      "step:   105980, time: 0.399, loss: 0.013127\n",
      "step:   106000, time: 0.398, loss: 0.020213\n",
      "step:   106020, time: 0.385, loss: 0.014188\n",
      "step:   106040, time: 0.430, loss: 0.015734\n",
      "step:   106060, time: 0.381, loss: 0.023448\n",
      "step:   106080, time: 0.411, loss: 0.023695\n",
      "step:   106100, time: 0.424, loss: 0.010913\n",
      "step:   106120, time: 0.390, loss: 0.020078\n",
      "step:   106140, time: 0.402, loss: 0.017405\n",
      "step:   106160, time: 0.390, loss: 0.008859\n",
      "step:   106180, time: 0.386, loss: 0.012130\n",
      "step:   106200, time: 0.396, loss: 0.017127\n",
      "step:   106220, time: 0.465, loss: 0.193010\n",
      "step:   106240, time: 0.367, loss: 0.008897\n",
      "step:   106260, time: 0.374, loss: 0.010905\n",
      "step:   106280, time: 0.401, loss: 0.016373\n",
      "step:   106300, time: 0.429, loss: 0.013199\n",
      "step:   106320, time: 0.405, loss: 0.022835\n",
      "step:   106340, time: 0.387, loss: 0.018156\n",
      "step:   106360, time: 0.384, loss: 0.013441\n",
      "step:   106380, time: 0.425, loss: 0.023797\n",
      "step:   106400, time: 0.428, loss: 0.010866\n",
      "step:   106420, time: 0.418, loss: 0.006775\n",
      "step:   106440, time: 0.445, loss: 0.014114\n",
      "step:   106460, time: 0.398, loss: 0.011618\n",
      "step:   106480, time: 0.397, loss: 0.014306\n",
      "step:   106500, time: 0.375, loss: 0.017535\n",
      "step:   106520, time: 0.398, loss: 0.029405\n",
      "step:   106540, time: 0.382, loss: 0.008321\n",
      "step:   106560, time: 0.401, loss: 0.015194\n",
      "step:   106580, time: 0.402, loss: 0.016326\n",
      "step:   106600, time: 0.393, loss: 0.016396\n",
      "step:   106620, time: 0.403, loss: 0.012605\n",
      "step:   106640, time: 0.389, loss: 0.018730\n",
      "step:   106660, time: 0.398, loss: 0.023943\n",
      "step:   106680, time: 0.121, loss: 0.002819\n",
      "step:   106700, time: 0.409, loss: 0.011354\n",
      "step:   106720, time: 0.411, loss: 0.017953\n",
      "step:   106740, time: 0.415, loss: 0.019557\n",
      "step:   106760, time: 0.398, loss: 0.017442\n",
      "step:   106780, time: 0.383, loss: 0.003397\n",
      "step:   106800, time: 0.400, loss: 0.016584\n",
      "step:   106820, time: 0.403, loss: 0.010697\n",
      "step:   106840, time: 0.388, loss: 0.017733\n",
      "step:   106860, time: 0.396, loss: 0.013522\n",
      "step:   106880, time: 0.411, loss: 0.017743\n",
      "step:   106900, time: 0.376, loss: 0.021556\n",
      "step:   106920, time: 0.396, loss: 0.010992\n",
      "step:   106940, time: 0.407, loss: 0.009702\n",
      "step:   106960, time: 0.414, loss: 0.019443\n",
      "step:   106980, time: 0.406, loss: 0.012583\n",
      "step:   107000, time: 0.393, loss: 0.018130\n",
      "step:   107020, time: 0.403, loss: 0.019969\n",
      "step:   107040, time: 0.406, loss: 0.019532\n",
      "step:   107060, time: 0.407, loss: 0.017293\n",
      "step:   107080, time: 0.399, loss: 0.009991\n",
      "step:   107100, time: 0.412, loss: 0.013521\n",
      "step:   107120, time: 0.401, loss: 0.015124\n",
      "step:   107140, time: 0.424, loss: 0.018945\n",
      "step:   107160, time: 0.427, loss: 0.016945\n",
      "step:   107180, time: 0.428, loss: 0.269646\n",
      "step:   107200, time: 0.409, loss: 0.014177\n",
      "step:   107220, time: 0.392, loss: 0.017134\n",
      "step:   107240, time: 0.387, loss: 0.023234\n",
      "step:   107260, time: 0.392, loss: 0.013769\n",
      "step:   107280, time: 0.396, loss: 0.013658\n",
      "step:   107300, time: 0.387, loss: 0.018746\n",
      "step:   107320, time: 0.392, loss: 0.009617\n",
      "step:   107340, time: 0.380, loss: 0.024945\n",
      "step:   107360, time: 0.396, loss: 0.012814\n",
      "step:   107380, time: 0.405, loss: 0.018591\n",
      "step:   107400, time: 0.399, loss: 0.017318\n",
      "step:   107420, time: 0.404, loss: 0.010047\n",
      "step:   107440, time: 0.404, loss: 0.016559\n",
      "step:   107460, time: 0.408, loss: 0.010063\n",
      "step:   107480, time: 0.391, loss: 0.015156\n",
      "step:   107500, time: 0.386, loss: 0.012051\n",
      "step:   107520, time: 0.384, loss: 0.008829\n",
      "step:   107540, time: 0.418, loss: 0.018661\n",
      "step:   107560, time: 0.385, loss: 0.006215\n",
      "step:   107580, time: 0.383, loss: 0.007278\n",
      "step:   107600, time: 0.422, loss: 0.016944\n",
      "step:   107620, time: 0.415, loss: 0.008175\n",
      "step:   107640, time: 0.382, loss: 0.025005\n",
      "step:   107660, time: 0.373, loss: 0.011236\n",
      "step:   107680, time: 0.402, loss: 0.015144\n",
      "step:   107700, time: 0.428, loss: 0.011792\n",
      "step:   107720, time: 0.421, loss: 0.010291\n",
      "step:   107740, time: 0.386, loss: 0.006630\n",
      "step:   107760, time: 0.417, loss: 0.011720\n",
      "step:   107780, time: 0.419, loss: 0.010893\n",
      "step:   107800, time: 0.399, loss: 0.013970\n",
      "step:   107820, time: 0.377, loss: 0.006449\n",
      "step:   107840, time: 0.382, loss: 0.015372\n",
      "step:   107860, time: 0.406, loss: 0.013727\n",
      "step:   107880, time: 0.424, loss: 0.015515\n",
      "step:   107900, time: 0.420, loss: 0.212193\n",
      "step:   107920, time: 0.395, loss: 0.024082\n",
      "step:   107940, time: 0.401, loss: 0.013270\n",
      "step:   107960, time: 0.382, loss: 0.006386\n",
      "step:   107980, time: 0.407, loss: 0.010047\n",
      "step:   108000, time: 0.415, loss: 0.018063\n",
      "step:   108020, time: 0.387, loss: 0.012990\n",
      "step:   108040, time: 0.411, loss: 0.181903\n",
      "step:   108060, time: 0.379, loss: 0.021918\n",
      "step:   108080, time: 0.394, loss: 0.013858\n",
      "step:   108100, time: 0.385, loss: 0.007805\n",
      "step:   108120, time: 0.404, loss: 0.016111\n",
      "step:   108140, time: 0.393, loss: 0.021934\n",
      "step:   108160, time: 0.412, loss: 0.019734\n",
      "step:   108180, time: 0.409, loss: 0.008532\n",
      "step:   108200, time: 0.375, loss: 0.013289\n",
      "step:   108220, time: 0.388, loss: 0.008041\n",
      "step:   108240, time: 0.421, loss: 0.019872\n",
      "step:   108260, time: 0.395, loss: 0.009699\n",
      "step:   108280, time: 0.371, loss: 0.024264\n",
      "step:   108300, time: 0.407, loss: 0.018242\n",
      "step:   108320, time: 0.412, loss: 0.008794\n",
      "step:   108340, time: 0.394, loss: 0.017442\n",
      "step:   108360, time: 0.438, loss: 0.011989\n",
      "step:   108380, time: 0.404, loss: 0.014998\n",
      "step:   108400, time: 0.399, loss: 0.019254\n",
      "step:   108420, time: 0.433, loss: 0.016104\n",
      "step:   108440, time: 0.406, loss: 0.024554\n",
      "step:   108460, time: 0.392, loss: 0.021707\n",
      "step:   108480, time: 0.400, loss: 0.011565\n",
      "step:   108500, time: 0.408, loss: 0.010919\n",
      "step:   108520, time: 0.399, loss: 0.010376\n",
      "step:   108540, time: 0.391, loss: 0.015645\n",
      "step:   108560, time: 0.432, loss: 0.013148\n",
      "step:   108580, time: 0.415, loss: 0.013368\n",
      "step:   108600, time: 0.424, loss: 0.013610\n",
      "step:   108620, time: 0.405, loss: 0.011468\n",
      "step:   108640, time: 0.412, loss: 0.014352\n",
      "step:   108660, time: 0.430, loss: 0.020470\n",
      "step:   108680, time: 0.392, loss: 0.022948\n",
      "step:   108700, time: 0.406, loss: 0.016484\n",
      "step:   108720, time: 0.413, loss: 0.014818\n",
      "step:   108740, time: 0.397, loss: 0.025067\n",
      "step:   108760, time: 0.403, loss: 0.009344\n",
      "step:   108780, time: 0.378, loss: 0.016044\n",
      "step:   108800, time: 0.397, loss: 0.018070\n",
      "step:   108820, time: 0.392, loss: 0.022981\n",
      "step:   108840, time: 0.396, loss: 0.009280\n",
      "step:   108860, time: 0.399, loss: 0.023836\n",
      "step:   108880, time: 0.433, loss: 0.015124\n",
      "step:   108900, time: 0.396, loss: 0.015382\n",
      "step:   108920, time: 0.429, loss: 0.015456\n",
      "step:   108940, time: 0.406, loss: 0.015554\n",
      "step:   108960, time: 0.378, loss: 0.018282\n",
      "step:   108980, time: 0.396, loss: 0.012114\n",
      "step:   109000, time: 0.394, loss: 0.011903\n",
      "step:   109020, time: 0.384, loss: 0.018786\n",
      "step:   109040, time: 0.380, loss: 0.017412\n",
      "step:   109060, time: 0.398, loss: 0.017594\n",
      "step:   109080, time: 0.409, loss: 0.022514\n",
      "step:   109100, time: 0.399, loss: 0.011112\n",
      "step:   109120, time: 0.410, loss: 0.016937\n",
      "step:   109140, time: 0.392, loss: 0.011399\n",
      "step:   109160, time: 0.405, loss: 0.018378\n",
      "step:   109180, time: 0.398, loss: 0.019752\n",
      "step:   109200, time: 0.393, loss: 0.013030\n",
      "step:   109220, time: 0.407, loss: 0.018141\n",
      "step:   109240, time: 0.420, loss: 0.013995\n",
      "step:   109260, time: 0.409, loss: 0.014595\n",
      "step:   109280, time: 0.443, loss: 0.181172\n",
      "step:   109300, time: 0.372, loss: 0.011343\n",
      "step:   109320, time: 0.389, loss: 0.010850\n",
      "step:   109340, time: 0.399, loss: 0.015974\n",
      "step:   109360, time: 0.422, loss: 0.016879\n",
      "step:   109380, time: 0.434, loss: 0.010085\n",
      "step:   109400, time: 0.437, loss: 0.017682\n",
      "step:   109420, time: 0.434, loss: 0.020663\n",
      "step:   109440, time: 0.423, loss: 0.017171\n",
      "step:   109460, time: 0.396, loss: 0.015233\n",
      "step:   109480, time: 0.412, loss: 0.020947\n",
      "step:   109500, time: 0.412, loss: 0.016568\n",
      "step:   109520, time: 0.410, loss: 0.024520\n",
      "step:   109540, time: 0.421, loss: 0.015564\n",
      "step:   109560, time: 0.413, loss: 0.016003\n",
      "step:   109580, time: 0.398, loss: 0.023239\n",
      "step:   109600, time: 0.399, loss: 0.011871\n",
      "step:   109620, time: 0.423, loss: 0.019312\n",
      "step:   109640, time: 0.389, loss: 0.015333\n",
      "step:   109660, time: 0.388, loss: 0.014525\n",
      "step:   109680, time: 0.390, loss: 0.015414\n",
      "step:   109700, time: 0.406, loss: 0.017680\n",
      "step:   109720, time: 0.392, loss: 0.016331\n",
      "step:   109740, time: 0.371, loss: 0.019801\n",
      "step:   109760, time: 0.401, loss: 0.009324\n",
      "step:   109780, time: 0.393, loss: 0.017840\n",
      "step:   109800, time: 0.395, loss: 0.012584\n",
      "step:   109820, time: 0.410, loss: 0.014197\n",
      "step:   109840, time: 0.429, loss: 0.013080\n",
      "step:   109860, time: 0.381, loss: 0.015691\n",
      "step:   109880, time: 0.397, loss: 0.015443\n",
      "step:   109900, time: 0.391, loss: 0.009343\n",
      "step:   109920, time: 0.401, loss: 0.009955\n",
      "step:   109940, time: 0.406, loss: 0.015758\n",
      "step:   109960, time: 0.406, loss: 0.022236\n",
      "step:   109980, time: 0.399, loss: 0.020374\n",
      "step:   110000, time: 0.397, loss: 0.012747\n",
      "step:   110020, time: 0.405, loss: 0.013731\n",
      "step:   110040, time: 0.415, loss: 0.006656\n",
      "step:   110060, time: 0.404, loss: 0.017720\n",
      "step:   110080, time: 0.408, loss: 0.015248\n",
      "step:   110100, time: 0.397, loss: 0.016194\n",
      "step:   110120, time: 0.381, loss: 0.015288\n",
      "step:   110140, time: 0.382, loss: 0.006978\n",
      "step:   110160, time: 0.412, loss: 0.008867\n",
      "step:   110180, time: 0.397, loss: 0.012750\n",
      "step:   110200, time: 0.421, loss: 0.016655\n",
      "step:   110220, time: 0.371, loss: 0.018596\n",
      "step:   110240, time: 0.412, loss: 0.009540\n",
      "step:   110260, time: 0.397, loss: 0.013245\n",
      "step:   110280, time: 0.393, loss: 0.007580\n",
      "step:   110300, time: 0.406, loss: 0.017316\n",
      "step:   110320, time: 0.389, loss: 0.016296\n",
      "step:   110340, time: 0.397, loss: 0.024777\n",
      "step:   110360, time: 0.391, loss: 0.018715\n",
      "step:   110380, time: 0.418, loss: 0.010028\n",
      "step:   110400, time: 0.379, loss: 0.015478\n",
      "step:   110420, time: 0.418, loss: 0.010548\n",
      "step:   110440, time: 0.408, loss: 0.009289\n",
      "step:   110460, time: 0.390, loss: 0.009070\n",
      "step:   110480, time: 0.410, loss: 0.013569\n",
      "step:   110500, time: 0.412, loss: 0.017767\n",
      "step:   110520, time: 0.393, loss: 0.024340\n",
      "step:   110540, time: 0.404, loss: 0.024423\n",
      "step:   110560, time: 0.390, loss: 0.011635\n",
      "step:   110580, time: 0.392, loss: 0.010619\n",
      "step:   110600, time: 0.407, loss: 0.010372\n",
      "step:   110620, time: 0.397, loss: 0.011657\n",
      "step:   110640, time: 0.424, loss: 0.021607\n",
      "step:   110660, time: 0.393, loss: 0.012313\n",
      "step:   110680, time: 0.389, loss: 0.015494\n",
      "step:   110700, time: 0.389, loss: 0.017207\n",
      "step:   110720, time: 0.387, loss: 0.013786\n",
      "step:   110740, time: 0.387, loss: 0.023326\n",
      "step:   110760, time: 0.375, loss: 0.014308\n",
      "step:   110780, time: 0.389, loss: 0.011701\n",
      "step:   110800, time: 0.412, loss: 0.008233\n",
      "step:   110820, time: 0.386, loss: 0.017123\n",
      "step:   110840, time: 0.389, loss: 0.017531\n",
      "step:   110860, time: 0.424, loss: 0.021149\n",
      "step:   110880, time: 0.362, loss: 0.002956\n",
      "step:   110900, time: 0.412, loss: 0.023906\n",
      "step:   110920, time: 0.370, loss: 0.018586\n",
      "step:   110940, time: 0.382, loss: 0.019579\n",
      "step:   110960, time: 0.402, loss: 0.007920\n",
      "step:   110980, time: 0.408, loss: 0.013422\n",
      "step:   111000, time: 0.390, loss: 0.009061\n",
      "step:   111020, time: 0.393, loss: 0.005788\n",
      "step:   111040, time: 0.414, loss: 0.015887\n",
      "step:   111060, time: 0.410, loss: 0.018913\n",
      "step:   111080, time: 0.378, loss: 0.014741\n",
      "step:   111100, time: 0.410, loss: 0.019164\n",
      "step:   111120, time: 0.407, loss: 0.013899\n",
      "step:   111140, time: 0.400, loss: 0.013612\n",
      "step:   111160, time: 0.395, loss: 0.019672\n",
      "step:   111180, time: 0.393, loss: 0.018513\n",
      "step:   111200, time: 0.402, loss: 0.020158\n",
      "step:   111220, time: 0.401, loss: 0.017193\n",
      "step:   111240, time: 0.429, loss: 0.011198\n",
      "step:   111260, time: 0.387, loss: 0.011824\n",
      "step:   111280, time: 0.388, loss: 0.022941\n",
      "step:   111300, time: 0.418, loss: 0.017906\n",
      "step:   111320, time: 0.387, loss: 0.013142\n",
      "step:   111340, time: 0.390, loss: 0.015502\n",
      "step:   111360, time: 0.425, loss: 0.020870\n",
      "step:   111380, time: 0.397, loss: 0.012457\n",
      "step:   111400, time: 0.405, loss: 0.011555\n",
      "step:   111420, time: 0.418, loss: 0.014341\n",
      "step:   111440, time: 0.403, loss: 0.019805\n",
      "step:   111460, time: 0.386, loss: 0.017817\n",
      "step:   111480, time: 0.405, loss: 0.009929\n",
      "step:   111500, time: 0.384, loss: 0.019002\n",
      "step:   111520, time: 0.392, loss: 0.006406\n",
      "step:   111540, time: 0.382, loss: 0.013529\n",
      "step:   111560, time: 0.395, loss: 0.016611\n",
      "step:   111580, time: 0.391, loss: 0.013836\n",
      "step:   111600, time: 0.412, loss: 0.010705\n",
      "step:   111620, time: 0.416, loss: 0.016898\n",
      "step:   111640, time: 0.418, loss: 0.020536\n",
      "step:   111660, time: 0.397, loss: 0.021236\n",
      "step:   111680, time: 0.395, loss: 0.019980\n",
      "step:   111700, time: 0.393, loss: 0.017356\n",
      "step:   111720, time: 0.391, loss: 0.021104\n",
      "step:   111740, time: 0.405, loss: 0.015334\n",
      "step:   111760, time: 0.380, loss: 0.011355\n",
      "step:   111780, time: 0.381, loss: 0.025668\n",
      "step:   111800, time: 0.395, loss: 0.029653\n",
      "step:   111820, time: 0.395, loss: 0.014823\n",
      "step:   111840, time: 0.414, loss: 0.017080\n",
      "step:   111860, time: 0.395, loss: 0.015243\n",
      "step:   111880, time: 0.406, loss: 0.016461\n",
      "step:   111900, time: 0.392, loss: 0.013893\n",
      "step:   111920, time: 0.393, loss: 0.019067\n",
      "step:   111940, time: 0.393, loss: 0.014935\n",
      "step:   111960, time: 0.406, loss: 0.022137\n",
      "step:   111980, time: 0.419, loss: 0.014962\n",
      "step:   112000, time: 0.399, loss: 0.007671\n",
      "step:   112020, time: 0.395, loss: 0.011742\n",
      "step:   112040, time: 0.386, loss: 0.010666\n",
      "step:   112060, time: 0.407, loss: 0.018796\n",
      "step:   112080, time: 0.383, loss: 0.014567\n",
      "step:   112100, time: 0.371, loss: 0.014087\n",
      "step:   112120, time: 0.372, loss: 0.014340\n",
      "step:   112140, time: 0.417, loss: 0.010722\n",
      "step:   112160, time: 0.410, loss: 0.012415\n",
      "step:   112180, time: 0.384, loss: 0.017823\n",
      "step:   112200, time: 0.429, loss: 0.014507\n",
      "step:   112220, time: 0.391, loss: 0.014633\n",
      "step:   112240, time: 0.398, loss: 0.015349\n",
      "step:   112260, time: 0.448, loss: 0.013719\n",
      "step:   112280, time: 0.429, loss: 0.034618\n",
      "step:   112300, time: 0.383, loss: 0.011221\n",
      "step:   112320, time: 0.402, loss: 0.018567\n",
      "step:   112340, time: 0.437, loss: 0.010407\n",
      "step:   112360, time: 0.399, loss: 0.009963\n",
      "step:   112380, time: 0.373, loss: 0.013207\n",
      "step:   112400, time: 0.385, loss: 0.009151\n",
      "step:   112420, time: 0.410, loss: 0.033584\n",
      "step:   112440, time: 0.395, loss: 0.020442\n",
      "step:   112460, time: 0.389, loss: 0.015867\n",
      "step:   112480, time: 0.398, loss: 0.022289\n",
      "step:   112500, time: 0.394, loss: 0.012457\n",
      "step:   112520, time: 0.459, loss: 0.011119\n",
      "step:   112540, time: 0.423, loss: 0.169709\n",
      "step:   112560, time: 0.413, loss: 0.020197\n",
      "step:   112580, time: 0.399, loss: 0.006497\n",
      "step:   112600, time: 0.403, loss: 0.009350\n",
      "step:   112620, time: 0.435, loss: 0.013788\n",
      "step:   112640, time: 0.411, loss: 0.009736\n",
      "step:   112660, time: 0.375, loss: 0.013287\n",
      "step:   112680, time: 0.407, loss: 0.039155\n",
      "step:   112700, time: 0.413, loss: 0.018237\n",
      "step:   112720, time: 0.398, loss: 0.009694\n",
      "step:   112740, time: 0.420, loss: 0.014347\n",
      "step:   112760, time: 0.378, loss: 0.017533\n",
      "step:   112780, time: 0.386, loss: 0.016752\n",
      "step:   112800, time: 0.392, loss: 0.010893\n",
      "step:   112820, time: 0.430, loss: 0.010135\n",
      "step:   112840, time: 0.393, loss: 0.010263\n",
      "step:   112860, time: 0.381, loss: 0.011893\n",
      "step:   112880, time: 0.475, loss: 0.017231\n",
      "step:   112900, time: 0.397, loss: 0.008237\n",
      "step:   112920, time: 0.403, loss: 0.018517\n",
      "step:   112940, time: 0.388, loss: 0.013808\n",
      "step:   112960, time: 0.372, loss: 0.014739\n",
      "step:   112980, time: 0.387, loss: 0.009668\n",
      "step:   113000, time: 0.371, loss: 0.009295\n",
      "step:   113020, time: 0.398, loss: 0.013410\n",
      "step:   113040, time: 0.396, loss: 0.023562\n",
      "step:   113060, time: 0.382, loss: 0.021292\n",
      "step:   113080, time: 0.416, loss: 0.010442\n",
      "step:   113100, time: 0.380, loss: 0.012832\n",
      "step:   113120, time: 0.388, loss: 0.004999\n",
      "step:   113140, time: 0.400, loss: 0.018138\n",
      "step:   113160, time: 0.404, loss: 0.014232\n",
      "step:   113180, time: 0.407, loss: 0.012854\n",
      "step:   113200, time: 0.407, loss: 0.008546\n",
      "step:   113220, time: 0.401, loss: 0.018535\n",
      "step:   113240, time: 0.417, loss: 0.013297\n",
      "step:   113260, time: 0.414, loss: 0.008201\n",
      "step:   113280, time: 0.398, loss: 0.010869\n",
      "step:   113300, time: 0.384, loss: 0.012488\n",
      "step:   113320, time: 0.380, loss: 0.008307\n",
      "step:   113340, time: 0.395, loss: 0.008272\n",
      "step:   113360, time: 0.426, loss: 0.015565\n",
      "step:   113380, time: 0.387, loss: 0.008404\n",
      "step:   113400, time: 0.415, loss: 0.011874\n",
      "step:   113420, time: 0.385, loss: 0.016272\n",
      "step:   113440, time: 0.428, loss: 0.011339\n",
      "step:   113460, time: 0.407, loss: 0.013427\n",
      "step:   113480, time: 0.408, loss: 0.016708\n",
      "step:   113500, time: 0.411, loss: 0.020800\n",
      "step:   113520, time: 0.397, loss: 0.024314\n",
      "step:   113540, time: 0.393, loss: 0.010280\n",
      "step:   113560, time: 0.392, loss: 0.011531\n",
      "step:   113580, time: 0.427, loss: 0.013915\n",
      "step:   113600, time: 0.386, loss: 0.021247\n",
      "step:   113620, time: 0.406, loss: 0.020506\n",
      "step:   113640, time: 0.395, loss: 0.008840\n",
      "step:   113660, time: 0.412, loss: 0.012181\n",
      "step:   113680, time: 0.398, loss: 0.007178\n",
      "step:   113700, time: 0.399, loss: 0.009082\n",
      "step:   113720, time: 0.399, loss: 0.017175\n",
      "step:   113740, time: 0.368, loss: 0.011565\n",
      "step:   113760, time: 0.387, loss: 0.003964\n",
      "step:   113780, time: 0.393, loss: 0.015402\n",
      "step:   113800, time: 0.381, loss: 0.018325\n",
      "step:   113820, time: 0.396, loss: 0.022403\n",
      "step:   113840, time: 0.402, loss: 0.013159\n",
      "step:   113860, time: 0.403, loss: 0.017435\n",
      "step:   113880, time: 0.383, loss: 0.010240\n",
      "step:   113900, time: 0.398, loss: 0.016847\n",
      "step:   113920, time: 0.386, loss: 0.016801\n",
      "step:   113940, time: 0.410, loss: 0.011338\n",
      "step:   113960, time: 0.367, loss: 0.014877\n",
      "step:   113980, time: 0.396, loss: 0.015442\n",
      "step:   114000, time: 0.405, loss: 0.011114\n",
      "step:   114020, time: 0.379, loss: 0.022161\n",
      "step:   114040, time: 0.403, loss: 0.018200\n",
      "step:   114060, time: 0.390, loss: 0.007274\n",
      "step:   114080, time: 0.393, loss: 0.014658\n",
      "step:   114100, time: 0.393, loss: 0.018881\n",
      "step:   114120, time: 0.396, loss: 0.011933\n",
      "step:   114140, time: 0.386, loss: 0.017557\n",
      "step:   114160, time: 0.389, loss: 0.012869\n",
      "step:   114180, time: 0.387, loss: 0.012088\n",
      "step:   114200, time: 0.407, loss: 0.015913\n",
      "step:   114220, time: 0.395, loss: 0.013372\n",
      "step:   114240, time: 0.389, loss: 0.018632\n",
      "step:   114260, time: 0.381, loss: 0.004349\n",
      "step:   114280, time: 0.426, loss: 0.013658\n",
      "step:   114300, time: 0.412, loss: 0.015354\n",
      "step:   114320, time: 0.395, loss: 0.018236\n",
      "step:   114340, time: 0.391, loss: 0.008113\n",
      "step:   114360, time: 0.372, loss: 0.017197\n",
      "step:   114380, time: 0.399, loss: 0.010761\n",
      "step:   114400, time: 0.395, loss: 0.012862\n",
      "step:   114420, time: 0.381, loss: 0.016414\n",
      "step:   114440, time: 0.393, loss: 0.021290\n",
      "step:   114460, time: 0.428, loss: 0.012285\n",
      "step:   114480, time: 0.399, loss: 0.021618\n",
      "step:   114500, time: 0.417, loss: 0.017315\n",
      "step:   114520, time: 0.391, loss: 0.014713\n",
      "step:   114540, time: 0.387, loss: 0.013321\n",
      "step:   114560, time: 0.394, loss: 0.009666\n",
      "step:   114580, time: 0.384, loss: 0.022801\n",
      "step:   114600, time: 0.414, loss: 0.014347\n",
      "step:   114620, time: 0.398, loss: 0.016748\n",
      "step:   114640, time: 0.419, loss: 0.016517\n",
      "step:   114660, time: 0.428, loss: 0.011865\n",
      "step:   114680, time: 0.400, loss: 0.020051\n",
      "step:   114700, time: 0.407, loss: 0.029442\n",
      "step:   114720, time: 0.387, loss: 0.020296\n",
      "step:   114740, time: 0.393, loss: 0.015527\n",
      "step:   114760, time: 0.389, loss: 0.012337\n",
      "step:   114780, time: 0.392, loss: 0.010280\n",
      "step:   114800, time: 0.394, loss: 0.010337\n",
      "step:   114820, time: 0.440, loss: 0.018975\n",
      "step:   114840, time: 0.406, loss: 0.012933\n",
      "step:   114860, time: 0.402, loss: 0.010975\n",
      "step:   114880, time: 0.397, loss: 0.018764\n",
      "step:   114900, time: 0.396, loss: 0.022811\n",
      "step:   114920, time: 0.407, loss: 0.018214\n",
      "step:   114940, time: 0.412, loss: 0.017165\n",
      "step:   114960, time: 0.382, loss: 0.016222\n",
      "step:   114980, time: 0.383, loss: 0.020276\n",
      "step:   115000, time: 0.398, loss: 0.017874\n",
      "step:   115020, time: 0.416, loss: 0.012521\n",
      "step:   115040, time: 0.383, loss: 0.014649\n",
      "step:   115060, time: 0.385, loss: 0.002772\n",
      "step:   115080, time: 0.388, loss: 0.018426\n",
      "step:   115100, time: 0.402, loss: 0.018556\n",
      "step:   115120, time: 0.414, loss: 0.013562\n",
      "step:   115140, time: 0.408, loss: 0.019155\n",
      "step:   115160, time: 0.424, loss: 0.021849\n",
      "step:   115180, time: 0.411, loss: 0.007617\n",
      "step:   115200, time: 0.449, loss: 0.014253\n",
      "step:   115220, time: 0.403, loss: 0.010388\n",
      "step:   115240, time: 0.394, loss: 0.010318\n",
      "step:   115260, time: 0.394, loss: 0.014853\n",
      "step:   115280, time: 0.384, loss: 0.008372\n",
      "step:   115300, time: 0.395, loss: 0.018039\n",
      "step:   115320, time: 0.394, loss: 0.013712\n",
      "step:   115340, time: 0.394, loss: 0.025471\n",
      "step:   115360, time: 0.388, loss: 0.012791\n",
      "step:   115380, time: 0.390, loss: 0.006283\n",
      "step:   115400, time: 0.406, loss: 0.015496\n",
      "step:   115420, time: 0.397, loss: 0.015314\n",
      "step:   115440, time: 0.410, loss: 0.020488\n",
      "step:   115460, time: 0.406, loss: 0.013420\n",
      "step:   115480, time: 0.405, loss: 0.019477\n",
      "step:   115500, time: 0.384, loss: 0.011499\n",
      "step:   115520, time: 0.388, loss: 0.019228\n",
      "step:   115540, time: 0.384, loss: 0.020240\n",
      "step:   115560, time: 0.380, loss: 0.009541\n",
      "step:   115580, time: 0.383, loss: 0.016170\n",
      "step:   115600, time: 0.413, loss: 0.025402\n",
      "step:   115620, time: 0.403, loss: 0.011292\n",
      "step:   115640, time: 0.410, loss: 0.005611\n",
      "step:   115660, time: 0.403, loss: 0.017270\n",
      "step:   115680, time: 0.396, loss: 0.014386\n",
      "step:   115700, time: 0.386, loss: 0.015395\n",
      "step:   115720, time: 0.368, loss: 0.006883\n",
      "step:   115740, time: 0.398, loss: 0.018700\n",
      "step:   115760, time: 0.405, loss: 0.005282\n",
      "step:   115780, time: 0.369, loss: 0.004332\n",
      "step:   115800, time: 0.421, loss: 0.017800\n",
      "step:   115820, time: 0.403, loss: 0.011657\n",
      "step:   115840, time: 0.403, loss: 0.019164\n",
      "step:   115860, time: 0.410, loss: 0.021700\n",
      "step:   115880, time: 0.402, loss: 0.008689\n",
      "step:   115900, time: 0.391, loss: 0.026502\n",
      "step:   115920, time: 0.389, loss: 0.020955\n",
      "step:   115940, time: 0.421, loss: 0.021479\n",
      "step:   115960, time: 0.430, loss: 0.022681\n",
      "step:   115980, time: 0.408, loss: 0.012598\n",
      "step:   116000, time: 0.387, loss: 0.021624\n",
      "step:   116020, time: 0.393, loss: 0.021883\n",
      "step:   116040, time: 0.400, loss: 0.019081\n",
      "step:   116060, time: 0.408, loss: 0.019616\n",
      "step:   116080, time: 0.396, loss: 0.018529\n",
      "step:   116100, time: 0.418, loss: 0.019225\n",
      "step:   116120, time: 0.441, loss: 0.007158\n",
      "step:   116140, time: 0.449, loss: 0.020387\n",
      "step:   116160, time: 0.400, loss: 0.016984\n",
      "step:   116180, time: 0.400, loss: 0.005802\n",
      "step:   116200, time: 0.411, loss: 0.005722\n",
      "step:   116220, time: 0.389, loss: 0.006623\n",
      "step:   116240, time: 0.403, loss: 0.011025\n",
      "step:   116260, time: 0.404, loss: 0.021518\n",
      "step:   116280, time: 0.385, loss: 0.014886\n",
      "step:   116300, time: 0.390, loss: 0.014271\n",
      "step:   116320, time: 0.391, loss: 0.021457\n",
      "step:   116340, time: 0.379, loss: 0.017581\n",
      "step:   116360, time: 0.382, loss: 0.014158\n",
      "step:   116380, time: 0.404, loss: 0.008566\n",
      "step:   116400, time: 0.403, loss: 0.022949\n",
      "step:   116420, time: 0.385, loss: 0.019458\n",
      "step:   116440, time: 0.391, loss: 0.012952\n",
      "step:   116460, time: 0.381, loss: 0.007441\n",
      "step:   116480, time: 0.406, loss: 0.020816\n",
      "step:   116500, time: 0.400, loss: 0.012774\n",
      "step:   116520, time: 0.414, loss: 0.013341\n",
      "step:   116540, time: 0.406, loss: 0.010131\n",
      "step:   116560, time: 0.412, loss: 0.016782\n",
      "step:   116580, time: 0.405, loss: 0.016402\n",
      "step:   116600, time: 0.411, loss: 0.011128\n",
      "step:   116620, time: 0.411, loss: 0.019456\n",
      "step:   116640, time: 0.390, loss: 0.021581\n",
      "step:   116660, time: 0.372, loss: 0.008122\n",
      "step:   116680, time: 0.377, loss: 0.014685\n",
      "step:   116700, time: 0.413, loss: 0.014429\n",
      "step:   116720, time: 0.426, loss: 0.006704\n",
      "step:   116740, time: 0.427, loss: 0.158736\n",
      "step:   116760, time: 0.411, loss: 0.018320\n",
      "step:   116780, time: 0.420, loss: 0.015305\n",
      "step:   116800, time: 0.390, loss: 0.021181\n",
      "step:   116820, time: 0.414, loss: 0.015291\n",
      "step:   116840, time: 0.392, loss: 0.013584\n",
      "step:   116860, time: 0.409, loss: 0.009262\n",
      "step:   116880, time: 0.422, loss: 0.011614\n",
      "step:   116900, time: 0.412, loss: 0.020414\n",
      "step:   116920, time: 0.404, loss: 0.018266\n",
      "step:   116940, time: 0.403, loss: 0.016588\n",
      "step:   116960, time: 0.393, loss: 0.009615\n",
      "step:   116980, time: 0.421, loss: 0.021049\n",
      "step:   117000, time: 0.389, loss: 0.018275\n",
      "step:   117020, time: 0.393, loss: 0.017730\n",
      "step:   117040, time: 0.446, loss: 0.009227\n",
      "step:   117060, time: 0.385, loss: 0.011210\n",
      "step:   117080, time: 0.419, loss: 0.014142\n",
      "step:   117100, time: 0.404, loss: 0.011546\n",
      "step:   117120, time: 0.397, loss: 0.009429\n",
      "step:   117140, time: 0.399, loss: 0.006075\n",
      "step:   117160, time: 0.405, loss: 0.017167\n",
      "step:   117180, time: 0.381, loss: 0.015822\n",
      "step:   117200, time: 0.387, loss: 0.009554\n",
      "step:   117220, time: 0.460, loss: 0.020057\n",
      "step:   117240, time: 0.395, loss: 0.016193\n",
      "step:   117260, time: 0.386, loss: 0.006105\n",
      "step:   117280, time: 0.406, loss: 0.017030\n",
      "step:   117300, time: 0.417, loss: 0.015927\n",
      "step:   117320, time: 0.391, loss: 0.012116\n",
      "step:   117340, time: 0.395, loss: 0.022774\n",
      "step:   117360, time: 0.413, loss: 0.015575\n",
      "step:   117380, time: 0.405, loss: 0.007527\n",
      "step:   117400, time: 0.405, loss: 0.022263\n",
      "step:   117420, time: 0.380, loss: 0.014057\n",
      "step:   117440, time: 0.403, loss: 0.009390\n",
      "step:   117460, time: 0.380, loss: 0.007631\n",
      "step:   117480, time: 0.396, loss: 0.018951\n",
      "step:   117500, time: 0.373, loss: 0.019499\n",
      "step:   117520, time: 0.388, loss: 0.019481\n",
      "step:   117540, time: 0.400, loss: 0.014332\n",
      "step:   117560, time: 0.399, loss: 0.016837\n",
      "step:   117580, time: 0.380, loss: 0.012339\n",
      "step:   117600, time: 0.387, loss: 0.021283\n",
      "step:   117620, time: 0.376, loss: 0.016436\n",
      "step:   117640, time: 0.398, loss: 0.011295\n",
      "step:   117660, time: 0.384, loss: 0.009440\n",
      "step:   117680, time: 0.424, loss: 0.017389\n",
      "step:   117700, time: 0.401, loss: 0.009257\n",
      "step:   117720, time: 0.385, loss: 0.012606\n",
      "step:   117740, time: 0.402, loss: 0.017247\n",
      "step:   117760, time: 0.394, loss: 0.018464\n",
      "step:   117780, time: 0.410, loss: 0.014637\n",
      "step:   117800, time: 0.400, loss: 0.018477\n",
      "step:   117820, time: 0.418, loss: 0.057635\n",
      "step:   117840, time: 0.398, loss: 0.011220\n",
      "step:   117860, time: 0.402, loss: 0.010093\n",
      "step:   117880, time: 0.454, loss: 0.015655\n",
      "step:   117900, time: 0.399, loss: 0.019570\n",
      "step:   117920, time: 0.390, loss: 0.008065\n",
      "step:   117940, time: 0.394, loss: 0.015787\n",
      "step:   117960, time: 0.393, loss: 0.018611\n",
      "step:   117980, time: 0.390, loss: 0.018185\n",
      "step:   118000, time: 0.408, loss: 0.013576\n",
      "step:   118020, time: 0.385, loss: 0.022780\n",
      "step:   118040, time: 0.385, loss: 0.021690\n",
      "step:   118060, time: 0.429, loss: 0.012399\n",
      "step:   118080, time: 0.402, loss: 0.015637\n",
      "step:   118100, time: 0.400, loss: 0.023561\n",
      "step:   118120, time: 0.396, loss: 0.014986\n",
      "step:   118140, time: 0.415, loss: 0.011767\n",
      "step:   118160, time: 0.414, loss: 0.014909\n",
      "step:   118180, time: 0.391, loss: 0.011145\n",
      "step:   118200, time: 0.402, loss: 0.007177\n",
      "step:   118220, time: 0.387, loss: 0.015078\n",
      "step:   118240, time: 0.397, loss: 0.024126\n",
      "step:   118260, time: 0.392, loss: 0.019635\n",
      "step:   118280, time: 0.392, loss: 0.015311\n",
      "step:   118300, time: 0.377, loss: 0.017869\n",
      "step:   118320, time: 0.397, loss: 0.020671\n",
      "step:   118340, time: 0.382, loss: 0.013117\n",
      "step:   118360, time: 0.407, loss: 0.012121\n",
      "step:   118380, time: 0.428, loss: 0.021466\n",
      "step:   118400, time: 0.420, loss: 0.013661\n",
      "step:   118420, time: 0.376, loss: 0.013077\n",
      "step:   118440, time: 0.388, loss: 0.006651\n",
      "step:   118460, time: 0.416, loss: 0.013407\n",
      "step:   118480, time: 0.397, loss: 0.004516\n",
      "step:   118500, time: 0.407, loss: 0.017093\n",
      "step:   118520, time: 0.395, loss: 0.016374\n",
      "step:   118540, time: 0.401, loss: 0.020517\n",
      "step:   118560, time: 0.375, loss: 0.008741\n",
      "step:   118580, time: 0.395, loss: 0.012799\n",
      "step:   118600, time: 0.404, loss: 0.021086\n",
      "step:   118620, time: 0.417, loss: 0.010084\n",
      "step:   118640, time: 0.389, loss: 0.013811\n",
      "step:   118660, time: 0.399, loss: 0.011604\n",
      "step:   118680, time: 0.371, loss: 0.013926\n",
      "step:   118700, time: 0.408, loss: 0.022738\n",
      "step:   118720, time: 0.408, loss: 0.022917\n",
      "step:   118740, time: 0.399, loss: 0.009917\n",
      "step:   118760, time: 0.399, loss: 0.016088\n",
      "step:   118780, time: 0.394, loss: 0.015754\n",
      "step:   118800, time: 0.421, loss: 0.010010\n",
      "step:   118820, time: 0.383, loss: 0.016389\n",
      "step:   118840, time: 0.415, loss: 0.016239\n",
      "step:   118860, time: 0.404, loss: 0.011700\n",
      "step:   118880, time: 0.402, loss: 0.005609\n",
      "step:   118900, time: 0.394, loss: 0.013342\n",
      "step:   118920, time: 0.436, loss: 0.138813\n",
      "step:   118940, time: 0.395, loss: 0.013954\n",
      "step:   118960, time: 0.394, loss: 0.019570\n",
      "step:   118980, time: 0.407, loss: 0.017021\n",
      "step:   119000, time: 0.388, loss: 0.020445\n",
      "step:   119020, time: 0.403, loss: 0.016890\n",
      "step:   119040, time: 0.410, loss: 0.014434\n",
      "step:   119060, time: 0.426, loss: 0.012204\n",
      "step:   119080, time: 0.386, loss: 0.014518\n",
      "step:   119100, time: 0.413, loss: 0.009792\n",
      "step:   119120, time: 0.391, loss: 0.022082\n",
      "step:   119140, time: 0.407, loss: 0.007913\n",
      "step:   119160, time: 0.397, loss: 0.005497\n",
      "step:   119180, time: 0.382, loss: 0.013580\n",
      "step:   119200, time: 0.383, loss: 0.016242\n",
      "step:   119220, time: 0.395, loss: 0.008486\n",
      "step:   119240, time: 0.386, loss: 0.011435\n",
      "step:   119260, time: 0.364, loss: 0.019732\n",
      "step:   119280, time: 0.405, loss: 0.018343\n",
      "step:   119300, time: 0.412, loss: 0.010999\n",
      "step:   119320, time: 0.391, loss: 0.011329\n",
      "step:   119340, time: 0.398, loss: 0.023620\n",
      "step:   119360, time: 0.427, loss: 0.016723\n",
      "step:   119380, time: 0.410, loss: 0.019098\n",
      "step:   119400, time: 0.441, loss: 0.009711\n",
      "step:   119420, time: 0.408, loss: 0.016751\n",
      "step:   119440, time: 0.406, loss: 0.011770\n",
      "step:   119460, time: 0.387, loss: 0.015977\n",
      "step:   119480, time: 0.396, loss: 0.012549\n",
      "step:   119500, time: 0.372, loss: 0.009887\n",
      "step:   119520, time: 0.398, loss: 0.013376\n",
      "step:   119540, time: 0.426, loss: 0.022571\n",
      "step:   119560, time: 0.404, loss: 0.015480\n",
      "step:   119580, time: 0.420, loss: 0.012074\n",
      "step:   119600, time: 0.406, loss: 0.016381\n",
      "step:   119620, time: 0.422, loss: 0.021602\n",
      "step:   119640, time: 0.387, loss: 0.015640\n",
      "step:   119660, time: 0.396, loss: 0.022320\n",
      "step:   119680, time: 0.407, loss: 0.013290\n",
      "step:   119700, time: 0.396, loss: 0.011363\n",
      "step:   119720, time: 0.394, loss: 0.017925\n",
      "step:   119740, time: 0.408, loss: 0.011155\n",
      "step:   119760, time: 0.390, loss: 0.004570\n",
      "step:   119780, time: 0.420, loss: 0.011819\n",
      "step:   119800, time: 0.376, loss: 0.006522\n",
      "step:   119820, time: 0.411, loss: 0.011383\n",
      "step:   119840, time: 0.383, loss: 0.014619\n",
      "step:   119860, time: 0.409, loss: 0.012554\n",
      "step:   119880, time: 0.410, loss: 0.018345\n",
      "step:   119900, time: 0.412, loss: 0.015188\n",
      "step:   119920, time: 0.378, loss: 0.006142\n",
      "step:   119940, time: 0.395, loss: 0.012027\n",
      "step:   119960, time: 0.396, loss: 0.012086\n",
      "step:   119980, time: 0.379, loss: 0.005303\n",
      "step:   120000, time: 0.396, loss: 0.015343\n",
      "step:   120020, time: 0.399, loss: 0.013628\n",
      "step:   120040, time: 0.408, loss: 0.016548\n",
      "step:   120060, time: 0.417, loss: 0.024671\n",
      "step:   120080, time: 0.384, loss: 0.002169\n",
      "step:   120100, time: 0.428, loss: 0.012335\n",
      "step:   120120, time: 0.402, loss: 0.022457\n",
      "step:   120140, time: 0.409, loss: 0.008554\n",
      "step:   120160, time: 0.414, loss: 0.013265\n",
      "step:   120180, time: 0.386, loss: 0.016208\n",
      "step:   120200, time: 0.402, loss: 0.019069\n",
      "step:   120220, time: 0.389, loss: 0.017673\n",
      "step:   120240, time: 0.400, loss: 0.007501\n",
      "step:   120260, time: 0.354, loss: 0.008251\n",
      "step:   120280, time: 0.425, loss: 0.386607\n",
      "step:   120300, time: 0.373, loss: 0.010575\n",
      "step:   120320, time: 0.386, loss: 0.014028\n",
      "step:   120340, time: 0.421, loss: 0.019105\n",
      "step:   120360, time: 0.385, loss: 0.010474\n",
      "step:   120380, time: 0.420, loss: 0.019180\n",
      "step:   120400, time: 0.406, loss: 0.017705\n",
      "step:   120420, time: 0.395, loss: 0.023981\n",
      "step:   120440, time: 0.397, loss: 0.017434\n",
      "step:   120460, time: 0.439, loss: 0.021926\n",
      "step:   120480, time: 0.406, loss: 0.012155\n",
      "step:   120500, time: 0.387, loss: 0.027682\n",
      "step:   120520, time: 0.389, loss: 0.010713\n",
      "step:   120540, time: 0.386, loss: 0.021730\n",
      "step:   120560, time: 0.404, loss: 0.020605\n",
      "step:   120580, time: 0.429, loss: 0.017408\n",
      "step:   120600, time: 0.381, loss: 0.006733\n",
      "step:   120620, time: 0.423, loss: 0.019018\n",
      "step:   120640, time: 0.386, loss: 0.013856\n",
      "step:   120660, time: 0.402, loss: 0.008703\n",
      "step:   120680, time: 0.413, loss: 0.019245\n",
      "step:   120700, time: 0.411, loss: 0.013735\n",
      "step:   120720, time: 0.386, loss: 0.014545\n",
      "step:   120740, time: 0.405, loss: 0.010651\n",
      "step:   120760, time: 0.389, loss: 0.013634\n",
      "step:   120780, time: 0.398, loss: 0.020109\n",
      "step:   120800, time: 0.397, loss: 0.015577\n",
      "step:   120820, time: 0.384, loss: 0.018765\n",
      "step:   120840, time: 0.386, loss: 0.016905\n",
      "step:   120860, time: 0.386, loss: 0.027366\n",
      "step:   120880, time: 0.401, loss: 0.029950\n",
      "step:   120900, time: 0.422, loss: 0.127476\n",
      "step:   120920, time: 0.368, loss: 0.004958\n",
      "step:   120940, time: 0.414, loss: 0.027915\n",
      "step:   120960, time: 0.399, loss: 0.010307\n",
      "step:   120980, time: 0.390, loss: 0.017512\n",
      "step:   121000, time: 0.388, loss: 0.010755\n",
      "step:   121020, time: 0.404, loss: 0.008792\n",
      "step:   121040, time: 0.416, loss: 0.015412\n",
      "step:   121060, time: 0.410, loss: 0.015381\n",
      "step:   121080, time: 0.398, loss: 0.016799\n",
      "step:   121100, time: 0.405, loss: 0.020589\n",
      "step:   121120, time: 0.399, loss: 0.009709\n",
      "step:   121140, time: 0.400, loss: 0.016748\n",
      "step:   121160, time: 0.400, loss: 0.009108\n",
      "step:   121180, time: 0.430, loss: 0.015289\n",
      "step:   121200, time: 0.400, loss: 0.023515\n",
      "step:   121220, time: 0.405, loss: 0.026086\n",
      "step:   121240, time: 0.419, loss: 0.020611\n",
      "step:   121260, time: 0.381, loss: 0.013348\n",
      "step:   121280, time: 0.392, loss: 0.005976\n",
      "step:   121300, time: 0.422, loss: 0.007085\n",
      "step:   121320, time: 0.391, loss: 0.015169\n",
      "step:   121340, time: 0.377, loss: 0.009455\n",
      "step:   121360, time: 0.368, loss: 0.017463\n",
      "step:   121380, time: 0.400, loss: 0.009478\n",
      "step:   121400, time: 0.387, loss: 0.021307\n",
      "step:   121420, time: 0.429, loss: 0.023146\n",
      "step:   121440, time: 0.409, loss: 0.025716\n",
      "step:   121460, time: 0.393, loss: 0.013088\n",
      "step:   121480, time: 0.411, loss: 0.009839\n",
      "step:   121500, time: 0.415, loss: 0.018213\n",
      "step:   121520, time: 0.412, loss: 0.133572\n",
      "step:   121540, time: 0.397, loss: 0.011001\n",
      "step:   121560, time: 0.425, loss: 0.014057\n",
      "step:   121580, time: 0.386, loss: 0.011151\n",
      "step:   121600, time: 0.408, loss: 0.015161\n",
      "step:   121620, time: 0.407, loss: 0.013274\n",
      "step:   121640, time: 0.397, loss: 0.016752\n",
      "step:   121660, time: 0.407, loss: 0.005735\n",
      "step:   121680, time: 0.441, loss: 0.016922\n",
      "step:   121700, time: 0.409, loss: 0.008966\n",
      "step:   121720, time: 0.402, loss: 0.011742\n",
      "step:   121740, time: 0.385, loss: 0.007462\n",
      "step:   121760, time: 0.392, loss: 0.014998\n",
      "step:   121780, time: 0.394, loss: 0.018998\n",
      "step:   121800, time: 0.402, loss: 0.018919\n",
      "step:   121820, time: 0.391, loss: 0.019332\n",
      "step:   121840, time: 0.407, loss: 0.015676\n",
      "step:   121860, time: 0.406, loss: 0.016411\n",
      "step:   121880, time: 0.376, loss: 0.020556\n",
      "step:   121900, time: 0.420, loss: 0.022367\n",
      "step:   121920, time: 0.388, loss: 0.014331\n",
      "step:   121940, time: 0.390, loss: 0.018230\n",
      "step:   121960, time: 0.401, loss: 0.013350\n",
      "step:   121980, time: 0.399, loss: 0.014366\n",
      "step:   122000, time: 0.439, loss: 0.162535\n",
      "step:   122020, time: 0.402, loss: 0.017359\n",
      "step:   122040, time: 0.422, loss: 0.011938\n",
      "step:   122060, time: 0.402, loss: 0.014095\n",
      "step:   122080, time: 0.393, loss: 0.017112\n",
      "step:   122100, time: 0.389, loss: 0.016218\n",
      "step:   122120, time: 0.405, loss: 0.014174\n",
      "step:   122140, time: 0.388, loss: 0.013416\n",
      "step:   122160, time: 0.399, loss: 0.012539\n",
      "step:   122180, time: 0.399, loss: 0.015184\n",
      "step:   122200, time: 0.380, loss: 0.015042\n",
      "step:   122220, time: 0.384, loss: 0.018901\n",
      "step:   122240, time: 0.390, loss: 0.007825\n",
      "step:   122260, time: 0.419, loss: 0.019100\n",
      "step:   122280, time: 0.423, loss: 0.015878\n",
      "step:   122300, time: 0.401, loss: 0.016427\n",
      "step:   122320, time: 0.384, loss: 0.014101\n",
      "step:   122340, time: 0.390, loss: 0.017624\n",
      "step:   122360, time: 0.396, loss: 0.035971\n",
      "step:   122380, time: 0.381, loss: 0.014387\n",
      "step:   122400, time: 0.406, loss: 0.015864\n",
      "step:   122420, time: 0.426, loss: 0.012408\n",
      "step:   122440, time: 0.398, loss: 0.016093\n",
      "step:   122460, time: 0.381, loss: 0.019967\n",
      "step:   122480, time: 0.390, loss: 0.020822\n",
      "step:   122500, time: 0.391, loss: 0.026354\n",
      "step:   122520, time: 0.392, loss: 0.014329\n",
      "step:   122540, time: 0.410, loss: 0.016967\n",
      "step:   122560, time: 0.399, loss: 0.015083\n",
      "step:   122580, time: 0.398, loss: 0.017064\n",
      "step:   122600, time: 0.405, loss: 0.014517\n",
      "step:   122620, time: 0.438, loss: 0.014716\n",
      "step:   122640, time: 0.401, loss: 0.005625\n",
      "step:   122660, time: 0.411, loss: 0.012351\n",
      "step:   122680, time: 0.399, loss: 0.015779\n",
      "step:   122700, time: 0.384, loss: 0.020902\n",
      "step:   122720, time: 0.391, loss: 0.014752\n",
      "step:   122740, time: 0.380, loss: 0.008909\n",
      "step:   122760, time: 0.383, loss: 0.003947\n",
      "step:   122780, time: 0.391, loss: 0.014504\n",
      "step:   122800, time: 0.371, loss: 0.013172\n",
      "step:   122820, time: 0.391, loss: 0.014046\n",
      "step:   122840, time: 0.412, loss: 0.025132\n",
      "step:   122860, time: 0.400, loss: 0.025042\n",
      "step:   122880, time: 0.433, loss: 0.011588\n",
      "step:   122900, time: 0.434, loss: 0.016200\n",
      "step:   122920, time: 0.417, loss: 0.013986\n",
      "step:   122940, time: 0.421, loss: 0.017493\n",
      "step:   122960, time: 0.416, loss: 0.026560\n",
      "step:   122980, time: 0.403, loss: 0.003048\n",
      "step:   123000, time: 0.411, loss: 0.018123\n",
      "step:   123020, time: 0.410, loss: 0.017147\n",
      "step:   123040, time: 0.394, loss: 0.024416\n",
      "step:   123060, time: 0.392, loss: 0.014567\n",
      "step:   123080, time: 0.414, loss: 0.007106\n",
      "step:   123100, time: 0.376, loss: 0.011148\n",
      "step:   123120, time: 0.399, loss: 0.013001\n",
      "step:   123140, time: 0.437, loss: 0.016828\n",
      "step:   123160, time: 0.401, loss: 0.019079\n",
      "step:   123180, time: 0.392, loss: 0.015278\n",
      "step:   123200, time: 0.386, loss: 0.009503\n",
      "step:   123220, time: 0.398, loss: 0.014186\n",
      "step:   123240, time: 0.407, loss: 0.011841\n",
      "step:   123260, time: 0.421, loss: 0.009092\n",
      "step:   123280, time: 0.420, loss: 0.016895\n",
      "step:   123300, time: 0.405, loss: 0.007418\n",
      "step:   123320, time: 0.396, loss: 0.014785\n",
      "step:   123340, time: 0.450, loss: 0.015908\n",
      "step:   123360, time: 0.424, loss: 0.012468\n",
      "step:   123380, time: 0.415, loss: 0.019860\n",
      "step:   123400, time: 0.419, loss: 0.008848\n",
      "step:   123420, time: 0.380, loss: 0.012683\n",
      "step:   123440, time: 0.396, loss: 0.018805\n",
      "step:   123460, time: 0.403, loss: 0.013833\n",
      "step:   123480, time: 0.383, loss: 0.016902\n",
      "step:   123500, time: 0.408, loss: 0.013166\n",
      "step:   123520, time: 0.456, loss: 0.016040\n",
      "step:   123540, time: 0.392, loss: 0.011599\n",
      "step:   123560, time: 0.396, loss: 0.017483\n",
      "step:   123580, time: 0.404, loss: 0.007000\n",
      "step:   123600, time: 0.382, loss: 0.010919\n",
      "step:   123620, time: 0.417, loss: 0.018350\n",
      "step:   123640, time: 0.408, loss: 0.013972\n",
      "step:   123660, time: 0.391, loss: 0.010051\n",
      "step:   123680, time: 0.387, loss: 0.015637\n",
      "step:   123700, time: 0.427, loss: 0.015655\n",
      "step:   123720, time: 0.413, loss: 0.014689\n",
      "step:   123740, time: 0.389, loss: 0.016352\n",
      "step:   123760, time: 0.398, loss: 0.016375\n",
      "step:   123780, time: 0.373, loss: 0.011063\n",
      "step:   123800, time: 0.405, loss: 0.018205\n",
      "step:   123820, time: 0.394, loss: 0.009481\n",
      "step:   123840, time: 0.405, loss: 0.015766\n",
      "step:   123860, time: 0.402, loss: 0.015485\n",
      "step:   123880, time: 0.396, loss: 0.013660\n",
      "step:   123900, time: 0.388, loss: 0.014810\n",
      "step:   123920, time: 0.401, loss: 0.009327\n",
      "step:   123940, time: 0.391, loss: 0.010249\n",
      "step:   123960, time: 0.416, loss: 0.019639\n",
      "step:   123980, time: 0.393, loss: 0.018074\n",
      "step:   124000, time: 0.407, loss: 0.020931\n",
      "step:   124020, time: 0.418, loss: 0.019859\n",
      "step:   124040, time: 0.409, loss: 0.013958\n",
      "step:   124060, time: 0.449, loss: 0.021621\n",
      "step:   124080, time: 0.396, loss: 0.012121\n",
      "step:   124100, time: 0.406, loss: 0.024318\n",
      "step:   124120, time: 0.377, loss: 0.017740\n",
      "step:   124140, time: 0.402, loss: 0.022208\n",
      "step:   124160, time: 0.399, loss: 0.020446\n",
      "step:   124180, time: 0.404, loss: 0.016803\n",
      "step:   124200, time: 0.392, loss: 0.020151\n",
      "step:   124220, time: 0.384, loss: 0.011753\n",
      "step:   124240, time: 0.386, loss: 0.013186\n",
      "step:   124260, time: 0.404, loss: 0.012963\n",
      "step:   124280, time: 0.396, loss: 0.022895\n",
      "step:   124300, time: 0.389, loss: 0.011227\n",
      "step:   124320, time: 0.383, loss: 0.011270\n",
      "step:   124340, time: 0.402, loss: 0.020325\n",
      "step:   124360, time: 0.401, loss: 0.016462\n",
      "step:   124380, time: 0.395, loss: 0.017226\n",
      "step:   124400, time: 0.392, loss: 0.013999\n",
      "step:   124420, time: 0.402, loss: 0.011044\n",
      "step:   124440, time: 0.406, loss: 0.015145\n",
      "step:   124460, time: 0.118, loss: 0.002134\n",
      "step:   124480, time: 0.394, loss: 0.007745\n",
      "step:   124500, time: 0.395, loss: 0.013407\n",
      "step:   124520, time: 0.398, loss: 0.032033\n",
      "step:   124540, time: 0.435, loss: 0.017211\n",
      "step:   124560, time: 0.405, loss: 0.016243\n",
      "step:   124580, time: 0.416, loss: 0.020160\n",
      "step:   124600, time: 0.399, loss: 0.022402\n",
      "step:   124620, time: 0.436, loss: 0.012566\n",
      "step:   124640, time: 0.401, loss: 0.017770\n",
      "step:   124660, time: 0.417, loss: 0.010078\n",
      "step:   124680, time: 0.415, loss: 0.021060\n",
      "step:   124700, time: 0.427, loss: 0.010504\n",
      "step:   124720, time: 0.465, loss: 0.016887\n",
      "step:   124740, time: 0.408, loss: 0.011827\n",
      "step:   124760, time: 0.425, loss: 0.020474\n",
      "step:   124780, time: 0.400, loss: 0.018507\n",
      "step:   124800, time: 0.418, loss: 0.012261\n",
      "step:   124820, time: 0.393, loss: 0.012025\n",
      "step:   124840, time: 0.392, loss: 0.018228\n",
      "step:   124860, time: 0.440, loss: 0.012800\n",
      "step:   124880, time: 0.400, loss: 0.019969\n",
      "step:   124900, time: 0.435, loss: 0.011144\n",
      "step:   124920, time: 0.403, loss: 0.014794\n",
      "step:   124940, time: 0.403, loss: 0.020791\n",
      "step:   124960, time: 0.418, loss: 0.017403\n",
      "step:   124980, time: 0.404, loss: 0.015638\n",
      "step:   125000, time: 0.411, loss: 0.017500\n",
      "step:   125020, time: 0.409, loss: 0.014164\n",
      "step:   125040, time: 0.404, loss: 0.012497\n",
      "step:   125060, time: 0.393, loss: 0.020280\n",
      "step:   125080, time: 0.402, loss: 0.016583\n",
      "step:   125100, time: 0.400, loss: 0.011643\n",
      "step:   125120, time: 0.398, loss: 0.010214\n",
      "step:   125140, time: 0.414, loss: 0.013835\n",
      "step:   125160, time: 0.426, loss: 0.012286\n",
      "step:   125180, time: 0.376, loss: 0.011219\n",
      "step:   125200, time: 0.381, loss: 0.019386\n",
      "step:   125220, time: 0.421, loss: 0.019869\n",
      "step:   125240, time: 0.395, loss: 0.024786\n",
      "step:   125260, time: 0.411, loss: 0.014919\n",
      "step:   125280, time: 0.382, loss: 0.007718\n",
      "step:   125300, time: 0.411, loss: 0.018959\n",
      "step:   125320, time: 0.389, loss: 0.016252\n",
      "step:   125340, time: 0.403, loss: 0.003199\n",
      "step:   125360, time: 0.385, loss: 0.008890\n",
      "step:   125380, time: 0.420, loss: 0.011207\n",
      "step:   125400, time: 0.374, loss: 0.013678\n",
      "step:   125420, time: 0.397, loss: 0.009002\n",
      "step:   125440, time: 0.388, loss: 0.009548\n",
      "step:   125460, time: 0.401, loss: 0.008381\n",
      "step:   125480, time: 0.382, loss: 0.014161\n",
      "step:   125500, time: 0.371, loss: 0.018936\n",
      "step:   125520, time: 0.399, loss: 0.016578\n",
      "step:   125540, time: 0.373, loss: 0.020648\n",
      "step:   125560, time: 0.428, loss: 0.240028\n",
      "step:   125580, time: 0.415, loss: 0.006117\n",
      "step:   125600, time: 0.396, loss: 0.012969\n",
      "step:   125620, time: 0.393, loss: 0.015787\n",
      "step:   125640, time: 0.425, loss: 0.009662\n",
      "step:   125660, time: 0.411, loss: 0.016174\n",
      "step:   125680, time: 0.421, loss: 0.012159\n",
      "step:   125700, time: 0.397, loss: 0.016270\n",
      "step:   125720, time: 0.391, loss: 0.019683\n",
      "step:   125740, time: 0.408, loss: 0.014892\n",
      "step:   125760, time: 0.397, loss: 0.014947\n",
      "step:   125780, time: 0.392, loss: 0.018300\n",
      "step:   125800, time: 0.397, loss: 0.005392\n",
      "step:   125820, time: 0.397, loss: 0.009812\n",
      "step:   125840, time: 0.376, loss: 0.014044\n",
      "step:   125860, time: 0.391, loss: 0.016112\n",
      "step:   125880, time: 0.410, loss: 0.011192\n",
      "step:   125900, time: 0.417, loss: 0.019111\n",
      "step:   125920, time: 0.396, loss: 0.016682\n",
      "step:   125940, time: 0.390, loss: 0.017058\n",
      "step:   125960, time: 0.407, loss: 0.019054\n",
      "step:   125980, time: 0.435, loss: 0.008868\n",
      "step:   126000, time: 0.392, loss: 0.009944\n",
      "step:   126020, time: 0.401, loss: 0.015864\n",
      "step:   126040, time: 0.401, loss: 0.010201\n",
      "step:   126060, time: 0.380, loss: 0.016525\n",
      "step:   126080, time: 0.383, loss: 0.014850\n",
      "step:   126100, time: 0.389, loss: 0.016498\n",
      "step:   126120, time: 0.395, loss: 0.011899\n",
      "step:   126140, time: 0.406, loss: 0.011854\n",
      "step:   126160, time: 0.409, loss: 0.021957\n",
      "step:   126180, time: 0.374, loss: 0.014660\n",
      "step:   126200, time: 0.385, loss: 0.004703\n",
      "step:   126220, time: 0.376, loss: 0.007659\n",
      "step:   126240, time: 0.417, loss: 0.021709\n",
      "step:   126260, time: 0.397, loss: 0.016538\n",
      "step:   126280, time: 0.420, loss: 0.022226\n",
      "step:   126300, time: 0.394, loss: 0.016661\n",
      "step:   126320, time: 0.418, loss: 0.020149\n",
      "step:   126340, time: 0.405, loss: 0.011569\n",
      "step:   126360, time: 0.380, loss: 0.010015\n",
      "step:   126380, time: 0.435, loss: 0.016994\n",
      "step:   126400, time: 0.391, loss: 0.009548\n",
      "step:   126420, time: 0.412, loss: 0.014251\n",
      "step:   126440, time: 0.422, loss: 0.015414\n",
      "step:   126460, time: 0.376, loss: 0.022083\n",
      "step:   126480, time: 0.429, loss: 0.011244\n",
      "step:   126500, time: 0.402, loss: 0.011084\n",
      "step:   126520, time: 0.385, loss: 0.017262\n",
      "step:   126540, time: 0.400, loss: 0.018165\n",
      "step:   126560, time: 0.423, loss: 0.018289\n",
      "step:   126580, time: 0.394, loss: 0.011622\n",
      "step:   126600, time: 0.390, loss: 0.018177\n",
      "step:   126620, time: 0.404, loss: 0.017173\n",
      "step:   126640, time: 0.391, loss: 0.014840\n",
      "step:   126660, time: 0.396, loss: 0.012216\n",
      "step:   126680, time: 0.427, loss: 0.019780\n",
      "step:   126700, time: 0.421, loss: 0.011095\n",
      "step:   126720, time: 0.407, loss: 0.011968\n",
      "step:   126740, time: 0.447, loss: 0.011116\n",
      "step:   126760, time: 0.411, loss: 0.012796\n",
      "step:   126780, time: 0.407, loss: 0.009468\n",
      "step:   126800, time: 0.372, loss: 0.012351\n",
      "step:   126820, time: 0.414, loss: 0.022954\n",
      "step:   126840, time: 0.388, loss: 0.015687\n",
      "step:   126860, time: 0.405, loss: 0.015315\n",
      "step:   126880, time: 0.375, loss: 0.017370\n",
      "step:   126900, time: 0.408, loss: 0.014300\n",
      "step:   126920, time: 0.406, loss: 0.015371\n",
      "step:   126940, time: 0.408, loss: 0.013549\n",
      "step:   126960, time: 0.370, loss: 0.016021\n",
      "step:   126980, time: 0.391, loss: 0.012219\n",
      "step:   127000, time: 0.421, loss: 0.010540\n",
      "step:   127020, time: 0.392, loss: 0.012608\n",
      "step:   127040, time: 0.380, loss: 0.015326\n",
      "step:   127060, time: 0.410, loss: 0.008927\n",
      "step:   127080, time: 0.392, loss: 0.013968\n",
      "step:   127100, time: 0.442, loss: 0.016860\n",
      "step:   127120, time: 0.434, loss: 0.012899\n",
      "step:   127140, time: 0.378, loss: 0.004347\n",
      "step:   127160, time: 0.390, loss: 0.002617\n",
      "step:   127180, time: 0.395, loss: 0.012373\n",
      "step:   127200, time: 0.377, loss: 0.013391\n",
      "step:   127220, time: 0.412, loss: 0.017642\n",
      "step:   127240, time: 0.446, loss: 0.020557\n",
      "step:   127260, time: 0.440, loss: 0.014038\n",
      "step:   127280, time: 0.398, loss: 0.019061\n",
      "step:   127300, time: 0.409, loss: 0.021370\n",
      "step:   127320, time: 0.419, loss: 0.020546\n",
      "step:   127340, time: 0.437, loss: 0.134186\n",
      "step:   127360, time: 0.412, loss: 0.018235\n",
      "step:   127380, time: 0.402, loss: 0.019193\n",
      "step:   127400, time: 0.406, loss: 0.012602\n",
      "step:   127420, time: 0.404, loss: 0.023615\n",
      "step:   127440, time: 0.392, loss: 0.007683\n",
      "step:   127460, time: 0.426, loss: 0.024171\n",
      "step:   127480, time: 0.436, loss: 0.019840\n",
      "step:   127500, time: 0.389, loss: 0.002326\n",
      "step:   127520, time: 0.392, loss: 0.011276\n",
      "step:   127540, time: 0.402, loss: 0.015226\n",
      "step:   127560, time: 0.408, loss: 0.022630\n",
      "step:   127580, time: 0.428, loss: 0.014534\n",
      "step:   127600, time: 0.390, loss: 0.024204\n",
      "step:   127620, time: 0.399, loss: 0.016066\n",
      "step:   127640, time: 0.418, loss: 0.018534\n",
      "step:   127660, time: 0.425, loss: 0.011833\n",
      "step:   127680, time: 0.382, loss: 0.018479\n",
      "step:   127700, time: 0.399, loss: 0.012458\n",
      "step:   127720, time: 0.401, loss: 0.012346\n",
      "step:   127740, time: 0.405, loss: 0.019252\n",
      "step:   127760, time: 0.410, loss: 0.014207\n",
      "step:   127780, time: 0.419, loss: 0.007271\n",
      "step:   127800, time: 0.390, loss: 0.011505\n",
      "step:   127820, time: 0.410, loss: 0.008722\n",
      "step:   127840, time: 0.414, loss: 0.015320\n",
      "step:   127860, time: 0.375, loss: 0.005053\n",
      "step:   127880, time: 0.411, loss: 0.018569\n",
      "step:   127900, time: 0.413, loss: 0.012248\n",
      "step:   127920, time: 0.386, loss: 0.013612\n",
      "step:   127940, time: 0.403, loss: 0.012874\n",
      "step:   127960, time: 0.400, loss: 0.010249\n",
      "step:   127980, time: 0.427, loss: 0.017813\n",
      "step:   128000, time: 0.427, loss: 0.010575\n",
      "step:   128020, time: 0.394, loss: 0.012040\n",
      "step:   128040, time: 0.393, loss: 0.018739\n",
      "step:   128060, time: 0.406, loss: 0.017726\n",
      "step:   128080, time: 0.393, loss: 0.015695\n",
      "step:   128100, time: 0.392, loss: 0.009899\n",
      "step:   128120, time: 0.406, loss: 0.014466\n",
      "step:   128140, time: 0.435, loss: 0.015779\n",
      "step:   128160, time: 0.400, loss: 0.007620\n",
      "step:   128180, time: 0.425, loss: 0.018518\n",
      "step:   128200, time: 0.396, loss: 0.013023\n",
      "step:   128220, time: 0.390, loss: 0.013272\n",
      "step:   128240, time: 0.421, loss: 0.013165\n",
      "step:   128260, time: 0.397, loss: 0.016999\n",
      "step:   128280, time: 0.404, loss: 0.016548\n",
      "step:   128300, time: 0.395, loss: 0.017892\n",
      "step:   128320, time: 0.418, loss: 0.020923\n",
      "step:   128340, time: 0.449, loss: 0.121289\n",
      "step:   128360, time: 0.412, loss: 0.018816\n",
      "step:   128380, time: 0.419, loss: 0.012669\n",
      "step:   128400, time: 0.421, loss: 0.011407\n",
      "step:   128420, time: 0.409, loss: 0.114067\n",
      "step:   128440, time: 0.401, loss: 0.017218\n",
      "step:   128460, time: 0.387, loss: 0.006219\n",
      "step:   128480, time: 0.395, loss: 0.019894\n",
      "step:   128500, time: 0.433, loss: 0.014250\n",
      "step:   128520, time: 0.386, loss: 0.010261\n",
      "step:   128540, time: 0.397, loss: 0.012038\n",
      "step:   128560, time: 0.424, loss: 0.022941\n",
      "step:   128580, time: 0.406, loss: 0.011739\n",
      "step:   128600, time: 0.408, loss: 0.015892\n",
      "step:   128620, time: 0.419, loss: 0.015275\n",
      "step:   128640, time: 0.379, loss: 0.014619\n",
      "step:   128660, time: 0.425, loss: 0.129957\n",
      "step:   128680, time: 0.407, loss: 0.010794\n",
      "step:   128700, time: 0.396, loss: 0.012180\n",
      "step:   128720, time: 0.399, loss: 0.013617\n",
      "step:   128740, time: 0.406, loss: 0.011563\n",
      "step:   128760, time: 0.379, loss: 0.012090\n",
      "step:   128780, time: 0.386, loss: 0.012180\n",
      "step:   128800, time: 0.423, loss: 0.012921\n",
      "step:   128820, time: 0.407, loss: 0.026561\n",
      "step:   128840, time: 0.405, loss: 0.012784\n",
      "step:   128860, time: 0.393, loss: 0.012236\n",
      "step:   128880, time: 0.389, loss: 0.014456\n",
      "step:   128900, time: 0.409, loss: 0.014833\n",
      "step:   128920, time: 0.405, loss: 0.020239\n",
      "step:   128940, time: 0.460, loss: 0.009247\n",
      "step:   128960, time: 0.408, loss: 0.003074\n",
      "step:   128980, time: 0.422, loss: 0.006934\n",
      "step:   129000, time: 0.401, loss: 0.013810\n",
      "step:   129020, time: 0.401, loss: 0.012221\n",
      "step:   129040, time: 0.431, loss: 0.019251\n",
      "step:   129060, time: 0.447, loss: 0.019710\n",
      "step:   129080, time: 0.425, loss: 0.011896\n",
      "step:   129100, time: 0.393, loss: 0.003444\n",
      "step:   129120, time: 0.425, loss: 0.017163\n",
      "step:   129140, time: 0.413, loss: 0.017653\n",
      "step:   129160, time: 0.387, loss: 0.016160\n",
      "step:   129180, time: 0.385, loss: 0.014990\n",
      "step:   129200, time: 0.408, loss: 0.006311\n",
      "step:   129220, time: 0.398, loss: 0.010064\n",
      "step:   129240, time: 0.447, loss: 0.016694\n",
      "step:   129260, time: 0.400, loss: 0.026821\n",
      "step:   129280, time: 0.413, loss: 0.022833\n",
      "step:   129300, time: 0.414, loss: 0.017948\n",
      "step:   129320, time: 0.411, loss: 0.016639\n",
      "step:   129340, time: 0.405, loss: 0.016902\n",
      "step:   129360, time: 0.423, loss: 0.023113\n",
      "step:   129380, time: 0.379, loss: 0.009597\n",
      "step:   129400, time: 0.399, loss: 0.018439\n",
      "step:   129420, time: 0.409, loss: 0.008554\n",
      "step:   129440, time: 0.453, loss: 0.017389\n",
      "step:   129460, time: 0.442, loss: 0.016213\n",
      "step:   129480, time: 0.425, loss: 0.018231\n",
      "step:   129500, time: 0.425, loss: 0.018162\n",
      "step:   129520, time: 0.412, loss: 0.040503\n",
      "step:   129540, time: 0.405, loss: 0.020064\n",
      "step:   129560, time: 0.430, loss: 0.020082\n",
      "step:   129580, time: 0.433, loss: 0.009630\n",
      "step:   129600, time: 0.457, loss: 0.011370\n",
      "step:   129620, time: 0.417, loss: 0.012835\n",
      "step:   129640, time: 0.419, loss: 0.003036\n",
      "step:   129660, time: 0.435, loss: 0.009394\n",
      "step:   129680, time: 0.443, loss: 0.020203\n",
      "step:   129700, time: 0.445, loss: 0.014806\n",
      "step:   129720, time: 0.419, loss: 0.004876\n",
      "step:   129740, time: 0.419, loss: 0.219862\n",
      "step:   129760, time: 0.433, loss: 0.017082\n",
      "step:   129780, time: 0.407, loss: 0.009016\n",
      "step:   129800, time: 0.427, loss: 0.017329\n",
      "step:   129820, time: 0.439, loss: 0.009599\n",
      "step:   129840, time: 0.414, loss: 0.008347\n",
      "step:   129860, time: 0.410, loss: 0.011361\n",
      "step:   129880, time: 0.442, loss: 0.010679\n",
      "step:   129900, time: 0.442, loss: 0.016824\n",
      "step:   129920, time: 0.542, loss: 0.017717\n",
      "step:   129940, time: 0.540, loss: 0.015170\n",
      "step:   129960, time: 0.486, loss: 0.018292\n",
      "step:   129980, time: 0.397, loss: 0.018711\n",
      "step:   130000, time: 0.400, loss: 0.021245\n",
      "step:   130020, time: 0.397, loss: 0.005369\n",
      "step:   130040, time: 0.410, loss: 0.018472\n",
      "step:   130060, time: 0.404, loss: 0.016177\n",
      "step:   130080, time: 0.390, loss: 0.008447\n",
      "step:   130100, time: 0.379, loss: 0.016668\n",
      "step:   130120, time: 0.395, loss: 0.016236\n",
      "step:   130140, time: 0.400, loss: 0.013284\n",
      "step:   130160, time: 0.393, loss: 0.011023\n",
      "step:   130180, time: 0.420, loss: 0.013124\n",
      "step:   130200, time: 0.400, loss: 0.006663\n",
      "step:   130220, time: 0.402, loss: 0.008659\n",
      "step:   130240, time: 0.390, loss: 0.023799\n",
      "step:   130260, time: 0.420, loss: 0.024368\n",
      "step:   130280, time: 0.398, loss: 0.012705\n",
      "step:   130300, time: 0.405, loss: 0.012044\n",
      "step:   130320, time: 0.415, loss: 0.005200\n",
      "step:   130340, time: 0.422, loss: 0.018545\n",
      "step:   130360, time: 0.400, loss: 0.008969\n",
      "step:   130380, time: 0.401, loss: 0.013605\n",
      "step:   130400, time: 0.402, loss: 0.014052\n",
      "step:   130420, time: 0.386, loss: 0.023099\n",
      "step:   130440, time: 0.407, loss: 0.008703\n",
      "step:   130460, time: 0.389, loss: 0.010836\n",
      "step:   130480, time: 0.405, loss: 0.017980\n",
      "step:   130500, time: 0.414, loss: 0.017766\n",
      "step:   130520, time: 0.392, loss: 0.026219\n",
      "step:   130540, time: 0.399, loss: 0.007143\n",
      "step:   130560, time: 0.406, loss: 0.017763\n",
      "step:   130580, time: 0.389, loss: 0.014077\n",
      "step:   130600, time: 0.400, loss: 0.009405\n",
      "step:   130620, time: 0.398, loss: 0.008320\n",
      "step:   130640, time: 0.407, loss: 0.018937\n",
      "step:   130660, time: 0.390, loss: 0.015875\n",
      "step:   130680, time: 0.431, loss: 0.021280\n",
      "step:   130700, time: 0.409, loss: 0.013043\n",
      "step:   130720, time: 0.409, loss: 0.022094\n",
      "step:   130740, time: 0.386, loss: 0.012427\n",
      "step:   130760, time: 0.389, loss: 0.007880\n",
      "step:   130780, time: 0.409, loss: 0.012341\n",
      "step:   130800, time: 0.406, loss: 0.017554\n",
      "step:   130820, time: 0.441, loss: 0.019864\n",
      "step:   130840, time: 0.401, loss: 0.008203\n",
      "step:   130860, time: 0.381, loss: 0.021599\n",
      "step:   130880, time: 0.405, loss: 0.014788\n",
      "step:   130900, time: 0.400, loss: 0.012833\n",
      "step:   130920, time: 0.417, loss: 0.016534\n",
      "step:   130940, time: 0.379, loss: 0.016562\n",
      "step:   130960, time: 0.406, loss: 0.005832\n",
      "step:   130980, time: 0.428, loss: 0.018647\n",
      "step:   131000, time: 0.398, loss: 0.008069\n",
      "step:   131020, time: 0.374, loss: 0.019790\n",
      "step:   131040, time: 0.421, loss: 0.014871\n",
      "step:   131060, time: 0.412, loss: 0.021055\n",
      "step:   131080, time: 0.425, loss: 0.018242\n",
      "step:   131100, time: 0.411, loss: 0.014100\n",
      "step:   131120, time: 0.423, loss: 0.013831\n",
      "step:   131140, time: 0.379, loss: 0.024797\n",
      "step:   131160, time: 0.409, loss: 0.018390\n",
      "step:   131180, time: 0.404, loss: 0.016571\n",
      "step:   131200, time: 0.401, loss: 0.017831\n",
      "step:   131220, time: 0.419, loss: 0.017986\n",
      "step:   131240, time: 0.441, loss: 0.018432\n",
      "step:   131260, time: 0.412, loss: 0.026818\n",
      "step:   131280, time: 0.398, loss: 0.012516\n",
      "step:   131300, time: 0.415, loss: 0.014802\n",
      "step:   131320, time: 0.396, loss: 0.016765\n",
      "step:   131340, time: 0.417, loss: 0.017367\n",
      "step:   131360, time: 0.391, loss: 0.016173\n",
      "step:   131380, time: 0.390, loss: 0.014695\n",
      "step:   131400, time: 0.382, loss: 0.012799\n",
      "step:   131420, time: 0.421, loss: 0.006432\n",
      "step:   131440, time: 0.419, loss: 0.020227\n",
      "step:   131460, time: 0.385, loss: 0.006867\n",
      "step:   131480, time: 0.390, loss: 0.009089\n",
      "step:   131500, time: 0.412, loss: 0.011965\n",
      "step:   131520, time: 0.419, loss: 0.020807\n",
      "step:   131540, time: 0.407, loss: 0.009730\n",
      "step:   131560, time: 0.406, loss: 0.017712\n",
      "step:   131580, time: 0.399, loss: 0.015279\n",
      "step:   131600, time: 0.379, loss: 0.016346\n",
      "step:   131620, time: 0.398, loss: 0.015667\n",
      "step:   131640, time: 0.416, loss: 0.016971\n",
      "step:   131660, time: 0.396, loss: 0.102084\n",
      "step:   131680, time: 0.397, loss: 0.022732\n",
      "step:   131700, time: 0.432, loss: 0.020734\n",
      "step:   131720, time: 0.375, loss: 0.012158\n",
      "step:   131740, time: 0.385, loss: 0.019584\n",
      "step:   131760, time: 0.414, loss: 0.013437\n",
      "step:   131780, time: 0.432, loss: 0.014917\n",
      "step:   131800, time: 0.390, loss: 0.019628\n",
      "step:   131820, time: 0.391, loss: 0.017977\n",
      "step:   131840, time: 0.397, loss: 0.016739\n",
      "step:   131860, time: 0.382, loss: 0.013744\n",
      "step:   131880, time: 0.385, loss: 0.026641\n",
      "step:   131900, time: 0.386, loss: 0.019383\n",
      "step:   131920, time: 0.406, loss: 0.010748\n",
      "step:   131940, time: 0.389, loss: 0.024571\n",
      "step:   131960, time: 0.396, loss: 0.013982\n",
      "step:   131980, time: 0.407, loss: 0.013091\n",
      "step:   132000, time: 0.397, loss: 0.011800\n",
      "step:   132020, time: 0.405, loss: 0.019398\n",
      "step:   132040, time: 0.408, loss: 0.019045\n",
      "step:   132060, time: 0.422, loss: 0.014163\n",
      "step:   132080, time: 0.433, loss: 0.015441\n",
      "step:   132100, time: 0.387, loss: 0.008322\n",
      "step:   132120, time: 0.363, loss: 0.012398\n",
      "step:   132140, time: 0.403, loss: 0.019454\n",
      "step:   132160, time: 0.382, loss: 0.013333\n",
      "step:   132180, time: 0.393, loss: 0.015426\n",
      "step:   132200, time: 0.404, loss: 0.057455\n",
      "step:   132220, time: 0.396, loss: 0.013876\n",
      "step:   132240, time: 0.416, loss: 0.014115\n",
      "step:   132260, time: 0.442, loss: 0.021643\n",
      "step:   132280, time: 0.386, loss: 0.018642\n",
      "step:   132300, time: 0.416, loss: 0.008012\n",
      "step:   132320, time: 0.403, loss: 0.011901\n",
      "step:   132340, time: 0.389, loss: 0.009828\n",
      "step:   132360, time: 0.381, loss: 0.006821\n",
      "step:   132380, time: 0.400, loss: 0.017045\n",
      "step:   132400, time: 0.432, loss: 0.015339\n",
      "step:   132420, time: 0.395, loss: 0.009205\n",
      "step:   132440, time: 0.382, loss: 0.008828\n",
      "step:   132460, time: 0.398, loss: 0.015013\n",
      "step:   132480, time: 0.438, loss: 0.019184\n",
      "step:   132500, time: 0.414, loss: 0.014697\n",
      "step:   132520, time: 0.393, loss: 0.025621\n",
      "step:   132540, time: 0.407, loss: 0.011652\n",
      "step:   132560, time: 0.399, loss: 0.017708\n",
      "step:   132580, time: 0.385, loss: 0.035159\n",
      "step:   132600, time: 0.375, loss: 0.016699\n",
      "step:   132620, time: 0.422, loss: 0.013281\n",
      "step:   132640, time: 0.411, loss: 0.010644\n",
      "step:   132660, time: 0.397, loss: 0.005532\n",
      "step:   132680, time: 0.413, loss: 0.015498\n",
      "step:   132700, time: 0.414, loss: 0.014229\n",
      "step:   132720, time: 0.389, loss: 0.018710\n",
      "step:   132740, time: 0.400, loss: 0.014249\n",
      "step:   132760, time: 0.381, loss: 0.017172\n",
      "step:   132780, time: 0.409, loss: 0.020963\n",
      "step:   132800, time: 0.426, loss: 0.025670\n",
      "step:   132820, time: 0.417, loss: 0.009395\n",
      "step:   132840, time: 0.386, loss: 0.013654\n",
      "step:   132860, time: 0.390, loss: 0.015851\n",
      "step:   132880, time: 0.423, loss: 0.016639\n",
      "step:   132900, time: 0.403, loss: 0.014429\n",
      "step:   132920, time: 0.400, loss: 0.015812\n",
      "step:   132940, time: 0.459, loss: 0.121094\n",
      "step:   132960, time: 0.421, loss: 0.015821\n",
      "step:   132980, time: 0.374, loss: 0.010786\n",
      "step:   133000, time: 0.426, loss: 0.010283\n",
      "step:   133020, time: 0.401, loss: 0.015800\n",
      "step:   133040, time: 0.414, loss: 0.011888\n",
      "step:   133060, time: 0.406, loss: 0.014313\n",
      "step:   133080, time: 0.413, loss: 0.018055\n",
      "step:   133100, time: 0.385, loss: 0.011178\n",
      "step:   133120, time: 0.407, loss: 0.011985\n",
      "step:   133140, time: 0.385, loss: 0.016975\n",
      "step:   133160, time: 0.419, loss: 0.019601\n",
      "step:   133180, time: 0.454, loss: 0.014893\n",
      "step:   133200, time: 0.409, loss: 0.009739\n",
      "step:   133220, time: 0.400, loss: 0.020008\n",
      "step:   133240, time: 0.400, loss: 0.010513\n",
      "step:   133260, time: 0.401, loss: 0.018959\n",
      "step:   133280, time: 0.385, loss: 0.013760\n",
      "step:   133300, time: 0.425, loss: 0.015971\n",
      "step:   133320, time: 0.402, loss: 0.018107\n",
      "step:   133340, time: 0.392, loss: 0.022535\n",
      "step:   133360, time: 0.399, loss: 0.021614\n",
      "step:   133380, time: 0.420, loss: 0.024506\n",
      "step:   133400, time: 0.419, loss: 0.016080\n",
      "step:   133420, time: 0.415, loss: 0.021283\n",
      "step:   133440, time: 0.405, loss: 0.019855\n",
      "step:   133460, time: 0.395, loss: 0.011783\n",
      "step:   133480, time: 0.420, loss: 0.020136\n",
      "step:   133500, time: 0.400, loss: 0.007197\n",
      "step:   133520, time: 0.438, loss: 0.012099\n",
      "step:   133540, time: 0.406, loss: 0.010273\n",
      "step:   133560, time: 0.392, loss: 0.012657\n",
      "step:   133580, time: 0.405, loss: 0.020923\n",
      "step:   133600, time: 0.400, loss: 0.013117\n",
      "step:   133620, time: 0.402, loss: 0.011608\n",
      "step:   133640, time: 0.404, loss: 0.021273\n",
      "step:   133660, time: 0.377, loss: 0.007601\n",
      "step:   133680, time: 0.400, loss: 0.021970\n",
      "step:   133700, time: 0.404, loss: 0.008663\n",
      "step:   133720, time: 0.396, loss: 0.021227\n",
      "step:   133740, time: 0.410, loss: 0.011040\n",
      "step:   133760, time: 0.405, loss: 0.017485\n",
      "step:   133780, time: 0.387, loss: 0.015872\n",
      "step:   133800, time: 0.396, loss: 0.011828\n",
      "step:   133820, time: 0.396, loss: 0.011680\n",
      "step:   133840, time: 0.406, loss: 0.017035\n",
      "step:   133860, time: 0.411, loss: 0.023341\n",
      "step:   133880, time: 0.395, loss: 0.018164\n",
      "step:   133900, time: 0.402, loss: 0.115984\n",
      "step:   133920, time: 0.451, loss: 0.010730\n",
      "step:   133940, time: 0.401, loss: 0.016823\n",
      "step:   133960, time: 0.425, loss: 0.032675\n",
      "step:   133980, time: 0.421, loss: 0.017764\n",
      "step:   134000, time: 0.412, loss: 0.012327\n",
      "step:   134020, time: 0.427, loss: 0.017938\n",
      "step:   134040, time: 0.400, loss: 0.008751\n",
      "step:   134060, time: 0.401, loss: 0.010408\n",
      "step:   134080, time: 0.407, loss: 0.009728\n",
      "step:   134100, time: 0.432, loss: 0.021604\n",
      "step:   134120, time: 0.382, loss: 0.018971\n",
      "step:   134140, time: 0.389, loss: 0.011397\n",
      "step:   134160, time: 0.379, loss: 0.011862\n",
      "step:   134180, time: 0.395, loss: 0.013572\n",
      "step:   134200, time: 0.378, loss: 0.018651\n",
      "step:   134220, time: 0.404, loss: 0.015032\n",
      "step:   134240, time: 0.425, loss: 0.015653\n",
      "step:   134260, time: 0.398, loss: 0.009361\n",
      "step:   134280, time: 0.395, loss: 0.017202\n",
      "step:   134300, time: 0.409, loss: 0.008600\n",
      "step:   134320, time: 0.382, loss: 0.021704\n",
      "step:   134340, time: 0.403, loss: 0.013314\n",
      "step:   134360, time: 0.425, loss: 0.009922\n",
      "step:   134380, time: 0.410, loss: 0.017615\n",
      "step:   134400, time: 0.395, loss: 0.009931\n",
      "step:   134420, time: 0.374, loss: 0.015611\n",
      "step:   134440, time: 0.388, loss: 0.016693\n",
      "step:   134460, time: 0.395, loss: 0.026097\n",
      "step:   134480, time: 0.441, loss: 0.015004\n",
      "step:   134500, time: 0.381, loss: 0.008191\n",
      "step:   134520, time: 0.391, loss: 0.016643\n",
      "step:   134540, time: 0.394, loss: 0.027330\n",
      "step:   134560, time: 0.403, loss: 0.013968\n",
      "step:   134580, time: 0.391, loss: 0.023092\n",
      "step:   134600, time: 0.419, loss: 0.018616\n",
      "step:   134620, time: 0.386, loss: 0.007656\n",
      "step:   134640, time: 0.416, loss: 0.016316\n",
      "step:   134660, time: 0.434, loss: 0.021020\n",
      "step:   134680, time: 0.411, loss: 0.018076\n",
      "step:   134700, time: 0.415, loss: 0.017603\n",
      "step:   134720, time: 0.405, loss: 0.009400\n",
      "step:   134740, time: 0.425, loss: 0.019301\n",
      "step:   134760, time: 0.388, loss: 0.013830\n",
      "step:   134780, time: 0.416, loss: 0.010968\n",
      "step:   134800, time: 0.406, loss: 0.023203\n",
      "step:   134820, time: 0.379, loss: 0.013643\n",
      "step:   134840, time: 0.432, loss: 0.014194\n",
      "step:   134860, time: 0.409, loss: 0.016281\n",
      "step:   134880, time: 0.406, loss: 0.014382\n",
      "step:   134900, time: 0.405, loss: 0.020441\n",
      "step:   134920, time: 0.374, loss: 0.010625\n",
      "step:   134940, time: 0.384, loss: 0.019194\n",
      "step:   134960, time: 0.393, loss: 0.018679\n",
      "step:   134980, time: 0.387, loss: 0.015956\n",
      "step:   135000, time: 0.400, loss: 0.015382\n",
      "step:   135020, time: 0.408, loss: 0.009575\n",
      "step:   135040, time: 0.372, loss: 0.016739\n",
      "step:   135060, time: 0.389, loss: 0.014493\n",
      "step:   135080, time: 0.400, loss: 0.016687\n",
      "step:   135100, time: 0.377, loss: 0.008168\n",
      "step:   135120, time: 0.403, loss: 0.009248\n",
      "step:   135140, time: 0.401, loss: 0.019128\n",
      "step:   135160, time: 0.373, loss: 0.012438\n",
      "step:   135180, time: 0.407, loss: 0.011985\n",
      "step:   135200, time: 0.403, loss: 0.016213\n",
      "step:   135220, time: 0.421, loss: 0.105926\n",
      "step:   135240, time: 0.383, loss: 0.019622\n",
      "step:   135260, time: 0.411, loss: 0.015466\n",
      "step:   135280, time: 0.397, loss: 0.012372\n",
      "step:   135300, time: 0.409, loss: 0.009581\n",
      "step:   135320, time: 0.392, loss: 0.014336\n",
      "step:   135340, time: 0.416, loss: 0.015095\n",
      "step:   135360, time: 0.397, loss: 0.009232\n",
      "step:   135380, time: 0.448, loss: 0.014221\n",
      "step:   135400, time: 0.395, loss: 0.008495\n",
      "step:   135420, time: 0.399, loss: 0.010499\n",
      "step:   135440, time: 0.381, loss: 0.017904\n",
      "step:   135460, time: 0.414, loss: 0.018123\n",
      "step:   135480, time: 0.374, loss: 0.024212\n",
      "step:   135500, time: 0.400, loss: 0.013621\n",
      "step:   135520, time: 0.391, loss: 0.008177\n",
      "step:   135540, time: 0.390, loss: 0.007712\n",
      "step:   135560, time: 0.415, loss: 0.011179\n",
      "step:   135580, time: 0.421, loss: 0.017683\n",
      "step:   135600, time: 0.424, loss: 0.010837\n",
      "step:   135620, time: 0.376, loss: 0.019697\n",
      "step:   135640, time: 0.421, loss: 0.015747\n",
      "step:   135660, time: 0.386, loss: 0.019089\n",
      "step:   135680, time: 0.424, loss: 0.005637\n",
      "step:   135700, time: 0.397, loss: 0.021060\n",
      "step:   135720, time: 0.399, loss: 0.020690\n",
      "step:   135740, time: 0.397, loss: 0.014359\n",
      "step:   135760, time: 0.379, loss: 0.018309\n",
      "step:   135780, time: 0.393, loss: 0.012671\n",
      "step:   135800, time: 0.427, loss: 0.044049\n",
      "step:   135820, time: 0.395, loss: 0.023366\n",
      "step:   135840, time: 0.401, loss: 0.016455\n",
      "step:   135860, time: 0.386, loss: 0.035803\n",
      "step:   135880, time: 0.402, loss: 0.014701\n",
      "step:   135900, time: 0.411, loss: 0.014366\n",
      "step:   135920, time: 0.389, loss: 0.016155\n",
      "step:   135940, time: 0.425, loss: 0.011584\n",
      "step:   135960, time: 0.378, loss: 0.018994\n",
      "step:   135980, time: 0.420, loss: 0.014035\n",
      "step:   136000, time: 0.393, loss: 0.016969\n",
      "step:   136020, time: 0.398, loss: 0.020733\n",
      "step:   136040, time: 0.395, loss: 0.021903\n",
      "step:   136060, time: 0.399, loss: 0.026026\n",
      "step:   136080, time: 0.403, loss: 0.011395\n",
      "step:   136100, time: 0.431, loss: 0.018911\n",
      "step:   136120, time: 0.386, loss: 0.027466\n",
      "step:   136140, time: 0.432, loss: 0.222761\n",
      "step:   136160, time: 0.379, loss: 0.013924\n",
      "step:   136180, time: 0.367, loss: 0.011266\n",
      "step:   136200, time: 0.408, loss: 0.010843\n",
      "step:   136220, time: 0.376, loss: 0.015413\n",
      "step:   136240, time: 0.430, loss: 0.016869\n",
      "step:   136260, time: 0.390, loss: 0.016387\n",
      "step:   136280, time: 0.392, loss: 0.006763\n",
      "step:   136300, time: 0.394, loss: 0.009476\n",
      "step:   136320, time: 0.421, loss: 0.016374\n",
      "step:   136340, time: 0.436, loss: 0.018617\n",
      "step:   136360, time: 0.425, loss: 0.020238\n",
      "step:   136380, time: 0.418, loss: 0.010710\n",
      "step:   136400, time: 0.427, loss: 0.020363\n",
      "step:   136420, time: 0.436, loss: 0.020276\n",
      "step:   136440, time: 0.410, loss: 0.019641\n",
      "step:   136460, time: 0.401, loss: 0.014711\n",
      "step:   136480, time: 0.409, loss: 0.014155\n",
      "step:   136500, time: 0.417, loss: 0.015217\n",
      "step:   136520, time: 0.383, loss: 0.018596\n",
      "step:   136540, time: 0.393, loss: 0.011104\n",
      "step:   136560, time: 0.399, loss: 0.016277\n",
      "step:   136580, time: 0.386, loss: 0.015759\n",
      "step:   136600, time: 0.437, loss: 0.020629\n",
      "step:   136620, time: 0.384, loss: 0.013281\n",
      "step:   136640, time: 0.390, loss: 0.012816\n",
      "step:   136660, time: 0.410, loss: 0.011732\n",
      "step:   136680, time: 0.437, loss: 0.008509\n",
      "step:   136700, time: 0.394, loss: 0.020875\n",
      "step:   136720, time: 0.385, loss: 0.013152\n",
      "step:   136740, time: 0.390, loss: 0.011838\n",
      "step:   136760, time: 0.411, loss: 0.021949\n",
      "step:   136780, time: 0.419, loss: 0.010400\n",
      "step:   136800, time: 0.394, loss: 0.009326\n",
      "step:   136820, time: 0.388, loss: 0.015846\n",
      "step:   136840, time: 0.405, loss: 0.011841\n",
      "step:   136860, time: 0.415, loss: 0.017403\n",
      "step:   136880, time: 0.402, loss: 0.017972\n",
      "step:   136900, time: 0.395, loss: 0.011448\n",
      "step:   136920, time: 0.388, loss: 0.013031\n",
      "step:   136940, time: 0.384, loss: 0.016175\n",
      "step:   136960, time: 0.393, loss: 0.023199\n",
      "step:   136980, time: 0.385, loss: 0.008671\n",
      "step:   137000, time: 0.394, loss: 0.010545\n",
      "step:   137020, time: 0.399, loss: 0.015816\n",
      "step:   137040, time: 0.397, loss: 0.012042\n",
      "step:   137060, time: 0.419, loss: 0.045583\n",
      "step:   137080, time: 0.408, loss: 0.009628\n",
      "step:   137100, time: 0.413, loss: 0.007786\n",
      "step:   137120, time: 0.392, loss: 0.022617\n",
      "step:   137140, time: 0.379, loss: 0.011282\n",
      "step:   137160, time: 0.419, loss: 0.005151\n",
      "step:   137180, time: 0.380, loss: 0.020704\n",
      "step:   137200, time: 0.408, loss: 0.020624\n",
      "step:   137220, time: 0.406, loss: 0.021479\n",
      "step:   137240, time: 0.407, loss: 0.015796\n",
      "step:   137260, time: 0.404, loss: 0.009598\n",
      "step:   137280, time: 0.396, loss: 0.005608\n",
      "step:   137300, time: 0.406, loss: 0.015912\n",
      "step:   137320, time: 0.383, loss: 0.011473\n",
      "step:   137340, time: 0.435, loss: 0.010806\n",
      "step:   137360, time: 0.390, loss: 0.013670\n",
      "step:   137380, time: 0.404, loss: 0.017496\n",
      "step:   137400, time: 0.404, loss: 0.017872\n",
      "step:   137420, time: 0.392, loss: 0.011205\n",
      "step:   137440, time: 0.377, loss: 0.014539\n",
      "step:   137460, time: 0.413, loss: 0.011661\n",
      "step:   137480, time: 0.397, loss: 0.020713\n",
      "step:   137500, time: 0.394, loss: 0.015623\n",
      "step:   137520, time: 0.399, loss: 0.013357\n",
      "step:   137540, time: 0.390, loss: 0.014378\n",
      "step:   137560, time: 0.419, loss: 0.022227\n",
      "step:   137580, time: 0.372, loss: 0.012708\n",
      "step:   137600, time: 0.424, loss: 0.013211\n",
      "step:   137620, time: 0.380, loss: 0.019403\n",
      "step:   137640, time: 0.407, loss: 0.007664\n",
      "step:   137660, time: 0.384, loss: 0.013403\n",
      "step:   137680, time: 0.432, loss: 0.014342\n",
      "step:   137700, time: 0.376, loss: 0.014186\n",
      "step:   137720, time: 0.392, loss: 0.006229\n",
      "step:   137740, time: 0.396, loss: 0.021118\n",
      "step:   137760, time: 0.414, loss: 0.012488\n",
      "step:   137780, time: 0.404, loss: 0.009516\n",
      "step:   137800, time: 0.379, loss: 0.014192\n",
      "step:   137820, time: 0.406, loss: 0.009359\n",
      "step:   137840, time: 0.402, loss: 0.013083\n",
      "step:   137860, time: 0.410, loss: 0.008940\n",
      "step:   137880, time: 0.410, loss: 0.012796\n",
      "step:   137900, time: 0.418, loss: 0.011286\n",
      "step:   137920, time: 0.440, loss: 0.017190\n",
      "step:   137940, time: 0.404, loss: 0.017481\n",
      "step:   137960, time: 0.422, loss: 0.019210\n",
      "step:   137980, time: 0.387, loss: 0.015303\n",
      "step:   138000, time: 0.398, loss: 0.020556\n",
      "step:   138020, time: 0.391, loss: 0.016894\n",
      "step:   138040, time: 0.408, loss: 0.017569\n",
      "step:   138060, time: 0.413, loss: 0.012880\n",
      "step:   138080, time: 0.410, loss: 0.009441\n",
      "step:   138100, time: 0.403, loss: 0.013208\n",
      "step:   138120, time: 0.414, loss: 0.018574\n",
      "step:   138140, time: 0.383, loss: 0.020909\n",
      "step:   138160, time: 0.398, loss: 0.119157\n",
      "step:   138180, time: 0.387, loss: 0.018781\n",
      "step:   138200, time: 0.371, loss: 0.012833\n",
      "step:   138220, time: 0.424, loss: 0.010431\n",
      "step:   138240, time: 0.381, loss: 0.016997\n",
      "step:   138260, time: 0.429, loss: 0.016853\n",
      "step:   138280, time: 0.395, loss: 0.023783\n",
      "step:   138300, time: 0.379, loss: 0.013171\n",
      "step:   138320, time: 0.404, loss: 0.019671\n",
      "step:   138340, time: 0.401, loss: 0.014235\n",
      "step:   138360, time: 0.397, loss: 0.014348\n",
      "step:   138380, time: 0.397, loss: 0.008522\n",
      "step:   138400, time: 0.418, loss: 0.019490\n",
      "step:   138420, time: 0.388, loss: 0.013627\n",
      "step:   138440, time: 0.403, loss: 0.022827\n",
      "step:   138460, time: 0.415, loss: 0.011614\n",
      "step:   138480, time: 0.387, loss: 0.020820\n",
      "step:   138500, time: 0.406, loss: 0.025809\n",
      "step:   138520, time: 0.384, loss: 0.014805\n",
      "step:   138540, time: 0.396, loss: 0.007140\n",
      "step:   138560, time: 0.387, loss: 0.009519\n",
      "step:   138580, time: 0.405, loss: 0.005714\n",
      "step:   138600, time: 0.412, loss: 0.023783\n",
      "step:   138620, time: 0.385, loss: 0.014418\n",
      "step:   138640, time: 0.396, loss: 0.010988\n",
      "step:   138660, time: 0.378, loss: 0.003106\n",
      "step:   138680, time: 0.409, loss: 0.013305\n",
      "step:   138700, time: 0.400, loss: 0.014891\n",
      "step:   138720, time: 0.405, loss: 0.005399\n",
      "step:   138740, time: 0.389, loss: 0.008449\n",
      "step:   138760, time: 0.424, loss: 0.020855\n",
      "step:   138780, time: 0.377, loss: 0.013233\n",
      "step:   138800, time: 0.403, loss: 0.017675\n",
      "step:   138820, time: 0.411, loss: 0.009871\n",
      "step:   138840, time: 0.391, loss: 0.013473\n",
      "step:   138860, time: 0.392, loss: 0.014035\n",
      "step:   138880, time: 0.442, loss: 0.216273\n",
      "step:   138900, time: 0.382, loss: 0.013541\n",
      "step:   138920, time: 0.435, loss: 0.010338\n",
      "step:   138940, time: 0.397, loss: 0.010300\n",
      "step:   138960, time: 0.389, loss: 0.019843\n",
      "step:   138980, time: 0.422, loss: 0.116846\n",
      "step:   139000, time: 0.391, loss: 0.010573\n",
      "step:   139020, time: 0.418, loss: 0.016092\n",
      "step:   139040, time: 0.400, loss: 0.013871\n",
      "step:   139060, time: 0.400, loss: 0.013810\n",
      "step:   139080, time: 0.417, loss: 0.016495\n",
      "step:   139100, time: 0.412, loss: 0.018025\n",
      "step:   139120, time: 0.395, loss: 0.014946\n",
      "step:   139140, time: 0.438, loss: 0.013852\n",
      "step:   139160, time: 0.387, loss: 0.011358\n",
      "step:   139180, time: 0.391, loss: 0.009361\n",
      "step:   139200, time: 0.402, loss: 0.016590\n",
      "step:   139220, time: 0.395, loss: 0.009379\n",
      "step:   139240, time: 0.359, loss: 0.006898\n",
      "step:   139260, time: 0.426, loss: 0.020430\n",
      "step:   139280, time: 0.406, loss: 0.010329\n",
      "step:   139300, time: 0.405, loss: 0.013839\n",
      "step:   139320, time: 0.388, loss: 0.015146\n",
      "step:   139340, time: 0.400, loss: 0.011951\n",
      "step:   139360, time: 0.381, loss: 0.016639\n",
      "step:   139380, time: 0.386, loss: 0.010887\n",
      "step:   139400, time: 0.415, loss: 0.016777\n",
      "step:   139420, time: 0.381, loss: 0.005810\n",
      "step:   139440, time: 0.390, loss: 0.022249\n",
      "step:   139460, time: 0.401, loss: 0.016840\n",
      "step:   139480, time: 0.396, loss: 0.014227\n",
      "step:   139500, time: 0.405, loss: 0.013004\n",
      "step:   139520, time: 0.390, loss: 0.011892\n",
      "step:   139540, time: 0.392, loss: 0.016197\n",
      "step:   139560, time: 0.397, loss: 0.013830\n",
      "step:   139580, time: 0.382, loss: 0.012531\n",
      "step:   139600, time: 0.407, loss: 0.015185\n",
      "step:   139620, time: 0.411, loss: 0.019611\n",
      "step:   139640, time: 0.390, loss: 0.017024\n",
      "step:   139660, time: 0.423, loss: 0.018745\n",
      "step:   139680, time: 0.375, loss: 0.007090\n",
      "step:   139700, time: 0.407, loss: 0.012259\n",
      "step:   139720, time: 0.396, loss: 0.018409\n",
      "step:   139740, time: 0.403, loss: 0.018324\n",
      "step:   139760, time: 0.414, loss: 0.008669\n",
      "step:   139780, time: 0.395, loss: 0.013933\n",
      "step:   139800, time: 0.444, loss: 0.014383\n",
      "step:   139820, time: 0.401, loss: 0.013291\n",
      "step:   139840, time: 0.445, loss: 0.013164\n",
      "step:   139860, time: 0.398, loss: 0.012787\n",
      "step:   139880, time: 0.383, loss: 0.020254\n",
      "step:   139900, time: 0.420, loss: 0.018235\n",
      "step:   139920, time: 0.421, loss: 0.014348\n",
      "step:   139940, time: 0.375, loss: 0.017751\n",
      "step:   139960, time: 0.435, loss: 0.166426\n",
      "step:   139980, time: 0.395, loss: 0.014655\n",
      "step:   140000, time: 0.394, loss: 0.018759\n",
      "step:   140020, time: 0.426, loss: 0.018356\n",
      "step:   140040, time: 0.412, loss: 0.014042\n",
      "step:   140060, time: 0.404, loss: 0.016174\n",
      "step:   140080, time: 0.385, loss: 0.017788\n",
      "step:   140100, time: 0.382, loss: 0.014184\n",
      "step:   140120, time: 0.373, loss: 0.019372\n",
      "step:   140140, time: 0.401, loss: 0.013915\n",
      "step:   140160, time: 0.409, loss: 0.018347\n",
      "step:   140180, time: 0.406, loss: 0.017466\n",
      "step:   140200, time: 0.418, loss: 0.015124\n",
      "step:   140220, time: 0.392, loss: 0.018853\n",
      "step:   140240, time: 0.419, loss: 0.013128\n",
      "step:   140260, time: 0.386, loss: 0.009882\n",
      "step:   140280, time: 0.374, loss: 0.017562\n",
      "step:   140300, time: 0.397, loss: 0.009511\n",
      "step:   140320, time: 0.389, loss: 0.016991\n",
      "step:   140340, time: 0.402, loss: 0.012427\n",
      "step:   140360, time: 0.427, loss: 0.015082\n",
      "step:   140380, time: 0.369, loss: 0.011582\n",
      "step:   140400, time: 0.425, loss: 0.026133\n",
      "step:   140420, time: 0.398, loss: 0.014766\n",
      "step:   140440, time: 0.396, loss: 0.014802\n",
      "step:   140460, time: 0.406, loss: 0.013039\n",
      "step:   140480, time: 0.385, loss: 0.017034\n",
      "step:   140500, time: 0.389, loss: 0.021771\n",
      "step:   140520, time: 0.408, loss: 0.155417\n",
      "step:   140540, time: 0.396, loss: 0.014906\n",
      "step:   140560, time: 0.385, loss: 0.017283\n",
      "step:   140580, time: 0.435, loss: 0.026796\n",
      "step:   140600, time: 0.390, loss: 0.009164\n",
      "step:   140620, time: 0.399, loss: 0.021479\n",
      "step:   140640, time: 0.405, loss: 0.144486\n",
      "step:   140660, time: 0.390, loss: 0.014331\n",
      "step:   140680, time: 0.409, loss: 0.017828\n",
      "step:   140700, time: 0.387, loss: 0.010148\n",
      "step:   140720, time: 0.416, loss: 0.015556\n",
      "step:   140740, time: 0.389, loss: 0.015396\n",
      "step:   140760, time: 0.420, loss: 0.013090\n",
      "step:   140780, time: 0.388, loss: 0.009017\n",
      "step:   140800, time: 0.422, loss: 0.015163\n",
      "step:   140820, time: 0.415, loss: 0.010502\n",
      "step:   140840, time: 0.413, loss: 0.012329\n",
      "step:   140860, time: 0.401, loss: 0.014941\n",
      "step:   140880, time: 0.400, loss: 0.010563\n",
      "step:   140900, time: 0.410, loss: 0.006713\n",
      "step:   140920, time: 0.410, loss: 0.012773\n",
      "step:   140940, time: 0.356, loss: 0.013834\n",
      "step:   140960, time: 0.384, loss: 0.019107\n",
      "step:   140980, time: 0.400, loss: 0.011248\n",
      "step:   141000, time: 0.401, loss: 0.015536\n",
      "step:   141020, time: 0.393, loss: 0.023620\n",
      "step:   141040, time: 0.394, loss: 0.020623\n",
      "step:   141060, time: 0.398, loss: 0.014693\n",
      "step:   141080, time: 0.404, loss: 0.012942\n",
      "step:   141100, time: 0.388, loss: 0.014878\n",
      "step:   141120, time: 0.392, loss: 0.012990\n",
      "step:   141140, time: 0.414, loss: 0.013495\n",
      "step:   141160, time: 0.399, loss: 0.013180\n",
      "step:   141180, time: 0.396, loss: 0.014191\n",
      "step:   141200, time: 0.428, loss: 0.024571\n",
      "step:   141220, time: 0.360, loss: 0.004232\n",
      "step:   141240, time: 0.390, loss: 0.016462\n",
      "step:   141260, time: 0.415, loss: 0.026111\n",
      "step:   141280, time: 0.418, loss: 0.010970\n",
      "step:   141300, time: 0.383, loss: 0.012276\n",
      "step:   141320, time: 0.418, loss: 0.015377\n",
      "step:   141340, time: 0.380, loss: 0.013209\n",
      "step:   141360, time: 0.389, loss: 0.011015\n",
      "step:   141380, time: 0.390, loss: 0.014499\n",
      "step:   141400, time: 0.373, loss: 0.023151\n",
      "step:   141420, time: 0.380, loss: 0.006201\n",
      "step:   141440, time: 0.389, loss: 0.017039\n",
      "step:   141460, time: 0.408, loss: 0.010221\n",
      "step:   141480, time: 0.370, loss: 0.006395\n",
      "step:   141500, time: 0.415, loss: 0.013353\n",
      "step:   141520, time: 0.380, loss: 0.022551\n",
      "step:   141540, time: 0.412, loss: 0.013097\n",
      "step:   141560, time: 0.393, loss: 0.018988\n",
      "step:   141580, time: 0.394, loss: 0.017034\n",
      "step:   141600, time: 0.395, loss: 0.012704\n",
      "step:   141620, time: 0.385, loss: 0.010821\n",
      "step:   141640, time: 0.400, loss: 0.013180\n",
      "step:   141660, time: 0.381, loss: 0.014551\n",
      "step:   141680, time: 0.433, loss: 0.024552\n",
      "step:   141700, time: 0.412, loss: 0.014798\n",
      "step:   141720, time: 0.438, loss: 0.026321\n",
      "step:   141740, time: 0.398, loss: 0.017834\n",
      "step:   141760, time: 0.388, loss: 0.008663\n",
      "step:   141780, time: 0.413, loss: 0.022518\n",
      "step:   141800, time: 0.393, loss: 0.015947\n",
      "step:   141820, time: 0.415, loss: 0.013471\n",
      "step:   141840, time: 0.400, loss: 0.016457\n",
      "step:   141860, time: 0.402, loss: 0.012156\n",
      "step:   141880, time: 0.415, loss: 0.013650\n",
      "step:   141900, time: 0.437, loss: 0.020615\n",
      "step:   141920, time: 0.416, loss: 0.011091\n",
      "step:   141940, time: 0.417, loss: 0.013504\n",
      "step:   141960, time: 0.423, loss: 0.017476\n",
      "step:   141980, time: 0.405, loss: 0.013992\n",
      "step:   142000, time: 0.438, loss: 0.011235\n",
      "step:   142020, time: 0.380, loss: 0.010598\n",
      "step:   142040, time: 0.407, loss: 0.008258\n",
      "step:   142060, time: 0.403, loss: 0.011533\n",
      "step:   142080, time: 0.409, loss: 0.015298\n",
      "step:   142100, time: 0.388, loss: 0.022152\n",
      "step:   142120, time: 0.391, loss: 0.003416\n",
      "step:   142140, time: 0.409, loss: 0.008059\n",
      "step:   142160, time: 0.385, loss: 0.006438\n",
      "step:   142180, time: 0.369, loss: 0.004503\n",
      "step:   142200, time: 0.421, loss: 0.010496\n",
      "step:   142220, time: 0.406, loss: 0.021222\n",
      "step:   142240, time: 0.118, loss: 0.018632\n",
      "step:   142260, time: 0.398, loss: 0.014249\n",
      "step:   142280, time: 0.405, loss: 0.016093\n",
      "step:   142300, time: 0.421, loss: 0.018561\n",
      "step:   142320, time: 0.386, loss: 0.009846\n",
      "step:   142340, time: 0.420, loss: 0.010947\n",
      "step:   142360, time: 0.386, loss: 0.013853\n",
      "step:   142380, time: 0.378, loss: 0.016999\n",
      "step:   142400, time: 0.377, loss: 0.006688\n",
      "step:   142420, time: 0.394, loss: 0.006899\n",
      "step:   142440, time: 0.396, loss: 0.008695\n",
      "step:   142460, time: 0.422, loss: 0.016377\n",
      "step:   142480, time: 0.444, loss: 0.008964\n",
      "step:   142500, time: 0.414, loss: 0.018500\n",
      "step:   142520, time: 0.417, loss: 0.009366\n",
      "step:   142540, time: 0.382, loss: 0.012796\n",
      "step:   142560, time: 0.387, loss: 0.017995\n",
      "step:   142580, time: 0.406, loss: 0.015429\n",
      "step:   142600, time: 0.426, loss: 0.014537\n",
      "step:   142620, time: 0.394, loss: 0.016911\n",
      "step:   142640, time: 0.432, loss: 0.010462\n",
      "step:   142660, time: 0.409, loss: 0.006747\n",
      "step:   142680, time: 0.396, loss: 0.008998\n",
      "step:   142700, time: 0.378, loss: 0.026300\n",
      "step:   142720, time: 0.397, loss: 0.015101\n",
      "step:   142740, time: 0.393, loss: 0.008533\n",
      "step:   142760, time: 0.395, loss: 0.023128\n",
      "step:   142780, time: 0.383, loss: 0.019995\n",
      "step:   142800, time: 0.412, loss: 0.009066\n",
      "step:   142820, time: 0.403, loss: 0.015970\n",
      "step:   142840, time: 0.392, loss: 0.013079\n",
      "step:   142860, time: 0.402, loss: 0.015488\n",
      "step:   142880, time: 0.403, loss: 0.012529\n",
      "step:   142900, time: 0.433, loss: 0.014090\n",
      "step:   142920, time: 0.415, loss: 0.018220\n",
      "step:   142940, time: 0.397, loss: 0.010139\n",
      "step:   142960, time: 0.373, loss: 0.010160\n",
      "step:   142980, time: 0.418, loss: 0.014172\n",
      "step:   143000, time: 0.413, loss: 0.011789\n",
      "step:   143020, time: 0.404, loss: 0.010480\n",
      "step:   143040, time: 0.392, loss: 0.012379\n",
      "step:   143060, time: 0.392, loss: 0.014915\n",
      "step:   143080, time: 0.431, loss: 0.013783\n",
      "step:   143100, time: 0.403, loss: 0.014500\n",
      "step:   143120, time: 0.400, loss: 0.014677\n",
      "step:   143140, time: 0.403, loss: 0.014462\n",
      "step:   143160, time: 0.404, loss: 0.016306\n",
      "step:   143180, time: 0.432, loss: 0.017917\n",
      "step:   143200, time: 0.421, loss: 0.014673\n",
      "step:   143220, time: 0.383, loss: 0.022887\n",
      "step:   143240, time: 0.405, loss: 0.010488\n",
      "step:   143260, time: 0.416, loss: 0.014794\n",
      "step:   143280, time: 0.384, loss: 0.014348\n",
      "step:   143300, time: 0.408, loss: 0.012481\n",
      "step:   143320, time: 0.396, loss: 0.012853\n",
      "step:   143340, time: 0.398, loss: 0.011243\n",
      "step:   143360, time: 0.415, loss: 0.013619\n",
      "step:   143380, time: 0.399, loss: 0.003033\n",
      "step:   143400, time: 0.411, loss: 0.015525\n",
      "step:   143420, time: 0.405, loss: 0.018314\n",
      "step:   143440, time: 0.411, loss: 0.005703\n",
      "step:   143460, time: 0.369, loss: 0.011292\n",
      "step:   143480, time: 0.422, loss: 0.024071\n",
      "step:   143500, time: 0.398, loss: 0.022129\n",
      "step:   143520, time: 0.393, loss: 0.018353\n",
      "step:   143540, time: 0.385, loss: 0.025800\n",
      "step:   143560, time: 0.431, loss: 0.013192\n",
      "step:   143580, time: 0.403, loss: 0.009665\n",
      "step:   143600, time: 0.425, loss: 0.018433\n",
      "step:   143620, time: 0.372, loss: 0.007632\n",
      "step:   143640, time: 0.392, loss: 0.019258\n",
      "step:   143660, time: 0.392, loss: 0.021433\n",
      "step:   143680, time: 0.387, loss: 0.011077\n",
      "step:   143700, time: 0.384, loss: 0.020307\n",
      "step:   143720, time: 0.412, loss: 0.017973\n",
      "step:   143740, time: 0.418, loss: 0.010672\n",
      "step:   143760, time: 0.418, loss: 0.018412\n",
      "step:   143780, time: 0.402, loss: 0.013583\n",
      "step:   143800, time: 0.406, loss: 0.016119\n",
      "step:   143820, time: 0.420, loss: 0.013426\n",
      "step:   143840, time: 0.386, loss: 0.010720\n",
      "step:   143860, time: 0.429, loss: 0.016424\n",
      "step:   143880, time: 0.378, loss: 0.010189\n",
      "step:   143900, time: 0.407, loss: 0.022611\n",
      "step:   143920, time: 0.384, loss: 0.015096\n",
      "step:   143940, time: 0.420, loss: 0.019273\n",
      "step:   143960, time: 0.412, loss: 0.108259\n",
      "step:   143980, time: 0.393, loss: 0.015812\n",
      "step:   144000, time: 0.438, loss: 0.009811\n",
      "step:   144020, time: 0.370, loss: 0.007294\n",
      "step:   144040, time: 0.416, loss: 0.018774\n",
      "step:   144060, time: 0.397, loss: 0.016521\n",
      "step:   144080, time: 0.388, loss: 0.011227\n",
      "step:   144100, time: 0.391, loss: 0.009900\n",
      "step:   144120, time: 0.393, loss: 0.010468\n",
      "step:   144140, time: 0.401, loss: 0.022504\n",
      "step:   144160, time: 0.386, loss: 0.015822\n",
      "step:   144180, time: 0.400, loss: 0.017852\n",
      "step:   144200, time: 0.400, loss: 0.018059\n",
      "step:   144220, time: 0.403, loss: 0.016090\n",
      "step:   144240, time: 0.416, loss: 0.021136\n",
      "step:   144260, time: 0.373, loss: 0.013997\n",
      "step:   144280, time: 0.388, loss: 0.006436\n",
      "step:   144300, time: 0.394, loss: 0.012664\n",
      "step:   144320, time: 0.363, loss: 0.009212\n",
      "step:   144340, time: 0.401, loss: 0.011355\n",
      "step:   144360, time: 0.400, loss: 0.016080\n",
      "step:   144380, time: 0.441, loss: 0.016726\n",
      "step:   144400, time: 0.381, loss: 0.012024\n",
      "step:   144420, time: 0.382, loss: 0.016661\n",
      "step:   144440, time: 0.417, loss: 0.106609\n",
      "step:   144460, time: 0.416, loss: 0.011679\n",
      "step:   144480, time: 0.414, loss: 0.018739\n",
      "step:   144500, time: 0.423, loss: 0.011876\n",
      "step:   144520, time: 0.412, loss: 0.011852\n",
      "step:   144540, time: 0.382, loss: 0.004174\n",
      "step:   144560, time: 0.416, loss: 0.013800\n",
      "step:   144580, time: 0.376, loss: 0.003139\n",
      "step:   144600, time: 0.408, loss: 0.010975\n",
      "step:   144620, time: 0.413, loss: 0.017055\n",
      "step:   144640, time: 0.417, loss: 0.018301\n",
      "step:   144660, time: 0.410, loss: 0.017298\n",
      "step:   144680, time: 0.400, loss: 0.020613\n",
      "step:   144700, time: 0.381, loss: 0.013703\n",
      "step:   144720, time: 0.408, loss: 0.013621\n",
      "step:   144740, time: 0.416, loss: 0.003157\n",
      "step:   144760, time: 0.375, loss: 0.014848\n",
      "step:   144780, time: 0.405, loss: 0.016487\n",
      "step:   144800, time: 0.399, loss: 0.015268\n",
      "step:   144820, time: 0.411, loss: 0.014665\n",
      "step:   144840, time: 0.384, loss: 0.007883\n",
      "step:   144860, time: 0.391, loss: 0.015445\n",
      "step:   144880, time: 0.396, loss: 0.018740\n",
      "step:   144900, time: 0.385, loss: 0.009903\n",
      "step:   144920, time: 0.386, loss: 0.006533\n",
      "step:   144940, time: 0.394, loss: 0.011884\n",
      "step:   144960, time: 0.402, loss: 0.008704\n",
      "step:   144980, time: 0.390, loss: 0.007733\n",
      "step:   145000, time: 0.368, loss: 0.002939\n",
      "step:   145020, time: 0.411, loss: 0.012390\n",
      "step:   145040, time: 0.414, loss: 0.015128\n",
      "step:   145060, time: 0.385, loss: 0.010635\n",
      "step:   145080, time: 0.400, loss: 0.006545\n",
      "step:   145100, time: 0.387, loss: 0.013822\n",
      "step:   145120, time: 0.433, loss: 0.018294\n",
      "step:   145140, time: 0.401, loss: 0.008302\n",
      "step:   145160, time: 0.405, loss: 0.008593\n",
      "step:   145180, time: 0.395, loss: 0.011084\n",
      "step:   145200, time: 0.376, loss: 0.019202\n",
      "step:   145220, time: 0.416, loss: 0.013827\n",
      "step:   145240, time: 0.382, loss: 0.017976\n",
      "step:   145260, time: 0.406, loss: 0.003484\n",
      "step:   145280, time: 0.387, loss: 0.014177\n",
      "step:   145300, time: 0.409, loss: 0.002843\n",
      "step:   145320, time: 0.409, loss: 0.013393\n",
      "step:   145340, time: 0.378, loss: 0.013565\n",
      "step:   145360, time: 0.416, loss: 0.014993\n",
      "step:   145380, time: 0.375, loss: 0.012420\n",
      "step:   145400, time: 0.379, loss: 0.008304\n",
      "step:   145420, time: 0.422, loss: 0.019535\n",
      "step:   145440, time: 0.406, loss: 0.013804\n",
      "step:   145460, time: 0.401, loss: 0.019262\n",
      "step:   145480, time: 0.401, loss: 0.017115\n",
      "step:   145500, time: 0.414, loss: 0.015639\n",
      "step:   145520, time: 0.399, loss: 0.019148\n",
      "step:   145540, time: 0.390, loss: 0.013252\n",
      "step:   145560, time: 0.424, loss: 0.018704\n",
      "step:   145580, time: 0.398, loss: 0.014755\n",
      "step:   145600, time: 0.414, loss: 0.019484\n",
      "step:   145620, time: 0.434, loss: 0.013202\n",
      "step:   145640, time: 0.411, loss: 0.017942\n",
      "step:   145660, time: 0.419, loss: 0.008316\n",
      "step:   145680, time: 0.417, loss: 0.012554\n",
      "step:   145700, time: 0.411, loss: 0.007164\n",
      "step:   145720, time: 0.418, loss: 0.015191\n",
      "step:   145740, time: 0.434, loss: 0.019181\n",
      "step:   145760, time: 0.442, loss: 0.011447\n",
      "step:   145780, time: 0.436, loss: 0.008114\n",
      "step:   145800, time: 0.426, loss: 0.014531\n",
      "step:   145820, time: 0.402, loss: 0.010431\n",
      "step:   145840, time: 0.418, loss: 0.016209\n",
      "step:   145860, time: 0.470, loss: 0.017791\n",
      "step:   145880, time: 0.401, loss: 0.010188\n",
      "step:   145900, time: 0.390, loss: 0.016516\n",
      "step:   145920, time: 0.413, loss: 0.017828\n",
      "step:   145940, time: 0.423, loss: 0.024233\n",
      "step:   145960, time: 0.414, loss: 0.022811\n",
      "step:   145980, time: 0.416, loss: 0.019519\n",
      "step:   146000, time: 0.396, loss: 0.010723\n",
      "step:   146020, time: 0.402, loss: 0.005266\n",
      "step:   146040, time: 0.396, loss: 0.008773\n",
      "step:   146060, time: 0.374, loss: 0.011108\n",
      "step:   146080, time: 0.399, loss: 0.012549\n",
      "step:   146100, time: 0.433, loss: 0.016770\n",
      "step:   146120, time: 0.416, loss: 0.004832\n",
      "step:   146140, time: 0.396, loss: 0.012244\n",
      "step:   146160, time: 0.406, loss: 0.016455\n",
      "step:   146180, time: 0.392, loss: 0.006844\n",
      "step:   146200, time: 0.410, loss: 0.013803\n",
      "step:   146220, time: 0.410, loss: 0.020919\n",
      "step:   146240, time: 0.390, loss: 0.015055\n",
      "step:   146260, time: 0.381, loss: 0.007399\n",
      "step:   146280, time: 0.386, loss: 0.011049\n",
      "step:   146300, time: 0.412, loss: 0.011592\n",
      "step:   146320, time: 0.435, loss: 0.015283\n",
      "step:   146340, time: 0.393, loss: 0.008363\n",
      "step:   146360, time: 0.414, loss: 0.015126\n",
      "step:   146380, time: 0.420, loss: 0.112502\n",
      "step:   146400, time: 0.391, loss: 0.011209\n",
      "step:   146420, time: 0.391, loss: 0.013889\n",
      "step:   146440, time: 0.384, loss: 0.017644\n",
      "step:   146460, time: 0.410, loss: 0.019984\n",
      "step:   146480, time: 0.408, loss: 0.009827\n",
      "step:   146500, time: 0.410, loss: 0.013671\n",
      "step:   146520, time: 0.397, loss: 0.020526\n",
      "step:   146540, time: 0.402, loss: 0.009259\n",
      "step:   146560, time: 0.390, loss: 0.016580\n",
      "step:   146580, time: 0.386, loss: 0.006608\n",
      "step:   146600, time: 0.390, loss: 0.023949\n",
      "step:   146620, time: 0.449, loss: 0.171545\n",
      "step:   146640, time: 0.396, loss: 0.013749\n",
      "step:   146660, time: 0.412, loss: 0.012007\n",
      "step:   146680, time: 0.414, loss: 0.009835\n",
      "step:   146700, time: 0.398, loss: 0.021527\n",
      "step:   146720, time: 0.395, loss: 0.014285\n",
      "step:   146740, time: 0.407, loss: 0.020098\n",
      "step:   146760, time: 0.383, loss: 0.011744\n",
      "step:   146780, time: 0.428, loss: 0.013779\n",
      "step:   146800, time: 0.395, loss: 0.017149\n",
      "step:   146820, time: 0.389, loss: 0.003985\n",
      "step:   146840, time: 0.392, loss: 0.016683\n",
      "step:   146860, time: 0.398, loss: 0.010860\n",
      "step:   146880, time: 0.396, loss: 0.004893\n",
      "step:   146900, time: 0.382, loss: 0.019007\n",
      "step:   146920, time: 0.420, loss: 0.015358\n",
      "step:   146940, time: 0.393, loss: 0.014985\n",
      "step:   146960, time: 0.408, loss: 0.011122\n",
      "step:   146980, time: 0.405, loss: 0.009100\n",
      "step:   147000, time: 0.410, loss: 0.018556\n",
      "step:   147020, time: 0.384, loss: 0.010935\n",
      "step:   147040, time: 0.379, loss: 0.014726\n",
      "step:   147060, time: 0.407, loss: 0.016231\n",
      "step:   147080, time: 0.407, loss: 0.014372\n",
      "step:   147100, time: 0.399, loss: 0.012199\n",
      "step:   147120, time: 0.386, loss: 0.022281\n",
      "step:   147140, time: 0.387, loss: 0.002612\n",
      "step:   147160, time: 0.389, loss: 0.012025\n",
      "step:   147180, time: 0.370, loss: 0.018127\n",
      "step:   147200, time: 0.384, loss: 0.011033\n",
      "step:   147220, time: 0.400, loss: 0.019849\n",
      "step:   147240, time: 0.451, loss: 0.011775\n",
      "step:   147260, time: 0.416, loss: 0.024895\n",
      "step:   147280, time: 0.402, loss: 0.006318\n",
      "step:   147300, time: 0.400, loss: 0.014132\n",
      "step:   147320, time: 0.395, loss: 0.014660\n",
      "step:   147340, time: 0.400, loss: 0.014541\n",
      "step:   147360, time: 0.413, loss: 0.025515\n",
      "step:   147380, time: 0.431, loss: 0.011116\n",
      "step:   147400, time: 0.427, loss: 0.048750\n",
      "step:   147420, time: 0.429, loss: 0.014058\n",
      "step:   147440, time: 0.381, loss: 0.018539\n",
      "step:   147460, time: 0.421, loss: 0.020290\n",
      "step:   147480, time: 0.366, loss: 0.016874\n",
      "step:   147500, time: 0.399, loss: 0.009348\n",
      "step:   147520, time: 0.396, loss: 0.011931\n",
      "step:   147540, time: 0.412, loss: 0.016559\n",
      "step:   147560, time: 0.384, loss: 0.023360\n",
      "step:   147580, time: 0.407, loss: 0.016386\n",
      "step:   147600, time: 0.407, loss: 0.009327\n",
      "step:   147620, time: 0.400, loss: 0.018240\n",
      "step:   147640, time: 0.391, loss: 0.011898\n",
      "step:   147660, time: 0.386, loss: 0.011611\n",
      "step:   147680, time: 0.402, loss: 0.015676\n",
      "step:   147700, time: 0.399, loss: 0.019108\n",
      "step:   147720, time: 0.390, loss: 0.008174\n",
      "step:   147740, time: 0.423, loss: 0.021688\n",
      "step:   147760, time: 0.407, loss: 0.026876\n",
      "step:   147780, time: 0.384, loss: 0.018577\n",
      "step:   147800, time: 0.395, loss: 0.014424\n",
      "step:   147820, time: 0.416, loss: 0.015703\n",
      "step:   147840, time: 0.396, loss: 0.007077\n",
      "step:   147860, time: 0.376, loss: 0.014421\n",
      "step:   147880, time: 0.422, loss: 0.019169\n",
      "step:   147900, time: 0.416, loss: 0.013816\n",
      "step:   147920, time: 0.386, loss: 0.014073\n",
      "step:   147940, time: 0.398, loss: 0.009205\n",
      "step:   147960, time: 0.428, loss: 0.019740\n",
      "step:   147980, time: 0.399, loss: 0.017591\n",
      "step:   148000, time: 0.375, loss: 0.012504\n",
      "step:   148020, time: 0.402, loss: 0.011040\n",
      "step:   148040, time: 0.418, loss: 0.012622\n",
      "step:   148060, time: 0.399, loss: 0.011494\n",
      "step:   148080, time: 0.431, loss: 0.015136\n",
      "step:   148100, time: 0.395, loss: 0.012713\n",
      "step:   148120, time: 0.394, loss: 0.009665\n",
      "step:   148140, time: 0.387, loss: 0.012550\n",
      "step:   148160, time: 0.421, loss: 0.008580\n",
      "step:   148180, time: 0.393, loss: 0.005910\n",
      "step:   148200, time: 0.419, loss: 0.022237\n",
      "step:   148220, time: 0.377, loss: 0.018431\n",
      "step:   148240, time: 0.384, loss: 0.020910\n",
      "step:   148260, time: 0.401, loss: 0.007812\n",
      "step:   148280, time: 0.417, loss: 0.009827\n",
      "step:   148300, time: 0.386, loss: 0.020481\n",
      "step:   148320, time: 0.413, loss: 0.012082\n",
      "step:   148340, time: 0.404, loss: 0.015982\n",
      "step:   148360, time: 0.381, loss: 0.016916\n",
      "step:   148380, time: 0.368, loss: 0.014574\n",
      "step:   148400, time: 0.410, loss: 0.012565\n",
      "step:   148420, time: 0.432, loss: 0.014458\n",
      "step:   148440, time: 0.402, loss: 0.014154\n",
      "step:   148460, time: 0.400, loss: 0.013561\n",
      "step:   148480, time: 0.404, loss: 0.009216\n",
      "step:   148500, time: 0.391, loss: 0.011591\n",
      "step:   148520, time: 0.411, loss: 0.008266\n",
      "step:   148540, time: 0.393, loss: 0.008341\n",
      "step:   148560, time: 0.393, loss: 0.020085\n",
      "step:   148580, time: 0.377, loss: 0.022170\n",
      "step:   148600, time: 0.393, loss: 0.018479\n",
      "step:   148620, time: 0.427, loss: 0.012928\n",
      "step:   148640, time: 0.421, loss: 0.017439\n",
      "step:   148660, time: 0.396, loss: 0.010772\n",
      "step:   148680, time: 0.407, loss: 0.022606\n",
      "step:   148700, time: 0.414, loss: 0.016642\n",
      "step:   148720, time: 0.415, loss: 0.011564\n",
      "step:   148740, time: 0.392, loss: 0.012283\n",
      "step:   148760, time: 0.433, loss: 0.016400\n",
      "step:   148780, time: 0.395, loss: 0.016594\n",
      "step:   148800, time: 0.377, loss: 0.018133\n",
      "step:   148820, time: 0.405, loss: 0.012120\n",
      "step:   148840, time: 0.415, loss: 0.018026\n",
      "step:   148860, time: 0.395, loss: 0.017154\n",
      "step:   148880, time: 0.426, loss: 0.010107\n",
      "step:   148900, time: 0.396, loss: 0.019592\n",
      "step:   148920, time: 0.419, loss: 0.013161\n",
      "step:   148940, time: 0.380, loss: 0.010478\n",
      "step:   148960, time: 0.411, loss: 0.015723\n",
      "step:   148980, time: 0.418, loss: 0.018248\n",
      "step:   149000, time: 0.410, loss: 0.015743\n",
      "step:   149020, time: 0.414, loss: 0.018140\n",
      "step:   149040, time: 0.402, loss: 0.013783\n",
      "step:   149060, time: 0.436, loss: 0.019469\n",
      "step:   149080, time: 0.432, loss: 0.007807\n",
      "step:   149100, time: 0.408, loss: 0.020561\n",
      "step:   149120, time: 0.398, loss: 0.018691\n",
      "step:   149140, time: 0.412, loss: 0.013739\n",
      "step:   149160, time: 0.392, loss: 0.015827\n",
      "step:   149180, time: 0.389, loss: 0.011854\n",
      "step:   149200, time: 0.395, loss: 0.028405\n",
      "step:   149220, time: 0.381, loss: 0.013255\n",
      "step:   149240, time: 0.405, loss: 0.014847\n",
      "step:   149260, time: 0.406, loss: 0.009994\n",
      "step:   149280, time: 0.412, loss: 0.010082\n",
      "step:   149300, time: 0.410, loss: 0.010816\n",
      "step:   149320, time: 0.405, loss: 0.014330\n",
      "step:   149340, time: 0.371, loss: 0.009594\n",
      "step:   149360, time: 0.416, loss: 0.023096\n",
      "step:   149380, time: 0.405, loss: 0.019003\n",
      "step:   149400, time: 0.428, loss: 0.015976\n",
      "step:   149420, time: 0.375, loss: 0.009415\n",
      "step:   149440, time: 0.382, loss: 0.015736\n",
      "step:   149460, time: 0.376, loss: 0.009300\n",
      "step:   149480, time: 0.427, loss: 0.014023\n",
      "step:   149500, time: 0.406, loss: 0.019589\n",
      "step:   149520, time: 0.392, loss: 0.017579\n",
      "step:   149540, time: 0.404, loss: 0.008611\n",
      "step:   149560, time: 0.403, loss: 0.016789\n",
      "step:   149580, time: 0.401, loss: 0.013590\n",
      "step:   149600, time: 0.423, loss: 0.016583\n",
      "step:   149620, time: 0.398, loss: 0.012818\n",
      "step:   149640, time: 0.384, loss: 0.017444\n",
      "step:   149660, time: 0.403, loss: 0.006562\n",
      "step:   149680, time: 0.406, loss: 0.016733\n",
      "step:   149700, time: 0.368, loss: 0.019436\n",
      "step:   149720, time: 0.414, loss: 0.015344\n",
      "step:   149740, time: 0.413, loss: 0.010510\n",
      "step:   149760, time: 0.405, loss: 0.023493\n",
      "step:   149780, time: 0.404, loss: 0.010629\n",
      "step:   149800, time: 0.389, loss: 0.011723\n",
      "step:   149820, time: 0.385, loss: 0.008068\n",
      "step:   149840, time: 0.412, loss: 0.009737\n",
      "step:   149860, time: 0.427, loss: 0.011931\n",
      "step:   149880, time: 0.403, loss: 0.014559\n",
      "step:   149900, time: 0.393, loss: 0.011546\n",
      "step:   149920, time: 0.448, loss: 0.006233\n",
      "step:   149940, time: 0.402, loss: 0.012738\n",
      "step:   149960, time: 0.397, loss: 0.015831\n",
      "step:   149980, time: 0.402, loss: 0.014371\n",
      "step:   150000, time: 0.377, loss: 0.015348\n",
      "step:   150020, time: 0.416, loss: 0.014874\n",
      "step:   150040, time: 0.401, loss: 0.010731\n",
      "step:   150060, time: 0.403, loss: 0.012531\n",
      "step:   150080, time: 0.369, loss: 0.012629\n",
      "step:   150100, time: 0.410, loss: 0.013670\n",
      "step:   150120, time: 0.416, loss: 0.011688\n",
      "step:   150140, time: 0.381, loss: 0.024156\n",
      "step:   150160, time: 0.372, loss: 0.012578\n",
      "step:   150180, time: 0.404, loss: 0.018369\n",
      "step:   150200, time: 0.445, loss: 0.127112\n",
      "step:   150220, time: 0.425, loss: 0.023063\n",
      "step:   150240, time: 0.403, loss: 0.011213\n",
      "step:   150260, time: 0.380, loss: 0.008424\n",
      "step:   150280, time: 0.444, loss: 0.020736\n",
      "step:   150300, time: 0.397, loss: 0.010805\n",
      "step:   150320, time: 0.393, loss: 0.018776\n",
      "step:   150340, time: 0.377, loss: 0.026255\n",
      "step:   150360, time: 0.449, loss: 0.120766\n",
      "step:   150380, time: 0.380, loss: 0.014567\n",
      "step:   150400, time: 0.422, loss: 0.007475\n",
      "step:   150420, time: 0.373, loss: 0.013833\n",
      "step:   150440, time: 0.415, loss: 0.016008\n",
      "step:   150460, time: 0.392, loss: 0.015476\n",
      "step:   150480, time: 0.395, loss: 0.013894\n",
      "step:   150500, time: 0.416, loss: 0.016301\n",
      "step:   150520, time: 0.406, loss: 0.021661\n",
      "step:   150540, time: 0.419, loss: 0.019813\n",
      "step:   150560, time: 0.421, loss: 0.012182\n",
      "step:   150580, time: 0.420, loss: 0.013896\n",
      "step:   150600, time: 0.405, loss: 0.009719\n",
      "step:   150620, time: 0.411, loss: 0.019760\n",
      "step:   150640, time: 0.413, loss: 0.017267\n",
      "step:   150660, time: 0.408, loss: 0.016273\n",
      "step:   150680, time: 0.396, loss: 0.011424\n",
      "step:   150700, time: 0.415, loss: 0.152859\n",
      "step:   150720, time: 0.419, loss: 0.015062\n",
      "step:   150740, time: 0.396, loss: 0.017796\n",
      "step:   150760, time: 0.380, loss: 0.016793\n",
      "step:   150780, time: 0.400, loss: 0.018751\n",
      "step:   150800, time: 0.433, loss: 0.029016\n",
      "step:   150820, time: 0.389, loss: 0.022746\n",
      "step:   150840, time: 0.448, loss: 0.023801\n",
      "step:   150860, time: 0.389, loss: 0.014753\n",
      "step:   150880, time: 0.406, loss: 0.009416\n",
      "step:   150900, time: 0.393, loss: 0.003013\n",
      "step:   150920, time: 0.374, loss: 0.012241\n",
      "step:   150940, time: 0.387, loss: 0.011312\n",
      "step:   150960, time: 0.390, loss: 0.013308\n",
      "step:   150980, time: 0.416, loss: 0.168483\n",
      "step:   151000, time: 0.385, loss: 0.024798\n",
      "step:   151020, time: 0.411, loss: 0.008693\n",
      "step:   151040, time: 0.378, loss: 0.024639\n",
      "step:   151060, time: 0.397, loss: 0.012705\n",
      "step:   151080, time: 0.372, loss: 0.020135\n",
      "step:   151100, time: 0.389, loss: 0.017772\n",
      "step:   151120, time: 0.397, loss: 0.014089\n",
      "step:   151140, time: 0.385, loss: 0.015046\n",
      "step:   151160, time: 0.425, loss: 0.012369\n",
      "step:   151180, time: 0.386, loss: 0.017626\n",
      "step:   151200, time: 0.415, loss: 0.020081\n",
      "step:   151220, time: 0.405, loss: 0.011810\n",
      "step:   151240, time: 0.408, loss: 0.019100\n",
      "step:   151260, time: 0.425, loss: 0.015612\n",
      "step:   151280, time: 0.419, loss: 0.022944\n",
      "step:   151300, time: 0.366, loss: 0.015155\n",
      "step:   151320, time: 0.425, loss: 0.016153\n",
      "step:   151340, time: 0.386, loss: 0.010697\n",
      "step:   151360, time: 0.402, loss: 0.008632\n",
      "step:   151380, time: 0.410, loss: 0.014488\n",
      "step:   151400, time: 0.389, loss: 0.018094\n",
      "step:   151420, time: 0.410, loss: 0.015658\n",
      "step:   151440, time: 0.397, loss: 0.006240\n",
      "step:   151460, time: 0.387, loss: 0.013224\n",
      "step:   151480, time: 0.390, loss: 0.019388\n",
      "step:   151500, time: 0.393, loss: 0.014101\n",
      "step:   151520, time: 0.408, loss: 0.017716\n",
      "step:   151540, time: 0.385, loss: 0.011849\n",
      "step:   151560, time: 0.385, loss: 0.015264\n",
      "step:   151580, time: 0.431, loss: 0.013246\n",
      "step:   151600, time: 0.401, loss: 0.012538\n",
      "step:   151620, time: 0.408, loss: 0.014429\n",
      "step:   151640, time: 0.378, loss: 0.014342\n",
      "step:   151660, time: 0.400, loss: 0.008080\n",
      "step:   151680, time: 0.393, loss: 0.014457\n",
      "step:   151700, time: 0.383, loss: 0.012237\n",
      "step:   151720, time: 0.397, loss: 0.015311\n",
      "step:   151740, time: 0.388, loss: 0.010431\n",
      "step:   151760, time: 0.417, loss: 0.016338\n",
      "step:   151780, time: 0.391, loss: 0.079864\n",
      "step:   151800, time: 0.378, loss: 0.017295\n",
      "step:   151820, time: 0.396, loss: 0.003689\n",
      "step:   151840, time: 0.387, loss: 0.017192\n",
      "step:   151860, time: 0.402, loss: 0.014877\n",
      "step:   151880, time: 0.423, loss: 0.014648\n",
      "step:   151900, time: 0.397, loss: 0.014034\n",
      "step:   151920, time: 0.394, loss: 0.008651\n",
      "step:   151940, time: 0.426, loss: 0.019699\n",
      "step:   151960, time: 0.387, loss: 0.012970\n",
      "step:   151980, time: 0.390, loss: 0.016983\n",
      "step:   152000, time: 0.404, loss: 0.020666\n",
      "step:   152020, time: 0.394, loss: 0.012159\n",
      "step:   152040, time: 0.402, loss: 0.021316\n",
      "step:   152060, time: 0.411, loss: 0.023849\n",
      "step:   152080, time: 0.406, loss: 0.013423\n",
      "step:   152100, time: 0.382, loss: 0.006820\n",
      "step:   152120, time: 0.414, loss: 0.015327\n",
      "step:   152140, time: 0.418, loss: 0.013445\n",
      "step:   152160, time: 0.427, loss: 0.016228\n",
      "step:   152180, time: 0.408, loss: 0.018854\n",
      "step:   152200, time: 0.408, loss: 0.018836\n",
      "step:   152220, time: 0.396, loss: 0.006477\n",
      "step:   152240, time: 0.395, loss: 0.016122\n",
      "step:   152260, time: 0.405, loss: 0.017576\n",
      "step:   152280, time: 0.384, loss: 0.014057\n",
      "step:   152300, time: 0.415, loss: 0.010681\n",
      "step:   152320, time: 0.379, loss: 0.017692\n",
      "step:   152340, time: 0.419, loss: 0.023934\n",
      "step:   152360, time: 0.403, loss: 0.017885\n",
      "step:   152380, time: 0.382, loss: 0.016540\n",
      "step:   152400, time: 0.379, loss: 0.013705\n",
      "step:   152420, time: 0.414, loss: 0.015914\n",
      "step:   152440, time: 0.390, loss: 0.010689\n",
      "step:   152460, time: 0.404, loss: 0.010871\n",
      "step:   152480, time: 0.414, loss: 0.013807\n",
      "step:   152500, time: 0.431, loss: 0.016257\n",
      "step:   152520, time: 0.405, loss: 0.018273\n",
      "step:   152540, time: 0.438, loss: 0.019442\n",
      "step:   152560, time: 0.383, loss: 0.013063\n",
      "step:   152580, time: 0.391, loss: 0.007356\n",
      "step:   152600, time: 0.393, loss: 0.008934\n",
      "step:   152620, time: 0.418, loss: 0.010476\n",
      "step:   152640, time: 0.431, loss: 0.019165\n",
      "step:   152660, time: 0.391, loss: 0.011533\n",
      "step:   152680, time: 0.427, loss: 0.011135\n",
      "step:   152700, time: 0.413, loss: 0.015037\n",
      "step:   152720, time: 0.405, loss: 0.019258\n",
      "step:   152740, time: 0.421, loss: 0.020564\n",
      "step:   152760, time: 0.393, loss: 0.015108\n",
      "step:   152780, time: 0.398, loss: 0.019554\n",
      "step:   152800, time: 0.388, loss: 0.018887\n",
      "step:   152820, time: 0.435, loss: 0.018163\n",
      "step:   152840, time: 0.397, loss: 0.013885\n",
      "step:   152860, time: 0.431, loss: 0.010323\n",
      "step:   152880, time: 0.390, loss: 0.014114\n",
      "step:   152900, time: 0.395, loss: 0.013906\n",
      "step:   152920, time: 0.400, loss: 0.163920\n",
      "step:   152940, time: 0.383, loss: 0.025066\n",
      "step:   152960, time: 0.446, loss: 0.019220\n",
      "step:   152980, time: 0.425, loss: 0.169805\n",
      "step:   153000, time: 0.390, loss: 0.013373\n",
      "step:   153020, time: 0.389, loss: 0.020017\n",
      "step:   153040, time: 0.393, loss: 0.015080\n",
      "step:   153060, time: 0.398, loss: 0.025939\n",
      "step:   153080, time: 0.402, loss: 0.016035\n",
      "step:   153100, time: 0.426, loss: 0.013288\n",
      "step:   153120, time: 0.378, loss: 0.010583\n",
      "step:   153140, time: 0.410, loss: 0.118880\n",
      "step:   153160, time: 0.419, loss: 0.017112\n",
      "step:   153180, time: 0.416, loss: 0.018013\n",
      "step:   153200, time: 0.408, loss: 0.009253\n",
      "step:   153220, time: 0.404, loss: 0.012371\n",
      "step:   153240, time: 0.412, loss: 0.018024\n",
      "step:   153260, time: 0.378, loss: 0.015722\n",
      "step:   153280, time: 0.384, loss: 0.014931\n",
      "step:   153300, time: 0.396, loss: 0.006677\n",
      "step:   153320, time: 0.419, loss: 0.013771\n",
      "step:   153340, time: 0.444, loss: 0.018643\n",
      "step:   153360, time: 0.407, loss: 0.015387\n",
      "step:   153380, time: 0.421, loss: 0.022079\n",
      "step:   153400, time: 0.395, loss: 0.009693\n",
      "step:   153420, time: 0.360, loss: 0.012463\n",
      "step:   153440, time: 0.404, loss: 0.016198\n",
      "step:   153460, time: 0.387, loss: 0.015191\n",
      "step:   153480, time: 0.389, loss: 0.009766\n",
      "step:   153500, time: 0.418, loss: 0.016623\n",
      "step:   153520, time: 0.415, loss: 0.011584\n",
      "step:   153540, time: 0.379, loss: 0.013269\n",
      "step:   153560, time: 0.390, loss: 0.017845\n",
      "step:   153580, time: 0.412, loss: 0.007907\n",
      "step:   153600, time: 0.397, loss: 0.008850\n",
      "step:   153620, time: 0.404, loss: 0.014990\n",
      "step:   153640, time: 0.397, loss: 0.021064\n",
      "step:   153660, time: 0.401, loss: 0.015991\n",
      "step:   153680, time: 0.399, loss: 0.020667\n",
      "step:   153700, time: 0.406, loss: 0.018706\n",
      "step:   153720, time: 0.398, loss: 0.013699\n",
      "step:   153740, time: 0.414, loss: 0.018533\n",
      "step:   153760, time: 0.392, loss: 0.018365\n",
      "step:   153780, time: 0.388, loss: 0.016951\n",
      "step:   153800, time: 0.390, loss: 0.009103\n",
      "step:   153820, time: 0.406, loss: 0.013980\n",
      "step:   153840, time: 0.388, loss: 0.006869\n",
      "step:   153860, time: 0.388, loss: 0.011466\n",
      "step:   153880, time: 0.415, loss: 0.013587\n",
      "step:   153900, time: 0.402, loss: 0.009722\n",
      "step:   153920, time: 0.378, loss: 0.010968\n",
      "step:   153940, time: 0.404, loss: 0.013191\n",
      "step:   153960, time: 0.421, loss: 0.017932\n",
      "step:   153980, time: 0.344, loss: 0.013579\n",
      "step:   154000, time: 0.395, loss: 0.015037\n",
      "step:   154020, time: 0.379, loss: 0.021172\n",
      "step:   154040, time: 0.389, loss: 0.019741\n",
      "step:   154060, time: 0.399, loss: 0.018823\n",
      "step:   154080, time: 0.406, loss: 0.007409\n",
      "step:   154100, time: 0.409, loss: 0.017645\n",
      "step:   154120, time: 0.410, loss: 0.024451\n",
      "step:   154140, time: 0.384, loss: 0.022880\n",
      "step:   154160, time: 0.414, loss: 0.012093\n",
      "step:   154180, time: 0.404, loss: 0.010768\n",
      "step:   154200, time: 0.387, loss: 0.015085\n",
      "step:   154220, time: 0.398, loss: 0.019194\n",
      "step:   154240, time: 0.412, loss: 0.009691\n",
      "step:   154260, time: 0.451, loss: 0.010692\n",
      "step:   154280, time: 0.410, loss: 0.013301\n",
      "step:   154300, time: 0.392, loss: 0.013254\n",
      "step:   154320, time: 0.385, loss: 0.011704\n",
      "step:   154340, time: 0.390, loss: 0.011962\n",
      "step:   154360, time: 0.416, loss: 0.018490\n",
      "step:   154380, time: 0.394, loss: 0.011093\n",
      "step:   154400, time: 0.418, loss: 0.012718\n",
      "step:   154420, time: 0.383, loss: 0.004276\n",
      "step:   154440, time: 0.389, loss: 0.016235\n",
      "step:   154460, time: 0.426, loss: 0.015482\n",
      "step:   154480, time: 0.429, loss: 0.032356\n",
      "step:   154500, time: 0.388, loss: 0.017272\n",
      "step:   154520, time: 0.396, loss: 0.012843\n",
      "step:   154540, time: 0.373, loss: 0.019225\n",
      "step:   154560, time: 0.387, loss: 0.015300\n",
      "step:   154580, time: 0.386, loss: 0.014667\n",
      "step:   154600, time: 0.397, loss: 0.022793\n",
      "step:   154620, time: 0.413, loss: 0.016361\n",
      "step:   154640, time: 0.403, loss: 0.017562\n",
      "step:   154660, time: 0.431, loss: 0.007360\n",
      "step:   154680, time: 0.402, loss: 0.014382\n",
      "step:   154700, time: 0.381, loss: 0.020031\n",
      "step:   154720, time: 0.404, loss: 0.009192\n",
      "step:   154740, time: 0.384, loss: 0.012699\n",
      "step:   154760, time: 0.379, loss: 0.016095\n",
      "step:   154780, time: 0.387, loss: 0.013128\n",
      "step:   154800, time: 0.374, loss: 0.013875\n",
      "step:   154820, time: 0.419, loss: 0.021952\n",
      "step:   154840, time: 0.405, loss: 0.010486\n",
      "step:   154860, time: 0.429, loss: 0.013724\n",
      "step:   154880, time: 0.381, loss: 0.018690\n",
      "step:   154900, time: 0.399, loss: 0.022241\n",
      "step:   154920, time: 0.397, loss: 0.006304\n",
      "step:   154940, time: 0.418, loss: 0.011666\n",
      "step:   154960, time: 0.386, loss: 0.012000\n",
      "step:   154980, time: 0.392, loss: 0.021162\n",
      "step:   155000, time: 0.430, loss: 0.010399\n",
      "step:   155020, time: 0.385, loss: 0.009774\n",
      "step:   155040, time: 0.410, loss: 0.011925\n",
      "step:   155060, time: 0.394, loss: 0.008177\n",
      "step:   155080, time: 0.378, loss: 0.014717\n",
      "step:   155100, time: 0.400, loss: 0.024435\n",
      "step:   155120, time: 0.396, loss: 0.018279\n",
      "step:   155140, time: 0.411, loss: 0.018334\n",
      "step:   155160, time: 0.393, loss: 0.012522\n",
      "step:   155180, time: 0.391, loss: 0.009654\n",
      "step:   155200, time: 0.415, loss: 0.010665\n",
      "step:   155220, time: 0.397, loss: 0.007212\n",
      "step:   155240, time: 0.381, loss: 0.015277\n",
      "step:   155260, time: 0.415, loss: 0.016508\n",
      "step:   155280, time: 0.385, loss: 0.018245\n",
      "step:   155300, time: 0.418, loss: 0.016308\n",
      "step:   155320, time: 0.406, loss: 0.016164\n",
      "step:   155340, time: 0.380, loss: 0.020791\n",
      "step:   155360, time: 0.376, loss: 0.013487\n",
      "step:   155380, time: 0.408, loss: 0.013216\n",
      "step:   155400, time: 0.384, loss: 0.015810\n",
      "step:   155420, time: 0.391, loss: 0.004195\n",
      "step:   155440, time: 0.396, loss: 0.013643\n",
      "step:   155460, time: 0.383, loss: 0.019404\n",
      "step:   155480, time: 0.402, loss: 0.010955\n",
      "step:   155500, time: 0.383, loss: 0.007792\n",
      "step:   155520, time: 0.395, loss: 0.019402\n",
      "step:   155540, time: 0.393, loss: 0.014894\n",
      "step:   155560, time: 0.448, loss: 0.021122\n",
      "step:   155580, time: 0.386, loss: 0.018560\n",
      "step:   155600, time: 0.459, loss: 0.020539\n",
      "step:   155620, time: 0.380, loss: 0.022278\n",
      "step:   155640, time: 0.401, loss: 0.012831\n",
      "step:   155660, time: 0.402, loss: 0.012724\n",
      "step:   155680, time: 0.408, loss: 0.022428\n",
      "step:   155700, time: 0.393, loss: 0.014967\n",
      "step:   155720, time: 0.416, loss: 0.010214\n",
      "step:   155740, time: 0.437, loss: 0.022709\n",
      "step:   155760, time: 0.423, loss: 0.017745\n",
      "step:   155780, time: 0.384, loss: 0.010316\n",
      "step:   155800, time: 0.384, loss: 0.019263\n",
      "step:   155820, time: 0.398, loss: 0.016255\n",
      "step:   155840, time: 0.413, loss: 0.017555\n",
      "step:   155860, time: 0.393, loss: 0.019781\n",
      "step:   155880, time: 0.401, loss: 0.021904\n",
      "step:   155900, time: 0.399, loss: 0.015853\n",
      "step:   155920, time: 0.413, loss: 0.007754\n",
      "step:   155940, time: 0.390, loss: 0.006910\n",
      "step:   155960, time: 0.395, loss: 0.013020\n",
      "step:   155980, time: 0.396, loss: 0.010613\n",
      "step:   156000, time: 0.383, loss: 0.025388\n",
      "step:   156020, time: 0.394, loss: 0.019683\n",
      "step:   156040, time: 0.388, loss: 0.006952\n",
      "step:   156060, time: 0.383, loss: 0.016171\n",
      "step:   156080, time: 0.399, loss: 0.012233\n",
      "step:   156100, time: 0.393, loss: 0.013589\n",
      "step:   156120, time: 0.385, loss: 0.008588\n",
      "step:   156140, time: 0.399, loss: 0.010375\n",
      "step:   156160, time: 0.405, loss: 0.017193\n",
      "step:   156180, time: 0.411, loss: 0.017266\n",
      "step:   156200, time: 0.409, loss: 0.018089\n",
      "step:   156220, time: 0.388, loss: 0.014572\n",
      "step:   156240, time: 0.409, loss: 0.021342\n",
      "step:   156260, time: 0.408, loss: 0.013092\n",
      "step:   156280, time: 0.435, loss: 0.011820\n",
      "step:   156300, time: 0.423, loss: 0.081929\n",
      "step:   156320, time: 0.401, loss: 0.018525\n",
      "step:   156340, time: 0.397, loss: 0.014870\n",
      "step:   156360, time: 0.425, loss: 0.022611\n",
      "step:   156380, time: 0.398, loss: 0.017601\n",
      "step:   156400, time: 0.394, loss: 0.005641\n",
      "step:   156420, time: 0.429, loss: 0.099235\n",
      "step:   156440, time: 0.389, loss: 0.019173\n",
      "step:   156460, time: 0.376, loss: 0.014645\n",
      "step:   156480, time: 0.397, loss: 0.009590\n",
      "step:   156500, time: 0.374, loss: 0.007801\n",
      "step:   156520, time: 0.402, loss: 0.009869\n",
      "step:   156540, time: 0.408, loss: 0.012412\n",
      "step:   156560, time: 0.402, loss: 0.022233\n",
      "step:   156580, time: 0.423, loss: 0.013632\n",
      "step:   156600, time: 0.434, loss: 0.022072\n",
      "step:   156620, time: 0.429, loss: 0.007535\n",
      "step:   156640, time: 0.395, loss: 0.015049\n",
      "step:   156660, time: 0.385, loss: 0.014857\n",
      "step:   156680, time: 0.399, loss: 0.014191\n",
      "step:   156700, time: 0.398, loss: 0.014084\n",
      "step:   156720, time: 0.401, loss: 0.008102\n",
      "step:   156740, time: 0.413, loss: 0.012727\n",
      "step:   156760, time: 0.409, loss: 0.015958\n",
      "step:   156780, time: 0.415, loss: 0.010936\n",
      "step:   156800, time: 0.399, loss: 0.024036\n",
      "step:   156820, time: 0.381, loss: 0.017923\n",
      "step:   156840, time: 0.404, loss: 0.018419\n",
      "step:   156860, time: 0.393, loss: 0.013312\n",
      "step:   156880, time: 0.393, loss: 0.014519\n",
      "step:   156900, time: 0.411, loss: 0.012837\n",
      "step:   156920, time: 0.406, loss: 0.021252\n",
      "step:   156940, time: 0.407, loss: 0.010328\n",
      "step:   156960, time: 0.389, loss: 0.007072\n",
      "step:   156980, time: 0.403, loss: 0.016244\n",
      "step:   157000, time: 0.401, loss: 0.023993\n",
      "step:   157020, time: 0.413, loss: 0.015007\n",
      "step:   157040, time: 0.408, loss: 0.018707\n",
      "step:   157060, time: 0.404, loss: 0.010817\n",
      "step:   157080, time: 0.376, loss: 0.009739\n",
      "step:   157100, time: 0.392, loss: 0.012011\n",
      "step:   157120, time: 0.384, loss: 0.002756\n",
      "step:   157140, time: 0.408, loss: 0.015699\n",
      "step:   157160, time: 0.375, loss: 0.019022\n",
      "step:   157180, time: 0.397, loss: 0.018550\n",
      "step:   157200, time: 0.392, loss: 0.022192\n",
      "step:   157220, time: 0.417, loss: 0.021599\n",
      "step:   157240, time: 0.404, loss: 0.004853\n",
      "step:   157260, time: 0.426, loss: 0.016277\n",
      "step:   157280, time: 0.420, loss: 0.018871\n",
      "step:   157300, time: 0.400, loss: 0.017160\n",
      "step:   157320, time: 0.433, loss: 0.019686\n",
      "step:   157340, time: 0.389, loss: 0.021040\n",
      "step:   157360, time: 0.391, loss: 0.014828\n",
      "step:   157380, time: 0.438, loss: 0.011050\n",
      "step:   157400, time: 0.401, loss: 0.020283\n",
      "step:   157420, time: 0.390, loss: 0.011651\n",
      "step:   157440, time: 0.409, loss: 0.021358\n",
      "step:   157460, time: 0.432, loss: 0.013155\n",
      "step:   157480, time: 0.381, loss: 0.009252\n",
      "step:   157500, time: 0.448, loss: 0.012021\n",
      "step:   157520, time: 0.417, loss: 0.010139\n",
      "step:   157540, time: 0.402, loss: 0.018756\n",
      "step:   157560, time: 0.390, loss: 0.007035\n",
      "step:   157580, time: 0.385, loss: 0.007829\n",
      "step:   157600, time: 0.378, loss: 0.021601\n",
      "step:   157620, time: 0.391, loss: 0.018606\n",
      "step:   157640, time: 0.403, loss: 0.013483\n",
      "step:   157660, time: 0.401, loss: 0.008410\n",
      "step:   157680, time: 0.411, loss: 0.014026\n",
      "step:   157700, time: 0.388, loss: 0.009899\n",
      "step:   157720, time: 0.401, loss: 0.014318\n",
      "step:   157740, time: 0.395, loss: 0.009688\n",
      "step:   157760, time: 0.413, loss: 0.016208\n",
      "step:   157780, time: 0.392, loss: 0.022266\n",
      "step:   157800, time: 0.367, loss: 0.008290\n",
      "step:   157820, time: 0.420, loss: 0.015276\n",
      "step:   157840, time: 0.404, loss: 0.013124\n",
      "step:   157860, time: 0.412, loss: 0.019994\n",
      "step:   157880, time: 0.404, loss: 0.013369\n",
      "step:   157900, time: 0.410, loss: 0.013127\n",
      "step:   157920, time: 0.428, loss: 0.013884\n",
      "step:   157940, time: 0.397, loss: 0.017521\n",
      "step:   157960, time: 0.387, loss: 0.017689\n",
      "step:   157980, time: 0.409, loss: 0.014798\n",
      "step:   158000, time: 0.380, loss: 0.010099\n",
      "step:   158020, time: 0.405, loss: 0.007941\n",
      "step:   158040, time: 0.401, loss: 0.014082\n",
      "step:   158060, time: 0.388, loss: 0.020503\n",
      "step:   158080, time: 0.393, loss: 0.010668\n",
      "step:   158100, time: 0.409, loss: 0.006706\n",
      "step:   158120, time: 0.416, loss: 0.008065\n",
      "step:   158140, time: 0.407, loss: 0.012954\n",
      "step:   158160, time: 0.390, loss: 0.015368\n",
      "step:   158180, time: 0.379, loss: 0.018367\n",
      "step:   158200, time: 0.393, loss: 0.020987\n",
      "step:   158220, time: 0.389, loss: 0.013425\n",
      "step:   158240, time: 0.437, loss: 0.009923\n",
      "step:   158260, time: 0.395, loss: 0.006162\n",
      "step:   158280, time: 0.404, loss: 0.014835\n",
      "step:   158300, time: 0.403, loss: 0.008356\n",
      "step:   158320, time: 0.389, loss: 0.009422\n",
      "step:   158340, time: 0.384, loss: 0.015359\n",
      "step:   158360, time: 0.431, loss: 0.019343\n",
      "step:   158380, time: 0.391, loss: 0.011144\n",
      "step:   158400, time: 0.384, loss: 0.016106\n",
      "step:   158420, time: 0.438, loss: 0.017927\n",
      "step:   158440, time: 0.387, loss: 0.017952\n",
      "step:   158460, time: 0.394, loss: 0.019619\n",
      "step:   158480, time: 0.389, loss: 0.014833\n",
      "step:   158500, time: 0.417, loss: 0.023238\n",
      "step:   158520, time: 0.405, loss: 0.011388\n",
      "step:   158540, time: 0.413, loss: 0.015763\n",
      "step:   158560, time: 0.415, loss: 0.024817\n",
      "step:   158580, time: 0.397, loss: 0.005450\n",
      "step:   158600, time: 0.406, loss: 0.017064\n",
      "step:   158620, time: 0.396, loss: 0.023732\n",
      "step:   158640, time: 0.399, loss: 0.021348\n",
      "step:   158660, time: 0.390, loss: 0.017410\n",
      "step:   158680, time: 0.406, loss: 0.015043\n",
      "step:   158700, time: 0.397, loss: 0.013625\n",
      "step:   158720, time: 0.391, loss: 0.018253\n",
      "step:   158740, time: 0.395, loss: 0.011770\n",
      "step:   158760, time: 0.383, loss: 0.009840\n",
      "step:   158780, time: 0.392, loss: 0.014486\n",
      "step:   158800, time: 0.388, loss: 0.010129\n",
      "step:   158820, time: 0.398, loss: 0.023249\n",
      "step:   158840, time: 0.400, loss: 0.018841\n",
      "step:   158860, time: 0.400, loss: 0.009157\n",
      "step:   158880, time: 0.389, loss: 0.012181\n",
      "step:   158900, time: 0.406, loss: 0.014395\n",
      "step:   158920, time: 0.405, loss: 0.010950\n",
      "step:   158940, time: 0.403, loss: 0.012865\n",
      "step:   158960, time: 0.389, loss: 0.016173\n",
      "step:   158980, time: 0.408, loss: 0.014792\n",
      "step:   159000, time: 0.413, loss: 0.008760\n",
      "step:   159020, time: 0.387, loss: 0.019491\n",
      "step:   159040, time: 0.422, loss: 0.012817\n",
      "step:   159060, time: 0.396, loss: 0.018524\n",
      "step:   159080, time: 0.400, loss: 0.015360\n",
      "step:   159100, time: 0.413, loss: 0.021780\n",
      "step:   159120, time: 0.385, loss: 0.014216\n",
      "step:   159140, time: 0.427, loss: 0.017469\n",
      "step:   159160, time: 0.435, loss: 0.012347\n",
      "step:   159180, time: 0.393, loss: 0.018009\n",
      "step:   159200, time: 0.419, loss: 0.014635\n",
      "step:   159220, time: 0.381, loss: 0.011962\n",
      "step:   159240, time: 0.445, loss: 0.016687\n",
      "step:   159260, time: 0.396, loss: 0.013161\n",
      "step:   159280, time: 0.410, loss: 0.016304\n",
      "step:   159300, time: 0.376, loss: 0.014754\n",
      "step:   159320, time: 0.373, loss: 0.009545\n",
      "step:   159340, time: 0.411, loss: 0.014634\n",
      "step:   159360, time: 0.386, loss: 0.003654\n",
      "step:   159380, time: 0.414, loss: 0.013955\n",
      "step:   159400, time: 0.430, loss: 0.009827\n",
      "step:   159420, time: 0.456, loss: 0.016311\n",
      "step:   159440, time: 0.402, loss: 0.014407\n",
      "step:   159460, time: 0.399, loss: 0.012140\n",
      "step:   159480, time: 0.425, loss: 0.014604\n",
      "step:   159500, time: 0.396, loss: 0.005259\n",
      "step:   159520, time: 0.434, loss: 0.018233\n",
      "step:   159540, time: 0.404, loss: 0.009661\n",
      "step:   159560, time: 0.397, loss: 0.009364\n",
      "step:   159580, time: 0.396, loss: 0.026378\n",
      "step:   159600, time: 0.389, loss: 0.013875\n",
      "step:   159620, time: 0.408, loss: 0.015088\n",
      "step:   159640, time: 0.406, loss: 0.012450\n",
      "step:   159660, time: 0.383, loss: 0.012886\n",
      "step:   159680, time: 0.390, loss: 0.019908\n",
      "step:   159700, time: 0.409, loss: 0.016391\n",
      "step:   159720, time: 0.439, loss: 0.011241\n",
      "step:   159740, time: 0.417, loss: 0.010803\n",
      "step:   159760, time: 0.398, loss: 0.024311\n",
      "step:   159780, time: 0.429, loss: 0.014006\n",
      "step:   159800, time: 0.398, loss: 0.016063\n",
      "step:   159820, time: 0.400, loss: 0.018062\n",
      "step:   159840, time: 0.393, loss: 0.017772\n",
      "step:   159860, time: 0.402, loss: 0.015589\n",
      "step:   159880, time: 0.400, loss: 0.011667\n",
      "step:   159900, time: 0.410, loss: 0.010635\n",
      "step:   159920, time: 0.395, loss: 0.012038\n",
      "step:   159940, time: 0.387, loss: 0.019177\n",
      "step:   159960, time: 0.413, loss: 0.015186\n",
      "step:   159980, time: 0.387, loss: 0.013895\n",
      "step:   160000, time: 0.395, loss: 0.005296\n",
      "step:   160020, time: 0.117, loss: 0.028860\n",
      "step:   160040, time: 0.391, loss: 0.026318\n",
      "step:   160060, time: 0.398, loss: 0.011172\n",
      "step:   160080, time: 0.410, loss: 0.016700\n",
      "step:   160100, time: 0.435, loss: 0.015469\n",
      "step:   160120, time: 0.406, loss: 0.028682\n",
      "step:   160140, time: 0.396, loss: 0.027138\n",
      "step:   160160, time: 0.362, loss: 0.014670\n",
      "step:   160180, time: 0.407, loss: 0.008874\n",
      "step:   160200, time: 0.394, loss: 0.005398\n",
      "step:   160220, time: 0.403, loss: 0.015361\n",
      "step:   160240, time: 0.396, loss: 0.020100\n",
      "step:   160260, time: 0.411, loss: 0.012048\n",
      "step:   160280, time: 0.377, loss: 0.003868\n",
      "step:   160300, time: 0.380, loss: 0.012948\n",
      "step:   160320, time: 0.381, loss: 0.021558\n",
      "step:   160340, time: 0.403, loss: 0.007010\n",
      "step:   160360, time: 0.415, loss: 0.011251\n",
      "step:   160380, time: 0.421, loss: 0.013340\n",
      "step:   160400, time: 0.411, loss: 0.008437\n",
      "step:   160420, time: 0.385, loss: 0.014698\n",
      "step:   160440, time: 0.422, loss: 0.015524\n",
      "step:   160460, time: 0.403, loss: 0.013703\n",
      "step:   160480, time: 0.402, loss: 0.013987\n",
      "step:   160500, time: 0.412, loss: 0.024872\n",
      "step:   160520, time: 0.400, loss: 0.020135\n",
      "step:   160540, time: 0.417, loss: 0.239191\n",
      "step:   160560, time: 0.408, loss: 0.010362\n",
      "step:   160580, time: 0.403, loss: 0.016931\n",
      "step:   160600, time: 0.355, loss: 0.001850\n",
      "step:   160620, time: 0.407, loss: 0.018370\n",
      "step:   160640, time: 0.395, loss: 0.014559\n",
      "step:   160660, time: 0.399, loss: 0.014068\n",
      "step:   160680, time: 0.409, loss: 0.018070\n",
      "step:   160700, time: 0.396, loss: 0.008954\n",
      "step:   160720, time: 0.417, loss: 0.015295\n",
      "step:   160740, time: 0.417, loss: 0.019964\n",
      "step:   160760, time: 0.402, loss: 0.004945\n",
      "step:   160780, time: 0.408, loss: 0.020186\n",
      "step:   160800, time: 0.438, loss: 0.015299\n",
      "step:   160820, time: 0.416, loss: 0.010378\n",
      "step:   160840, time: 0.407, loss: 0.024660\n",
      "step:   160860, time: 0.368, loss: 0.010366\n",
      "step:   160880, time: 0.419, loss: 0.014455\n",
      "step:   160900, time: 0.425, loss: 0.018412\n",
      "step:   160920, time: 0.409, loss: 0.021944\n",
      "step:   160940, time: 0.406, loss: 0.020925\n",
      "step:   160960, time: 0.413, loss: 0.018560\n",
      "step:   160980, time: 0.375, loss: 0.009414\n",
      "step:   161000, time: 0.386, loss: 0.008381\n",
      "step:   161020, time: 0.404, loss: 0.016311\n",
      "step:   161040, time: 0.387, loss: 0.024388\n",
      "step:   161060, time: 0.408, loss: 0.014255\n",
      "step:   161080, time: 0.398, loss: 0.016000\n",
      "step:   161100, time: 0.401, loss: 0.022396\n",
      "step:   161120, time: 0.421, loss: 0.015648\n",
      "step:   161140, time: 0.398, loss: 0.011023\n",
      "step:   161160, time: 0.398, loss: 0.015878\n",
      "step:   161180, time: 0.416, loss: 0.021119\n",
      "step:   161200, time: 0.390, loss: 0.015968\n",
      "step:   161220, time: 0.421, loss: 0.015986\n",
      "step:   161240, time: 0.409, loss: 0.018102\n",
      "step:   161260, time: 0.404, loss: 0.017867\n",
      "step:   161280, time: 0.393, loss: 0.010888\n",
      "step:   161300, time: 0.430, loss: 0.018389\n",
      "step:   161320, time: 0.382, loss: 0.020126\n",
      "step:   161340, time: 0.389, loss: 0.015335\n",
      "step:   161360, time: 0.412, loss: 0.012692\n",
      "step:   161380, time: 0.409, loss: 0.012597\n",
      "step:   161400, time: 0.405, loss: 0.026448\n",
      "step:   161420, time: 0.394, loss: 0.015518\n",
      "step:   161440, time: 0.384, loss: 0.008505\n",
      "step:   161460, time: 0.395, loss: 0.009524\n",
      "step:   161480, time: 0.417, loss: 0.006125\n",
      "step:   161500, time: 0.376, loss: 0.020341\n",
      "step:   161520, time: 0.398, loss: 0.014833\n",
      "step:   161540, time: 0.387, loss: 0.009163\n",
      "step:   161560, time: 0.406, loss: 0.019305\n",
      "step:   161580, time: 0.401, loss: 0.016670\n",
      "step:   161600, time: 0.418, loss: 0.007183\n",
      "step:   161620, time: 0.397, loss: 0.009610\n",
      "step:   161640, time: 0.388, loss: 0.015003\n",
      "step:   161660, time: 0.465, loss: 0.021105\n",
      "step:   161680, time: 0.375, loss: 0.002796\n",
      "step:   161700, time: 0.382, loss: 0.018139\n",
      "step:   161720, time: 0.385, loss: 0.014398\n",
      "step:   161740, time: 0.410, loss: 0.016491\n",
      "step:   161760, time: 0.400, loss: 0.011834\n",
      "step:   161780, time: 0.395, loss: 0.015156\n",
      "step:   161800, time: 0.393, loss: 0.015591\n",
      "step:   161820, time: 0.383, loss: 0.003535\n",
      "step:   161840, time: 0.372, loss: 0.014421\n",
      "step:   161860, time: 0.385, loss: 0.025392\n",
      "step:   161880, time: 0.401, loss: 0.023618\n",
      "step:   161900, time: 0.406, loss: 0.008879\n",
      "step:   161920, time: 0.381, loss: 0.015727\n",
      "step:   161940, time: 0.380, loss: 0.016540\n",
      "step:   161960, time: 0.382, loss: 0.012090\n",
      "step:   161980, time: 0.409, loss: 0.009685\n",
      "step:   162000, time: 0.384, loss: 0.013138\n",
      "step:   162020, time: 0.398, loss: 0.018769\n",
      "step:   162040, time: 0.415, loss: 0.016605\n",
      "step:   162060, time: 0.403, loss: 0.013829\n",
      "step:   162080, time: 0.401, loss: 0.004484\n",
      "step:   162100, time: 0.415, loss: 0.008451\n",
      "step:   162120, time: 0.414, loss: 0.023306\n",
      "step:   162140, time: 0.392, loss: 0.018136\n",
      "step:   162160, time: 0.382, loss: 0.018938\n",
      "step:   162180, time: 0.420, loss: 0.017891\n",
      "step:   162200, time: 0.394, loss: 0.065128\n",
      "step:   162220, time: 0.420, loss: 0.014252\n",
      "step:   162240, time: 0.403, loss: 0.013203\n",
      "step:   162260, time: 0.387, loss: 0.008248\n",
      "step:   162280, time: 0.431, loss: 0.011724\n",
      "step:   162300, time: 0.385, loss: 0.011225\n",
      "step:   162320, time: 0.407, loss: 0.021393\n",
      "step:   162340, time: 0.392, loss: 0.015445\n",
      "step:   162360, time: 0.402, loss: 0.011083\n",
      "step:   162380, time: 0.395, loss: 0.013803\n",
      "step:   162400, time: 0.423, loss: 0.014802\n",
      "step:   162420, time: 0.416, loss: 0.014571\n",
      "step:   162440, time: 0.413, loss: 0.012927\n",
      "step:   162460, time: 0.390, loss: 0.005880\n",
      "step:   162480, time: 0.433, loss: 0.019283\n",
      "step:   162500, time: 0.389, loss: 0.009813\n",
      "step:   162520, time: 0.431, loss: 0.155749\n",
      "step:   162540, time: 0.414, loss: 0.004313\n",
      "step:   162560, time: 0.395, loss: 0.011068\n",
      "step:   162580, time: 0.394, loss: 0.012201\n",
      "step:   162600, time: 0.407, loss: 0.019536\n",
      "step:   162620, time: 0.420, loss: 0.021847\n",
      "step:   162640, time: 0.423, loss: 0.017855\n",
      "step:   162660, time: 0.392, loss: 0.014068\n",
      "step:   162680, time: 0.391, loss: 0.011152\n",
      "step:   162700, time: 0.401, loss: 0.005655\n",
      "step:   162720, time: 0.403, loss: 0.013879\n",
      "step:   162740, time: 0.392, loss: 0.006200\n",
      "step:   162760, time: 0.391, loss: 0.008494\n",
      "step:   162780, time: 0.417, loss: 0.010741\n",
      "step:   162800, time: 0.424, loss: 0.023230\n",
      "step:   162820, time: 0.423, loss: 0.015115\n",
      "step:   162840, time: 0.386, loss: 0.017841\n",
      "step:   162860, time: 0.403, loss: 0.008458\n",
      "step:   162880, time: 0.422, loss: 0.012453\n",
      "step:   162900, time: 0.412, loss: 0.020100\n",
      "step:   162920, time: 0.392, loss: 0.012712\n",
      "step:   162940, time: 0.412, loss: 0.017869\n",
      "step:   162960, time: 0.413, loss: 0.014228\n",
      "step:   162980, time: 0.400, loss: 0.014369\n",
      "step:   163000, time: 0.387, loss: 0.022626\n",
      "step:   163020, time: 0.402, loss: 0.014460\n",
      "step:   163040, time: 0.385, loss: 0.010487\n",
      "step:   163060, time: 0.458, loss: 0.017925\n",
      "step:   163080, time: 0.420, loss: 0.017544\n",
      "step:   163100, time: 0.404, loss: 0.017591\n",
      "step:   163120, time: 0.428, loss: 0.017240\n",
      "step:   163140, time: 0.420, loss: 0.011954\n",
      "step:   163160, time: 0.399, loss: 0.010633\n",
      "step:   163180, time: 0.402, loss: 0.017273\n",
      "step:   163200, time: 0.407, loss: 0.017079\n",
      "step:   163220, time: 0.418, loss: 0.022810\n",
      "step:   163240, time: 0.423, loss: 0.013928\n",
      "step:   163260, time: 0.393, loss: 0.007230\n",
      "step:   163280, time: 0.416, loss: 0.015297\n",
      "step:   163300, time: 0.416, loss: 0.018190\n",
      "step:   163320, time: 0.419, loss: 0.007959\n",
      "step:   163340, time: 0.385, loss: 0.003179\n",
      "step:   163360, time: 0.391, loss: 0.019881\n",
      "step:   163380, time: 0.417, loss: 0.093888\n",
      "step:   163400, time: 0.424, loss: 0.009869\n",
      "step:   163420, time: 0.406, loss: 0.012355\n",
      "step:   163440, time: 0.410, loss: 0.010033\n",
      "step:   163460, time: 0.433, loss: 0.016066\n",
      "step:   163480, time: 0.446, loss: 0.018365\n",
      "step:   163500, time: 0.436, loss: 0.015151\n",
      "step:   163520, time: 0.423, loss: 0.162157\n",
      "step:   163540, time: 0.410, loss: 0.015605\n",
      "step:   163560, time: 0.406, loss: 0.034735\n",
      "step:   163580, time: 0.388, loss: 0.002562\n",
      "step:   163600, time: 0.418, loss: 0.018696\n",
      "step:   163620, time: 0.381, loss: 0.003561\n",
      "step:   163640, time: 0.408, loss: 0.004765\n",
      "step:   163660, time: 0.391, loss: 0.022209\n",
      "step:   163680, time: 0.406, loss: 0.017520\n",
      "step:   163700, time: 0.401, loss: 0.016008\n",
      "step:   163720, time: 0.412, loss: 0.012124\n",
      "step:   163740, time: 0.397, loss: 0.018658\n",
      "step:   163760, time: 0.376, loss: 0.011174\n",
      "step:   163780, time: 0.400, loss: 0.017979\n",
      "step:   163800, time: 0.402, loss: 0.012167\n",
      "step:   163820, time: 0.397, loss: 0.010692\n",
      "step:   163840, time: 0.410, loss: 0.013457\n",
      "step:   163860, time: 0.399, loss: 0.011873\n",
      "step:   163880, time: 0.404, loss: 0.008045\n",
      "step:   163900, time: 0.406, loss: 0.023922\n",
      "step:   163920, time: 0.367, loss: 0.010897\n",
      "step:   163940, time: 0.413, loss: 0.010880\n",
      "step:   163960, time: 0.401, loss: 0.010570\n",
      "step:   163980, time: 0.414, loss: 0.021183\n",
      "step:   164000, time: 0.377, loss: 0.007377\n",
      "step:   164020, time: 0.397, loss: 0.006846\n",
      "step:   164040, time: 0.403, loss: 0.013344\n",
      "step:   164060, time: 0.385, loss: 0.023630\n",
      "step:   164080, time: 0.378, loss: 0.022008\n",
      "step:   164100, time: 0.402, loss: 0.019363\n",
      "step:   164120, time: 0.397, loss: 0.018448\n",
      "step:   164140, time: 0.407, loss: 0.013363\n",
      "step:   164160, time: 0.422, loss: 0.022315\n",
      "step:   164180, time: 0.403, loss: 0.016211\n",
      "step:   164200, time: 0.397, loss: 0.012721\n",
      "step:   164220, time: 0.437, loss: 0.013369\n",
      "step:   164240, time: 0.391, loss: 0.021045\n",
      "step:   164260, time: 0.417, loss: 0.021068\n",
      "step:   164280, time: 0.404, loss: 0.011270\n",
      "step:   164300, time: 0.376, loss: 0.008812\n",
      "step:   164320, time: 0.388, loss: 0.009945\n",
      "step:   164340, time: 0.449, loss: 0.168072\n",
      "step:   164360, time: 0.430, loss: 0.016619\n",
      "step:   164380, time: 0.419, loss: 0.021687\n",
      "step:   164400, time: 0.402, loss: 0.011651\n",
      "step:   164420, time: 0.390, loss: 0.014986\n",
      "step:   164440, time: 0.389, loss: 0.007279\n",
      "step:   164460, time: 0.409, loss: 0.018870\n",
      "step:   164480, time: 0.427, loss: 0.018837\n",
      "step:   164500, time: 0.409, loss: 0.015275\n",
      "step:   164520, time: 0.399, loss: 0.024568\n",
      "step:   164540, time: 0.401, loss: 0.007953\n",
      "step:   164560, time: 0.404, loss: 0.018633\n",
      "step:   164580, time: 0.409, loss: 0.014353\n",
      "step:   164600, time: 0.398, loss: 0.013023\n",
      "step:   164620, time: 0.368, loss: 0.021918\n",
      "step:   164640, time: 0.403, loss: 0.021126\n",
      "step:   164660, time: 0.416, loss: 0.012521\n",
      "step:   164680, time: 0.413, loss: 0.011536\n",
      "step:   164700, time: 0.407, loss: 0.013110\n",
      "step:   164720, time: 0.406, loss: 0.018176\n",
      "step:   164740, time: 0.412, loss: 0.013892\n",
      "step:   164760, time: 0.385, loss: 0.008298\n",
      "step:   164780, time: 0.420, loss: 0.156661\n",
      "step:   164800, time: 0.398, loss: 0.017976\n",
      "step:   164820, time: 0.387, loss: 0.018156\n",
      "step:   164840, time: 0.392, loss: 0.015442\n",
      "step:   164860, time: 0.386, loss: 0.013251\n",
      "step:   164880, time: 0.446, loss: 0.015565\n",
      "step:   164900, time: 0.435, loss: 0.015995\n",
      "step:   164920, time: 0.393, loss: 0.025299\n",
      "step:   164940, time: 0.395, loss: 0.009179\n",
      "step:   164960, time: 0.383, loss: 0.010224\n",
      "step:   164980, time: 0.406, loss: 0.009587\n",
      "step:   165000, time: 0.395, loss: 0.017582\n",
      "step:   165020, time: 0.380, loss: 0.017876\n",
      "step:   165040, time: 0.384, loss: 0.009091\n",
      "step:   165060, time: 0.420, loss: 0.020945\n",
      "step:   165080, time: 0.468, loss: 0.018691\n",
      "step:   165100, time: 0.401, loss: 0.049969\n",
      "step:   165120, time: 0.397, loss: 0.013088\n",
      "step:   165140, time: 0.416, loss: 0.021161\n",
      "step:   165160, time: 0.391, loss: 0.010954\n",
      "step:   165180, time: 0.399, loss: 0.018993\n",
      "step:   165200, time: 0.407, loss: 0.008310\n",
      "step:   165220, time: 0.380, loss: 0.015517\n",
      "step:   165240, time: 0.388, loss: 0.024329\n",
      "step:   165260, time: 0.398, loss: 0.012102\n",
      "step:   165280, time: 0.397, loss: 0.017718\n",
      "step:   165300, time: 0.391, loss: 0.020143\n",
      "step:   165320, time: 0.415, loss: 0.014072\n",
      "step:   165340, time: 0.409, loss: 0.009510\n",
      "step:   165360, time: 0.417, loss: 0.020165\n",
      "step:   165380, time: 0.388, loss: 0.013163\n",
      "step:   165400, time: 0.413, loss: 0.017277\n",
      "step:   165420, time: 0.399, loss: 0.015696\n",
      "step:   165440, time: 0.395, loss: 0.020106\n",
      "step:   165460, time: 0.412, loss: 0.009524\n",
      "step:   165480, time: 0.408, loss: 0.008640\n",
      "step:   165500, time: 0.406, loss: 0.015480\n",
      "step:   165520, time: 0.380, loss: 0.022074\n",
      "step:   165540, time: 0.387, loss: 0.019765\n",
      "step:   165560, time: 0.390, loss: 0.006383\n",
      "step:   165580, time: 0.381, loss: 0.021102\n",
      "step:   165600, time: 0.393, loss: 0.019835\n",
      "step:   165620, time: 0.399, loss: 0.014031\n",
      "step:   165640, time: 0.414, loss: 0.009939\n",
      "step:   165660, time: 0.407, loss: 0.017144\n",
      "step:   165680, time: 0.402, loss: 0.008354\n",
      "step:   165700, time: 0.389, loss: 0.012841\n",
      "step:   165720, time: 0.407, loss: 0.014097\n",
      "step:   165740, time: 0.383, loss: 0.019719\n",
      "step:   165760, time: 0.384, loss: 0.021962\n",
      "step:   165780, time: 0.401, loss: 0.011055\n",
      "step:   165800, time: 0.411, loss: 0.231474\n",
      "step:   165820, time: 0.425, loss: 0.010309\n",
      "step:   165840, time: 0.396, loss: 0.016424\n",
      "step:   165860, time: 0.376, loss: 0.006820\n",
      "step:   165880, time: 0.396, loss: 0.012523\n",
      "step:   165900, time: 0.409, loss: 0.133352\n",
      "step:   165920, time: 0.414, loss: 0.012017\n",
      "step:   165940, time: 0.402, loss: 0.014844\n",
      "step:   165960, time: 0.403, loss: 0.030228\n",
      "step:   165980, time: 0.387, loss: 0.018150\n",
      "step:   166000, time: 0.405, loss: 0.195900\n",
      "step:   166020, time: 0.413, loss: 0.015406\n",
      "step:   166040, time: 0.402, loss: 0.021241\n",
      "step:   166060, time: 0.412, loss: 0.016996\n",
      "step:   166080, time: 0.413, loss: 0.013756\n",
      "step:   166100, time: 0.398, loss: 0.013178\n",
      "step:   166120, time: 0.404, loss: 0.020932\n",
      "step:   166140, time: 0.415, loss: 0.013540\n",
      "step:   166160, time: 0.421, loss: 0.013143\n",
      "step:   166180, time: 0.403, loss: 0.011414\n",
      "step:   166200, time: 0.382, loss: 0.009628\n",
      "step:   166220, time: 0.417, loss: 0.009408\n",
      "step:   166240, time: 0.450, loss: 0.020198\n",
      "step:   166260, time: 0.380, loss: 0.012130\n",
      "step:   166280, time: 0.383, loss: 0.011584\n",
      "step:   166300, time: 0.391, loss: 0.010449\n",
      "step:   166320, time: 0.412, loss: 0.011571\n",
      "step:   166340, time: 0.395, loss: 0.009276\n",
      "step:   166360, time: 0.395, loss: 0.015854\n",
      "step:   166380, time: 0.416, loss: 0.022505\n",
      "step:   166400, time: 0.378, loss: 0.003487\n",
      "step:   166420, time: 0.399, loss: 0.014351\n",
      "step:   166440, time: 0.381, loss: 0.011808\n",
      "step:   166460, time: 0.403, loss: 0.013068\n",
      "step:   166480, time: 0.400, loss: 0.007202\n",
      "step:   166500, time: 0.407, loss: 0.018652\n",
      "step:   166520, time: 0.403, loss: 0.009332\n",
      "step:   166540, time: 0.438, loss: 0.013505\n",
      "step:   166560, time: 0.467, loss: 0.017300\n",
      "step:   166580, time: 0.453, loss: 0.012611\n",
      "step:   166600, time: 0.381, loss: 0.005099\n",
      "step:   166620, time: 0.427, loss: 0.016834\n",
      "step:   166640, time: 0.416, loss: 0.007340\n",
      "step:   166660, time: 0.410, loss: 0.007953\n",
      "step:   166680, time: 0.431, loss: 0.013403\n",
      "step:   166700, time: 0.431, loss: 0.025603\n",
      "step:   166720, time: 0.440, loss: 0.019885\n",
      "step:   166740, time: 0.459, loss: 0.019606\n",
      "step:   166760, time: 0.414, loss: 0.015520\n",
      "step:   166780, time: 0.415, loss: 0.020759\n",
      "step:   166800, time: 0.418, loss: 0.022006\n",
      "step:   166820, time: 0.396, loss: 0.009204\n",
      "step:   166840, time: 0.437, loss: 0.023988\n",
      "step:   166860, time: 0.417, loss: 0.014747\n",
      "step:   166880, time: 0.400, loss: 0.012907\n",
      "step:   166900, time: 0.401, loss: 0.018993\n",
      "step:   166920, time: 0.435, loss: 0.014304\n",
      "step:   166940, time: 0.444, loss: 0.018323\n",
      "step:   166960, time: 0.409, loss: 0.008342\n",
      "step:   166980, time: 0.407, loss: 0.020739\n",
      "step:   167000, time: 0.447, loss: 0.015588\n",
      "step:   167020, time: 0.421, loss: 0.006464\n",
      "step:   167040, time: 0.403, loss: 0.011914\n",
      "step:   167060, time: 0.420, loss: 0.018769\n",
      "step:   167080, time: 0.433, loss: 0.016632\n",
      "step:   167100, time: 0.446, loss: 0.014762\n",
      "step:   167120, time: 0.405, loss: 0.014821\n",
      "step:   167140, time: 0.400, loss: 0.010079\n",
      "step:   167160, time: 0.400, loss: 0.019948\n",
      "step:   167180, time: 0.418, loss: 0.018617\n",
      "step:   167200, time: 0.424, loss: 0.021570\n",
      "step:   167220, time: 0.409, loss: 0.019563\n",
      "step:   167240, time: 0.395, loss: 0.015697\n",
      "step:   167260, time: 0.421, loss: 0.018623\n",
      "step:   167280, time: 0.375, loss: 0.009099\n",
      "step:   167300, time: 0.386, loss: 0.015279\n",
      "step:   167320, time: 0.391, loss: 0.008615\n",
      "step:   167340, time: 0.417, loss: 0.019104\n",
      "step:   167360, time: 0.418, loss: 0.011948\n",
      "step:   167380, time: 0.400, loss: 0.010053\n",
      "step:   167400, time: 0.393, loss: 0.012818\n",
      "step:   167420, time: 0.402, loss: 0.012664\n",
      "step:   167440, time: 0.377, loss: 0.009371\n",
      "step:   167460, time: 0.399, loss: 0.013326\n",
      "step:   167480, time: 0.390, loss: 0.017425\n",
      "step:   167500, time: 0.400, loss: 0.020141\n",
      "step:   167520, time: 0.406, loss: 0.016201\n",
      "step:   167540, time: 0.407, loss: 0.010700\n",
      "step:   167560, time: 0.407, loss: 0.020210\n",
      "step:   167580, time: 0.401, loss: 0.010836\n",
      "step:   167600, time: 0.375, loss: 0.003947\n",
      "step:   167620, time: 0.381, loss: 0.023127\n",
      "step:   167640, time: 0.393, loss: 0.014552\n",
      "step:   167660, time: 0.394, loss: 0.014883\n",
      "step:   167680, time: 0.400, loss: 0.016992\n",
      "step:   167700, time: 0.403, loss: 0.011506\n",
      "step:   167720, time: 0.382, loss: 0.009359\n",
      "step:   167740, time: 0.365, loss: 0.002877\n",
      "step:   167760, time: 0.415, loss: 0.013338\n",
      "step:   167780, time: 0.385, loss: 0.022889\n",
      "step:   167800, time: 0.399, loss: 0.019733\n",
      "step:   167820, time: 0.395, loss: 0.006129\n",
      "step:   167840, time: 0.406, loss: 0.010208\n",
      "step:   167860, time: 0.385, loss: 0.011412\n",
      "step:   167880, time: 0.362, loss: 0.018898\n",
      "step:   167900, time: 0.416, loss: 0.012964\n",
      "step:   167920, time: 0.416, loss: 0.018067\n",
      "step:   167940, time: 0.413, loss: 0.009962\n",
      "step:   167960, time: 0.421, loss: 0.014965\n",
      "step:   167980, time: 0.402, loss: 0.010240\n",
      "step:   168000, time: 0.419, loss: 0.011882\n",
      "step:   168020, time: 0.391, loss: 0.018192\n",
      "step:   168040, time: 0.389, loss: 0.019338\n",
      "step:   168060, time: 0.395, loss: 0.019248\n",
      "step:   168080, time: 0.392, loss: 0.020782\n",
      "step:   168100, time: 0.370, loss: 0.003420\n",
      "step:   168120, time: 0.400, loss: 0.014813\n",
      "step:   168140, time: 0.389, loss: 0.010808\n",
      "step:   168160, time: 0.410, loss: 0.012598\n",
      "step:   168180, time: 0.408, loss: 0.018218\n",
      "step:   168200, time: 0.423, loss: 0.021813\n",
      "step:   168220, time: 0.386, loss: 0.023332\n",
      "step:   168240, time: 0.429, loss: 0.019990\n",
      "step:   168260, time: 0.389, loss: 0.013525\n",
      "step:   168280, time: 0.425, loss: 0.020839\n",
      "step:   168300, time: 0.396, loss: 0.014047\n",
      "step:   168320, time: 0.384, loss: 0.004984\n",
      "step:   168340, time: 0.412, loss: 0.015839\n",
      "step:   168360, time: 0.429, loss: 0.025745\n",
      "step:   168380, time: 0.404, loss: 0.016954\n",
      "step:   168400, time: 0.394, loss: 0.020906\n",
      "step:   168420, time: 0.418, loss: 0.012182\n",
      "step:   168440, time: 0.376, loss: 0.022666\n",
      "step:   168460, time: 0.401, loss: 0.018773\n",
      "step:   168480, time: 0.429, loss: 0.020995\n",
      "step:   168500, time: 0.403, loss: 0.027265\n",
      "step:   168520, time: 0.404, loss: 0.015668\n",
      "step:   168540, time: 0.381, loss: 0.009193\n",
      "step:   168560, time: 0.397, loss: 0.018543\n",
      "step:   168580, time: 0.390, loss: 0.014146\n",
      "step:   168600, time: 0.389, loss: 0.017179\n",
      "step:   168620, time: 0.411, loss: 0.022142\n",
      "step:   168640, time: 0.419, loss: 0.033709\n",
      "step:   168660, time: 0.375, loss: 0.013189\n",
      "step:   168680, time: 0.432, loss: 0.010279\n",
      "step:   168700, time: 0.384, loss: 0.011231\n",
      "step:   168720, time: 0.391, loss: 0.011780\n",
      "step:   168740, time: 0.382, loss: 0.015393\n",
      "step:   168760, time: 0.414, loss: 0.014512\n",
      "step:   168780, time: 0.390, loss: 0.007967\n",
      "step:   168800, time: 0.414, loss: 0.017231\n",
      "step:   168820, time: 0.432, loss: 0.127256\n",
      "step:   168840, time: 0.411, loss: 0.017156\n",
      "step:   168860, time: 0.406, loss: 0.016546\n",
      "step:   168880, time: 0.406, loss: 0.013888\n",
      "step:   168900, time: 0.392, loss: 0.009659\n",
      "step:   168920, time: 0.391, loss: 0.008273\n",
      "step:   168940, time: 0.395, loss: 0.011950\n",
      "step:   168960, time: 0.415, loss: 0.018240\n",
      "step:   168980, time: 0.390, loss: 0.013389\n",
      "step:   169000, time: 0.407, loss: 0.015479\n",
      "step:   169020, time: 0.386, loss: 0.012396\n",
      "step:   169040, time: 0.411, loss: 0.016221\n",
      "step:   169060, time: 0.410, loss: 0.018165\n",
      "step:   169080, time: 0.379, loss: 0.016330\n",
      "step:   169100, time: 0.394, loss: 0.013557\n",
      "step:   169120, time: 0.408, loss: 0.005900\n",
      "step:   169140, time: 0.363, loss: 0.015764\n",
      "step:   169160, time: 0.393, loss: 0.011368\n",
      "step:   169180, time: 0.391, loss: 0.007477\n",
      "step:   169200, time: 0.393, loss: 0.013036\n",
      "step:   169220, time: 0.406, loss: 0.018785\n",
      "step:   169240, time: 0.407, loss: 0.018669\n",
      "step:   169260, time: 0.397, loss: 0.013325\n",
      "step:   169280, time: 0.384, loss: 0.010068\n",
      "step:   169300, time: 0.392, loss: 0.010237\n",
      "step:   169320, time: 0.393, loss: 0.017196\n",
      "step:   169340, time: 0.401, loss: 0.017624\n",
      "step:   169360, time: 0.398, loss: 0.013194\n",
      "step:   169380, time: 0.406, loss: 0.022845\n",
      "step:   169400, time: 0.401, loss: 0.012438\n",
      "step:   169420, time: 0.438, loss: 0.014591\n",
      "step:   169440, time: 0.431, loss: 0.018113\n",
      "step:   169460, time: 0.423, loss: 0.019250\n",
      "step:   169480, time: 0.385, loss: 0.016581\n",
      "step:   169500, time: 0.391, loss: 0.038450\n",
      "step:   169520, time: 0.398, loss: 0.021531\n",
      "step:   169540, time: 0.377, loss: 0.008201\n",
      "step:   169560, time: 0.386, loss: 0.020117\n",
      "step:   169580, time: 0.404, loss: 0.014573\n",
      "step:   169600, time: 0.390, loss: 0.008188\n",
      "step:   169620, time: 0.407, loss: 0.023910\n",
      "step:   169640, time: 0.397, loss: 0.015791\n",
      "step:   169660, time: 0.394, loss: 0.018263\n",
      "step:   169680, time: 0.377, loss: 0.017653\n",
      "step:   169700, time: 0.395, loss: 0.006853\n",
      "step:   169720, time: 0.414, loss: 0.015720\n",
      "step:   169740, time: 0.380, loss: 0.013514\n",
      "step:   169760, time: 0.372, loss: 0.025263\n",
      "step:   169780, time: 0.423, loss: 0.016293\n",
      "step:   169800, time: 0.428, loss: 0.018858\n",
      "step:   169820, time: 0.416, loss: 0.015153\n",
      "step:   169840, time: 0.378, loss: 0.014671\n",
      "step:   169860, time: 0.392, loss: 0.019087\n",
      "step:   169880, time: 0.388, loss: 0.016374\n",
      "step:   169900, time: 0.392, loss: 0.005636\n",
      "step:   169920, time: 0.382, loss: 0.015985\n",
      "step:   169940, time: 0.390, loss: 0.015997\n",
      "step:   169960, time: 0.400, loss: 0.020965\n",
      "step:   169980, time: 0.435, loss: 0.012880\n",
      "step:   170000, time: 0.392, loss: 0.009294\n",
      "step:   170020, time: 0.410, loss: 0.015315\n",
      "step:   170040, time: 0.401, loss: 0.019485\n",
      "step:   170060, time: 0.409, loss: 0.018494\n",
      "step:   170080, time: 0.400, loss: 0.018889\n",
      "step:   170100, time: 0.430, loss: 0.010354\n",
      "step:   170120, time: 0.398, loss: 0.017534\n",
      "step:   170140, time: 0.407, loss: 0.015149\n",
      "step:   170160, time: 0.433, loss: 0.017058\n",
      "step:   170180, time: 0.436, loss: 0.008787\n",
      "step:   170200, time: 0.407, loss: 0.018023\n",
      "step:   170220, time: 0.455, loss: 0.014754\n",
      "step:   170240, time: 0.403, loss: 0.004201\n",
      "step:   170260, time: 0.429, loss: 0.017101\n",
      "step:   170280, time: 0.441, loss: 0.020742\n",
      "step:   170300, time: 0.384, loss: 0.019741\n",
      "step:   170320, time: 0.402, loss: 0.011228\n",
      "step:   170340, time: 0.426, loss: 0.010693\n",
      "step:   170360, time: 0.436, loss: 0.026018\n",
      "step:   170380, time: 0.421, loss: 0.024590\n",
      "step:   170400, time: 0.411, loss: 0.011221\n",
      "step:   170420, time: 0.389, loss: 0.012870\n",
      "step:   170440, time: 0.404, loss: 0.014573\n",
      "step:   170460, time: 0.401, loss: 0.016373\n",
      "step:   170480, time: 0.407, loss: 0.013821\n",
      "step:   170500, time: 0.406, loss: 0.011972\n",
      "step:   170520, time: 0.411, loss: 0.012140\n",
      "step:   170540, time: 0.421, loss: 0.020783\n",
      "step:   170560, time: 0.412, loss: 0.007892\n",
      "step:   170580, time: 0.385, loss: 0.009437\n",
      "step:   170600, time: 0.407, loss: 0.022141\n",
      "step:   170620, time: 0.392, loss: 0.009851\n",
      "step:   170640, time: 0.401, loss: 0.019310\n",
      "step:   170660, time: 0.403, loss: 0.018329\n",
      "step:   170680, time: 0.386, loss: 0.015803\n",
      "step:   170700, time: 0.390, loss: 0.009555\n",
      "step:   170720, time: 0.385, loss: 0.014071\n",
      "step:   170740, time: 0.420, loss: 0.013794\n",
      "step:   170760, time: 0.413, loss: 0.015080\n",
      "step:   170780, time: 0.388, loss: 0.012037\n",
      "step:   170800, time: 0.388, loss: 0.007586\n",
      "step:   170820, time: 0.382, loss: 0.005242\n",
      "step:   170840, time: 0.395, loss: 0.014360\n",
      "step:   170860, time: 0.387, loss: 0.012349\n",
      "step:   170880, time: 0.384, loss: 0.015066\n",
      "step:   170900, time: 0.399, loss: 0.015608\n",
      "step:   170920, time: 0.386, loss: 0.007152\n",
      "step:   170940, time: 0.406, loss: 0.010143\n",
      "step:   170960, time: 0.408, loss: 0.045955\n",
      "step:   170980, time: 0.379, loss: 0.013917\n",
      "step:   171000, time: 0.420, loss: 0.009736\n",
      "step:   171020, time: 0.376, loss: 0.011795\n",
      "step:   171040, time: 0.412, loss: 0.008557\n",
      "step:   171060, time: 0.385, loss: 0.017344\n",
      "step:   171080, time: 0.396, loss: 0.016074\n",
      "step:   171100, time: 0.401, loss: 0.010899\n",
      "step:   171120, time: 0.400, loss: 0.014466\n",
      "step:   171140, time: 0.414, loss: 0.015140\n",
      "step:   171160, time: 0.401, loss: 0.014442\n",
      "step:   171180, time: 0.409, loss: 0.016981\n",
      "step:   171200, time: 0.380, loss: 0.011733\n",
      "step:   171220, time: 0.390, loss: 0.013481\n",
      "step:   171240, time: 0.411, loss: 0.011908\n",
      "step:   171260, time: 0.414, loss: 0.008976\n",
      "step:   171280, time: 0.384, loss: 0.018811\n",
      "step:   171300, time: 0.407, loss: 0.018218\n",
      "step:   171320, time: 0.404, loss: 0.011288\n",
      "step:   171340, time: 0.399, loss: 0.010074\n",
      "step:   171360, time: 0.396, loss: 0.023873\n",
      "step:   171380, time: 0.384, loss: 0.008557\n",
      "step:   171400, time: 0.398, loss: 0.017300\n",
      "step:   171420, time: 0.383, loss: 0.007772\n",
      "step:   171440, time: 0.391, loss: 0.010747\n",
      "step:   171460, time: 0.392, loss: 0.018293\n",
      "step:   171480, time: 0.417, loss: 0.015732\n",
      "step:   171500, time: 0.381, loss: 0.005586\n",
      "step:   171520, time: 0.431, loss: 0.018787\n",
      "step:   171540, time: 0.395, loss: 0.014792\n",
      "step:   171560, time: 0.385, loss: 0.016571\n",
      "step:   171580, time: 0.431, loss: 0.015619\n",
      "step:   171600, time: 0.395, loss: 0.012941\n",
      "step:   171620, time: 0.401, loss: 0.012143\n",
      "step:   171640, time: 0.401, loss: 0.012958\n",
      "step:   171660, time: 0.382, loss: 0.006901\n",
      "step:   171680, time: 0.385, loss: 0.012105\n",
      "step:   171700, time: 0.375, loss: 0.024146\n",
      "step:   171720, time: 0.387, loss: 0.004232\n",
      "step:   171740, time: 0.393, loss: 0.021790\n",
      "step:   171760, time: 0.392, loss: 0.015404\n",
      "step:   171780, time: 0.385, loss: 0.012169\n",
      "step:   171800, time: 0.393, loss: 0.019101\n",
      "step:   171820, time: 0.396, loss: 0.016033\n",
      "step:   171840, time: 0.380, loss: 0.011900\n",
      "step:   171860, time: 0.473, loss: 0.013397\n",
      "step:   171880, time: 0.391, loss: 0.009958\n",
      "step:   171900, time: 0.390, loss: 0.006019\n",
      "step:   171920, time: 0.403, loss: 0.013951\n",
      "step:   171940, time: 0.401, loss: 0.016105\n",
      "step:   171960, time: 0.385, loss: 0.007157\n",
      "step:   171980, time: 0.412, loss: 0.016001\n",
      "step:   172000, time: 0.377, loss: 0.011984\n",
      "step:   172020, time: 0.438, loss: 0.015985\n",
      "step:   172040, time: 0.406, loss: 0.020108\n",
      "step:   172060, time: 0.409, loss: 0.017057\n",
      "step:   172080, time: 0.388, loss: 0.010671\n",
      "step:   172100, time: 0.417, loss: 0.007373\n",
      "step:   172120, time: 0.398, loss: 0.009642\n",
      "step:   172140, time: 0.410, loss: 0.017431\n",
      "step:   172160, time: 0.403, loss: 0.019249\n",
      "step:   172180, time: 0.386, loss: 0.013599\n",
      "step:   172200, time: 0.414, loss: 0.020492\n",
      "step:   172220, time: 0.399, loss: 0.017170\n",
      "step:   172240, time: 0.393, loss: 0.020302\n",
      "step:   172260, time: 0.403, loss: 0.007521\n",
      "step:   172280, time: 0.386, loss: 0.021504\n",
      "step:   172300, time: 0.402, loss: 0.017851\n",
      "step:   172320, time: 0.391, loss: 0.016629\n",
      "step:   172340, time: 0.411, loss: 0.010677\n",
      "step:   172360, time: 0.393, loss: 0.016867\n",
      "step:   172380, time: 0.376, loss: 0.022872\n",
      "step:   172400, time: 0.398, loss: 0.015941\n",
      "step:   172420, time: 0.379, loss: 0.018434\n",
      "step:   172440, time: 0.384, loss: 0.017995\n",
      "step:   172460, time: 0.408, loss: 0.014924\n",
      "step:   172480, time: 0.423, loss: 0.009762\n",
      "step:   172500, time: 0.400, loss: 0.021794\n",
      "step:   172520, time: 0.390, loss: 0.014848\n",
      "step:   172540, time: 0.415, loss: 0.016866\n",
      "step:   172560, time: 0.375, loss: 0.026161\n",
      "step:   172580, time: 0.377, loss: 0.008878\n",
      "step:   172600, time: 0.393, loss: 0.007135\n",
      "step:   172620, time: 0.387, loss: 0.006720\n",
      "step:   172640, time: 0.413, loss: 0.016590\n",
      "step:   172660, time: 0.395, loss: 0.012822\n",
      "step:   172680, time: 0.380, loss: 0.013315\n",
      "step:   172700, time: 0.394, loss: 0.009572\n",
      "step:   172720, time: 0.420, loss: 0.018494\n",
      "step:   172740, time: 0.390, loss: 0.009983\n",
      "step:   172760, time: 0.412, loss: 0.010191\n",
      "step:   172780, time: 0.412, loss: 0.020116\n",
      "step:   172800, time: 0.395, loss: 0.020114\n",
      "step:   172820, time: 0.378, loss: 0.013875\n",
      "step:   172840, time: 0.387, loss: 0.009349\n",
      "step:   172860, time: 0.390, loss: 0.015171\n",
      "step:   172880, time: 0.391, loss: 0.015937\n",
      "step:   172900, time: 0.391, loss: 0.017429\n",
      "step:   172920, time: 0.407, loss: 0.012984\n",
      "step:   172940, time: 0.391, loss: 0.016911\n",
      "step:   172960, time: 0.385, loss: 0.008179\n",
      "step:   172980, time: 0.400, loss: 0.015051\n",
      "step:   173000, time: 0.411, loss: 0.013107\n",
      "step:   173020, time: 0.406, loss: 0.011924\n",
      "step:   173040, time: 0.431, loss: 0.016074\n",
      "step:   173060, time: 0.390, loss: 0.013807\n",
      "step:   173080, time: 0.407, loss: 0.013778\n",
      "step:   173100, time: 0.399, loss: 0.018654\n",
      "step:   173120, time: 0.403, loss: 0.021811\n",
      "step:   173140, time: 0.384, loss: 0.013832\n",
      "step:   173160, time: 0.417, loss: 0.017489\n",
      "step:   173180, time: 0.439, loss: 0.015373\n",
      "step:   173200, time: 0.380, loss: 0.018446\n",
      "step:   173220, time: 0.421, loss: 0.016366\n",
      "step:   173240, time: 0.394, loss: 0.009877\n",
      "step:   173260, time: 0.402, loss: 0.017642\n",
      "step:   173280, time: 0.392, loss: 0.020285\n",
      "step:   173300, time: 0.398, loss: 0.009438\n",
      "step:   173320, time: 0.363, loss: 0.007907\n",
      "step:   173340, time: 0.420, loss: 0.013885\n",
      "step:   173360, time: 0.401, loss: 0.011696\n",
      "step:   173380, time: 0.420, loss: 0.016429\n",
      "step:   173400, time: 0.412, loss: 0.009496\n",
      "step:   173420, time: 0.414, loss: 0.019088\n",
      "step:   173440, time: 0.397, loss: 0.011283\n",
      "step:   173460, time: 0.425, loss: 0.018269\n",
      "step:   173480, time: 0.397, loss: 0.007760\n",
      "step:   173500, time: 0.404, loss: 0.013505\n",
      "step:   173520, time: 0.416, loss: 0.015891\n",
      "step:   173540, time: 0.393, loss: 0.016904\n",
      "step:   173560, time: 0.390, loss: 0.019082\n",
      "step:   173580, time: 0.417, loss: 0.015247\n",
      "step:   173600, time: 0.404, loss: 0.016061\n",
      "step:   173620, time: 0.413, loss: 0.015400\n",
      "step:   173640, time: 0.382, loss: 0.010935\n",
      "step:   173660, time: 0.378, loss: 0.018041\n",
      "step:   173680, time: 0.402, loss: 0.011556\n",
      "step:   173700, time: 0.402, loss: 0.005753\n",
      "step:   173720, time: 0.401, loss: 0.005506\n",
      "step:   173740, time: 0.381, loss: 0.004452\n",
      "step:   173760, time: 0.384, loss: 0.008785\n",
      "step:   173780, time: 0.405, loss: 0.016030\n",
      "step:   173800, time: 0.417, loss: 0.015649\n",
      "step:   173820, time: 0.404, loss: 0.010661\n",
      "step:   173840, time: 0.421, loss: 0.020256\n",
      "step:   173860, time: 0.387, loss: 0.007412\n",
      "step:   173880, time: 0.406, loss: 0.020099\n",
      "step:   173900, time: 0.387, loss: 0.012459\n",
      "step:   173920, time: 0.403, loss: 0.018187\n",
      "step:   173940, time: 0.409, loss: 0.012177\n",
      "step:   173960, time: 0.406, loss: 0.025799\n",
      "step:   173980, time: 0.416, loss: 0.009435\n",
      "step:   174000, time: 0.412, loss: 0.016316\n",
      "step:   174020, time: 0.434, loss: 0.020948\n",
      "step:   174040, time: 0.410, loss: 0.011851\n",
      "step:   174060, time: 0.430, loss: 0.020935\n",
      "step:   174080, time: 0.398, loss: 0.014896\n",
      "step:   174100, time: 0.395, loss: 0.015041\n",
      "step:   174120, time: 0.416, loss: 0.019631\n",
      "step:   174140, time: 0.439, loss: 0.015814\n",
      "step:   174160, time: 0.404, loss: 0.016184\n",
      "step:   174180, time: 0.385, loss: 0.011098\n",
      "step:   174200, time: 0.391, loss: 0.016647\n",
      "step:   174220, time: 0.401, loss: 0.030665\n",
      "step:   174240, time: 0.388, loss: 0.011960\n",
      "step:   174260, time: 0.408, loss: 0.011883\n",
      "step:   174280, time: 0.424, loss: 0.008889\n",
      "step:   174300, time: 0.383, loss: 0.009447\n",
      "step:   174320, time: 0.401, loss: 0.006514\n",
      "step:   174340, time: 0.389, loss: 0.012869\n",
      "step:   174360, time: 0.403, loss: 0.014396\n",
      "step:   174380, time: 0.403, loss: 0.017393\n",
      "step:   174400, time: 0.406, loss: 0.012662\n",
      "step:   174420, time: 0.405, loss: 0.013207\n",
      "step:   174440, time: 0.402, loss: 0.024914\n",
      "step:   174460, time: 0.412, loss: 0.016484\n",
      "step:   174480, time: 0.409, loss: 0.020843\n",
      "step:   174500, time: 0.386, loss: 0.014253\n",
      "step:   174520, time: 0.393, loss: 0.010572\n",
      "step:   174540, time: 0.401, loss: 0.014879\n",
      "step:   174560, time: 0.391, loss: 0.037450\n",
      "step:   174580, time: 0.385, loss: 0.025240\n",
      "step:   174600, time: 0.423, loss: 0.020527\n",
      "step:   174620, time: 0.417, loss: 0.017998\n",
      "step:   174640, time: 0.409, loss: 0.023460\n",
      "step:   174660, time: 0.393, loss: 0.017228\n",
      "step:   174680, time: 0.384, loss: 0.017434\n",
      "step:   174700, time: 0.397, loss: 0.014513\n",
      "step:   174720, time: 0.410, loss: 0.015781\n",
      "step:   174740, time: 0.371, loss: 0.011989\n",
      "step:   174760, time: 0.394, loss: 0.008229\n",
      "step:   174780, time: 0.406, loss: 0.014718\n",
      "step:   174800, time: 0.405, loss: 0.019305\n",
      "step:   174820, time: 0.408, loss: 0.014188\n",
      "step:   174840, time: 0.384, loss: 0.018201\n",
      "step:   174860, time: 0.407, loss: 0.008761\n",
      "step:   174880, time: 0.408, loss: 0.010498\n",
      "step:   174900, time: 0.398, loss: 0.014538\n",
      "step:   174920, time: 0.421, loss: 0.020693\n",
      "step:   174940, time: 0.410, loss: 0.015572\n",
      "step:   174960, time: 0.399, loss: 0.013240\n",
      "step:   174980, time: 0.407, loss: 0.007753\n",
      "step:   175000, time: 0.404, loss: 0.023024\n",
      "step:   175020, time: 0.394, loss: 0.012030\n",
      "step:   175040, time: 0.398, loss: 0.012297\n",
      "step:   175060, time: 0.398, loss: 0.018534\n",
      "step:   175080, time: 0.390, loss: 0.020880\n",
      "step:   175100, time: 0.386, loss: 0.009445\n",
      "step:   175120, time: 0.396, loss: 0.010676\n",
      "step:   175140, time: 0.392, loss: 0.011699\n",
      "step:   175160, time: 0.388, loss: 0.004435\n",
      "step:   175180, time: 0.406, loss: 0.015986\n",
      "step:   175200, time: 0.386, loss: 0.007796\n",
      "step:   175220, time: 0.397, loss: 0.007643\n",
      "step:   175240, time: 0.427, loss: 0.015804\n",
      "step:   175260, time: 0.396, loss: 0.008828\n",
      "step:   175280, time: 0.393, loss: 0.010630\n",
      "step:   175300, time: 0.407, loss: 0.005489\n",
      "step:   175320, time: 0.388, loss: 0.015775\n",
      "step:   175340, time: 0.376, loss: 0.024240\n",
      "step:   175360, time: 0.423, loss: 0.013986\n",
      "step:   175380, time: 0.381, loss: 0.020964\n",
      "step:   175400, time: 0.406, loss: 0.018357\n",
      "step:   175420, time: 0.406, loss: 0.138888\n",
      "step:   175440, time: 0.392, loss: 0.013592\n",
      "step:   175460, time: 0.394, loss: 0.011150\n",
      "step:   175480, time: 0.432, loss: 0.006682\n",
      "step:   175500, time: 0.397, loss: 0.009706\n",
      "step:   175520, time: 0.401, loss: 0.014608\n",
      "step:   175540, time: 0.419, loss: 0.020502\n",
      "step:   175560, time: 0.387, loss: 0.010871\n",
      "step:   175580, time: 0.393, loss: 0.011164\n",
      "step:   175600, time: 0.386, loss: 0.019060\n",
      "step:   175620, time: 0.418, loss: 0.012849\n",
      "step:   175640, time: 0.383, loss: 0.018020\n",
      "step:   175660, time: 0.393, loss: 0.016866\n",
      "step:   175680, time: 0.387, loss: 0.018632\n",
      "step:   175700, time: 0.413, loss: 0.006861\n",
      "step:   175720, time: 0.408, loss: 0.010754\n",
      "step:   175740, time: 0.391, loss: 0.015584\n",
      "step:   175760, time: 0.395, loss: 0.008055\n",
      "step:   175780, time: 0.445, loss: 0.007927\n",
      "step:   175800, time: 0.402, loss: 0.019380\n",
      "step:   175820, time: 0.390, loss: 0.019505\n",
      "step:   175840, time: 0.370, loss: 0.020462\n",
      "step:   175860, time: 0.381, loss: 0.023747\n",
      "step:   175880, time: 0.400, loss: 0.010685\n",
      "step:   175900, time: 0.407, loss: 0.015791\n",
      "step:   175920, time: 0.416, loss: 0.009899\n",
      "step:   175940, time: 0.385, loss: 0.019240\n",
      "step:   175960, time: 0.392, loss: 0.007293\n",
      "step:   175980, time: 0.407, loss: 0.019552\n",
      "step:   176000, time: 0.391, loss: 0.011303\n",
      "step:   176020, time: 0.402, loss: 0.008453\n",
      "step:   176040, time: 0.382, loss: 0.011494\n",
      "step:   176060, time: 0.420, loss: 0.023426\n",
      "step:   176080, time: 0.382, loss: 0.012105\n",
      "step:   176100, time: 0.424, loss: 0.015947\n",
      "step:   176120, time: 0.386, loss: 0.005720\n",
      "step:   176140, time: 0.404, loss: 0.009947\n",
      "step:   176160, time: 0.378, loss: 0.013349\n",
      "step:   176180, time: 0.389, loss: 0.014468\n",
      "step:   176200, time: 0.383, loss: 0.015939\n",
      "step:   176220, time: 0.413, loss: 0.015023\n",
      "step:   176240, time: 0.413, loss: 0.015398\n",
      "step:   176260, time: 0.411, loss: 0.010935\n",
      "step:   176280, time: 0.456, loss: 0.017673\n",
      "step:   176300, time: 0.410, loss: 0.014666\n",
      "step:   176320, time: 0.390, loss: 0.006395\n",
      "step:   176340, time: 0.399, loss: 0.013024\n",
      "step:   176360, time: 0.421, loss: 0.016801\n",
      "step:   176380, time: 0.410, loss: 0.010601\n",
      "step:   176400, time: 0.428, loss: 0.013145\n",
      "step:   176420, time: 0.409, loss: 0.016470\n",
      "step:   176440, time: 0.383, loss: 0.012965\n",
      "step:   176460, time: 0.408, loss: 0.021643\n",
      "step:   176480, time: 0.389, loss: 0.014316\n",
      "step:   176500, time: 0.398, loss: 0.015980\n",
      "step:   176520, time: 0.374, loss: 0.009264\n",
      "step:   176540, time: 0.405, loss: 0.027990\n",
      "step:   176560, time: 0.391, loss: 0.021508\n",
      "step:   176580, time: 0.407, loss: 0.016395\n",
      "step:   176600, time: 0.389, loss: 0.013824\n",
      "step:   176620, time: 0.411, loss: 0.014347\n",
      "step:   176640, time: 0.394, loss: 0.010712\n",
      "step:   176660, time: 0.435, loss: 0.011913\n",
      "step:   176680, time: 0.412, loss: 0.012219\n",
      "step:   176700, time: 0.409, loss: 0.016305\n",
      "step:   176720, time: 0.415, loss: 0.112058\n",
      "step:   176740, time: 0.381, loss: 0.018342\n",
      "step:   176760, time: 0.376, loss: 0.020668\n",
      "step:   176780, time: 0.393, loss: 0.008635\n",
      "step:   176800, time: 0.383, loss: 0.008649\n",
      "step:   176820, time: 0.404, loss: 0.016012\n",
      "step:   176840, time: 0.423, loss: 0.015267\n",
      "step:   176860, time: 0.383, loss: 0.011076\n",
      "step:   176880, time: 0.406, loss: 0.021280\n",
      "step:   176900, time: 0.411, loss: 0.018442\n",
      "step:   176920, time: 0.423, loss: 0.020772\n",
      "step:   176940, time: 0.435, loss: 0.012315\n",
      "step:   176960, time: 0.412, loss: 0.008733\n",
      "step:   176980, time: 0.408, loss: 0.021125\n",
      "step:   177000, time: 0.403, loss: 0.016806\n",
      "step:   177020, time: 0.449, loss: 0.013169\n",
      "step:   177040, time: 0.452, loss: 0.018136\n",
      "step:   177060, time: 0.429, loss: 0.019148\n",
      "step:   177080, time: 0.386, loss: 0.009784\n",
      "step:   177100, time: 0.417, loss: 0.011669\n",
      "step:   177120, time: 0.406, loss: 0.013211\n",
      "step:   177140, time: 0.377, loss: 0.016077\n",
      "step:   177160, time: 0.398, loss: 0.021861\n",
      "step:   177180, time: 0.404, loss: 0.010039\n",
      "step:   177200, time: 0.405, loss: 0.012107\n",
      "step:   177220, time: 0.389, loss: 0.007653\n",
      "step:   177240, time: 0.422, loss: 0.019123\n",
      "step:   177260, time: 0.415, loss: 0.020657\n",
      "step:   177280, time: 0.394, loss: 0.010841\n",
      "step:   177300, time: 0.393, loss: 0.009853\n",
      "step:   177320, time: 0.402, loss: 0.004519\n",
      "step:   177340, time: 0.407, loss: 0.015128\n",
      "step:   177360, time: 0.410, loss: 0.011532\n",
      "step:   177380, time: 0.443, loss: 0.019851\n",
      "step:   177400, time: 0.429, loss: 0.016775\n",
      "step:   177420, time: 0.394, loss: 0.008865\n",
      "step:   177440, time: 0.405, loss: 0.015134\n",
      "step:   177460, time: 0.376, loss: 0.014496\n",
      "step:   177480, time: 0.395, loss: 0.012632\n",
      "step:   177500, time: 0.393, loss: 0.015886\n",
      "step:   177520, time: 0.392, loss: 0.012586\n",
      "step:   177540, time: 0.399, loss: 0.013762\n",
      "step:   177560, time: 0.414, loss: 0.019367\n",
      "step:   177580, time: 0.396, loss: 0.013432\n",
      "step:   177600, time: 0.402, loss: 0.018101\n",
      "step:   177620, time: 0.413, loss: 0.008102\n",
      "step:   177640, time: 0.416, loss: 0.011745\n",
      "step:   177660, time: 0.395, loss: 0.017006\n",
      "step:   177680, time: 0.408, loss: 0.014802\n",
      "step:   177700, time: 0.434, loss: 0.014542\n",
      "step:   177720, time: 0.402, loss: 0.011287\n",
      "step:   177740, time: 0.433, loss: 0.024015\n",
      "step:   177760, time: 0.412, loss: 0.013832\n",
      "step:   177780, time: 0.407, loss: 0.012880\n",
      "step:   177800, time: 0.112, loss: 0.021409\n",
      "step:   177820, time: 0.406, loss: 0.022889\n",
      "step:   177840, time: 0.392, loss: 0.019001\n",
      "step:   177860, time: 0.409, loss: 0.014501\n",
      "step:   177880, time: 0.394, loss: 0.018151\n",
      "step:   177900, time: 0.415, loss: 0.014431\n",
      "step:   177920, time: 0.391, loss: 0.013624\n",
      "step:   177940, time: 0.439, loss: 0.015652\n",
      "step:   177960, time: 0.416, loss: 0.018252\n",
      "step:   177980, time: 0.398, loss: 0.010297\n",
      "step:   178000, time: 0.408, loss: 0.024081\n",
      "step:   178020, time: 0.383, loss: 0.019255\n",
      "step:   178040, time: 0.413, loss: 0.017155\n",
      "step:   178060, time: 0.371, loss: 0.010016\n",
      "step:   178080, time: 0.371, loss: 0.012412\n",
      "step:   178100, time: 0.397, loss: 0.023436\n",
      "step:   178120, time: 0.389, loss: 0.012736\n",
      "step:   178140, time: 0.413, loss: 0.013624\n",
      "step:   178160, time: 0.412, loss: 0.012729\n",
      "step:   178180, time: 0.379, loss: 0.004163\n",
      "step:   178200, time: 0.423, loss: 0.016412\n",
      "step:   178220, time: 0.413, loss: 0.017587\n",
      "step:   178240, time: 0.403, loss: 0.015440\n",
      "step:   178260, time: 0.395, loss: 0.008030\n",
      "step:   178280, time: 0.402, loss: 0.014655\n",
      "step:   178300, time: 0.380, loss: 0.006238\n",
      "step:   178320, time: 0.434, loss: 0.020406\n",
      "step:   178340, time: 0.405, loss: 0.012231\n",
      "step:   178360, time: 0.392, loss: 0.011842\n",
      "step:   178380, time: 0.401, loss: 0.015161\n",
      "step:   178400, time: 0.404, loss: 0.017458\n",
      "step:   178420, time: 0.400, loss: 0.010694\n",
      "step:   178440, time: 0.426, loss: 0.017532\n",
      "step:   178460, time: 0.408, loss: 0.019407\n",
      "step:   178480, time: 0.405, loss: 0.012269\n",
      "step:   178500, time: 0.398, loss: 0.013129\n",
      "step:   178520, time: 0.389, loss: 0.005705\n",
      "step:   178540, time: 0.394, loss: 0.019263\n",
      "step:   178560, time: 0.437, loss: 0.162373\n",
      "step:   178580, time: 0.417, loss: 0.016270\n",
      "step:   178600, time: 0.413, loss: 0.015027\n",
      "step:   178620, time: 0.434, loss: 0.012032\n",
      "step:   178640, time: 0.407, loss: 0.012167\n",
      "step:   178660, time: 0.410, loss: 0.019546\n",
      "step:   178680, time: 0.430, loss: 0.017031\n",
      "step:   178700, time: 0.388, loss: 0.015310\n",
      "step:   178720, time: 0.415, loss: 0.007699\n",
      "step:   178740, time: 0.383, loss: 0.012382\n",
      "step:   178760, time: 0.442, loss: 0.015153\n",
      "step:   178780, time: 0.428, loss: 0.011774\n",
      "step:   178800, time: 0.409, loss: 0.011875\n",
      "step:   178820, time: 0.398, loss: 0.018211\n",
      "step:   178840, time: 0.437, loss: 0.010775\n",
      "step:   178860, time: 0.426, loss: 0.021256\n",
      "step:   178880, time: 0.399, loss: 0.019030\n",
      "step:   178900, time: 0.400, loss: 0.009482\n",
      "step:   178920, time: 0.383, loss: 0.014913\n",
      "step:   178940, time: 0.409, loss: 0.019428\n",
      "step:   178960, time: 0.433, loss: 0.017889\n",
      "step:   178980, time: 0.407, loss: 0.018314\n",
      "step:   179000, time: 0.412, loss: 0.233678\n",
      "step:   179020, time: 0.398, loss: 0.021107\n",
      "step:   179040, time: 0.392, loss: 0.016892\n",
      "step:   179060, time: 0.408, loss: 0.012701\n",
      "step:   179080, time: 0.389, loss: 0.006761\n",
      "step:   179100, time: 0.405, loss: 0.014562\n",
      "step:   179120, time: 0.390, loss: 0.024403\n",
      "step:   179140, time: 0.451, loss: 0.016863\n",
      "step:   179160, time: 0.398, loss: 0.008719\n",
      "step:   179180, time: 0.402, loss: 0.015850\n",
      "step:   179200, time: 0.406, loss: 0.014417\n",
      "step:   179220, time: 0.399, loss: 0.014587\n",
      "step:   179240, time: 0.394, loss: 0.016270\n",
      "step:   179260, time: 0.397, loss: 0.015611\n",
      "step:   179280, time: 0.399, loss: 0.112173\n",
      "step:   179300, time: 0.381, loss: 0.014252\n",
      "step:   179320, time: 0.421, loss: 0.123308\n",
      "step:   179340, time: 0.388, loss: 0.020318\n",
      "step:   179360, time: 0.396, loss: 0.018631\n",
      "step:   179380, time: 0.399, loss: 0.021565\n",
      "step:   179400, time: 0.404, loss: 0.024633\n",
      "step:   179420, time: 0.392, loss: 0.014889\n",
      "step:   179440, time: 0.381, loss: 0.014174\n",
      "step:   179460, time: 0.382, loss: 0.003562\n",
      "step:   179480, time: 0.381, loss: 0.015233\n",
      "step:   179500, time: 0.399, loss: 0.016035\n",
      "step:   179520, time: 0.402, loss: 0.009036\n",
      "step:   179540, time: 0.411, loss: 0.017364\n",
      "step:   179560, time: 0.389, loss: 0.014024\n",
      "step:   179580, time: 0.390, loss: 0.028268\n",
      "step:   179600, time: 0.394, loss: 0.011575\n",
      "step:   179620, time: 0.427, loss: 0.020801\n",
      "step:   179640, time: 0.402, loss: 0.008309\n",
      "step:   179660, time: 0.393, loss: 0.013299\n",
      "step:   179680, time: 0.369, loss: 0.013247\n",
      "step:   179700, time: 0.415, loss: 0.014164\n",
      "step:   179720, time: 0.384, loss: 0.011574\n",
      "step:   179740, time: 0.373, loss: 0.011925\n",
      "step:   179760, time: 0.388, loss: 0.020579\n",
      "step:   179780, time: 0.395, loss: 0.007459\n",
      "step:   179800, time: 0.391, loss: 0.016754\n",
      "step:   179820, time: 0.402, loss: 0.018108\n",
      "step:   179840, time: 0.392, loss: 0.013031\n",
      "step:   179860, time: 0.401, loss: 0.014790\n",
      "step:   179880, time: 0.417, loss: 0.025721\n",
      "step:   179900, time: 0.377, loss: 0.010379\n",
      "step:   179920, time: 0.392, loss: 0.011119\n",
      "step:   179940, time: 0.393, loss: 0.015170\n",
      "step:   179960, time: 0.390, loss: 0.021068\n",
      "step:   179980, time: 0.422, loss: 0.014687\n",
      "step:   180000, time: 0.388, loss: 0.014146\n",
      "step:   180020, time: 0.404, loss: 0.014751\n",
      "step:   180040, time: 0.406, loss: 0.015079\n",
      "step:   180060, time: 0.417, loss: 0.014471\n",
      "step:   180080, time: 0.388, loss: 0.006061\n",
      "step:   180100, time: 0.393, loss: 0.012755\n",
      "step:   180120, time: 0.388, loss: 0.011652\n",
      "step:   180140, time: 0.395, loss: 0.007354\n",
      "step:   180160, time: 0.419, loss: 0.012267\n",
      "step:   180180, time: 0.394, loss: 0.020807\n",
      "step:   180200, time: 0.397, loss: 0.012259\n",
      "step:   180220, time: 0.397, loss: 0.015443\n",
      "step:   180240, time: 0.369, loss: 0.015341\n",
      "step:   180260, time: 0.399, loss: 0.014310\n",
      "step:   180280, time: 0.411, loss: 0.011051\n",
      "step:   180300, time: 0.385, loss: 0.015866\n",
      "step:   180320, time: 0.393, loss: 0.007010\n",
      "step:   180340, time: 0.373, loss: 0.013193\n",
      "step:   180360, time: 0.401, loss: 0.017318\n",
      "step:   180380, time: 0.408, loss: 0.010785\n",
      "step:   180400, time: 0.402, loss: 0.024812\n",
      "step:   180420, time: 0.402, loss: 0.007844\n",
      "step:   180440, time: 0.420, loss: 0.014423\n",
      "step:   180460, time: 0.399, loss: 0.007932\n",
      "step:   180480, time: 0.396, loss: 0.014335\n",
      "step:   180500, time: 0.394, loss: 0.013437\n",
      "step:   180520, time: 0.410, loss: 0.019392\n",
      "step:   180540, time: 0.377, loss: 0.015852\n",
      "step:   180560, time: 0.391, loss: 0.019303\n",
      "step:   180580, time: 0.415, loss: 0.010546\n",
      "step:   180600, time: 0.383, loss: 0.012745\n",
      "step:   180620, time: 0.408, loss: 0.016793\n",
      "step:   180640, time: 0.409, loss: 0.019742\n",
      "step:   180660, time: 0.401, loss: 0.017935\n",
      "step:   180680, time: 0.409, loss: 0.015567\n",
      "step:   180700, time: 0.389, loss: 0.021485\n",
      "step:   180720, time: 0.409, loss: 0.013835\n",
      "step:   180740, time: 0.410, loss: 0.012126\n",
      "step:   180760, time: 0.392, loss: 0.016943\n",
      "step:   180780, time: 0.414, loss: 0.015656\n",
      "step:   180800, time: 0.451, loss: 0.015775\n",
      "step:   180820, time: 0.423, loss: 0.024529\n",
      "step:   180840, time: 0.429, loss: 0.133002\n",
      "step:   180860, time: 0.391, loss: 0.014036\n",
      "step:   180880, time: 0.406, loss: 0.018274\n",
      "step:   180900, time: 0.407, loss: 0.015818\n",
      "step:   180920, time: 0.406, loss: 0.012565\n",
      "step:   180940, time: 0.382, loss: 0.011919\n",
      "step:   180960, time: 0.398, loss: 0.016914\n",
      "step:   180980, time: 0.424, loss: 0.010900\n",
      "step:   181000, time: 0.387, loss: 0.012546\n",
      "step:   181020, time: 0.428, loss: 0.016219\n",
      "step:   181040, time: 0.383, loss: 0.024020\n",
      "step:   181060, time: 0.393, loss: 0.015935\n",
      "step:   181080, time: 0.389, loss: 0.019671\n",
      "step:   181100, time: 0.449, loss: 0.023104\n",
      "step:   181120, time: 0.412, loss: 0.020192\n",
      "step:   181140, time: 0.404, loss: 0.007816\n",
      "step:   181160, time: 0.417, loss: 0.016883\n",
      "step:   181180, time: 0.388, loss: 0.011700\n",
      "step:   181200, time: 0.404, loss: 0.014966\n",
      "step:   181220, time: 0.379, loss: 0.031340\n",
      "step:   181240, time: 0.427, loss: 0.018057\n",
      "step:   181260, time: 0.394, loss: 0.010180\n",
      "step:   181280, time: 0.428, loss: 0.019103\n",
      "step:   181300, time: 0.397, loss: 0.017773\n",
      "step:   181320, time: 0.402, loss: 0.013962\n",
      "step:   181340, time: 0.385, loss: 0.018432\n",
      "step:   181360, time: 0.415, loss: 0.018277\n",
      "step:   181380, time: 0.393, loss: 0.010298\n",
      "step:   181400, time: 0.402, loss: 0.011670\n",
      "step:   181420, time: 0.389, loss: 0.021041\n",
      "step:   181440, time: 0.397, loss: 0.014269\n",
      "step:   181460, time: 0.414, loss: 0.017211\n",
      "step:   181480, time: 0.378, loss: 0.025920\n",
      "step:   181500, time: 0.371, loss: 0.009759\n",
      "step:   181520, time: 0.414, loss: 0.013751\n",
      "step:   181540, time: 0.411, loss: 0.014044\n",
      "step:   181560, time: 0.409, loss: 0.016645\n",
      "step:   181580, time: 0.407, loss: 0.013946\n",
      "step:   181600, time: 0.380, loss: 0.004948\n",
      "step:   181620, time: 0.393, loss: 0.014368\n",
      "step:   181640, time: 0.396, loss: 0.022247\n",
      "step:   181660, time: 0.408, loss: 0.013448\n",
      "step:   181680, time: 0.395, loss: 0.006283\n",
      "step:   181700, time: 0.429, loss: 0.168100\n",
      "step:   181720, time: 0.447, loss: 0.017105\n",
      "step:   181740, time: 0.387, loss: 0.009194\n",
      "step:   181760, time: 0.408, loss: 0.011387\n",
      "step:   181780, time: 0.407, loss: 0.021461\n",
      "step:   181800, time: 0.404, loss: 0.017543\n",
      "step:   181820, time: 0.425, loss: 0.012977\n",
      "step:   181840, time: 0.391, loss: 0.012370\n",
      "step:   181860, time: 0.390, loss: 0.008247\n",
      "step:   181880, time: 0.378, loss: 0.014664\n",
      "step:   181900, time: 0.420, loss: 0.009146\n",
      "step:   181920, time: 0.398, loss: 0.017467\n",
      "step:   181940, time: 0.418, loss: 0.013412\n",
      "step:   181960, time: 0.410, loss: 0.025638\n",
      "step:   181980, time: 0.404, loss: 0.021506\n",
      "step:   182000, time: 0.400, loss: 0.024489\n",
      "step:   182020, time: 0.405, loss: 0.015932\n",
      "step:   182040, time: 0.416, loss: 0.015873\n",
      "step:   182060, time: 0.401, loss: 0.010370\n",
      "step:   182080, time: 0.404, loss: 0.013933\n",
      "step:   182100, time: 0.409, loss: 0.009963\n",
      "step:   182120, time: 0.409, loss: 0.014029\n",
      "step:   182140, time: 0.413, loss: 0.016452\n",
      "step:   182160, time: 0.389, loss: 0.021365\n",
      "step:   182180, time: 0.383, loss: 0.011661\n",
      "step:   182200, time: 0.398, loss: 0.016347\n",
      "step:   182220, time: 0.400, loss: 0.016288\n",
      "step:   182240, time: 0.407, loss: 0.011952\n",
      "step:   182260, time: 0.407, loss: 0.017528\n",
      "step:   182280, time: 0.396, loss: 0.028586\n",
      "step:   182300, time: 0.407, loss: 0.019537\n",
      "step:   182320, time: 0.399, loss: 0.009280\n",
      "step:   182340, time: 0.387, loss: 0.010714\n",
      "step:   182360, time: 0.395, loss: 0.016670\n",
      "step:   182380, time: 0.412, loss: 0.018011\n",
      "step:   182400, time: 0.387, loss: 0.010832\n",
      "step:   182420, time: 0.414, loss: 0.013975\n",
      "step:   182440, time: 0.389, loss: 0.019367\n",
      "step:   182460, time: 0.402, loss: 0.018605\n",
      "step:   182480, time: 0.394, loss: 0.011414\n",
      "step:   182500, time: 0.408, loss: 0.012194\n",
      "step:   182520, time: 0.404, loss: 0.019851\n",
      "step:   182540, time: 0.415, loss: 0.015594\n",
      "step:   182560, time: 0.419, loss: 0.018576\n",
      "step:   182580, time: 0.409, loss: 0.007381\n",
      "step:   182600, time: 0.387, loss: 0.017323\n",
      "step:   182620, time: 0.381, loss: 0.014813\n",
      "step:   182640, time: 0.406, loss: 0.019405\n",
      "step:   182660, time: 0.412, loss: 0.007040\n",
      "step:   182680, time: 0.390, loss: 0.002991\n",
      "step:   182700, time: 0.393, loss: 0.006383\n",
      "step:   182720, time: 0.390, loss: 0.015754\n",
      "step:   182740, time: 0.418, loss: 0.014027\n",
      "step:   182760, time: 0.403, loss: 0.017010\n",
      "step:   182780, time: 0.420, loss: 0.015658\n",
      "step:   182800, time: 0.415, loss: 0.009675\n",
      "step:   182820, time: 0.430, loss: 0.020798\n",
      "step:   182840, time: 0.406, loss: 0.015016\n",
      "step:   182860, time: 0.381, loss: 0.013918\n",
      "step:   182880, time: 0.377, loss: 0.012546\n",
      "step:   182900, time: 0.410, loss: 0.014907\n",
      "step:   182920, time: 0.423, loss: 0.015881\n",
      "step:   182940, time: 0.391, loss: 0.016312\n",
      "step:   182960, time: 0.415, loss: 0.013901\n",
      "step:   182980, time: 0.403, loss: 0.017412\n",
      "step:   183000, time: 0.383, loss: 0.013686\n",
      "step:   183020, time: 0.394, loss: 0.022279\n",
      "step:   183040, time: 0.408, loss: 0.027006\n",
      "step:   183060, time: 0.393, loss: 0.014532\n",
      "step:   183080, time: 0.374, loss: 0.012120\n",
      "step:   183100, time: 0.401, loss: 0.009799\n",
      "step:   183120, time: 0.394, loss: 0.018573\n",
      "step:   183140, time: 0.398, loss: 0.019555\n",
      "step:   183160, time: 0.404, loss: 0.019760\n",
      "step:   183180, time: 0.394, loss: 0.022690\n",
      "step:   183200, time: 0.387, loss: 0.012699\n",
      "step:   183220, time: 0.386, loss: 0.010390\n",
      "step:   183240, time: 0.398, loss: 0.012220\n",
      "step:   183260, time: 0.426, loss: 0.020230\n",
      "step:   183280, time: 0.372, loss: 0.009516\n",
      "step:   183300, time: 0.422, loss: 0.020394\n",
      "step:   183320, time: 0.427, loss: 0.023220\n",
      "step:   183340, time: 0.382, loss: 0.023848\n",
      "step:   183360, time: 0.391, loss: 0.016333\n",
      "step:   183380, time: 0.404, loss: 0.016637\n",
      "step:   183400, time: 0.401, loss: 0.010754\n",
      "step:   183420, time: 0.406, loss: 0.013571\n",
      "step:   183440, time: 0.373, loss: 0.017942\n",
      "step:   183460, time: 0.400, loss: 0.011052\n",
      "step:   183480, time: 0.409, loss: 0.022140\n",
      "step:   183500, time: 0.413, loss: 0.017021\n",
      "step:   183520, time: 0.420, loss: 0.010068\n",
      "step:   183540, time: 0.414, loss: 0.012045\n",
      "step:   183560, time: 0.394, loss: 0.033927\n",
      "step:   183580, time: 0.396, loss: 0.013804\n",
      "step:   183600, time: 0.412, loss: 0.010206\n",
      "step:   183620, time: 0.391, loss: 0.016795\n",
      "step:   183640, time: 0.415, loss: 0.018407\n",
      "step:   183660, time: 0.482, loss: 0.081352\n",
      "step:   183680, time: 0.410, loss: 0.012650\n",
      "step:   183700, time: 0.410, loss: 0.016740\n",
      "step:   183720, time: 0.397, loss: 0.005302\n",
      "step:   183740, time: 0.415, loss: 0.017964\n",
      "step:   183760, time: 0.377, loss: 0.013745\n",
      "step:   183780, time: 0.417, loss: 0.015034\n",
      "step:   183800, time: 0.369, loss: 0.008454\n",
      "step:   183820, time: 0.422, loss: 0.013099\n",
      "step:   183840, time: 0.398, loss: 0.011862\n",
      "step:   183860, time: 0.431, loss: 0.010235\n",
      "step:   183880, time: 0.404, loss: 0.009551\n",
      "step:   183900, time: 0.413, loss: 0.010911\n",
      "step:   183920, time: 0.360, loss: 0.006423\n",
      "step:   183940, time: 0.405, loss: 0.010611\n",
      "step:   183960, time: 0.402, loss: 0.014995\n",
      "step:   183980, time: 0.411, loss: 0.013355\n",
      "step:   184000, time: 0.379, loss: 0.008878\n",
      "step:   184020, time: 0.400, loss: 0.019157\n",
      "step:   184040, time: 0.406, loss: 0.017395\n",
      "step:   184060, time: 0.402, loss: 0.019192\n",
      "step:   184080, time: 0.395, loss: 0.011533\n",
      "step:   184100, time: 0.412, loss: 0.014997\n",
      "step:   184120, time: 0.420, loss: 0.023303\n",
      "step:   184140, time: 0.392, loss: 0.022864\n",
      "step:   184160, time: 0.424, loss: 0.017593\n",
      "step:   184180, time: 0.407, loss: 0.010851\n",
      "step:   184200, time: 0.396, loss: 0.007265\n",
      "step:   184220, time: 0.401, loss: 0.016805\n",
      "step:   184240, time: 0.406, loss: 0.011712\n",
      "step:   184260, time: 0.405, loss: 0.112371\n",
      "step:   184280, time: 0.405, loss: 0.017042\n",
      "step:   184300, time: 0.423, loss: 0.021280\n",
      "step:   184320, time: 0.393, loss: 0.018550\n",
      "step:   184340, time: 0.384, loss: 0.014953\n",
      "step:   184360, time: 0.408, loss: 0.023862\n",
      "step:   184380, time: 0.404, loss: 0.006487\n",
      "step:   184400, time: 0.434, loss: 0.008966\n",
      "step:   184420, time: 0.407, loss: 0.007452\n",
      "step:   184440, time: 0.414, loss: 0.018953\n",
      "step:   184460, time: 0.415, loss: 0.016106\n",
      "step:   184480, time: 0.403, loss: 0.009900\n",
      "step:   184500, time: 0.392, loss: 0.008180\n",
      "step:   184520, time: 0.402, loss: 0.022750\n",
      "step:   184540, time: 0.422, loss: 0.021676\n",
      "step:   184560, time: 0.411, loss: 0.019395\n",
      "step:   184580, time: 0.431, loss: 0.015789\n",
      "step:   184600, time: 0.431, loss: 0.014600\n",
      "step:   184620, time: 0.391, loss: 0.014707\n",
      "step:   184640, time: 0.436, loss: 0.014148\n",
      "step:   184660, time: 0.400, loss: 0.020034\n",
      "step:   184680, time: 0.397, loss: 0.014484\n",
      "step:   184700, time: 0.379, loss: 0.014327\n",
      "step:   184720, time: 0.390, loss: 0.036681\n",
      "step:   184740, time: 0.390, loss: 0.019871\n",
      "step:   184760, time: 0.428, loss: 0.013961\n",
      "step:   184780, time: 0.388, loss: 0.019615\n",
      "step:   184800, time: 0.386, loss: 0.014682\n",
      "step:   184820, time: 0.394, loss: 0.016133\n",
      "step:   184840, time: 0.413, loss: 0.015147\n",
      "step:   184860, time: 0.423, loss: 0.016083\n",
      "step:   184880, time: 0.384, loss: 0.011777\n",
      "step:   184900, time: 0.375, loss: 0.022666\n",
      "step:   184920, time: 0.373, loss: 0.014165\n",
      "step:   184940, time: 0.391, loss: 0.017845\n",
      "step:   184960, time: 0.356, loss: 0.017965\n",
      "step:   184980, time: 0.380, loss: 0.014199\n",
      "step:   185000, time: 0.416, loss: 0.014961\n",
      "step:   185020, time: 0.421, loss: 0.012864\n",
      "step:   185040, time: 0.418, loss: 0.038930\n",
      "step:   185060, time: 0.431, loss: 0.022628\n",
      "step:   185080, time: 0.378, loss: 0.008472\n",
      "step:   185100, time: 0.383, loss: 0.004533\n",
      "step:   185120, time: 0.389, loss: 0.007959\n",
      "step:   185140, time: 0.419, loss: 0.008803\n",
      "step:   185160, time: 0.421, loss: 0.017094\n",
      "step:   185180, time: 0.425, loss: 0.012062\n",
      "step:   185200, time: 0.375, loss: 0.015908\n",
      "step:   185220, time: 0.399, loss: 0.019676\n",
      "step:   185240, time: 0.407, loss: 0.107416\n",
      "step:   185260, time: 0.383, loss: 0.015493\n",
      "step:   185280, time: 0.411, loss: 0.042652\n",
      "step:   185300, time: 0.386, loss: 0.007524\n",
      "step:   185320, time: 0.400, loss: 0.009733\n",
      "step:   185340, time: 0.399, loss: 0.020300\n",
      "step:   185360, time: 0.456, loss: 0.014371\n",
      "step:   185380, time: 0.419, loss: 0.016524\n",
      "step:   185400, time: 0.388, loss: 0.016432\n",
      "step:   185420, time: 0.401, loss: 0.007429\n",
      "step:   185440, time: 0.405, loss: 0.010764\n",
      "step:   185460, time: 0.407, loss: 0.015857\n",
      "step:   185480, time: 0.394, loss: 0.009459\n",
      "step:   185500, time: 0.409, loss: 0.011126\n",
      "step:   185520, time: 0.385, loss: 0.010290\n",
      "step:   185540, time: 0.418, loss: 0.109876\n",
      "step:   185560, time: 0.395, loss: 0.015334\n",
      "step:   185580, time: 0.390, loss: 0.013488\n",
      "step:   185600, time: 0.407, loss: 0.018088\n",
      "step:   185620, time: 0.388, loss: 0.021354\n",
      "step:   185640, time: 0.396, loss: 0.008289\n",
      "step:   185660, time: 0.408, loss: 0.014760\n",
      "step:   185680, time: 0.395, loss: 0.009429\n",
      "step:   185700, time: 0.384, loss: 0.013589\n",
      "step:   185720, time: 0.398, loss: 0.012732\n",
      "step:   185740, time: 0.424, loss: 0.011071\n",
      "step:   185760, time: 0.403, loss: 0.021725\n",
      "step:   185780, time: 0.414, loss: 0.016430\n",
      "step:   185800, time: 0.393, loss: 0.021414\n",
      "step:   185820, time: 0.384, loss: 0.009580\n",
      "step:   185840, time: 0.385, loss: 0.011488\n",
      "step:   185860, time: 0.395, loss: 0.020970\n",
      "step:   185880, time: 0.389, loss: 0.019946\n",
      "step:   185900, time: 0.387, loss: 0.013696\n",
      "step:   185920, time: 0.382, loss: 0.018668\n",
      "step:   185940, time: 0.385, loss: 0.013885\n",
      "step:   185960, time: 0.390, loss: 0.016841\n",
      "step:   185980, time: 0.393, loss: 0.016909\n",
      "step:   186000, time: 0.413, loss: 0.028565\n",
      "step:   186020, time: 0.377, loss: 0.007999\n",
      "step:   186040, time: 0.403, loss: 0.018616\n",
      "step:   186060, time: 0.384, loss: 0.006437\n",
      "step:   186080, time: 0.402, loss: 0.020536\n",
      "step:   186100, time: 0.389, loss: 0.019167\n",
      "step:   186120, time: 0.394, loss: 0.018679\n",
      "step:   186140, time: 0.406, loss: 0.013369\n",
      "step:   186160, time: 0.433, loss: 0.018736\n",
      "step:   186180, time: 0.404, loss: 0.011217\n",
      "step:   186200, time: 0.399, loss: 0.011981\n",
      "step:   186220, time: 0.413, loss: 0.013987\n",
      "step:   186240, time: 0.389, loss: 0.005813\n",
      "step:   186260, time: 0.409, loss: 0.010670\n",
      "step:   186280, time: 0.411, loss: 0.022458\n",
      "step:   186300, time: 0.384, loss: 0.019290\n",
      "step:   186320, time: 0.402, loss: 0.016305\n",
      "step:   186340, time: 0.418, loss: 0.014626\n",
      "step:   186360, time: 0.395, loss: 0.018236\n",
      "step:   186380, time: 0.414, loss: 0.012109\n",
      "step:   186400, time: 0.390, loss: 0.024027\n",
      "step:   186420, time: 0.373, loss: 0.013228\n",
      "step:   186440, time: 0.411, loss: 0.017171\n",
      "step:   186460, time: 0.415, loss: 0.015007\n",
      "step:   186480, time: 0.379, loss: 0.021012\n",
      "step:   186500, time: 0.401, loss: 0.012862\n",
      "step:   186520, time: 0.371, loss: 0.011593\n",
      "step:   186540, time: 0.419, loss: 0.019290\n",
      "step:   186560, time: 0.409, loss: 0.020525\n",
      "step:   186580, time: 0.402, loss: 0.016554\n",
      "step:   186600, time: 0.385, loss: 0.004064\n",
      "step:   186620, time: 0.395, loss: 0.013944\n",
      "step:   186640, time: 0.404, loss: 0.011347\n",
      "step:   186660, time: 0.415, loss: 0.014391\n",
      "step:   186680, time: 0.419, loss: 0.015521\n",
      "step:   186700, time: 0.404, loss: 0.018200\n",
      "step:   186720, time: 0.423, loss: 0.015156\n",
      "step:   186740, time: 0.415, loss: 0.014675\n",
      "step:   186760, time: 0.406, loss: 0.014732\n",
      "step:   186780, time: 0.384, loss: 0.009109\n",
      "step:   186800, time: 0.397, loss: 0.014959\n",
      "step:   186820, time: 0.399, loss: 0.011474\n",
      "step:   186840, time: 0.392, loss: 0.015132\n",
      "step:   186860, time: 0.388, loss: 0.004300\n",
      "step:   186880, time: 0.434, loss: 0.177053\n",
      "step:   186900, time: 0.438, loss: 0.014980\n",
      "step:   186920, time: 0.414, loss: 0.015045\n",
      "step:   186940, time: 0.387, loss: 0.032176\n",
      "step:   186960, time: 0.407, loss: 0.020474\n",
      "step:   186980, time: 0.378, loss: 0.015341\n",
      "step:   187000, time: 0.399, loss: 0.024609\n",
      "step:   187020, time: 0.384, loss: 0.013032\n",
      "step:   187040, time: 0.391, loss: 0.015954\n",
      "step:   187060, time: 0.405, loss: 0.014436\n",
      "step:   187080, time: 0.446, loss: 0.015980\n",
      "step:   187100, time: 0.409, loss: 0.019009\n",
      "step:   187120, time: 0.416, loss: 0.017826\n",
      "step:   187140, time: 0.420, loss: 0.034413\n",
      "step:   187160, time: 0.409, loss: 0.012954\n",
      "step:   187180, time: 0.380, loss: 0.013270\n",
      "step:   187200, time: 0.424, loss: 0.019727\n",
      "step:   187220, time: 0.398, loss: 0.012366\n",
      "step:   187240, time: 0.408, loss: 0.015970\n",
      "step:   187260, time: 0.398, loss: 0.023086\n",
      "step:   187280, time: 0.383, loss: 0.006179\n",
      "step:   187300, time: 0.436, loss: 0.179753\n",
      "step:   187320, time: 0.383, loss: 0.006572\n",
      "step:   187340, time: 0.397, loss: 0.013907\n",
      "step:   187360, time: 0.418, loss: 0.112007\n",
      "step:   187380, time: 0.379, loss: 0.010189\n",
      "step:   187400, time: 0.421, loss: 0.030625\n",
      "step:   187420, time: 0.381, loss: 0.015575\n",
      "step:   187440, time: 0.410, loss: 0.016186\n",
      "step:   187460, time: 0.423, loss: 0.012015\n",
      "step:   187480, time: 0.401, loss: 0.018349\n",
      "step:   187500, time: 0.415, loss: 0.011535\n",
      "step:   187520, time: 0.391, loss: 0.015463\n",
      "step:   187540, time: 0.403, loss: 0.012653\n",
      "step:   187560, time: 0.399, loss: 0.015612\n",
      "step:   187580, time: 0.421, loss: 0.019778\n",
      "step:   187600, time: 0.427, loss: 0.013487\n",
      "step:   187620, time: 0.390, loss: 0.019044\n",
      "step:   187640, time: 0.458, loss: 0.013035\n",
      "step:   187660, time: 0.416, loss: 0.010023\n",
      "step:   187680, time: 0.404, loss: 0.007316\n",
      "step:   187700, time: 0.434, loss: 0.084066\n",
      "step:   187720, time: 0.425, loss: 0.014517\n",
      "step:   187740, time: 0.431, loss: 0.017323\n",
      "step:   187760, time: 0.393, loss: 0.015838\n",
      "step:   187780, time: 0.409, loss: 0.015220\n",
      "step:   187800, time: 0.423, loss: 0.013207\n",
      "step:   187820, time: 0.408, loss: 0.012354\n",
      "step:   187840, time: 0.419, loss: 0.008880\n",
      "step:   187860, time: 0.418, loss: 0.015996\n",
      "step:   187880, time: 0.399, loss: 0.004274\n",
      "step:   187900, time: 0.404, loss: 0.017730\n",
      "step:   187920, time: 0.419, loss: 0.014327\n",
      "step:   187940, time: 0.408, loss: 0.007821\n",
      "step:   187960, time: 0.422, loss: 0.017051\n",
      "step:   187980, time: 0.383, loss: 0.016701\n",
      "step:   188000, time: 0.431, loss: 0.013661\n",
      "step:   188020, time: 0.445, loss: 0.015445\n",
      "step:   188040, time: 0.399, loss: 0.015526\n",
      "step:   188060, time: 0.401, loss: 0.011028\n",
      "step:   188080, time: 0.409, loss: 0.007230\n",
      "step:   188100, time: 0.389, loss: 0.008428\n",
      "step:   188120, time: 0.376, loss: 0.023112\n",
      "step:   188140, time: 0.432, loss: 0.127843\n",
      "step:   188160, time: 0.401, loss: 0.021859\n",
      "step:   188180, time: 0.417, loss: 0.024709\n",
      "step:   188200, time: 0.383, loss: 0.008987\n",
      "step:   188220, time: 0.392, loss: 0.015895\n",
      "step:   188240, time: 0.396, loss: 0.020835\n",
      "step:   188260, time: 0.384, loss: 0.008501\n",
      "step:   188280, time: 0.395, loss: 0.017801\n",
      "step:   188300, time: 0.407, loss: 0.011728\n",
      "step:   188320, time: 0.395, loss: 0.014487\n",
      "step:   188340, time: 0.412, loss: 0.015472\n",
      "step:   188360, time: 0.401, loss: 0.013539\n",
      "step:   188380, time: 0.406, loss: 0.117066\n",
      "step:   188400, time: 0.400, loss: 0.011165\n",
      "step:   188420, time: 0.369, loss: 0.008583\n",
      "step:   188440, time: 0.411, loss: 0.006036\n",
      "step:   188460, time: 0.398, loss: 0.018396\n",
      "step:   188480, time: 0.394, loss: 0.021741\n",
      "step:   188500, time: 0.371, loss: 0.014523\n",
      "step:   188520, time: 0.378, loss: 0.006051\n",
      "step:   188540, time: 0.391, loss: 0.008456\n",
      "step:   188560, time: 0.404, loss: 0.008242\n",
      "step:   188580, time: 0.385, loss: 0.016750\n",
      "step:   188600, time: 0.382, loss: 0.019703\n",
      "step:   188620, time: 0.391, loss: 0.008464\n",
      "step:   188640, time: 0.403, loss: 0.018212\n",
      "step:   188660, time: 0.415, loss: 0.017815\n",
      "step:   188680, time: 0.399, loss: 0.013037\n",
      "step:   188700, time: 0.401, loss: 0.010596\n",
      "step:   188720, time: 0.403, loss: 0.016437\n",
      "step:   188740, time: 0.423, loss: 0.014231\n",
      "step:   188760, time: 0.396, loss: 0.012733\n",
      "step:   188780, time: 0.397, loss: 0.011627\n",
      "step:   188800, time: 0.381, loss: 0.015054\n",
      "step:   188820, time: 0.410, loss: 0.021854\n",
      "step:   188840, time: 0.412, loss: 0.010927\n",
      "step:   188860, time: 0.389, loss: 0.019597\n",
      "step:   188880, time: 0.393, loss: 0.016937\n",
      "step:   188900, time: 0.411, loss: 0.010225\n",
      "step:   188920, time: 0.398, loss: 0.014444\n",
      "step:   188940, time: 0.402, loss: 0.015041\n",
      "step:   188960, time: 0.412, loss: 0.014420\n",
      "step:   188980, time: 0.389, loss: 0.014425\n",
      "step:   189000, time: 0.389, loss: 0.013809\n",
      "step:   189020, time: 0.387, loss: 0.010252\n",
      "step:   189040, time: 0.412, loss: 0.021084\n",
      "step:   189060, time: 0.428, loss: 0.014373\n",
      "step:   189080, time: 0.372, loss: 0.013420\n",
      "step:   189100, time: 0.407, loss: 0.020439\n",
      "step:   189120, time: 0.406, loss: 0.013349\n",
      "step:   189140, time: 0.418, loss: 0.020341\n",
      "step:   189160, time: 0.397, loss: 0.013762\n",
      "step:   189180, time: 0.384, loss: 0.020793\n",
      "step:   189200, time: 0.406, loss: 0.006944\n",
      "step:   189220, time: 0.405, loss: 0.015362\n",
      "step:   189240, time: 0.411, loss: 0.009797\n",
      "step:   189260, time: 0.392, loss: 0.012867\n",
      "step:   189280, time: 0.425, loss: 0.018164\n",
      "step:   189300, time: 0.387, loss: 0.015729\n",
      "step:   189320, time: 0.401, loss: 0.019943\n",
      "step:   189340, time: 0.389, loss: 0.019021\n",
      "step:   189360, time: 0.421, loss: 0.016473\n",
      "step:   189380, time: 0.400, loss: 0.010596\n",
      "step:   189400, time: 0.422, loss: 0.017347\n",
      "step:   189420, time: 0.391, loss: 0.007549\n",
      "step:   189440, time: 0.390, loss: 0.020906\n",
      "step:   189460, time: 0.406, loss: 0.015137\n",
      "step:   189480, time: 0.402, loss: 0.024639\n",
      "step:   189500, time: 0.401, loss: 0.023695\n",
      "step:   189520, time: 0.401, loss: 0.021905\n",
      "step:   189540, time: 0.434, loss: 0.026110\n",
      "step:   189560, time: 0.405, loss: 0.014836\n",
      "step:   189580, time: 0.418, loss: 0.010258\n",
      "step:   189600, time: 0.402, loss: 0.013317\n",
      "step:   189620, time: 0.422, loss: 0.109442\n",
      "step:   189640, time: 0.410, loss: 0.013523\n",
      "step:   189660, time: 0.380, loss: 0.011041\n",
      "step:   189680, time: 0.360, loss: 0.020911\n",
      "step:   189700, time: 0.409, loss: 0.013886\n",
      "step:   189720, time: 0.402, loss: 0.010510\n",
      "step:   189740, time: 0.414, loss: 0.006406\n",
      "step:   189760, time: 0.417, loss: 0.012937\n",
      "step:   189780, time: 0.406, loss: 0.017087\n",
      "step:   189800, time: 0.395, loss: 0.007731\n",
      "step:   189820, time: 0.371, loss: 0.009665\n",
      "step:   189840, time: 0.392, loss: 0.015875\n",
      "step:   189860, time: 0.396, loss: 0.017432\n",
      "step:   189880, time: 0.409, loss: 0.012434\n",
      "step:   189900, time: 0.402, loss: 0.017203\n",
      "step:   189920, time: 0.388, loss: 0.012974\n",
      "step:   189940, time: 0.387, loss: 0.023869\n",
      "step:   189960, time: 0.381, loss: 0.015304\n",
      "step:   189980, time: 0.388, loss: 0.008754\n",
      "step:   190000, time: 0.377, loss: 0.016261\n",
      "step:   190020, time: 0.386, loss: 0.012967\n",
      "step:   190040, time: 0.375, loss: 0.019309\n",
      "step:   190060, time: 0.397, loss: 0.017953\n",
      "step:   190080, time: 0.402, loss: 0.012866\n",
      "step:   190100, time: 0.382, loss: 0.009492\n",
      "step:   190120, time: 0.396, loss: 0.016761\n",
      "step:   190140, time: 0.419, loss: 0.018962\n",
      "step:   190160, time: 0.401, loss: 0.019252\n",
      "step:   190180, time: 0.396, loss: 0.025623\n",
      "step:   190200, time: 0.388, loss: 0.007461\n",
      "step:   190220, time: 0.372, loss: 0.017027\n",
      "step:   190240, time: 0.375, loss: 0.009007\n",
      "step:   190260, time: 0.388, loss: 0.011333\n",
      "step:   190280, time: 0.404, loss: 0.014260\n",
      "step:   190300, time: 0.398, loss: 0.014685\n",
      "step:   190320, time: 0.434, loss: 0.012678\n",
      "step:   190340, time: 0.400, loss: 0.015647\n",
      "step:   190360, time: 0.407, loss: 0.011780\n",
      "step:   190380, time: 0.406, loss: 0.012276\n",
      "step:   190400, time: 0.436, loss: 0.020483\n",
      "step:   190420, time: 0.419, loss: 0.014684\n",
      "step:   190440, time: 0.420, loss: 0.017783\n",
      "step:   190460, time: 0.413, loss: 0.010390\n",
      "step:   190480, time: 0.437, loss: 0.015319\n",
      "step:   190500, time: 0.431, loss: 0.016926\n",
      "step:   190520, time: 0.409, loss: 0.005753\n",
      "step:   190540, time: 0.419, loss: 0.009863\n",
      "step:   190560, time: 0.404, loss: 0.011251\n",
      "step:   190580, time: 0.402, loss: 0.020397\n",
      "step:   190600, time: 0.404, loss: 0.013048\n",
      "step:   190620, time: 0.391, loss: 0.015211\n",
      "step:   190640, time: 0.426, loss: 0.018792\n",
      "step:   190660, time: 0.420, loss: 0.012686\n",
      "step:   190680, time: 0.422, loss: 0.015159\n",
      "step:   190700, time: 0.402, loss: 0.008695\n",
      "step:   190720, time: 0.399, loss: 0.026334\n",
      "step:   190740, time: 0.390, loss: 0.020157\n",
      "step:   190760, time: 0.413, loss: 0.013115\n",
      "step:   190780, time: 0.411, loss: 0.022467\n",
      "step:   190800, time: 0.381, loss: 0.016646\n",
      "step:   190820, time: 0.390, loss: 0.018675\n",
      "step:   190840, time: 0.380, loss: 0.012151\n",
      "step:   190860, time: 0.412, loss: 0.010862\n",
      "step:   190880, time: 0.386, loss: 0.010969\n",
      "step:   190900, time: 0.389, loss: 0.019715\n",
      "step:   190920, time: 0.388, loss: 0.013589\n",
      "step:   190940, time: 0.395, loss: 0.009169\n",
      "step:   190960, time: 0.400, loss: 0.014034\n",
      "step:   190980, time: 0.408, loss: 0.009580\n",
      "step:   191000, time: 0.398, loss: 0.013114\n",
      "step:   191020, time: 0.400, loss: 0.019374\n",
      "step:   191040, time: 0.398, loss: 0.012669\n",
      "step:   191060, time: 0.401, loss: 0.012817\n",
      "step:   191080, time: 0.389, loss: 0.012751\n",
      "step:   191100, time: 0.369, loss: 0.004034\n",
      "step:   191120, time: 0.417, loss: 0.012015\n",
      "step:   191140, time: 0.410, loss: 0.018768\n",
      "step:   191160, time: 0.416, loss: 0.017992\n",
      "step:   191180, time: 0.382, loss: 0.019440\n",
      "step:   191200, time: 0.390, loss: 0.018468\n",
      "step:   191220, time: 0.417, loss: 0.017182\n",
      "step:   191240, time: 0.418, loss: 0.003836\n",
      "step:   191260, time: 0.388, loss: 0.008660\n",
      "step:   191280, time: 0.419, loss: 0.016261\n",
      "step:   191300, time: 0.402, loss: 0.022693\n",
      "step:   191320, time: 0.396, loss: 0.018164\n",
      "step:   191340, time: 0.414, loss: 0.014151\n",
      "step:   191360, time: 0.381, loss: 0.011036\n",
      "step:   191380, time: 0.377, loss: 0.007273\n",
      "step:   191400, time: 0.388, loss: 0.010101\n",
      "step:   191420, time: 0.419, loss: 0.016784\n",
      "step:   191440, time: 0.399, loss: 0.006032\n",
      "step:   191460, time: 0.411, loss: 0.023082\n",
      "step:   191480, time: 0.413, loss: 0.013800\n",
      "step:   191500, time: 0.403, loss: 0.011515\n",
      "step:   191520, time: 0.388, loss: 0.011164\n",
      "step:   191540, time: 0.420, loss: 0.017657\n",
      "step:   191560, time: 0.407, loss: 0.014557\n",
      "step:   191580, time: 0.379, loss: 0.013992\n",
      "step:   191600, time: 0.381, loss: 0.010173\n",
      "step:   191620, time: 0.374, loss: 0.015318\n",
      "step:   191640, time: 0.407, loss: 0.023214\n",
      "step:   191660, time: 0.389, loss: 0.009008\n",
      "step:   191680, time: 0.392, loss: 0.010883\n",
      "step:   191700, time: 0.396, loss: 0.022033\n",
      "step:   191720, time: 0.421, loss: 0.007230\n",
      "step:   191740, time: 0.408, loss: 0.012181\n",
      "step:   191760, time: 0.397, loss: 0.019485\n",
      "step:   191780, time: 0.419, loss: 0.012366\n",
      "step:   191800, time: 0.383, loss: 0.014124\n",
      "step:   191820, time: 0.369, loss: 0.006393\n",
      "step:   191840, time: 0.409, loss: 0.010110\n",
      "step:   191860, time: 0.423, loss: 0.015988\n",
      "step:   191880, time: 0.396, loss: 0.016259\n",
      "step:   191900, time: 0.387, loss: 0.010384\n",
      "step:   191920, time: 0.392, loss: 0.010805\n",
      "step:   191940, time: 0.389, loss: 0.013477\n",
      "step:   191960, time: 0.409, loss: 0.010316\n",
      "step:   191980, time: 0.428, loss: 0.013293\n",
      "step:   192000, time: 0.387, loss: 0.014756\n",
      "step:   192020, time: 0.407, loss: 0.010563\n",
      "step:   192040, time: 0.379, loss: 0.004150\n",
      "step:   192060, time: 0.380, loss: 0.013842\n",
      "step:   192080, time: 0.392, loss: 0.014538\n",
      "step:   192100, time: 0.443, loss: 0.017790\n",
      "step:   192120, time: 0.395, loss: 0.006518\n",
      "step:   192140, time: 0.398, loss: 0.017089\n",
      "step:   192160, time: 0.387, loss: 0.011860\n",
      "step:   192180, time: 0.381, loss: 0.008003\n",
      "step:   192200, time: 0.424, loss: 0.011591\n",
      "step:   192220, time: 0.395, loss: 0.007939\n",
      "step:   192240, time: 0.422, loss: 0.011343\n",
      "step:   192260, time: 0.454, loss: 0.015118\n",
      "step:   192280, time: 0.410, loss: 0.015630\n",
      "step:   192300, time: 0.383, loss: 0.003387\n",
      "step:   192320, time: 0.394, loss: 0.017072\n",
      "step:   192340, time: 0.429, loss: 0.011141\n",
      "step:   192360, time: 0.387, loss: 0.010988\n",
      "step:   192380, time: 0.379, loss: 0.014936\n",
      "step:   192400, time: 0.392, loss: 0.021607\n",
      "step:   192420, time: 0.404, loss: 0.011159\n",
      "step:   192440, time: 0.405, loss: 0.014417\n",
      "step:   192460, time: 0.441, loss: 0.012192\n",
      "step:   192480, time: 0.392, loss: 0.009313\n",
      "step:   192500, time: 0.400, loss: 0.030174\n",
      "step:   192520, time: 0.398, loss: 0.021101\n",
      "step:   192540, time: 0.397, loss: 0.005946\n",
      "step:   192560, time: 0.376, loss: 0.018492\n",
      "step:   192580, time: 0.387, loss: 0.004532\n",
      "step:   192600, time: 0.386, loss: 0.014007\n",
      "step:   192620, time: 0.395, loss: 0.018703\n",
      "step:   192640, time: 0.423, loss: 0.023439\n",
      "step:   192660, time: 0.361, loss: 0.019301\n",
      "step:   192680, time: 0.407, loss: 0.020173\n",
      "step:   192700, time: 0.400, loss: 0.015054\n",
      "step:   192720, time: 0.423, loss: 0.020560\n",
      "step:   192740, time: 0.407, loss: 0.010543\n",
      "step:   192760, time: 0.416, loss: 0.017026\n",
      "step:   192780, time: 0.410, loss: 0.012669\n",
      "step:   192800, time: 0.404, loss: 0.020609\n",
      "step:   192820, time: 0.409, loss: 0.019411\n",
      "step:   192840, time: 0.434, loss: 0.107824\n",
      "step:   192860, time: 0.373, loss: 0.015319\n",
      "step:   192880, time: 0.396, loss: 0.013428\n",
      "step:   192900, time: 0.407, loss: 0.015268\n",
      "step:   192920, time: 0.410, loss: 0.014355\n",
      "step:   192940, time: 0.389, loss: 0.013323\n",
      "step:   192960, time: 0.402, loss: 0.015220\n",
      "step:   192980, time: 0.413, loss: 0.016094\n",
      "step:   193000, time: 0.455, loss: 0.009299\n",
      "step:   193020, time: 0.406, loss: 0.017713\n",
      "step:   193040, time: 0.397, loss: 0.011866\n",
      "step:   193060, time: 0.412, loss: 0.019388\n",
      "step:   193080, time: 0.440, loss: 0.037721\n",
      "step:   193100, time: 0.411, loss: 0.015031\n",
      "step:   193120, time: 0.411, loss: 0.014450\n",
      "step:   193140, time: 0.394, loss: 0.012845\n",
      "step:   193160, time: 0.423, loss: 0.011120\n",
      "step:   193180, time: 0.415, loss: 0.017560\n",
      "step:   193200, time: 0.408, loss: 0.018347\n",
      "step:   193220, time: 0.381, loss: 0.019861\n",
      "step:   193240, time: 0.397, loss: 0.018466\n",
      "step:   193260, time: 0.405, loss: 0.014635\n",
      "step:   193280, time: 0.380, loss: 0.009360\n",
      "step:   193300, time: 0.393, loss: 0.019455\n",
      "step:   193320, time: 0.390, loss: 0.007009\n",
      "step:   193340, time: 0.419, loss: 0.010861\n",
      "step:   193360, time: 0.429, loss: 0.015206\n",
      "step:   193380, time: 0.381, loss: 0.007426\n",
      "step:   193400, time: 0.395, loss: 0.017551\n",
      "step:   193420, time: 0.399, loss: 0.018379\n",
      "step:   193440, time: 0.369, loss: 0.011243\n",
      "step:   193460, time: 0.381, loss: 0.019205\n",
      "step:   193480, time: 0.395, loss: 0.017408\n",
      "step:   193500, time: 0.390, loss: 0.011819\n",
      "step:   193520, time: 0.402, loss: 0.013847\n",
      "step:   193540, time: 0.387, loss: 0.013904\n",
      "step:   193560, time: 0.425, loss: 0.022571\n",
      "step:   193580, time: 0.389, loss: 0.009668\n",
      "step:   193600, time: 0.396, loss: 0.014248\n",
      "step:   193620, time: 0.383, loss: 0.018894\n",
      "step:   193640, time: 0.397, loss: 0.020928\n",
      "step:   193660, time: 0.383, loss: 0.012781\n",
      "step:   193680, time: 0.410, loss: 0.011383\n",
      "step:   193700, time: 0.398, loss: 0.014692\n",
      "step:   193720, time: 0.407, loss: 0.014984\n",
      "step:   193740, time: 0.434, loss: 0.011324\n",
      "step:   193760, time: 0.402, loss: 0.019230\n",
      "step:   193780, time: 0.430, loss: 0.014534\n",
      "step:   193800, time: 0.405, loss: 0.016114\n",
      "step:   193820, time: 0.399, loss: 0.012004\n",
      "step:   193840, time: 0.384, loss: 0.024825\n",
      "step:   193860, time: 0.397, loss: 0.015853\n",
      "step:   193880, time: 0.426, loss: 0.074076\n",
      "step:   193900, time: 0.394, loss: 0.015273\n",
      "step:   193920, time: 0.477, loss: 0.016010\n",
      "step:   193940, time: 0.409, loss: 0.017348\n",
      "step:   193960, time: 0.404, loss: 0.016937\n",
      "step:   193980, time: 0.371, loss: 0.014548\n",
      "step:   194000, time: 0.369, loss: 0.009833\n",
      "step:   194020, time: 0.401, loss: 0.019720\n",
      "step:   194040, time: 0.390, loss: 0.013876\n",
      "step:   194060, time: 0.398, loss: 0.023655\n",
      "step:   194080, time: 0.396, loss: 0.012741\n",
      "step:   194100, time: 0.384, loss: 0.010820\n",
      "step:   194120, time: 0.435, loss: 0.019329\n",
      "step:   194140, time: 0.395, loss: 0.012931\n",
      "step:   194160, time: 0.386, loss: 0.022579\n",
      "step:   194180, time: 0.400, loss: 0.013997\n",
      "step:   194200, time: 0.416, loss: 0.020734\n",
      "step:   194220, time: 0.400, loss: 0.018030\n",
      "step:   194240, time: 0.418, loss: 0.017900\n",
      "step:   194260, time: 0.407, loss: 0.015609\n",
      "step:   194280, time: 0.377, loss: 0.012344\n",
      "step:   194300, time: 0.392, loss: 0.008742\n",
      "step:   194320, time: 0.400, loss: 0.016824\n",
      "step:   194340, time: 0.389, loss: 0.012059\n",
      "step:   194360, time: 0.399, loss: 0.011418\n",
      "step:   194380, time: 0.379, loss: 0.018994\n",
      "step:   194400, time: 0.404, loss: 0.009340\n",
      "step:   194420, time: 0.382, loss: 0.015531\n",
      "step:   194440, time: 0.430, loss: 0.020298\n",
      "step:   194460, time: 0.397, loss: 0.012902\n",
      "step:   194480, time: 0.428, loss: 0.013385\n",
      "step:   194500, time: 0.398, loss: 0.022113\n",
      "step:   194520, time: 0.409, loss: 0.017573\n",
      "step:   194540, time: 0.388, loss: 0.013590\n",
      "step:   194560, time: 0.394, loss: 0.009552\n",
      "step:   194580, time: 0.414, loss: 0.012267\n",
      "step:   194600, time: 0.405, loss: 0.019811\n",
      "step:   194620, time: 0.408, loss: 0.019051\n",
      "step:   194640, time: 0.414, loss: 0.018119\n",
      "step:   194660, time: 0.436, loss: 0.019296\n",
      "step:   194680, time: 0.411, loss: 0.010808\n",
      "step:   194700, time: 0.391, loss: 0.018516\n",
      "step:   194720, time: 0.391, loss: 0.012211\n",
      "step:   194740, time: 0.387, loss: 0.018841\n",
      "step:   194760, time: 0.391, loss: 0.018395\n",
      "step:   194780, time: 0.423, loss: 0.013468\n",
      "step:   194800, time: 0.400, loss: 0.018900\n",
      "step:   194820, time: 0.414, loss: 0.072289\n",
      "step:   194840, time: 0.411, loss: 0.011824\n",
      "step:   194860, time: 0.390, loss: 0.017957\n",
      "step:   194880, time: 0.401, loss: 0.020345\n",
      "step:   194900, time: 0.422, loss: 0.013709\n",
      "step:   194920, time: 0.433, loss: 0.012386\n",
      "step:   194940, time: 0.416, loss: 0.016321\n",
      "step:   194960, time: 0.401, loss: 0.011527\n",
      "step:   194980, time: 0.391, loss: 0.007209\n",
      "step:   195000, time: 0.389, loss: 0.017010\n",
      "step:   195020, time: 0.414, loss: 0.012571\n",
      "step:   195040, time: 0.430, loss: 0.017539\n",
      "step:   195060, time: 0.388, loss: 0.010979\n",
      "step:   195080, time: 0.398, loss: 0.010140\n",
      "step:   195100, time: 0.405, loss: 0.006324\n",
      "step:   195120, time: 0.406, loss: 0.014104\n",
      "step:   195140, time: 0.388, loss: 0.031715\n",
      "step:   195160, time: 0.414, loss: 0.016856\n",
      "step:   195180, time: 0.410, loss: 0.017313\n",
      "step:   195200, time: 0.425, loss: 0.009052\n",
      "step:   195220, time: 0.418, loss: 0.016455\n",
      "step:   195240, time: 0.385, loss: 0.014731\n",
      "step:   195260, time: 0.430, loss: 0.067071\n",
      "step:   195280, time: 0.380, loss: 0.019800\n",
      "step:   195300, time: 0.401, loss: 0.019915\n",
      "step:   195320, time: 0.397, loss: 0.016660\n",
      "step:   195340, time: 0.406, loss: 0.018190\n",
      "step:   195360, time: 0.403, loss: 0.016873\n",
      "step:   195380, time: 0.383, loss: 0.007513\n",
      "step:   195400, time: 0.428, loss: 0.018965\n",
      "step:   195420, time: 0.433, loss: 0.014336\n",
      "step:   195440, time: 0.401, loss: 0.012843\n",
      "step:   195460, time: 0.391, loss: 0.017171\n",
      "step:   195480, time: 0.404, loss: 0.025146\n",
      "step:   195500, time: 0.419, loss: 0.014536\n",
      "step:   195520, time: 0.421, loss: 0.082239\n",
      "step:   195540, time: 0.397, loss: 0.018428\n",
      "step:   195560, time: 0.409, loss: 0.011249\n",
      "step:   195580, time: 0.122, loss: 0.014440\n",
      "step:   195600, time: 0.380, loss: 0.015577\n",
      "step:   195620, time: 0.390, loss: 0.010418\n",
      "step:   195640, time: 0.437, loss: 0.016363\n",
      "step:   195660, time: 0.403, loss: 0.014460\n",
      "step:   195680, time: 0.420, loss: 0.012443\n",
      "step:   195700, time: 0.393, loss: 0.007633\n",
      "step:   195720, time: 0.399, loss: 0.021124\n",
      "step:   195740, time: 0.388, loss: 0.014798\n",
      "step:   195760, time: 0.392, loss: 0.011260\n",
      "step:   195780, time: 0.384, loss: 0.010482\n",
      "step:   195800, time: 0.432, loss: 0.055326\n",
      "step:   195820, time: 0.400, loss: 0.009653\n",
      "step:   195840, time: 0.401, loss: 0.019720\n",
      "step:   195860, time: 0.389, loss: 0.011298\n",
      "step:   195880, time: 0.424, loss: 0.011741\n",
      "step:   195900, time: 0.383, loss: 0.005462\n",
      "step:   195920, time: 0.407, loss: 0.020114\n",
      "step:   195940, time: 0.388, loss: 0.018905\n",
      "step:   195960, time: 0.406, loss: 0.017177\n",
      "step:   195980, time: 0.410, loss: 0.003874\n",
      "step:   196000, time: 0.412, loss: 0.017412\n",
      "step:   196020, time: 0.400, loss: 0.012978\n",
      "step:   196040, time: 0.411, loss: 0.006090\n",
      "step:   196060, time: 0.411, loss: 0.013546\n",
      "step:   196080, time: 0.398, loss: 0.006336\n",
      "step:   196100, time: 0.400, loss: 0.009250\n",
      "step:   196120, time: 0.412, loss: 0.021598\n",
      "step:   196140, time: 0.411, loss: 0.023504\n",
      "step:   196160, time: 0.404, loss: 0.018283\n",
      "step:   196180, time: 0.391, loss: 0.012213\n",
      "step:   196200, time: 0.380, loss: 0.011388\n",
      "step:   196220, time: 0.419, loss: 0.015878\n",
      "step:   196240, time: 0.388, loss: 0.014165\n",
      "step:   196260, time: 0.391, loss: 0.024953\n",
      "step:   196280, time: 0.374, loss: 0.010043\n",
      "step:   196300, time: 0.417, loss: 0.022134\n",
      "step:   196320, time: 0.408, loss: 0.017683\n",
      "step:   196340, time: 0.422, loss: 0.019852\n",
      "step:   196360, time: 0.418, loss: 0.013809\n",
      "step:   196380, time: 0.415, loss: 0.003990\n",
      "step:   196400, time: 0.390, loss: 0.015502\n",
      "step:   196420, time: 0.426, loss: 0.012147\n",
      "step:   196440, time: 0.383, loss: 0.015952\n",
      "step:   196460, time: 0.375, loss: 0.006891\n",
      "step:   196480, time: 0.381, loss: 0.013458\n",
      "step:   196500, time: 0.426, loss: 0.020898\n",
      "step:   196520, time: 0.380, loss: 0.005432\n",
      "step:   196540, time: 0.405, loss: 0.019034\n",
      "step:   196560, time: 0.401, loss: 0.013216\n",
      "step:   196580, time: 0.392, loss: 0.015974\n",
      "step:   196600, time: 0.423, loss: 0.019912\n",
      "step:   196620, time: 0.394, loss: 0.015602\n",
      "step:   196640, time: 0.393, loss: 0.017126\n",
      "step:   196660, time: 0.384, loss: 0.008857\n",
      "step:   196680, time: 0.430, loss: 0.017610\n",
      "step:   196700, time: 0.393, loss: 0.022310\n",
      "step:   196720, time: 0.389, loss: 0.013961\n",
      "step:   196740, time: 0.422, loss: 0.018003\n",
      "step:   196760, time: 0.413, loss: 0.010597\n",
      "step:   196780, time: 0.396, loss: 0.012379\n",
      "step:   196800, time: 0.412, loss: 0.023490\n",
      "step:   196820, time: 0.377, loss: 0.012301\n",
      "step:   196840, time: 0.388, loss: 0.003150\n",
      "step:   196860, time: 0.401, loss: 0.018767\n",
      "step:   196880, time: 0.405, loss: 0.013373\n",
      "step:   196900, time: 0.380, loss: 0.017423\n",
      "step:   196920, time: 0.384, loss: 0.015552\n",
      "step:   196940, time: 0.398, loss: 0.010209\n",
      "step:   196960, time: 0.420, loss: 0.021220\n",
      "step:   196980, time: 0.386, loss: 0.019582\n",
      "step:   197000, time: 0.407, loss: 0.014002\n",
      "step:   197020, time: 0.388, loss: 0.018230\n",
      "step:   197040, time: 0.416, loss: 0.003915\n",
      "step:   197060, time: 0.406, loss: 0.018350\n",
      "step:   197080, time: 0.414, loss: 0.019411\n",
      "step:   197100, time: 0.410, loss: 0.010000\n",
      "step:   197120, time: 0.386, loss: 0.018619\n",
      "step:   197140, time: 0.425, loss: 0.021073\n",
      "step:   197160, time: 0.460, loss: 0.014013\n",
      "step:   197180, time: 0.399, loss: 0.005226\n",
      "step:   197200, time: 0.406, loss: 0.011110\n",
      "step:   197220, time: 0.407, loss: 0.009821\n",
      "step:   197240, time: 0.432, loss: 0.015570\n",
      "step:   197260, time: 0.442, loss: 0.008607\n",
      "step:   197280, time: 0.394, loss: 0.011248\n",
      "step:   197300, time: 0.396, loss: 0.011123\n",
      "step:   197320, time: 0.405, loss: 0.010902\n",
      "step:   197340, time: 0.416, loss: 0.015586\n",
      "step:   197360, time: 0.391, loss: 0.008990\n",
      "step:   197380, time: 0.407, loss: 0.021118\n",
      "step:   197400, time: 0.421, loss: 0.012880\n",
      "step:   197420, time: 0.412, loss: 0.010924\n",
      "step:   197440, time: 0.400, loss: 0.011080\n",
      "step:   197460, time: 0.402, loss: 0.022998\n",
      "step:   197480, time: 0.398, loss: 0.015751\n",
      "step:   197500, time: 0.377, loss: 0.024868\n",
      "step:   197520, time: 0.428, loss: 0.163152\n",
      "step:   197540, time: 0.421, loss: 0.015727\n",
      "step:   197560, time: 0.384, loss: 0.010048\n",
      "step:   197580, time: 0.410, loss: 0.018073\n",
      "step:   197600, time: 0.397, loss: 0.008897\n",
      "step:   197620, time: 0.394, loss: 0.007904\n",
      "step:   197640, time: 0.397, loss: 0.008162\n",
      "step:   197660, time: 0.406, loss: 0.018273\n",
      "step:   197680, time: 0.419, loss: 0.016030\n",
      "step:   197700, time: 0.414, loss: 0.011726\n",
      "step:   197720, time: 0.411, loss: 0.014188\n",
      "step:   197740, time: 0.381, loss: 0.018673\n",
      "step:   197760, time: 0.411, loss: 0.011969\n",
      "step:   197780, time: 0.387, loss: 0.011346\n",
      "step:   197800, time: 0.397, loss: 0.036240\n",
      "step:   197820, time: 0.404, loss: 0.011073\n",
      "step:   197840, time: 0.408, loss: 0.008167\n",
      "step:   197860, time: 0.409, loss: 0.010974\n",
      "step:   197880, time: 0.418, loss: 0.024293\n",
      "step:   197900, time: 0.425, loss: 0.015771\n",
      "step:   197920, time: 0.392, loss: 0.009461\n",
      "step:   197940, time: 0.415, loss: 0.015126\n",
      "step:   197960, time: 0.398, loss: 0.013526\n",
      "step:   197980, time: 0.387, loss: 0.016669\n",
      "step:   198000, time: 0.383, loss: 0.010474\n",
      "step:   198020, time: 0.387, loss: 0.012150\n",
      "step:   198040, time: 0.407, loss: 0.017513\n",
      "step:   198060, time: 0.406, loss: 0.017313\n",
      "step:   198080, time: 0.413, loss: 0.012809\n",
      "step:   198100, time: 0.410, loss: 0.018567\n",
      "step:   198120, time: 0.424, loss: 0.021973\n",
      "step:   198140, time: 0.392, loss: 0.007387\n",
      "step:   198160, time: 0.403, loss: 0.010960\n",
      "step:   198180, time: 0.409, loss: 0.017705\n",
      "step:   198200, time: 0.393, loss: 0.020971\n",
      "step:   198220, time: 0.379, loss: 0.015880\n",
      "step:   198240, time: 0.385, loss: 0.031021\n",
      "step:   198260, time: 0.433, loss: 0.017256\n",
      "step:   198280, time: 0.385, loss: 0.016387\n",
      "step:   198300, time: 0.398, loss: 0.008897\n",
      "step:   198320, time: 0.433, loss: 0.110054\n",
      "step:   198340, time: 0.423, loss: 0.016429\n",
      "step:   198360, time: 0.393, loss: 0.019171\n",
      "step:   198380, time: 0.400, loss: 0.008957\n",
      "step:   198400, time: 0.404, loss: 0.012708\n",
      "step:   198420, time: 0.409, loss: 0.014364\n",
      "step:   198440, time: 0.432, loss: 0.018875\n",
      "step:   198460, time: 0.385, loss: 0.016042\n",
      "step:   198480, time: 0.391, loss: 0.014051\n",
      "step:   198500, time: 0.421, loss: 0.010008\n",
      "step:   198520, time: 0.413, loss: 0.008882\n",
      "step:   198540, time: 0.403, loss: 0.007050\n",
      "step:   198560, time: 0.387, loss: 0.018543\n",
      "step:   198580, time: 0.390, loss: 0.016759\n",
      "step:   198600, time: 0.438, loss: 0.020751\n",
      "step:   198620, time: 0.359, loss: 0.015488\n",
      "step:   198640, time: 0.397, loss: 0.012960\n",
      "step:   198660, time: 0.395, loss: 0.021240\n",
      "step:   198680, time: 0.425, loss: 0.016624\n",
      "step:   198700, time: 0.393, loss: 0.025408\n",
      "step:   198720, time: 0.411, loss: 0.016037\n",
      "step:   198740, time: 0.385, loss: 0.009729\n",
      "step:   198760, time: 0.407, loss: 0.007367\n",
      "step:   198780, time: 0.386, loss: 0.021181\n",
      "step:   198800, time: 0.394, loss: 0.023730\n",
      "step:   198820, time: 0.407, loss: 0.017054\n",
      "step:   198840, time: 0.424, loss: 0.015788\n",
      "step:   198860, time: 0.405, loss: 0.007055\n",
      "step:   198880, time: 0.396, loss: 0.017847\n",
      "step:   198900, time: 0.390, loss: 0.009949\n",
      "step:   198920, time: 0.398, loss: 0.013710\n",
      "step:   198940, time: 0.411, loss: 0.017132\n",
      "step:   198960, time: 0.433, loss: 0.017802\n",
      "step:   198980, time: 0.398, loss: 0.014981\n",
      "step:   199000, time: 0.419, loss: 0.015761\n",
      "step:   199020, time: 0.403, loss: 0.019494\n",
      "step:   199040, time: 0.395, loss: 0.014247\n",
      "step:   199060, time: 0.425, loss: 0.014524\n",
      "step:   199080, time: 0.395, loss: 0.014476\n",
      "step:   199100, time: 0.412, loss: 0.026285\n",
      "step:   199120, time: 0.425, loss: 0.013319\n",
      "step:   199140, time: 0.417, loss: 0.013149\n",
      "step:   199160, time: 0.386, loss: 0.008074\n",
      "step:   199180, time: 0.379, loss: 0.010495\n",
      "step:   199200, time: 0.405, loss: 0.013717\n",
      "step:   199220, time: 0.394, loss: 0.010625\n",
      "step:   199240, time: 0.395, loss: 0.015540\n",
      "step:   199260, time: 0.410, loss: 0.014227\n",
      "step:   199280, time: 0.448, loss: 0.017217\n",
      "step:   199300, time: 0.392, loss: 0.011019\n",
      "step:   199320, time: 0.398, loss: 0.011430\n",
      "step:   199340, time: 0.385, loss: 0.012274\n",
      "step:   199360, time: 0.388, loss: 0.015423\n",
      "step:   199380, time: 0.400, loss: 0.008793\n",
      "step:   199400, time: 0.404, loss: 0.020627\n",
      "step:   199420, time: 0.400, loss: 0.009579\n",
      "step:   199440, time: 0.405, loss: 0.010241\n",
      "step:   199460, time: 0.404, loss: 0.012683\n",
      "step:   199480, time: 0.438, loss: 0.023466\n",
      "step:   199500, time: 0.399, loss: 0.011457\n",
      "step:   199520, time: 0.405, loss: 0.017776\n",
      "step:   199540, time: 0.373, loss: 0.010846\n",
      "step:   199560, time: 0.419, loss: 0.012557\n",
      "step:   199580, time: 0.388, loss: 0.023940\n",
      "step:   199600, time: 0.395, loss: 0.009844\n",
      "step:   199620, time: 0.414, loss: 0.017030\n",
      "step:   199640, time: 0.390, loss: 0.016949\n",
      "step:   199660, time: 0.418, loss: 0.006324\n",
      "step:   199680, time: 0.414, loss: 0.014439\n",
      "step:   199700, time: 0.401, loss: 0.016120\n",
      "step:   199720, time: 0.395, loss: 0.026593\n",
      "step:   199740, time: 0.386, loss: 0.016508\n",
      "step:   199760, time: 0.380, loss: 0.010317\n",
      "step:   199780, time: 0.370, loss: 0.007638\n",
      "step:   199800, time: 0.392, loss: 0.020390\n",
      "step:   199820, time: 0.412, loss: 0.010423\n",
      "step:   199840, time: 0.426, loss: 0.018199\n",
      "step:   199860, time: 0.376, loss: 0.021484\n",
      "step:   199880, time: 0.398, loss: 0.015954\n",
      "step:   199900, time: 0.367, loss: 0.007636\n",
      "step:   199920, time: 0.407, loss: 0.015917\n",
      "step:   199940, time: 0.410, loss: 0.014928\n",
      "step:   199960, time: 0.398, loss: 0.022803\n",
      "step:   199980, time: 0.404, loss: 0.017643\n",
      "step:   200000, time: 0.378, loss: 0.015043\n",
      "Finished training GMM, nameed: gmm_train_new!\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name gmm_train_new --stage GMM --workers 4 --save_count 5000 --shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=4, checkpoint='checkpoints/gmm_train_new/gmm_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='data', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='gmm_traintest_new', radius=5, result_dir='result', shuffle=False, stage='GMM', tensorboard_dir='tensorboard', workers=4)\n",
      "Start to test stage: GMM, named: gmm_traintest_new!\n",
      "initialization method [normal]\n",
      "initialization method [normal]\n",
      "step:        1, time: 2.481\n",
      "step:        2, time: 0.394\n",
      "step:        3, time: 0.394\n",
      "step:        4, time: 0.379\n",
      "step:        5, time: 0.395\n",
      "step:        6, time: 0.418\n",
      "step:        7, time: 0.407\n",
      "step:        8, time: 0.413\n",
      "step:        9, time: 0.402\n",
      "step:       10, time: 0.396\n",
      "step:       11, time: 0.398\n",
      "step:       12, time: 0.376\n",
      "step:       13, time: 0.369\n",
      "step:       14, time: 0.381"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3384: UserWarning: Default grid_sample and affine_grid behavior has changed to align_corners=False since 1.3.0. Please specify align_corners=True if the old behavior is desired. See the documentation of grid_sample for details.\n",
      "  warnings.warn(\"Default grid_sample and affine_grid behavior has changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:       15, time: 0.394\n",
      "step:       16, time: 0.405\n",
      "step:       17, time: 0.381\n",
      "step:       18, time: 0.392\n",
      "step:       19, time: 0.416\n",
      "step:       20, time: 0.406\n",
      "step:       21, time: 0.388\n",
      "step:       22, time: 0.395\n",
      "step:       23, time: 0.387\n",
      "step:       24, time: 0.373\n",
      "step:       25, time: 0.392\n",
      "step:       26, time: 0.421\n",
      "step:       27, time: 0.438\n",
      "step:       28, time: 0.389\n",
      "step:       29, time: 0.390\n",
      "step:       30, time: 0.396\n",
      "step:       31, time: 0.409\n",
      "step:       32, time: 0.379\n",
      "step:       33, time: 0.394\n",
      "step:       34, time: 0.385\n",
      "step:       35, time: 0.385\n",
      "step:       36, time: 0.373\n",
      "step:       37, time: 0.394\n",
      "step:       38, time: 0.404\n",
      "step:       39, time: 0.380\n",
      "step:       40, time: 0.402\n",
      "step:       41, time: 0.368\n",
      "step:       42, time: 0.370\n",
      "step:       43, time: 0.366\n",
      "step:       44, time: 0.396\n",
      "step:       45, time: 0.404\n",
      "step:       46, time: 0.408\n",
      "step:       47, time: 0.409\n",
      "step:       48, time: 0.396\n",
      "step:       49, time: 0.463\n",
      "step:       50, time: 0.408\n",
      "step:       51, time: 0.402\n",
      "step:       52, time: 0.413\n",
      "step:       53, time: 0.414\n",
      "step:       54, time: 0.388\n",
      "step:       55, time: 0.397\n",
      "step:       56, time: 0.399\n",
      "step:       57, time: 0.425\n",
      "step:       58, time: 0.404\n",
      "step:       59, time: 0.373\n",
      "step:       60, time: 0.373\n",
      "step:       61, time: 0.434\n",
      "step:       62, time: 0.396\n",
      "step:       63, time: 0.391\n",
      "step:       64, time: 0.400\n",
      "step:       65, time: 0.395\n",
      "step:       66, time: 0.381\n",
      "step:       67, time: 0.400\n",
      "step:       68, time: 0.426\n",
      "step:       69, time: 0.391\n",
      "step:       70, time: 0.386\n",
      "step:       71, time: 0.412\n",
      "step:       72, time: 0.386\n",
      "step:       73, time: 0.370\n",
      "step:       74, time: 0.388\n",
      "step:       75, time: 0.384\n",
      "step:       76, time: 0.407\n",
      "step:       77, time: 0.382\n",
      "step:       78, time: 0.415\n",
      "step:       79, time: 0.380\n",
      "step:       80, time: 0.388\n",
      "step:       81, time: 0.393\n",
      "step:       82, time: 0.403\n",
      "step:       83, time: 0.420\n",
      "step:       84, time: 0.401\n",
      "step:       85, time: 0.398\n",
      "step:       86, time: 0.444\n",
      "step:       87, time: 0.417\n",
      "step:       88, time: 0.393\n",
      "step:       89, time: 0.391\n",
      "step:       90, time: 0.397\n",
      "step:       91, time: 0.391\n",
      "step:       92, time: 0.403\n",
      "step:       93, time: 0.406\n",
      "step:       94, time: 0.409\n",
      "step:       95, time: 0.373\n",
      "step:       96, time: 0.383\n",
      "step:       97, time: 0.388\n",
      "step:       98, time: 0.404\n",
      "step:       99, time: 0.401\n",
      "step:      100, time: 0.421\n",
      "step:      101, time: 0.385\n",
      "step:      102, time: 0.402\n",
      "step:      103, time: 0.397\n",
      "step:      104, time: 0.401\n",
      "step:      105, time: 0.376\n",
      "step:      106, time: 0.411\n",
      "step:      107, time: 0.388\n",
      "step:      108, time: 0.438\n",
      "step:      109, time: 0.411\n",
      "step:      110, time: 0.386\n",
      "step:      111, time: 0.396\n",
      "step:      112, time: 0.403\n",
      "step:      113, time: 0.395\n",
      "step:      114, time: 0.415\n",
      "step:      115, time: 0.402\n",
      "step:      116, time: 0.398\n",
      "step:      117, time: 0.376\n",
      "step:      118, time: 0.418\n",
      "step:      119, time: 0.384\n",
      "step:      120, time: 0.389\n",
      "step:      121, time: 0.381\n",
      "step:      122, time: 0.364\n",
      "step:      123, time: 0.407\n",
      "step:      124, time: 0.387\n",
      "step:      125, time: 0.393\n",
      "step:      126, time: 0.379\n",
      "step:      127, time: 0.423\n",
      "step:      128, time: 0.389\n",
      "step:      129, time: 0.361\n",
      "step:      130, time: 0.389\n",
      "step:      131, time: 0.386\n",
      "step:      132, time: 0.400\n",
      "step:      133, time: 0.406\n",
      "step:      134, time: 0.377\n",
      "step:      135, time: 0.383\n",
      "step:      136, time: 0.385\n",
      "step:      137, time: 0.391\n",
      "step:      138, time: 0.371\n",
      "step:      139, time: 0.387\n",
      "step:      140, time: 0.394\n",
      "step:      141, time: 0.384\n",
      "step:      142, time: 0.375\n",
      "step:      143, time: 0.363\n",
      "step:      144, time: 0.388\n",
      "step:      145, time: 0.398\n",
      "step:      146, time: 0.390\n",
      "step:      147, time: 0.413\n",
      "step:      148, time: 0.453\n",
      "step:      149, time: 0.414\n",
      "step:      150, time: 0.417\n",
      "step:      151, time: 0.390\n",
      "step:      152, time: 0.390\n",
      "step:      153, time: 0.378\n",
      "step:      154, time: 0.388\n",
      "step:      155, time: 0.403\n",
      "step:      156, time: 0.380\n",
      "step:      157, time: 0.400\n",
      "step:      158, time: 0.419\n",
      "step:      159, time: 0.389\n",
      "step:      160, time: 0.365\n",
      "step:      161, time: 0.399\n",
      "step:      162, time: 0.399\n",
      "step:      163, time: 0.392\n",
      "step:      164, time: 0.384\n",
      "step:      165, time: 0.391\n",
      "step:      166, time: 0.429\n",
      "step:      167, time: 0.402\n",
      "step:      168, time: 0.378\n",
      "step:      169, time: 0.414\n",
      "step:      170, time: 0.396\n",
      "step:      171, time: 0.387\n",
      "step:      172, time: 0.401\n",
      "step:      173, time: 0.365\n",
      "step:      174, time: 0.381\n",
      "step:      175, time: 0.383\n",
      "step:      176, time: 0.376\n",
      "step:      177, time: 0.378\n",
      "step:      178, time: 0.390\n",
      "step:      179, time: 0.388\n",
      "step:      180, time: 0.383\n",
      "step:      181, time: 0.392\n",
      "step:      182, time: 0.391\n",
      "step:      183, time: 0.371\n",
      "step:      184, time: 0.396\n",
      "step:      185, time: 0.416\n",
      "step:      186, time: 0.382\n",
      "step:      187, time: 0.413\n",
      "step:      188, time: 0.404\n",
      "step:      189, time: 0.401\n",
      "step:      190, time: 0.427\n",
      "step:      191, time: 0.380\n",
      "step:      192, time: 0.398\n",
      "step:      193, time: 0.366\n",
      "step:      194, time: 0.421\n",
      "step:      195, time: 0.406\n",
      "step:      196, time: 0.407\n",
      "step:      197, time: 0.394\n",
      "step:      198, time: 0.412\n",
      "step:      199, time: 0.381\n",
      "step:      200, time: 0.403\n",
      "step:      201, time: 0.412\n",
      "step:      202, time: 0.407\n",
      "step:      203, time: 0.402\n",
      "step:      204, time: 0.399\n",
      "step:      205, time: 0.390\n",
      "step:      206, time: 0.374\n",
      "step:      207, time: 0.395\n",
      "step:      208, time: 0.400\n",
      "step:      209, time: 0.396\n",
      "step:      210, time: 0.379\n",
      "step:      211, time: 0.379\n",
      "step:      212, time: 0.413\n",
      "step:      213, time: 0.395\n",
      "step:      214, time: 0.425\n",
      "step:      215, time: 0.403\n",
      "step:      216, time: 0.405\n",
      "step:      217, time: 0.384\n",
      "step:      218, time: 0.376\n",
      "step:      219, time: 0.407\n",
      "step:      220, time: 0.422\n",
      "step:      221, time: 0.373\n",
      "step:      222, time: 0.406\n",
      "step:      223, time: 0.388\n",
      "step:      224, time: 0.411\n",
      "step:      225, time: 0.373\n",
      "step:      226, time: 0.410\n",
      "step:      227, time: 0.409\n",
      "step:      228, time: 0.399\n",
      "step:      229, time: 0.424\n",
      "step:      230, time: 0.436\n",
      "step:      231, time: 0.393\n",
      "step:      232, time: 0.359\n",
      "step:      233, time: 0.392\n",
      "step:      234, time: 0.389\n",
      "step:      235, time: 0.416\n",
      "step:      236, time: 0.405\n",
      "step:      237, time: 0.419\n",
      "step:      238, time: 0.410\n",
      "step:      239, time: 0.400\n",
      "step:      240, time: 0.405\n",
      "step:      241, time: 0.396\n",
      "step:      242, time: 0.370\n",
      "step:      243, time: 0.386\n",
      "step:      244, time: 0.392\n",
      "step:      245, time: 0.377\n",
      "step:      246, time: 0.392\n",
      "step:      247, time: 0.404\n",
      "step:      248, time: 0.399\n",
      "step:      249, time: 0.385\n",
      "step:      250, time: 0.389\n",
      "step:      251, time: 0.381\n",
      "step:      252, time: 0.395\n",
      "step:      253, time: 0.388\n",
      "step:      254, time: 0.393\n",
      "step:      255, time: 0.402\n",
      "step:      256, time: 0.402\n",
      "step:      257, time: 0.355\n",
      "step:      258, time: 0.394\n",
      "step:      259, time: 0.394\n",
      "step:      260, time: 0.399\n",
      "step:      261, time: 0.439\n",
      "step:      262, time: 0.420\n",
      "step:      263, time: 0.414\n",
      "step:      264, time: 0.390\n",
      "step:      265, time: 0.363\n",
      "step:      266, time: 0.406\n",
      "step:      267, time: 0.379\n",
      "step:      268, time: 0.400\n",
      "step:      269, time: 0.439\n",
      "step:      270, time: 0.398\n",
      "step:      271, time: 0.385\n",
      "step:      272, time: 0.386\n",
      "step:      273, time: 0.379\n",
      "step:      274, time: 0.357\n",
      "step:      275, time: 0.370\n",
      "step:      276, time: 0.409\n",
      "step:      277, time: 0.371\n",
      "step:      278, time: 0.381\n",
      "step:      279, time: 0.401\n",
      "step:      280, time: 0.409\n",
      "step:      281, time: 0.363\n",
      "step:      282, time: 0.383\n",
      "step:      283, time: 0.385\n",
      "step:      284, time: 0.386\n",
      "step:      285, time: 0.394\n",
      "step:      286, time: 0.359\n",
      "step:      287, time: 0.398\n",
      "step:      288, time: 0.401\n",
      "step:      289, time: 0.377\n",
      "step:      290, time: 0.433\n",
      "step:      291, time: 0.388\n",
      "step:      292, time: 0.400\n",
      "step:      293, time: 0.391\n",
      "step:      294, time: 0.393\n",
      "step:      295, time: 0.377\n",
      "step:      296, time: 0.393\n",
      "step:      297, time: 0.389\n",
      "step:      298, time: 0.398\n",
      "step:      299, time: 0.373\n",
      "step:      300, time: 0.409\n",
      "step:      301, time: 0.412\n",
      "step:      302, time: 0.401\n",
      "step:      303, time: 0.387\n",
      "step:      304, time: 0.381\n",
      "step:      305, time: 0.391\n",
      "step:      306, time: 0.401\n",
      "step:      307, time: 0.373\n",
      "step:      308, time: 0.377\n",
      "step:      309, time: 0.371\n",
      "step:      310, time: 0.430\n",
      "step:      311, time: 0.443\n",
      "step:      312, time: 0.434\n",
      "step:      313, time: 0.410\n",
      "step:      314, time: 0.385\n",
      "step:      315, time: 0.405\n",
      "step:      316, time: 0.401\n",
      "step:      317, time: 0.401\n",
      "step:      318, time: 0.393\n",
      "step:      319, time: 0.385\n",
      "step:      320, time: 0.401\n",
      "step:      321, time: 0.416\n",
      "step:      322, time: 0.377\n",
      "step:      323, time: 0.393\n",
      "step:      324, time: 0.367\n",
      "step:      325, time: 0.388\n",
      "step:      326, time: 0.416\n",
      "step:      327, time: 0.401\n",
      "step:      328, time: 0.385\n",
      "step:      329, time: 0.425\n",
      "step:      330, time: 0.416\n",
      "step:      331, time: 0.382\n",
      "step:      332, time: 0.406\n",
      "step:      333, time: 0.397\n",
      "step:      334, time: 0.383\n",
      "step:      335, time: 0.395\n",
      "step:      336, time: 0.407\n",
      "step:      337, time: 0.405\n",
      "step:      338, time: 0.401\n",
      "step:      339, time: 0.373\n",
      "step:      340, time: 0.428\n",
      "step:      341, time: 0.370\n",
      "step:      342, time: 0.389\n",
      "step:      343, time: 0.376\n",
      "step:      344, time: 0.380\n",
      "step:      345, time: 0.382\n",
      "step:      346, time: 0.370\n",
      "step:      347, time: 0.377\n",
      "step:      348, time: 0.397\n",
      "step:      349, time: 0.412\n",
      "step:      350, time: 0.414\n",
      "step:      351, time: 0.435\n",
      "step:      352, time: 0.414\n",
      "step:      353, time: 0.402\n",
      "step:      354, time: 0.389\n",
      "step:      355, time: 0.394\n",
      "step:      356, time: 0.381\n",
      "step:      357, time: 0.374\n",
      "step:      358, time: 0.402\n",
      "step:      359, time: 0.416\n",
      "step:      360, time: 0.388\n",
      "step:      361, time: 0.411\n",
      "step:      362, time: 0.386\n",
      "step:      363, time: 0.377\n",
      "step:      364, time: 0.391\n",
      "step:      365, time: 0.404\n",
      "step:      366, time: 0.369\n",
      "step:      367, time: 0.387\n",
      "step:      368, time: 0.394\n",
      "step:      369, time: 0.399\n",
      "step:      370, time: 0.403\n",
      "step:      371, time: 0.389\n",
      "step:      372, time: 0.383\n",
      "step:      373, time: 0.397\n",
      "step:      374, time: 0.411\n",
      "step:      375, time: 0.379\n",
      "step:      376, time: 0.392\n",
      "step:      377, time: 0.362\n",
      "step:      378, time: 0.400\n",
      "step:      379, time: 0.395\n",
      "step:      380, time: 0.399\n",
      "step:      381, time: 0.399\n",
      "step:      382, time: 0.388\n",
      "step:      383, time: 0.376\n",
      "step:      384, time: 0.418\n",
      "step:      385, time: 0.371\n",
      "step:      386, time: 0.387\n",
      "step:      387, time: 0.396\n",
      "step:      388, time: 0.400\n",
      "step:      389, time: 0.391\n",
      "step:      390, time: 0.405\n",
      "step:      391, time: 0.403\n",
      "step:      392, time: 0.406\n",
      "step:      393, time: 0.412\n",
      "step:      394, time: 0.396\n",
      "step:      395, time: 0.380\n",
      "step:      396, time: 0.375\n",
      "step:      397, time: 0.374\n",
      "step:      398, time: 0.356\n",
      "step:      399, time: 0.385\n",
      "step:      400, time: 0.380\n",
      "step:      401, time: 0.396\n",
      "step:      402, time: 0.425\n",
      "step:      403, time: 0.391\n",
      "step:      404, time: 0.398\n",
      "step:      405, time: 0.388\n",
      "step:      406, time: 0.413\n",
      "step:      407, time: 0.400\n",
      "step:      408, time: 0.448\n",
      "step:      409, time: 0.391\n",
      "step:      410, time: 0.391\n",
      "step:      411, time: 0.373\n",
      "step:      412, time: 0.394\n",
      "step:      413, time: 0.365\n",
      "step:      414, time: 0.394\n",
      "step:      415, time: 0.392\n",
      "step:      416, time: 0.397\n",
      "step:      417, time: 0.383\n",
      "step:      418, time: 0.389\n",
      "step:      419, time: 0.394\n",
      "step:      420, time: 0.389\n",
      "step:      421, time: 0.413\n",
      "step:      422, time: 0.394\n",
      "step:      423, time: 0.378\n",
      "step:      424, time: 0.386\n",
      "step:      425, time: 0.396\n",
      "step:      426, time: 0.424\n",
      "step:      427, time: 0.384\n",
      "step:      428, time: 0.387\n",
      "step:      429, time: 0.397\n",
      "step:      430, time: 0.381\n",
      "step:      431, time: 0.410\n",
      "step:      432, time: 0.418\n",
      "step:      433, time: 0.426\n",
      "step:      434, time: 0.395\n",
      "step:      435, time: 0.368\n",
      "step:      436, time: 0.374\n",
      "step:      437, time: 0.388\n",
      "step:      438, time: 0.408\n",
      "step:      439, time: 0.415\n",
      "step:      440, time: 0.383\n",
      "step:      441, time: 0.412\n",
      "step:      442, time: 0.378\n",
      "step:      443, time: 0.386\n",
      "step:      444, time: 0.398\n",
      "step:      445, time: 0.390\n",
      "step:      446, time: 0.374\n",
      "step:      447, time: 0.373\n",
      "step:      448, time: 0.382\n",
      "step:      449, time: 0.380\n",
      "step:      450, time: 0.398\n",
      "step:      451, time: 0.410\n",
      "step:      452, time: 0.435\n",
      "step:      453, time: 0.449\n",
      "step:      454, time: 0.397\n",
      "step:      455, time: 0.419\n",
      "step:      456, time: 0.395\n",
      "step:      457, time: 0.404\n",
      "step:      458, time: 0.392\n",
      "step:      459, time: 0.376\n",
      "step:      460, time: 0.443\n",
      "step:      461, time: 0.434\n",
      "step:      462, time: 0.430\n",
      "step:      463, time: 0.418\n",
      "step:      464, time: 0.401\n",
      "step:      465, time: 0.391\n",
      "step:      466, time: 0.395\n",
      "step:      467, time: 0.402\n",
      "step:      468, time: 0.393\n",
      "step:      469, time: 0.381\n",
      "step:      470, time: 0.381\n",
      "step:      471, time: 0.382\n",
      "step:      472, time: 0.388\n",
      "step:      473, time: 0.414\n",
      "step:      474, time: 0.364\n",
      "step:      475, time: 0.371\n",
      "step:      476, time: 0.355\n",
      "step:      477, time: 0.405\n",
      "step:      478, time: 0.412\n",
      "step:      479, time: 0.393\n",
      "step:      480, time: 0.406\n",
      "step:      481, time: 0.401\n",
      "step:      482, time: 0.382\n",
      "step:      483, time: 0.384\n",
      "step:      484, time: 0.387\n",
      "step:      485, time: 0.375\n",
      "step:      486, time: 0.367\n",
      "step:      487, time: 0.430\n",
      "step:      488, time: 0.426\n",
      "step:      489, time: 0.394\n",
      "step:      490, time: 0.396\n",
      "step:      491, time: 0.415\n",
      "step:      492, time: 0.397\n",
      "step:      493, time: 0.409\n",
      "step:      494, time: 0.425\n",
      "step:      495, time: 0.402\n",
      "step:      496, time: 0.436\n",
      "step:      497, time: 0.415\n",
      "step:      498, time: 0.390\n",
      "step:      499, time: 0.403\n",
      "step:      500, time: 0.376\n",
      "step:      501, time: 0.365\n",
      "step:      502, time: 0.374\n",
      "step:      503, time: 0.379\n",
      "step:      504, time: 0.366\n",
      "step:      505, time: 0.364\n",
      "step:      506, time: 0.371\n",
      "step:      507, time: 0.369\n",
      "step:      508, time: 0.377\n",
      "Finished test GMM, named: gmm_traintest_new!\n"
     ]
    }
   ],
   "source": [
    "!python test.py --name gmm_traintest_new --stage GMM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoints/gmm_train_new/gmm_final.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try-On Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3118: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=4, checkpoint='', checkpoint_dir='checkpoints', data_list='train_pairs.txt', datamode='train', dataroot='data', decay_step=100000, display_count=20, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, keep_step=100000, lr=0.0001, name='tom_train_new', radius=5, save_count=5000, shuffle=True, stage='TOM', tensorboard_dir='tensorboard', workers=4)\n",
      "Start to train stage: TOM, named: tom_train_new!\n",
      "step:       20, time: 0.787, loss: 1.6022, l1: 0.2715, vgg: 0.9577, mask: 0.3729\n",
      "step:       40, time: 0.726, loss: 1.7061, l1: 0.3813, vgg: 0.9425, mask: 0.3824\n",
      "step:       60, time: 0.718, loss: 1.6039, l1: 0.3068, vgg: 0.9263, mask: 0.3708\n",
      "step:       80, time: 0.717, loss: 1.5892, l1: 0.2822, vgg: 0.9534, mask: 0.3535\n",
      "step:      100, time: 0.707, loss: 1.6024, l1: 0.2928, vgg: 0.9361, mask: 0.3735\n",
      "step:      120, time: 0.714, loss: 1.4792, l1: 0.2599, vgg: 0.8773, mask: 0.3420\n",
      "step:      140, time: 0.699, loss: 1.4724, l1: 0.2735, vgg: 0.8114, mask: 0.3876\n",
      "step:      160, time: 0.702, loss: 1.4420, l1: 0.2435, vgg: 0.8228, mask: 0.3757\n",
      "step:      180, time: 0.715, loss: 1.6449, l1: 0.3367, vgg: 0.9109, mask: 0.3973\n",
      "step:      200, time: 0.733, loss: 1.4543, l1: 0.2755, vgg: 0.7991, mask: 0.3796\n",
      "step:      220, time: 0.730, loss: 1.4886, l1: 0.2783, vgg: 0.8342, mask: 0.3761\n",
      "step:      240, time: 0.718, loss: 1.4231, l1: 0.2761, vgg: 0.7904, mask: 0.3565\n",
      "step:      260, time: 0.710, loss: 1.4228, l1: 0.2710, vgg: 0.7905, mask: 0.3613\n",
      "step:      280, time: 0.734, loss: 1.4415, l1: 0.2721, vgg: 0.7850, mask: 0.3843\n",
      "step:      300, time: 0.781, loss: 1.6311, l1: 0.3095, vgg: 0.9303, mask: 0.3913\n",
      "step:      320, time: 0.746, loss: 1.5521, l1: 0.3094, vgg: 0.8659, mask: 0.3768\n",
      "step:      340, time: 0.703, loss: 1.4135, l1: 0.2698, vgg: 0.7817, mask: 0.3621\n",
      "step:      360, time: 0.702, loss: 1.3560, l1: 0.2474, vgg: 0.7070, mask: 0.4016\n",
      "step:      380, time: 0.710, loss: 1.4272, l1: 0.2590, vgg: 0.8120, mask: 0.3562\n",
      "step:      400, time: 0.718, loss: 1.4512, l1: 0.3025, vgg: 0.8007, mask: 0.3480\n",
      "step:      420, time: 0.700, loss: 1.5269, l1: 0.3013, vgg: 0.8339, mask: 0.3917\n",
      "step:      440, time: 0.740, loss: 1.6408, l1: 0.3402, vgg: 0.9157, mask: 0.3849\n",
      "step:      460, time: 0.769, loss: 1.5053, l1: 0.2522, vgg: 0.8286, mask: 0.4245\n",
      "step:      480, time: 0.725, loss: 1.3649, l1: 0.2912, vgg: 0.7155, mask: 0.3582\n",
      "step:      500, time: 0.695, loss: 1.4010, l1: 0.2668, vgg: 0.7751, mask: 0.3590\n",
      "step:      520, time: 0.726, loss: 1.3677, l1: 0.2249, vgg: 0.7354, mask: 0.4075\n",
      "step:      540, time: 0.718, loss: 1.4353, l1: 0.2494, vgg: 0.8126, mask: 0.3733\n",
      "step:      560, time: 0.703, loss: 1.4495, l1: 0.2967, vgg: 0.7525, mask: 0.4003\n",
      "step:      580, time: 0.755, loss: 1.5053, l1: 0.3041, vgg: 0.8333, mask: 0.3680\n",
      "step:      600, time: 0.771, loss: 1.3399, l1: 0.2432, vgg: 0.7210, mask: 0.3757\n",
      "step:      620, time: 0.763, loss: 1.3054, l1: 0.2115, vgg: 0.7404, mask: 0.3535\n",
      "step:      640, time: 0.738, loss: 1.4896, l1: 0.3037, vgg: 0.7999, mask: 0.3860\n",
      "step:      660, time: 0.743, loss: 1.3435, l1: 0.2678, vgg: 0.7130, mask: 0.3627\n",
      "step:      680, time: 0.712, loss: 1.4453, l1: 0.2849, vgg: 0.7716, mask: 0.3888\n",
      "step:      700, time: 0.709, loss: 1.3727, l1: 0.2906, vgg: 0.7145, mask: 0.3677\n",
      "step:      720, time: 0.767, loss: 1.4343, l1: 0.2428, vgg: 0.7980, mask: 0.3935\n",
      "step:      740, time: 0.735, loss: 1.4697, l1: 0.2811, vgg: 0.7767, mask: 0.4119\n",
      "step:      760, time: 0.764, loss: 1.5307, l1: 0.2907, vgg: 0.8538, mask: 0.3862\n",
      "step:      780, time: 0.755, loss: 1.4239, l1: 0.2863, vgg: 0.7592, mask: 0.3784\n",
      "step:      800, time: 0.825, loss: 1.4724, l1: 0.2677, vgg: 0.8363, mask: 0.3684\n",
      "step:      820, time: 0.749, loss: 1.2920, l1: 0.2273, vgg: 0.7153, mask: 0.3494\n",
      "step:      840, time: 0.719, loss: 1.4065, l1: 0.2716, vgg: 0.7779, mask: 0.3570\n",
      "step:      860, time: 0.731, loss: 1.2862, l1: 0.2382, vgg: 0.6888, mask: 0.3591\n",
      "step:      880, time: 0.732, loss: 1.3770, l1: 0.2378, vgg: 0.7591, mask: 0.3801\n",
      "step:      900, time: 0.715, loss: 1.3615, l1: 0.2487, vgg: 0.7202, mask: 0.3925\n",
      "step:      920, time: 0.749, loss: 1.4767, l1: 0.2619, vgg: 0.8593, mask: 0.3556\n",
      "step:      940, time: 0.734, loss: 1.4052, l1: 0.2414, vgg: 0.7541, mask: 0.4097\n",
      "step:      960, time: 0.691, loss: 1.3818, l1: 0.2646, vgg: 0.7390, mask: 0.3782\n",
      "step:      980, time: 0.751, loss: 1.3974, l1: 0.2618, vgg: 0.7263, mask: 0.4093\n",
      "step:     1000, time: 0.739, loss: 1.3824, l1: 0.2577, vgg: 0.7382, mask: 0.3864\n",
      "step:     1020, time: 0.785, loss: 1.4072, l1: 0.2803, vgg: 0.7540, mask: 0.3730\n",
      "step:     1040, time: 0.732, loss: 1.3710, l1: 0.2253, vgg: 0.7443, mask: 0.4014\n",
      "step:     1060, time: 0.703, loss: 1.2410, l1: 0.2419, vgg: 0.6479, mask: 0.3512\n",
      "step:     1080, time: 0.803, loss: 1.5442, l1: 0.3207, vgg: 0.8197, mask: 0.4038\n",
      "step:     1100, time: 0.705, loss: 1.2367, l1: 0.2465, vgg: 0.6175, mask: 0.3727\n",
      "step:     1120, time: 0.815, loss: 1.3898, l1: 0.2293, vgg: 0.7945, mask: 0.3660\n",
      "step:     1140, time: 0.789, loss: 1.4581, l1: 0.2832, vgg: 0.7818, mask: 0.3932\n",
      "step:     1160, time: 0.711, loss: 1.3347, l1: 0.2466, vgg: 0.7223, mask: 0.3658\n",
      "step:     1180, time: 0.782, loss: 1.3658, l1: 0.2520, vgg: 0.7375, mask: 0.3763\n",
      "step:     1200, time: 0.760, loss: 1.4804, l1: 0.2371, vgg: 0.8962, mask: 0.3472\n",
      "step:     1220, time: 0.727, loss: 1.4753, l1: 0.3145, vgg: 0.7741, mask: 0.3867\n",
      "step:     1240, time: 0.774, loss: 1.3487, l1: 0.2531, vgg: 0.7193, mask: 0.3764\n",
      "step:     1260, time: 0.759, loss: 1.3140, l1: 0.2338, vgg: 0.7250, mask: 0.3553\n",
      "step:     1280, time: 0.719, loss: 1.3988, l1: 0.2646, vgg: 0.7791, mask: 0.3550\n",
      "step:     1300, time: 0.786, loss: 1.4073, l1: 0.2719, vgg: 0.7207, mask: 0.4147\n",
      "step:     1320, time: 0.741, loss: 1.5587, l1: 0.3429, vgg: 0.8139, mask: 0.4020\n",
      "step:     1340, time: 0.727, loss: 1.4028, l1: 0.2402, vgg: 0.7701, mask: 0.3925\n",
      "step:     1360, time: 0.712, loss: 1.2634, l1: 0.2417, vgg: 0.6820, mask: 0.3396\n",
      "step:     1380, time: 0.735, loss: 1.4946, l1: 0.3216, vgg: 0.7831, mask: 0.3899\n",
      "step:     1400, time: 0.728, loss: 1.3669, l1: 0.2501, vgg: 0.7195, mask: 0.3972\n",
      "step:     1420, time: 0.765, loss: 1.4302, l1: 0.2843, vgg: 0.7330, mask: 0.4129\n",
      "step:     1440, time: 0.762, loss: 1.4228, l1: 0.3103, vgg: 0.7179, mask: 0.3946\n",
      "step:     1460, time: 0.775, loss: 1.4494, l1: 0.2758, vgg: 0.8120, mask: 0.3617\n",
      "step:     1480, time: 0.711, loss: 1.4839, l1: 0.3600, vgg: 0.7121, mask: 0.4117\n",
      "step:     1500, time: 0.734, loss: 1.3829, l1: 0.2798, vgg: 0.7619, mask: 0.3412\n",
      "step:     1520, time: 0.746, loss: 1.3616, l1: 0.2619, vgg: 0.7104, mask: 0.3894\n",
      "step:     1540, time: 0.727, loss: 1.2775, l1: 0.2402, vgg: 0.6702, mask: 0.3671\n",
      "step:     1560, time: 0.748, loss: 1.3791, l1: 0.2694, vgg: 0.7226, mask: 0.3871\n",
      "step:     1580, time: 0.723, loss: 1.2969, l1: 0.2247, vgg: 0.7203, mask: 0.3518\n",
      "step:     1600, time: 0.732, loss: 1.3069, l1: 0.2423, vgg: 0.7082, mask: 0.3564\n",
      "step:     1620, time: 0.725, loss: 1.3369, l1: 0.2557, vgg: 0.7110, mask: 0.3702\n",
      "step:     1640, time: 0.719, loss: 1.3495, l1: 0.2788, vgg: 0.7143, mask: 0.3565\n",
      "step:     1660, time: 0.720, loss: 1.3041, l1: 0.2540, vgg: 0.6907, mask: 0.3594\n",
      "step:     1680, time: 0.717, loss: 1.3324, l1: 0.2379, vgg: 0.7272, mask: 0.3673\n",
      "step:     1700, time: 0.731, loss: 1.3556, l1: 0.2632, vgg: 0.7410, mask: 0.3514\n",
      "step:     1720, time: 0.725, loss: 1.2622, l1: 0.2077, vgg: 0.6720, mask: 0.3824\n",
      "step:     1740, time: 0.721, loss: 1.3310, l1: 0.2407, vgg: 0.7326, mask: 0.3577\n",
      "step:     1760, time: 0.764, loss: 1.3514, l1: 0.2770, vgg: 0.6987, mask: 0.3757\n",
      "step:     1780, time: 0.753, loss: 1.4995, l1: 0.3111, vgg: 0.8143, mask: 0.3741\n",
      "step:     1800, time: 0.707, loss: 1.3558, l1: 0.2900, vgg: 0.6854, mask: 0.3804\n",
      "step:     1820, time: 0.745, loss: 1.3354, l1: 0.2638, vgg: 0.7074, mask: 0.3642\n",
      "step:     1840, time: 0.737, loss: 1.4608, l1: 0.3051, vgg: 0.7749, mask: 0.3808\n",
      "step:     1860, time: 0.748, loss: 1.4240, l1: 0.2781, vgg: 0.7534, mask: 0.3926\n",
      "step:     1880, time: 0.694, loss: 1.2461, l1: 0.2006, vgg: 0.6858, mask: 0.3597\n",
      "step:     1900, time: 0.732, loss: 1.3087, l1: 0.2468, vgg: 0.7024, mask: 0.3595\n",
      "step:     1920, time: 0.693, loss: 1.3224, l1: 0.3238, vgg: 0.6314, mask: 0.3673\n",
      "step:     1940, time: 0.717, loss: 1.2988, l1: 0.2268, vgg: 0.7188, mask: 0.3532\n",
      "step:     1960, time: 0.742, loss: 1.3302, l1: 0.2501, vgg: 0.7333, mask: 0.3468\n",
      "step:     1980, time: 0.736, loss: 1.4134, l1: 0.2694, vgg: 0.7624, mask: 0.3816\n",
      "step:     2000, time: 0.684, loss: 1.2536, l1: 0.2519, vgg: 0.6209, mask: 0.3807\n",
      "step:     2020, time: 0.752, loss: 1.5598, l1: 0.3203, vgg: 0.8608, mask: 0.3788\n",
      "step:     2040, time: 0.737, loss: 1.3701, l1: 0.2778, vgg: 0.7233, mask: 0.3689\n",
      "step:     2060, time: 0.748, loss: 1.3563, l1: 0.2474, vgg: 0.7576, mask: 0.3512\n",
      "step:     2080, time: 0.742, loss: 1.2874, l1: 0.2321, vgg: 0.7202, mask: 0.3351\n",
      "step:     2100, time: 0.744, loss: 1.3010, l1: 0.2672, vgg: 0.6634, mask: 0.3704\n",
      "step:     2120, time: 0.720, loss: 1.4030, l1: 0.3431, vgg: 0.6859, mask: 0.3739\n",
      "step:     2140, time: 0.760, loss: 1.2908, l1: 0.2458, vgg: 0.6551, mask: 0.3899\n",
      "step:     2160, time: 0.726, loss: 1.3051, l1: 0.2797, vgg: 0.6586, mask: 0.3669\n",
      "step:     2180, time: 0.732, loss: 1.3792, l1: 0.2832, vgg: 0.7160, mask: 0.3800\n",
      "step:     2200, time: 0.729, loss: 1.2982, l1: 0.2218, vgg: 0.7064, mask: 0.3700\n",
      "step:     2220, time: 0.779, loss: 1.3972, l1: 0.2532, vgg: 0.7644, mask: 0.3796\n",
      "step:     2240, time: 0.739, loss: 1.4684, l1: 0.2846, vgg: 0.8065, mask: 0.3773\n",
      "step:     2260, time: 0.756, loss: 1.4540, l1: 0.2563, vgg: 0.7888, mask: 0.4089\n",
      "step:     2280, time: 0.715, loss: 1.4241, l1: 0.2907, vgg: 0.7324, mask: 0.4009\n",
      "step:     2300, time: 0.709, loss: 1.4021, l1: 0.2611, vgg: 0.7289, mask: 0.4121\n",
      "step:     2320, time: 0.775, loss: 1.3393, l1: 0.3035, vgg: 0.6738, mask: 0.3619\n",
      "step:     2340, time: 0.696, loss: 1.2863, l1: 0.2321, vgg: 0.6784, mask: 0.3758\n",
      "step:     2360, time: 0.736, loss: 1.4437, l1: 0.3255, vgg: 0.7071, mask: 0.4110\n",
      "step:     2380, time: 0.716, loss: 1.3687, l1: 0.2399, vgg: 0.7587, mask: 0.3700\n",
      "step:     2400, time: 0.738, loss: 1.2112, l1: 0.2270, vgg: 0.6236, mask: 0.3605\n",
      "step:     2420, time: 0.735, loss: 1.2224, l1: 0.2250, vgg: 0.6264, mask: 0.3710\n",
      "step:     2440, time: 0.736, loss: 1.2455, l1: 0.2506, vgg: 0.6497, mask: 0.3451\n",
      "step:     2460, time: 0.725, loss: 1.3926, l1: 0.2858, vgg: 0.6987, mask: 0.4082\n",
      "step:     2480, time: 0.718, loss: 1.2804, l1: 0.2279, vgg: 0.6856, mask: 0.3669\n",
      "step:     2500, time: 0.768, loss: 1.4440, l1: 0.2805, vgg: 0.7946, mask: 0.3688\n",
      "step:     2520, time: 0.731, loss: 1.4292, l1: 0.2905, vgg: 0.7283, mask: 0.4104\n",
      "step:     2540, time: 0.720, loss: 1.3040, l1: 0.2398, vgg: 0.6678, mask: 0.3964\n",
      "step:     2560, time: 0.722, loss: 1.4043, l1: 0.3185, vgg: 0.6829, mask: 0.4030\n",
      "step:     2580, time: 0.780, loss: 1.4223, l1: 0.2336, vgg: 0.8134, mask: 0.3753\n",
      "step:     2600, time: 0.702, loss: 1.2172, l1: 0.2109, vgg: 0.6656, mask: 0.3407\n",
      "step:     2620, time: 0.732, loss: 1.3967, l1: 0.2990, vgg: 0.7087, mask: 0.3890\n",
      "step:     2640, time: 0.734, loss: 1.2487, l1: 0.2485, vgg: 0.6486, mask: 0.3516\n",
      "step:     2660, time: 0.726, loss: 1.2385, l1: 0.2296, vgg: 0.6404, mask: 0.3686\n",
      "step:     2680, time: 0.747, loss: 1.3555, l1: 0.2384, vgg: 0.7129, mask: 0.4042\n",
      "step:     2700, time: 0.727, loss: 1.3249, l1: 0.2630, vgg: 0.6936, mask: 0.3682\n",
      "step:     2720, time: 0.701, loss: 1.2940, l1: 0.2176, vgg: 0.7181, mask: 0.3584\n",
      "step:     2740, time: 0.771, loss: 1.4237, l1: 0.2666, vgg: 0.7902, mask: 0.3669\n",
      "step:     2760, time: 0.718, loss: 1.3564, l1: 0.3093, vgg: 0.6806, mask: 0.3664\n",
      "step:     2780, time: 0.735, loss: 1.2975, l1: 0.2441, vgg: 0.6933, mask: 0.3601\n",
      "step:     2800, time: 0.739, loss: 1.4450, l1: 0.2778, vgg: 0.7566, mask: 0.4106\n",
      "step:     2820, time: 0.728, loss: 1.2998, l1: 0.2765, vgg: 0.6505, mask: 0.3728\n",
      "step:     2840, time: 0.708, loss: 1.1196, l1: 0.1992, vgg: 0.5970, mask: 0.3234\n",
      "step:     2860, time: 0.757, loss: 1.4769, l1: 0.2696, vgg: 0.7931, mask: 0.4142\n",
      "step:     2880, time: 0.728, loss: 1.2918, l1: 0.2313, vgg: 0.6967, mask: 0.3638\n",
      "step:     2900, time: 0.698, loss: 1.2613, l1: 0.2581, vgg: 0.6529, mask: 0.3504\n",
      "step:     2920, time: 0.715, loss: 1.2104, l1: 0.2128, vgg: 0.6462, mask: 0.3514\n",
      "step:     2940, time: 0.736, loss: 1.3129, l1: 0.2892, vgg: 0.6421, mask: 0.3815\n",
      "step:     2960, time: 0.765, loss: 1.3535, l1: 0.2559, vgg: 0.6943, mask: 0.4033\n",
      "step:     2980, time: 0.754, loss: 1.3388, l1: 0.2684, vgg: 0.7226, mask: 0.3478\n",
      "step:     3000, time: 0.746, loss: 1.3766, l1: 0.2999, vgg: 0.6703, mask: 0.4064\n",
      "step:     3020, time: 0.700, loss: 1.3203, l1: 0.2703, vgg: 0.6735, mask: 0.3766\n",
      "step:     3040, time: 0.742, loss: 1.2977, l1: 0.2588, vgg: 0.6740, mask: 0.3648\n",
      "step:     3060, time: 0.723, loss: 1.2269, l1: 0.2276, vgg: 0.6511, mask: 0.3482\n",
      "step:     3080, time: 0.712, loss: 1.2656, l1: 0.2813, vgg: 0.5853, mask: 0.3990\n",
      "step:     3100, time: 0.709, loss: 1.2473, l1: 0.2327, vgg: 0.6816, mask: 0.3330\n",
      "step:     3120, time: 0.738, loss: 1.5427, l1: 0.3313, vgg: 0.8294, mask: 0.3820\n",
      "step:     3140, time: 0.730, loss: 1.3213, l1: 0.2817, vgg: 0.6879, mask: 0.3517\n",
      "step:     3160, time: 0.704, loss: 1.3007, l1: 0.2311, vgg: 0.7183, mask: 0.3512\n",
      "step:     3180, time: 0.743, loss: 1.3446, l1: 0.2264, vgg: 0.7273, mask: 0.3909\n",
      "step:     3200, time: 0.714, loss: 1.3221, l1: 0.2745, vgg: 0.6827, mask: 0.3649\n",
      "step:     3220, time: 0.737, loss: 1.2394, l1: 0.2641, vgg: 0.6163, mask: 0.3589\n",
      "step:     3240, time: 0.740, loss: 1.3327, l1: 0.2615, vgg: 0.6893, mask: 0.3819\n",
      "step:     3260, time: 0.710, loss: 1.2076, l1: 0.2118, vgg: 0.6578, mask: 0.3380\n",
      "step:     3280, time: 0.715, loss: 1.2121, l1: 0.2018, vgg: 0.6814, mask: 0.3289\n",
      "step:     3300, time: 0.725, loss: 1.3200, l1: 0.2741, vgg: 0.6667, mask: 0.3791\n",
      "step:     3320, time: 0.742, loss: 1.4094, l1: 0.2898, vgg: 0.7410, mask: 0.3786\n",
      "step:     3340, time: 0.754, loss: 1.3194, l1: 0.2956, vgg: 0.6592, mask: 0.3646\n",
      "step:     3360, time: 0.762, loss: 1.2935, l1: 0.2383, vgg: 0.7041, mask: 0.3511\n",
      "step:     3380, time: 0.723, loss: 1.3069, l1: 0.2491, vgg: 0.6948, mask: 0.3630\n",
      "step:     3400, time: 0.707, loss: 1.2822, l1: 0.2540, vgg: 0.6487, mask: 0.3794\n",
      "step:     3420, time: 0.731, loss: 1.3760, l1: 0.3213, vgg: 0.6782, mask: 0.3765\n",
      "step:     3440, time: 0.724, loss: 1.4031, l1: 0.2928, vgg: 0.7158, mask: 0.3945\n",
      "step:     3460, time: 0.784, loss: 1.4889, l1: 0.2718, vgg: 0.8170, mask: 0.4001\n",
      "step:     3480, time: 0.749, loss: 1.4184, l1: 0.2940, vgg: 0.7450, mask: 0.3794\n",
      "step:     3500, time: 0.702, loss: 1.2897, l1: 0.2932, vgg: 0.6465, mask: 0.3500\n",
      "step:     3520, time: 0.724, loss: 1.3229, l1: 0.2681, vgg: 0.6719, mask: 0.3829\n",
      "step:     3540, time: 0.721, loss: 1.3221, l1: 0.2319, vgg: 0.7230, mask: 0.3672\n",
      "step:     3560, time: 0.708, loss: 1.3447, l1: 0.2581, vgg: 0.7132, mask: 0.3733\n",
      "step:     3580, time: 0.769, loss: 1.3038, l1: 0.2200, vgg: 0.6885, mask: 0.3953\n",
      "step:     3600, time: 0.713, loss: 1.2692, l1: 0.2387, vgg: 0.6615, mask: 0.3689\n",
      "step:     3620, time: 0.754, loss: 1.3583, l1: 0.2499, vgg: 0.7291, mask: 0.3792\n",
      "step:     3640, time: 0.737, loss: 1.2396, l1: 0.2307, vgg: 0.6470, mask: 0.3619\n",
      "step:     3660, time: 0.729, loss: 1.3925, l1: 0.2700, vgg: 0.7300, mask: 0.3925\n",
      "step:     3680, time: 0.750, loss: 1.3368, l1: 0.2526, vgg: 0.7070, mask: 0.3772\n",
      "step:     3700, time: 0.717, loss: 1.2586, l1: 0.2585, vgg: 0.6314, mask: 0.3687\n",
      "step:     3720, time: 0.746, loss: 1.3846, l1: 0.3042, vgg: 0.6811, mask: 0.3993\n",
      "step:     3740, time: 0.717, loss: 1.2458, l1: 0.2663, vgg: 0.6176, mask: 0.3618\n",
      "step:     3760, time: 0.712, loss: 1.2529, l1: 0.2466, vgg: 0.6445, mask: 0.3618\n",
      "step:     3780, time: 0.736, loss: 1.2907, l1: 0.2677, vgg: 0.6458, mask: 0.3772\n",
      "step:     3800, time: 0.705, loss: 1.2231, l1: 0.2094, vgg: 0.6516, mask: 0.3620\n",
      "step:     3820, time: 0.749, loss: 1.2873, l1: 0.2188, vgg: 0.6832, mask: 0.3853\n",
      "step:     3840, time: 0.741, loss: 1.4306, l1: 0.3111, vgg: 0.7279, mask: 0.3916\n",
      "step:     3860, time: 0.739, loss: 1.4443, l1: 0.2970, vgg: 0.7759, mask: 0.3714\n",
      "step:     3880, time: 0.764, loss: 1.5375, l1: 0.3125, vgg: 0.8087, mask: 0.4163\n",
      "step:     3900, time: 0.720, loss: 1.2369, l1: 0.2587, vgg: 0.6367, mask: 0.3415\n",
      "step:     3920, time: 0.753, loss: 1.3183, l1: 0.2646, vgg: 0.6809, mask: 0.3728\n",
      "step:     3940, time: 0.739, loss: 1.3435, l1: 0.2242, vgg: 0.7458, mask: 0.3735\n",
      "step:     3960, time: 0.745, loss: 1.3696, l1: 0.2993, vgg: 0.6751, mask: 0.3953\n",
      "step:     3980, time: 0.702, loss: 1.2074, l1: 0.2571, vgg: 0.5890, mask: 0.3613\n",
      "step:     4000, time: 0.715, loss: 1.2472, l1: 0.2194, vgg: 0.6684, mask: 0.3593\n",
      "step:     4020, time: 0.705, loss: 1.3015, l1: 0.2866, vgg: 0.6486, mask: 0.3664\n",
      "step:     4040, time: 0.748, loss: 1.3351, l1: 0.3046, vgg: 0.6509, mask: 0.3795\n",
      "step:     4060, time: 0.692, loss: 1.2530, l1: 0.2584, vgg: 0.6311, mask: 0.3635\n",
      "step:     4080, time: 0.789, loss: 1.2598, l1: 0.2139, vgg: 0.6766, mask: 0.3693\n",
      "step:     4100, time: 0.752, loss: 1.4279, l1: 0.2676, vgg: 0.7484, mask: 0.4120\n",
      "step:     4120, time: 0.767, loss: 1.3270, l1: 0.2643, vgg: 0.6337, mask: 0.4289\n",
      "step:     4140, time: 0.714, loss: 1.2944, l1: 0.2622, vgg: 0.6869, mask: 0.3453\n",
      "step:     4160, time: 0.716, loss: 1.1314, l1: 0.2539, vgg: 0.5331, mask: 0.3444\n",
      "step:     4180, time: 0.727, loss: 1.5119, l1: 0.3457, vgg: 0.7346, mask: 0.4316\n",
      "step:     4200, time: 0.702, loss: 1.2578, l1: 0.2369, vgg: 0.6262, mask: 0.3947\n",
      "step:     4220, time: 0.714, loss: 1.2222, l1: 0.2098, vgg: 0.6564, mask: 0.3560\n",
      "step:     4240, time: 0.752, loss: 1.4032, l1: 0.2448, vgg: 0.7770, mask: 0.3813\n",
      "step:     4260, time: 0.724, loss: 1.4159, l1: 0.2803, vgg: 0.7009, mask: 0.4346\n",
      "step:     4280, time: 0.727, loss: 1.2683, l1: 0.2636, vgg: 0.6225, mask: 0.3822\n",
      "step:     4300, time: 0.722, loss: 1.2115, l1: 0.2401, vgg: 0.6080, mask: 0.3634\n",
      "step:     4320, time: 0.733, loss: 1.3268, l1: 0.2661, vgg: 0.6782, mask: 0.3824\n",
      "step:     4340, time: 0.709, loss: 1.2404, l1: 0.2413, vgg: 0.6340, mask: 0.3651\n",
      "step:     4360, time: 0.785, loss: 1.3038, l1: 0.2483, vgg: 0.7072, mask: 0.3483\n",
      "step:     4380, time: 0.770, loss: 1.2656, l1: 0.2524, vgg: 0.6250, mask: 0.3882\n",
      "step:     4400, time: 0.738, loss: 1.2535, l1: 0.2382, vgg: 0.6383, mask: 0.3770\n",
      "step:     4420, time: 0.723, loss: 1.2448, l1: 0.2169, vgg: 0.6878, mask: 0.3400\n",
      "step:     4440, time: 0.728, loss: 1.2294, l1: 0.2054, vgg: 0.6816, mask: 0.3425\n",
      "step:     4460, time: 0.727, loss: 1.3129, l1: 0.2863, vgg: 0.6453, mask: 0.3813\n",
      "step:     4480, time: 0.739, loss: 1.1874, l1: 0.2199, vgg: 0.6333, mask: 0.3343\n",
      "step:     4500, time: 0.707, loss: 1.2889, l1: 0.2348, vgg: 0.6680, mask: 0.3861\n",
      "step:     4520, time: 0.739, loss: 1.2310, l1: 0.2340, vgg: 0.6418, mask: 0.3552\n",
      "step:     4540, time: 0.699, loss: 1.2862, l1: 0.2832, vgg: 0.6547, mask: 0.3483\n",
      "step:     4560, time: 0.739, loss: 1.3268, l1: 0.2569, vgg: 0.7107, mask: 0.3592\n",
      "step:     4580, time: 0.703, loss: 1.2030, l1: 0.1598, vgg: 0.6453, mask: 0.3978\n",
      "step:     4600, time: 0.751, loss: 1.4007, l1: 0.3053, vgg: 0.7292, mask: 0.3662\n",
      "step:     4620, time: 0.725, loss: 1.2422, l1: 0.2572, vgg: 0.5805, mask: 0.4045\n",
      "step:     4640, time: 0.721, loss: 1.2693, l1: 0.2344, vgg: 0.6855, mask: 0.3493\n",
      "step:     4660, time: 0.730, loss: 1.2477, l1: 0.2235, vgg: 0.6464, mask: 0.3778\n",
      "step:     4680, time: 0.720, loss: 1.3663, l1: 0.2791, vgg: 0.7169, mask: 0.3702\n",
      "step:     4700, time: 0.762, loss: 1.3469, l1: 0.2856, vgg: 0.6864, mask: 0.3749\n",
      "step:     4720, time: 0.726, loss: 1.2241, l1: 0.2541, vgg: 0.5970, mask: 0.3730\n",
      "step:     4740, time: 0.729, loss: 1.2597, l1: 0.2264, vgg: 0.6722, mask: 0.3611\n",
      "step:     4760, time: 0.734, loss: 1.3117, l1: 0.2441, vgg: 0.6932, mask: 0.3744\n",
      "step:     4780, time: 0.722, loss: 1.2889, l1: 0.2691, vgg: 0.6604, mask: 0.3594\n",
      "step:     4800, time: 0.744, loss: 1.3256, l1: 0.2566, vgg: 0.6965, mask: 0.3725\n",
      "step:     4820, time: 0.726, loss: 1.2677, l1: 0.2603, vgg: 0.6188, mask: 0.3886\n",
      "step:     4840, time: 0.726, loss: 1.3810, l1: 0.2966, vgg: 0.6935, mask: 0.3909\n",
      "step:     4860, time: 0.707, loss: 1.2496, l1: 0.2700, vgg: 0.6048, mask: 0.3748\n",
      "step:     4880, time: 0.702, loss: 1.2574, l1: 0.2999, vgg: 0.5915, mask: 0.3660\n",
      "step:     4900, time: 0.733, loss: 1.4269, l1: 0.3065, vgg: 0.7470, mask: 0.3734\n",
      "step:     4920, time: 0.743, loss: 1.2346, l1: 0.2481, vgg: 0.6341, mask: 0.3524\n",
      "step:     4940, time: 0.735, loss: 1.2344, l1: 0.2438, vgg: 0.6211, mask: 0.3695\n",
      "step:     4960, time: 0.722, loss: 1.2384, l1: 0.2369, vgg: 0.6418, mask: 0.3598\n",
      "step:     4980, time: 0.732, loss: 1.2943, l1: 0.2528, vgg: 0.6527, mask: 0.3888\n",
      "step:     5000, time: 0.756, loss: 1.2300, l1: 0.2303, vgg: 0.6429, mask: 0.3568\n",
      "step:     5020, time: 0.753, loss: 1.4378, l1: 0.3133, vgg: 0.6983, mask: 0.4262\n",
      "step:     5040, time: 0.745, loss: 1.2867, l1: 0.2254, vgg: 0.7065, mask: 0.3547\n",
      "step:     5060, time: 0.754, loss: 1.2651, l1: 0.2561, vgg: 0.6615, mask: 0.3475\n",
      "step:     5080, time: 0.740, loss: 1.3845, l1: 0.2723, vgg: 0.7395, mask: 0.3727\n",
      "step:     5100, time: 0.749, loss: 1.3289, l1: 0.2509, vgg: 0.7062, mask: 0.3718\n",
      "step:     5120, time: 0.755, loss: 1.3689, l1: 0.3124, vgg: 0.6700, mask: 0.3865\n",
      "step:     5140, time: 0.725, loss: 1.3053, l1: 0.2481, vgg: 0.6975, mask: 0.3598\n",
      "step:     5160, time: 0.737, loss: 1.3147, l1: 0.2393, vgg: 0.7118, mask: 0.3636\n",
      "step:     5180, time: 0.769, loss: 1.3608, l1: 0.2598, vgg: 0.7301, mask: 0.3709\n",
      "step:     5200, time: 0.743, loss: 1.3102, l1: 0.2792, vgg: 0.6435, mask: 0.3875\n",
      "step:     5220, time: 0.729, loss: 1.2717, l1: 0.2549, vgg: 0.6577, mask: 0.3590\n",
      "step:     5240, time: 0.712, loss: 1.2147, l1: 0.2410, vgg: 0.6281, mask: 0.3457\n",
      "step:     5260, time: 0.717, loss: 1.2463, l1: 0.2469, vgg: 0.5965, mask: 0.4029\n",
      "step:     5280, time: 0.712, loss: 1.3272, l1: 0.2932, vgg: 0.6369, mask: 0.3972\n",
      "step:     5300, time: 0.757, loss: 1.2706, l1: 0.2782, vgg: 0.6380, mask: 0.3545\n",
      "step:     5320, time: 0.730, loss: 1.2901, l1: 0.2450, vgg: 0.6555, mask: 0.3896\n",
      "step:     5340, time: 0.735, loss: 1.1779, l1: 0.2305, vgg: 0.6041, mask: 0.3433\n",
      "step:     5360, time: 0.744, loss: 1.3231, l1: 0.2750, vgg: 0.6599, mask: 0.3882\n",
      "step:     5380, time: 0.740, loss: 1.2607, l1: 0.2086, vgg: 0.6974, mask: 0.3546\n",
      "step:     5400, time: 0.738, loss: 1.2301, l1: 0.2323, vgg: 0.6303, mask: 0.3675\n",
      "step:     5420, time: 0.730, loss: 1.2471, l1: 0.2367, vgg: 0.6703, mask: 0.3401\n",
      "step:     5440, time: 0.714, loss: 1.2627, l1: 0.2553, vgg: 0.6651, mask: 0.3423\n",
      "step:     5460, time: 0.753, loss: 1.2795, l1: 0.2228, vgg: 0.6996, mask: 0.3571\n",
      "step:     5480, time: 0.768, loss: 1.2766, l1: 0.2502, vgg: 0.6523, mask: 0.3740\n",
      "step:     5500, time: 0.729, loss: 1.1485, l1: 0.2287, vgg: 0.6000, mask: 0.3198\n",
      "step:     5520, time: 0.764, loss: 1.2993, l1: 0.2774, vgg: 0.6436, mask: 0.3784\n",
      "step:     5540, time: 0.763, loss: 1.2390, l1: 0.2202, vgg: 0.6527, mask: 0.3661\n",
      "step:     5560, time: 0.748, loss: 1.2997, l1: 0.3088, vgg: 0.6271, mask: 0.3638\n",
      "step:     5580, time: 0.731, loss: 1.2709, l1: 0.2383, vgg: 0.6394, mask: 0.3932\n",
      "step:     5600, time: 0.719, loss: 1.2113, l1: 0.2304, vgg: 0.6371, mask: 0.3439\n",
      "step:     5620, time: 0.742, loss: 1.2840, l1: 0.2574, vgg: 0.6516, mask: 0.3750\n",
      "step:     5640, time: 0.746, loss: 1.4913, l1: 0.3519, vgg: 0.7235, mask: 0.4159\n",
      "step:     5660, time: 0.749, loss: 1.2530, l1: 0.2554, vgg: 0.6354, mask: 0.3622\n",
      "step:     5680, time: 0.729, loss: 1.1360, l1: 0.1943, vgg: 0.6075, mask: 0.3342\n",
      "step:     5700, time: 0.729, loss: 1.3455, l1: 0.2818, vgg: 0.6998, mask: 0.3638\n",
      "step:     5720, time: 0.760, loss: 1.2383, l1: 0.2776, vgg: 0.6168, mask: 0.3439\n",
      "step:     5740, time: 0.749, loss: 1.3481, l1: 0.2438, vgg: 0.7401, mask: 0.3642\n",
      "step:     5760, time: 0.720, loss: 1.2044, l1: 0.2270, vgg: 0.6482, mask: 0.3291\n",
      "step:     5780, time: 0.715, loss: 1.1226, l1: 0.2140, vgg: 0.5474, mask: 0.3611\n",
      "step:     5800, time: 0.729, loss: 1.2069, l1: 0.2683, vgg: 0.5825, mask: 0.3561\n",
      "step:     5820, time: 0.733, loss: 1.3011, l1: 0.2379, vgg: 0.7161, mask: 0.3471\n",
      "step:     5840, time: 0.742, loss: 1.3070, l1: 0.2909, vgg: 0.6438, mask: 0.3722\n",
      "step:     5860, time: 0.725, loss: 1.2369, l1: 0.2492, vgg: 0.5893, mask: 0.3983\n",
      "step:     5880, time: 0.721, loss: 1.3094, l1: 0.2886, vgg: 0.6502, mask: 0.3707\n",
      "step:     5900, time: 0.760, loss: 1.3284, l1: 0.2631, vgg: 0.6556, mask: 0.4097\n",
      "step:     5920, time: 0.721, loss: 1.2628, l1: 0.2566, vgg: 0.6408, mask: 0.3653\n",
      "step:     5940, time: 0.719, loss: 1.2405, l1: 0.2606, vgg: 0.6302, mask: 0.3497\n",
      "step:     5960, time: 0.731, loss: 1.3196, l1: 0.2562, vgg: 0.6825, mask: 0.3810\n",
      "step:     5980, time: 0.749, loss: 1.3380, l1: 0.2665, vgg: 0.6735, mask: 0.3980\n",
      "step:     6000, time: 0.738, loss: 1.3918, l1: 0.2614, vgg: 0.7190, mask: 0.4113\n",
      "step:     6020, time: 0.711, loss: 1.2847, l1: 0.2410, vgg: 0.6992, mask: 0.3445\n",
      "step:     6040, time: 0.740, loss: 1.3364, l1: 0.2366, vgg: 0.7128, mask: 0.3870\n",
      "step:     6060, time: 0.691, loss: 1.1903, l1: 0.2437, vgg: 0.6038, mask: 0.3427\n",
      "step:     6080, time: 0.735, loss: 1.3629, l1: 0.2593, vgg: 0.7346, mask: 0.3690\n",
      "step:     6100, time: 0.705, loss: 1.1327, l1: 0.2101, vgg: 0.5917, mask: 0.3310\n",
      "step:     6120, time: 0.732, loss: 1.2736, l1: 0.2999, vgg: 0.6194, mask: 0.3544\n",
      "step:     6140, time: 0.748, loss: 1.2783, l1: 0.2739, vgg: 0.6086, mask: 0.3957\n",
      "step:     6160, time: 0.734, loss: 1.4063, l1: 0.2643, vgg: 0.7584, mask: 0.3837\n",
      "step:     6180, time: 0.742, loss: 1.1793, l1: 0.2011, vgg: 0.6226, mask: 0.3556\n",
      "step:     6200, time: 0.715, loss: 1.3364, l1: 0.2869, vgg: 0.6811, mask: 0.3684\n",
      "step:     6220, time: 0.747, loss: 1.3869, l1: 0.2762, vgg: 0.7317, mask: 0.3791\n",
      "step:     6240, time: 0.731, loss: 1.3203, l1: 0.3241, vgg: 0.6002, mask: 0.3960\n",
      "step:     6260, time: 0.692, loss: 1.2706, l1: 0.2778, vgg: 0.6100, mask: 0.3828\n",
      "step:     6280, time: 0.738, loss: 1.2865, l1: 0.2657, vgg: 0.6324, mask: 0.3883\n",
      "step:     6300, time: 0.780, loss: 1.2745, l1: 0.2390, vgg: 0.6812, mask: 0.3544\n",
      "step:     6320, time: 0.737, loss: 1.3592, l1: 0.2952, vgg: 0.6866, mask: 0.3774\n",
      "step:     6340, time: 0.753, loss: 1.5070, l1: 0.2764, vgg: 0.8671, mask: 0.3635\n",
      "step:     6360, time: 0.721, loss: 1.2555, l1: 0.2717, vgg: 0.6156, mask: 0.3682\n",
      "step:     6380, time: 0.731, loss: 1.2285, l1: 0.2326, vgg: 0.6435, mask: 0.3524\n",
      "step:     6400, time: 0.747, loss: 1.3295, l1: 0.2739, vgg: 0.6685, mask: 0.3871\n",
      "step:     6420, time: 0.759, loss: 1.2739, l1: 0.2501, vgg: 0.6683, mask: 0.3555\n",
      "step:     6440, time: 0.740, loss: 1.1659, l1: 0.2229, vgg: 0.6023, mask: 0.3406\n",
      "step:     6460, time: 0.704, loss: 1.1567, l1: 0.2309, vgg: 0.5705, mask: 0.3553\n",
      "step:     6480, time: 0.750, loss: 1.4727, l1: 0.3590, vgg: 0.7207, mask: 0.3930\n",
      "step:     6500, time: 0.731, loss: 1.1618, l1: 0.2228, vgg: 0.5963, mask: 0.3427\n",
      "step:     6520, time: 0.724, loss: 1.2178, l1: 0.2373, vgg: 0.6260, mask: 0.3545\n",
      "step:     6540, time: 0.729, loss: 1.2656, l1: 0.2365, vgg: 0.6623, mask: 0.3669\n",
      "step:     6560, time: 0.715, loss: 1.3042, l1: 0.2622, vgg: 0.6703, mask: 0.3717\n",
      "step:     6580, time: 0.716, loss: 1.1803, l1: 0.2132, vgg: 0.6145, mask: 0.3526\n",
      "step:     6600, time: 0.746, loss: 1.3463, l1: 0.2330, vgg: 0.7634, mask: 0.3499\n",
      "step:     6620, time: 0.700, loss: 1.2157, l1: 0.2248, vgg: 0.6324, mask: 0.3585\n",
      "step:     6640, time: 0.707, loss: 1.1430, l1: 0.1987, vgg: 0.5966, mask: 0.3477\n",
      "step:     6660, time: 0.738, loss: 1.4457, l1: 0.2990, vgg: 0.7545, mask: 0.3922\n",
      "step:     6680, time: 0.709, loss: 1.2238, l1: 0.2300, vgg: 0.6247, mask: 0.3691\n",
      "step:     6700, time: 0.759, loss: 1.3638, l1: 0.2701, vgg: 0.6991, mask: 0.3946\n",
      "step:     6720, time: 0.774, loss: 1.4169, l1: 0.3319, vgg: 0.6525, mask: 0.4325\n",
      "step:     6740, time: 0.758, loss: 1.4858, l1: 0.3027, vgg: 0.8059, mask: 0.3772\n",
      "step:     6760, time: 0.774, loss: 1.2803, l1: 0.2528, vgg: 0.6676, mask: 0.3599\n",
      "step:     6780, time: 0.743, loss: 1.3120, l1: 0.2925, vgg: 0.6109, mask: 0.4085\n",
      "step:     6800, time: 0.739, loss: 1.4365, l1: 0.3176, vgg: 0.7276, mask: 0.3913\n",
      "step:     6820, time: 0.726, loss: 1.1290, l1: 0.2207, vgg: 0.5494, mask: 0.3590\n",
      "step:     6840, time: 0.739, loss: 1.1971, l1: 0.2104, vgg: 0.6425, mask: 0.3442\n",
      "step:     6860, time: 0.745, loss: 1.3307, l1: 0.2471, vgg: 0.6721, mask: 0.4115\n",
      "step:     6880, time: 0.794, loss: 1.4541, l1: 0.3316, vgg: 0.7020, mask: 0.4205\n",
      "step:     6900, time: 0.723, loss: 1.2714, l1: 0.2716, vgg: 0.6576, mask: 0.3422\n",
      "step:     6920, time: 0.731, loss: 1.2691, l1: 0.2445, vgg: 0.6864, mask: 0.3382\n",
      "step:     6940, time: 0.755, loss: 1.3494, l1: 0.2884, vgg: 0.6781, mask: 0.3829\n",
      "step:     6960, time: 0.748, loss: 1.3444, l1: 0.2371, vgg: 0.7442, mask: 0.3631\n",
      "step:     6980, time: 0.719, loss: 1.2389, l1: 0.2286, vgg: 0.6540, mask: 0.3563\n",
      "step:     7000, time: 0.745, loss: 1.3532, l1: 0.2763, vgg: 0.6719, mask: 0.4050\n",
      "step:     7020, time: 0.728, loss: 1.2324, l1: 0.2650, vgg: 0.5944, mask: 0.3730\n",
      "step:     7040, time: 0.715, loss: 1.1832, l1: 0.2170, vgg: 0.5646, mask: 0.4015\n",
      "step:     7060, time: 0.727, loss: 1.2409, l1: 0.2345, vgg: 0.6454, mask: 0.3610\n",
      "step:     7080, time: 0.740, loss: 1.2687, l1: 0.2813, vgg: 0.6367, mask: 0.3507\n",
      "step:     7100, time: 0.727, loss: 1.3018, l1: 0.2347, vgg: 0.6884, mask: 0.3787\n",
      "step:     7120, time: 0.722, loss: 1.2777, l1: 0.3009, vgg: 0.5981, mask: 0.3787\n",
      "step:     7140, time: 0.688, loss: 1.2197, l1: 0.2451, vgg: 0.6113, mask: 0.3634\n",
      "step:     7160, time: 0.748, loss: 1.2755, l1: 0.2759, vgg: 0.6288, mask: 0.3709\n",
      "step:     7180, time: 0.748, loss: 1.1562, l1: 0.2042, vgg: 0.6176, mask: 0.3345\n",
      "step:     7200, time: 0.728, loss: 1.2202, l1: 0.2485, vgg: 0.6053, mask: 0.3664\n",
      "step:     7220, time: 0.729, loss: 1.0463, l1: 0.1711, vgg: 0.5490, mask: 0.3262\n",
      "step:     7240, time: 0.722, loss: 1.2892, l1: 0.2434, vgg: 0.6984, mask: 0.3474\n",
      "step:     7260, time: 0.752, loss: 1.3719, l1: 0.3253, vgg: 0.6555, mask: 0.3910\n",
      "step:     7280, time: 0.720, loss: 1.2769, l1: 0.2486, vgg: 0.6390, mask: 0.3893\n",
      "step:     7300, time: 0.746, loss: 1.2417, l1: 0.2509, vgg: 0.6319, mask: 0.3589\n",
      "step:     7320, time: 0.743, loss: 1.1917, l1: 0.2236, vgg: 0.6249, mask: 0.3431\n",
      "step:     7340, time: 0.726, loss: 1.2815, l1: 0.2443, vgg: 0.6802, mask: 0.3570\n",
      "step:     7360, time: 0.745, loss: 1.1726, l1: 0.2003, vgg: 0.6270, mask: 0.3453\n",
      "step:     7380, time: 0.745, loss: 1.3857, l1: 0.2649, vgg: 0.7062, mask: 0.4146\n",
      "step:     7400, time: 0.691, loss: 1.2254, l1: 0.2557, vgg: 0.6067, mask: 0.3630\n",
      "step:     7420, time: 0.717, loss: 1.2668, l1: 0.2712, vgg: 0.5705, mask: 0.4251\n",
      "step:     7440, time: 0.738, loss: 1.3533, l1: 0.2708, vgg: 0.7343, mask: 0.3482\n",
      "step:     7460, time: 0.736, loss: 1.2819, l1: 0.2418, vgg: 0.6775, mask: 0.3625\n",
      "step:     7480, time: 0.793, loss: 1.3949, l1: 0.3007, vgg: 0.7029, mask: 0.3913\n",
      "step:     7500, time: 0.774, loss: 1.2338, l1: 0.2306, vgg: 0.6078, mask: 0.3954\n",
      "step:     7520, time: 0.741, loss: 1.3374, l1: 0.2494, vgg: 0.6902, mask: 0.3978\n",
      "step:     7540, time: 0.734, loss: 1.3613, l1: 0.2482, vgg: 0.7549, mask: 0.3582\n",
      "step:     7560, time: 0.709, loss: 1.3249, l1: 0.2878, vgg: 0.6725, mask: 0.3646\n",
      "step:     7580, time: 0.709, loss: 1.1794, l1: 0.2226, vgg: 0.6112, mask: 0.3457\n",
      "step:     7600, time: 0.763, loss: 1.3395, l1: 0.2532, vgg: 0.7003, mask: 0.3861\n",
      "step:     7620, time: 0.773, loss: 1.1849, l1: 0.2155, vgg: 0.6009, mask: 0.3684\n",
      "step:     7640, time: 0.712, loss: 1.1994, l1: 0.2156, vgg: 0.6412, mask: 0.3426\n",
      "step:     7660, time: 0.710, loss: 1.1133, l1: 0.2016, vgg: 0.5732, mask: 0.3386\n",
      "step:     7680, time: 0.714, loss: 1.1523, l1: 0.1903, vgg: 0.6280, mask: 0.3341\n",
      "step:     7700, time: 0.732, loss: 1.2046, l1: 0.2713, vgg: 0.5615, mask: 0.3718\n",
      "step:     7720, time: 0.731, loss: 1.4072, l1: 0.2602, vgg: 0.7349, mask: 0.4120\n",
      "step:     7740, time: 0.717, loss: 1.2126, l1: 0.2061, vgg: 0.6537, mask: 0.3527\n",
      "step:     7760, time: 0.769, loss: 1.2978, l1: 0.2465, vgg: 0.6805, mask: 0.3709\n",
      "step:     7780, time: 0.728, loss: 1.1027, l1: 0.1990, vgg: 0.5547, mask: 0.3489\n",
      "step:     7800, time: 0.775, loss: 1.3668, l1: 0.2408, vgg: 0.7259, mask: 0.4001\n",
      "step:     7820, time: 0.733, loss: 1.2624, l1: 0.2402, vgg: 0.6563, mask: 0.3659\n",
      "step:     7840, time: 0.738, loss: 1.2992, l1: 0.2405, vgg: 0.6700, mask: 0.3888\n",
      "step:     7860, time: 0.720, loss: 1.1832, l1: 0.2246, vgg: 0.6052, mask: 0.3534\n",
      "step:     7880, time: 0.732, loss: 1.2610, l1: 0.2518, vgg: 0.6402, mask: 0.3689\n",
      "step:     7900, time: 0.719, loss: 1.1410, l1: 0.2077, vgg: 0.6105, mask: 0.3227\n",
      "step:     7920, time: 0.729, loss: 1.2089, l1: 0.2319, vgg: 0.6275, mask: 0.3496\n",
      "step:     7940, time: 0.767, loss: 1.2524, l1: 0.2601, vgg: 0.6303, mask: 0.3621\n",
      "step:     7960, time: 0.738, loss: 1.2420, l1: 0.2750, vgg: 0.6172, mask: 0.3498\n",
      "step:     7980, time: 0.712, loss: 1.2005, l1: 0.2672, vgg: 0.5638, mask: 0.3695\n",
      "step:     8000, time: 0.755, loss: 1.2006, l1: 0.1926, vgg: 0.6148, mask: 0.3932\n",
      "step:     8020, time: 0.727, loss: 1.3786, l1: 0.3124, vgg: 0.6272, mask: 0.4390\n",
      "step:     8040, time: 0.747, loss: 1.3689, l1: 0.2869, vgg: 0.6980, mask: 0.3840\n",
      "step:     8060, time: 0.714, loss: 1.2675, l1: 0.2387, vgg: 0.6815, mask: 0.3473\n",
      "step:     8080, time: 0.722, loss: 1.3135, l1: 0.2818, vgg: 0.6516, mask: 0.3800\n",
      "step:     8100, time: 0.743, loss: 1.1729, l1: 0.2083, vgg: 0.6122, mask: 0.3523\n",
      "step:     8120, time: 0.717, loss: 1.1754, l1: 0.2121, vgg: 0.5742, mask: 0.3891\n",
      "step:     8140, time: 0.754, loss: 1.3151, l1: 0.2645, vgg: 0.6986, mask: 0.3520\n",
      "step:     8160, time: 0.716, loss: 1.2407, l1: 0.2406, vgg: 0.6195, mask: 0.3805\n",
      "step:     8180, time: 0.742, loss: 1.2944, l1: 0.2438, vgg: 0.6864, mask: 0.3643\n",
      "step:     8200, time: 0.712, loss: 1.2114, l1: 0.2555, vgg: 0.5884, mask: 0.3674\n",
      "step:     8220, time: 0.762, loss: 1.4255, l1: 0.3114, vgg: 0.6925, mask: 0.4216\n",
      "step:     8240, time: 0.750, loss: 1.3001, l1: 0.2393, vgg: 0.6795, mask: 0.3813\n",
      "step:     8260, time: 0.745, loss: 1.2609, l1: 0.2417, vgg: 0.6603, mask: 0.3589\n",
      "step:     8280, time: 0.736, loss: 1.1035, l1: 0.2068, vgg: 0.5486, mask: 0.3481\n",
      "step:     8300, time: 0.726, loss: 1.1555, l1: 0.2024, vgg: 0.5607, mask: 0.3923\n",
      "step:     8320, time: 0.703, loss: 1.3485, l1: 0.3511, vgg: 0.5966, mask: 0.4008\n",
      "step:     8340, time: 0.735, loss: 1.3622, l1: 0.2849, vgg: 0.6802, mask: 0.3970\n",
      "step:     8360, time: 0.687, loss: 1.0943, l1: 0.2170, vgg: 0.5315, mask: 0.3458\n",
      "step:     8380, time: 0.706, loss: 1.1584, l1: 0.2265, vgg: 0.5872, mask: 0.3447\n",
      "step:     8400, time: 0.722, loss: 1.3917, l1: 0.3458, vgg: 0.6184, mask: 0.4275\n",
      "step:     8420, time: 0.736, loss: 1.4526, l1: 0.3128, vgg: 0.7470, mask: 0.3927\n",
      "step:     8440, time: 0.730, loss: 1.2404, l1: 0.2262, vgg: 0.6646, mask: 0.3496\n",
      "step:     8460, time: 0.713, loss: 1.3768, l1: 0.2512, vgg: 0.7724, mask: 0.3532\n",
      "step:     8480, time: 0.720, loss: 1.1263, l1: 0.2062, vgg: 0.5832, mask: 0.3369\n",
      "step:     8500, time: 0.728, loss: 1.1933, l1: 0.2296, vgg: 0.5745, mask: 0.3892\n",
      "step:     8520, time: 0.728, loss: 1.2080, l1: 0.2475, vgg: 0.6234, mask: 0.3372\n",
      "step:     8540, time: 0.740, loss: 1.3478, l1: 0.2945, vgg: 0.6772, mask: 0.3760\n",
      "step:     8560, time: 0.730, loss: 1.2837, l1: 0.2904, vgg: 0.6093, mask: 0.3839\n",
      "step:     8580, time: 0.751, loss: 1.2786, l1: 0.2622, vgg: 0.6214, mask: 0.3950\n",
      "step:     8600, time: 0.736, loss: 1.2286, l1: 0.2543, vgg: 0.6308, mask: 0.3435\n",
      "step:     8620, time: 0.746, loss: 1.2634, l1: 0.3044, vgg: 0.6169, mask: 0.3421\n",
      "step:     8640, time: 0.749, loss: 1.3782, l1: 0.2608, vgg: 0.7459, mask: 0.3715\n",
      "step:     8660, time: 0.748, loss: 1.3153, l1: 0.2258, vgg: 0.7422, mask: 0.3473\n",
      "step:     8680, time: 0.712, loss: 1.2225, l1: 0.2563, vgg: 0.5917, mask: 0.3744\n",
      "step:     8700, time: 0.761, loss: 1.2721, l1: 0.2724, vgg: 0.6273, mask: 0.3724\n",
      "step:     8720, time: 0.691, loss: 1.1801, l1: 0.2274, vgg: 0.5716, mask: 0.3811\n",
      "step:     8740, time: 0.738, loss: 1.2670, l1: 0.2739, vgg: 0.6240, mask: 0.3690\n",
      "step:     8760, time: 0.780, loss: 1.4401, l1: 0.3270, vgg: 0.7139, mask: 0.3991\n",
      "step:     8780, time: 0.767, loss: 1.3513, l1: 0.2571, vgg: 0.7281, mask: 0.3661\n",
      "step:     8800, time: 0.725, loss: 1.1823, l1: 0.2026, vgg: 0.6306, mask: 0.3491\n",
      "step:     8820, time: 0.725, loss: 1.2810, l1: 0.2656, vgg: 0.6231, mask: 0.3923\n",
      "step:     8840, time: 0.740, loss: 1.3184, l1: 0.3173, vgg: 0.6132, mask: 0.3879\n",
      "step:     8860, time: 0.717, loss: 1.2587, l1: 0.2823, vgg: 0.5973, mask: 0.3791\n",
      "step:     8880, time: 0.736, loss: 1.2822, l1: 0.2449, vgg: 0.6914, mask: 0.3459\n",
      "step:     8900, time: 0.723, loss: 1.3759, l1: 0.2760, vgg: 0.7133, mask: 0.3865\n",
      "step:     8920, time: 0.765, loss: 1.3884, l1: 0.2825, vgg: 0.7118, mask: 0.3941\n",
      "step:     8940, time: 0.721, loss: 1.2148, l1: 0.2378, vgg: 0.5962, mask: 0.3808\n",
      "step:     8960, time: 0.715, loss: 1.2916, l1: 0.2637, vgg: 0.6302, mask: 0.3977\n",
      "step:     8980, time: 0.768, loss: 1.2964, l1: 0.2936, vgg: 0.6027, mask: 0.4001\n",
      "step:     9000, time: 0.732, loss: 1.2551, l1: 0.2792, vgg: 0.6054, mask: 0.3705\n",
      "step:     9020, time: 0.714, loss: 1.1539, l1: 0.2451, vgg: 0.5410, mask: 0.3678\n",
      "step:     9040, time: 0.761, loss: 1.3021, l1: 0.2434, vgg: 0.6962, mask: 0.3625\n",
      "step:     9060, time: 0.751, loss: 1.2985, l1: 0.2628, vgg: 0.6323, mask: 0.4033\n",
      "step:     9080, time: 0.760, loss: 1.3403, l1: 0.2675, vgg: 0.7179, mask: 0.3548\n",
      "step:     9100, time: 0.743, loss: 1.2429, l1: 0.2185, vgg: 0.6655, mask: 0.3588\n",
      "step:     9120, time: 0.728, loss: 1.2617, l1: 0.2446, vgg: 0.6207, mask: 0.3963\n",
      "step:     9140, time: 0.736, loss: 1.2157, l1: 0.1978, vgg: 0.6760, mask: 0.3420\n",
      "step:     9160, time: 0.727, loss: 1.3096, l1: 0.2874, vgg: 0.6423, mask: 0.3798\n",
      "step:     9180, time: 0.753, loss: 1.1835, l1: 0.2276, vgg: 0.5856, mask: 0.3703\n",
      "step:     9200, time: 0.769, loss: 1.3275, l1: 0.2755, vgg: 0.6741, mask: 0.3779\n",
      "step:     9220, time: 0.721, loss: 1.1579, l1: 0.1919, vgg: 0.6405, mask: 0.3255\n",
      "step:     9240, time: 0.761, loss: 1.3160, l1: 0.2639, vgg: 0.6496, mask: 0.4025\n",
      "step:     9260, time: 0.733, loss: 1.1521, l1: 0.2248, vgg: 0.5461, mask: 0.3813\n",
      "step:     9280, time: 0.754, loss: 1.2749, l1: 0.2418, vgg: 0.6719, mask: 0.3612\n",
      "step:     9300, time: 0.751, loss: 1.3214, l1: 0.2854, vgg: 0.6680, mask: 0.3681\n",
      "step:     9320, time: 0.750, loss: 1.3190, l1: 0.2540, vgg: 0.6996, mask: 0.3654\n",
      "step:     9340, time: 0.738, loss: 1.1780, l1: 0.2169, vgg: 0.6070, mask: 0.3541\n",
      "step:     9360, time: 0.727, loss: 1.2729, l1: 0.2783, vgg: 0.5849, mask: 0.4096\n",
      "step:     9380, time: 0.764, loss: 1.1728, l1: 0.2525, vgg: 0.5663, mask: 0.3540\n",
      "step:     9400, time: 0.736, loss: 1.3206, l1: 0.2583, vgg: 0.6739, mask: 0.3884\n",
      "step:     9420, time: 0.737, loss: 1.2567, l1: 0.2312, vgg: 0.6591, mask: 0.3665\n",
      "step:     9440, time: 0.728, loss: 1.2087, l1: 0.2087, vgg: 0.6186, mask: 0.3814\n",
      "step:     9460, time: 0.742, loss: 1.2886, l1: 0.2448, vgg: 0.6442, mask: 0.3997\n",
      "step:     9480, time: 0.711, loss: 1.2248, l1: 0.2435, vgg: 0.5976, mask: 0.3837\n",
      "step:     9500, time: 0.766, loss: 1.3710, l1: 0.3141, vgg: 0.6502, mask: 0.4066\n",
      "step:     9520, time: 0.730, loss: 1.2198, l1: 0.2415, vgg: 0.5957, mask: 0.3827\n",
      "step:     9540, time: 0.758, loss: 1.2812, l1: 0.2782, vgg: 0.6407, mask: 0.3623\n",
      "step:     9560, time: 0.697, loss: 1.1621, l1: 0.2113, vgg: 0.5953, mask: 0.3554\n",
      "step:     9580, time: 0.748, loss: 1.3034, l1: 0.2409, vgg: 0.6859, mask: 0.3765\n",
      "step:     9600, time: 0.724, loss: 1.2338, l1: 0.2224, vgg: 0.6409, mask: 0.3704\n",
      "step:     9620, time: 0.713, loss: 1.1993, l1: 0.2248, vgg: 0.6126, mask: 0.3619\n",
      "step:     9640, time: 0.730, loss: 1.2412, l1: 0.2651, vgg: 0.6029, mask: 0.3731\n",
      "step:     9660, time: 0.723, loss: 1.3179, l1: 0.2657, vgg: 0.6748, mask: 0.3774\n",
      "step:     9680, time: 0.766, loss: 1.2866, l1: 0.2408, vgg: 0.6356, mask: 0.4102\n",
      "step:     9700, time: 0.690, loss: 1.2020, l1: 0.2589, vgg: 0.6082, mask: 0.3350\n",
      "step:     9720, time: 0.762, loss: 1.2770, l1: 0.2536, vgg: 0.6447, mask: 0.3788\n",
      "step:     9740, time: 0.745, loss: 1.1659, l1: 0.2077, vgg: 0.5957, mask: 0.3625\n",
      "step:     9760, time: 0.730, loss: 1.2299, l1: 0.2301, vgg: 0.6260, mask: 0.3738\n",
      "step:     9780, time: 0.742, loss: 1.2860, l1: 0.2566, vgg: 0.6518, mask: 0.3776\n",
      "step:     9800, time: 0.758, loss: 1.2283, l1: 0.2508, vgg: 0.5993, mask: 0.3782\n",
      "step:     9820, time: 0.750, loss: 1.2761, l1: 0.3087, vgg: 0.5897, mask: 0.3777\n",
      "step:     9840, time: 0.723, loss: 1.2202, l1: 0.2381, vgg: 0.5973, mask: 0.3848\n",
      "step:     9860, time: 0.726, loss: 1.2586, l1: 0.2820, vgg: 0.5695, mask: 0.4071\n",
      "step:     9880, time: 0.751, loss: 1.3984, l1: 0.3360, vgg: 0.6784, mask: 0.3839\n",
      "step:     9900, time: 0.768, loss: 1.1447, l1: 0.1868, vgg: 0.6234, mask: 0.3345\n",
      "step:     9920, time: 0.741, loss: 1.2402, l1: 0.2333, vgg: 0.6643, mask: 0.3427\n",
      "step:     9940, time: 0.736, loss: 1.3072, l1: 0.2616, vgg: 0.6946, mask: 0.3509\n",
      "step:     9960, time: 0.722, loss: 1.2721, l1: 0.2835, vgg: 0.6163, mask: 0.3722\n",
      "step:     9980, time: 0.758, loss: 1.2023, l1: 0.2423, vgg: 0.5753, mask: 0.3846\n",
      "step:    10000, time: 0.725, loss: 1.2629, l1: 0.2599, vgg: 0.6310, mask: 0.3721\n",
      "step:    10020, time: 0.778, loss: 1.3777, l1: 0.2728, vgg: 0.7238, mask: 0.3810\n",
      "step:    10040, time: 0.735, loss: 1.1797, l1: 0.2070, vgg: 0.6192, mask: 0.3535\n",
      "step:    10060, time: 0.733, loss: 1.2794, l1: 0.2706, vgg: 0.5767, mask: 0.4321\n",
      "step:    10080, time: 0.744, loss: 1.2976, l1: 0.2959, vgg: 0.6092, mask: 0.3926\n",
      "step:    10100, time: 0.752, loss: 1.2288, l1: 0.2149, vgg: 0.6600, mask: 0.3539\n",
      "step:    10120, time: 0.708, loss: 1.1864, l1: 0.2213, vgg: 0.5798, mask: 0.3853\n",
      "step:    10140, time: 0.715, loss: 1.2416, l1: 0.2417, vgg: 0.5810, mask: 0.4189\n",
      "step:    10160, time: 0.733, loss: 1.1884, l1: 0.2128, vgg: 0.6000, mask: 0.3756\n",
      "step:    10180, time: 0.722, loss: 1.2416, l1: 0.2317, vgg: 0.6369, mask: 0.3730\n",
      "step:    10200, time: 0.713, loss: 1.1937, l1: 0.2246, vgg: 0.6177, mask: 0.3514\n",
      "step:    10220, time: 0.735, loss: 1.2797, l1: 0.2630, vgg: 0.6552, mask: 0.3615\n",
      "step:    10240, time: 0.767, loss: 1.3986, l1: 0.3278, vgg: 0.6751, mask: 0.3957\n",
      "step:    10260, time: 0.742, loss: 1.3237, l1: 0.2821, vgg: 0.6731, mask: 0.3684\n",
      "step:    10280, time: 0.785, loss: 1.3565, l1: 0.2768, vgg: 0.6755, mask: 0.4042\n",
      "step:    10300, time: 0.729, loss: 1.3991, l1: 0.3260, vgg: 0.6788, mask: 0.3943\n",
      "step:    10320, time: 0.748, loss: 1.2660, l1: 0.2810, vgg: 0.6051, mask: 0.3799\n",
      "step:    10340, time: 0.727, loss: 1.2595, l1: 0.2630, vgg: 0.6419, mask: 0.3545\n",
      "step:    10360, time: 0.769, loss: 1.2927, l1: 0.2344, vgg: 0.6910, mask: 0.3672\n",
      "step:    10380, time: 0.725, loss: 1.1931, l1: 0.2124, vgg: 0.6394, mask: 0.3413\n",
      "step:    10400, time: 0.715, loss: 1.3055, l1: 0.2755, vgg: 0.6344, mask: 0.3956\n",
      "step:    10420, time: 0.788, loss: 1.2606, l1: 0.2320, vgg: 0.6797, mask: 0.3489\n",
      "step:    10440, time: 0.713, loss: 1.1621, l1: 0.2249, vgg: 0.5863, mask: 0.3509\n",
      "step:    10460, time: 0.722, loss: 1.2038, l1: 0.2667, vgg: 0.5808, mask: 0.3563\n",
      "step:    10480, time: 0.782, loss: 1.2572, l1: 0.2150, vgg: 0.6966, mask: 0.3456\n",
      "step:    10500, time: 0.731, loss: 1.2014, l1: 0.2491, vgg: 0.5818, mask: 0.3705\n",
      "step:    10520, time: 0.723, loss: 1.2602, l1: 0.2792, vgg: 0.6253, mask: 0.3556\n",
      "step:    10540, time: 0.766, loss: 1.4407, l1: 0.2540, vgg: 0.8259, mask: 0.3608\n",
      "step:    10560, time: 0.730, loss: 1.2319, l1: 0.2355, vgg: 0.6190, mask: 0.3774\n",
      "step:    10580, time: 0.711, loss: 1.1508, l1: 0.2321, vgg: 0.5718, mask: 0.3469\n",
      "step:    10600, time: 0.793, loss: 1.1930, l1: 0.2200, vgg: 0.6118, mask: 0.3611\n",
      "step:    10620, time: 0.731, loss: 1.1734, l1: 0.2358, vgg: 0.5754, mask: 0.3621\n",
      "step:    10640, time: 0.741, loss: 1.2397, l1: 0.2415, vgg: 0.6562, mask: 0.3421\n",
      "step:    10660, time: 0.749, loss: 1.3002, l1: 0.2743, vgg: 0.6237, mask: 0.4021\n",
      "step:    10680, time: 0.763, loss: 1.2811, l1: 0.3297, vgg: 0.5769, mask: 0.3744\n",
      "step:    10700, time: 0.734, loss: 1.2325, l1: 0.2418, vgg: 0.6260, mask: 0.3647\n",
      "step:    10720, time: 0.754, loss: 1.3254, l1: 0.2887, vgg: 0.6364, mask: 0.4004\n",
      "step:    10740, time: 0.745, loss: 1.2323, l1: 0.2625, vgg: 0.5928, mask: 0.3770\n",
      "step:    10760, time: 0.801, loss: 1.1460, l1: 0.2028, vgg: 0.5917, mask: 0.3515\n",
      "step:    10780, time: 0.768, loss: 1.2635, l1: 0.2532, vgg: 0.6375, mask: 0.3729\n",
      "step:    10800, time: 0.756, loss: 1.2921, l1: 0.2641, vgg: 0.6569, mask: 0.3710\n",
      "step:    10820, time: 0.740, loss: 1.3201, l1: 0.2810, vgg: 0.6534, mask: 0.3857\n",
      "step:    10840, time: 0.751, loss: 1.3151, l1: 0.2631, vgg: 0.6369, mask: 0.4152\n",
      "step:    10860, time: 0.734, loss: 1.2208, l1: 0.2511, vgg: 0.6128, mask: 0.3569\n",
      "step:    10880, time: 0.736, loss: 1.1177, l1: 0.1984, vgg: 0.5747, mask: 0.3446\n",
      "step:    10900, time: 0.712, loss: 1.2108, l1: 0.2028, vgg: 0.6655, mask: 0.3425\n",
      "step:    10920, time: 0.756, loss: 1.2396, l1: 0.2003, vgg: 0.6616, mask: 0.3777\n",
      "step:    10940, time: 0.747, loss: 1.3410, l1: 0.2939, vgg: 0.6498, mask: 0.3973\n",
      "step:    10960, time: 0.791, loss: 1.2047, l1: 0.2338, vgg: 0.5891, mask: 0.3818\n",
      "step:    10980, time: 0.756, loss: 1.2186, l1: 0.2081, vgg: 0.6767, mask: 0.3338\n",
      "step:    11000, time: 0.690, loss: 1.1204, l1: 0.1977, vgg: 0.5866, mask: 0.3361\n",
      "step:    11020, time: 0.735, loss: 1.1478, l1: 0.1828, vgg: 0.5995, mask: 0.3655\n",
      "step:    11040, time: 0.762, loss: 1.2187, l1: 0.2220, vgg: 0.6199, mask: 0.3768\n",
      "step:    11060, time: 0.763, loss: 1.3244, l1: 0.2554, vgg: 0.6978, mask: 0.3711\n",
      "step:    11080, time: 0.751, loss: 1.2609, l1: 0.2655, vgg: 0.6259, mask: 0.3695\n",
      "step:    11100, time: 0.752, loss: 1.3065, l1: 0.2977, vgg: 0.6401, mask: 0.3687\n",
      "step:    11120, time: 0.700, loss: 1.2291, l1: 0.2474, vgg: 0.6255, mask: 0.3562\n",
      "step:    11140, time: 0.713, loss: 1.3025, l1: 0.2664, vgg: 0.6650, mask: 0.3710\n",
      "step:    11160, time: 0.701, loss: 1.1605, l1: 0.2171, vgg: 0.5894, mask: 0.3540\n",
      "step:    11180, time: 0.725, loss: 1.3511, l1: 0.2702, vgg: 0.6625, mask: 0.4184\n",
      "step:    11200, time: 0.747, loss: 1.4175, l1: 0.3142, vgg: 0.6922, mask: 0.4110\n",
      "step:    11220, time: 0.718, loss: 1.1036, l1: 0.1872, vgg: 0.5896, mask: 0.3268\n",
      "step:    11240, time: 0.764, loss: 1.4039, l1: 0.3202, vgg: 0.6673, mask: 0.4164\n",
      "step:    11260, time: 0.775, loss: 1.2167, l1: 0.2273, vgg: 0.6189, mask: 0.3705\n",
      "step:    11280, time: 0.738, loss: 1.1409, l1: 0.2167, vgg: 0.5817, mask: 0.3424\n",
      "step:    11300, time: 0.742, loss: 1.3053, l1: 0.2831, vgg: 0.6229, mask: 0.3992\n",
      "step:    11320, time: 0.784, loss: 1.3615, l1: 0.2688, vgg: 0.6601, mask: 0.4326\n",
      "step:    11340, time: 0.733, loss: 1.1594, l1: 0.2001, vgg: 0.5979, mask: 0.3614\n",
      "step:    11360, time: 0.775, loss: 1.1360, l1: 0.1973, vgg: 0.5950, mask: 0.3437\n",
      "step:    11380, time: 0.738, loss: 1.1953, l1: 0.2401, vgg: 0.5670, mask: 0.3882\n",
      "step:    11400, time: 0.751, loss: 1.4288, l1: 0.2961, vgg: 0.6970, mask: 0.4357\n",
      "step:    11420, time: 0.735, loss: 1.3502, l1: 0.2689, vgg: 0.7014, mask: 0.3798\n",
      "step:    11440, time: 0.795, loss: 1.2371, l1: 0.2760, vgg: 0.5979, mask: 0.3632\n",
      "step:    11460, time: 0.763, loss: 1.1606, l1: 0.1922, vgg: 0.6264, mask: 0.3420\n",
      "step:    11480, time: 0.780, loss: 1.2957, l1: 0.2441, vgg: 0.7018, mask: 0.3498\n",
      "step:    11500, time: 0.783, loss: 1.3126, l1: 0.2377, vgg: 0.6925, mask: 0.3823\n",
      "step:    11520, time: 0.898, loss: 1.2302, l1: 0.2663, vgg: 0.5742, mask: 0.3897\n",
      "step:    11540, time: 0.778, loss: 1.1233, l1: 0.2138, vgg: 0.5507, mask: 0.3588\n",
      "step:    11560, time: 0.758, loss: 1.2088, l1: 0.2519, vgg: 0.6013, mask: 0.3556\n",
      "step:    11580, time: 0.710, loss: 1.1124, l1: 0.2212, vgg: 0.5658, mask: 0.3255\n",
      "step:    11600, time: 0.764, loss: 1.1918, l1: 0.2306, vgg: 0.5909, mask: 0.3703\n",
      "step:    11620, time: 0.746, loss: 1.1701, l1: 0.2341, vgg: 0.5780, mask: 0.3579\n",
      "step:    11640, time: 0.750, loss: 1.2092, l1: 0.2329, vgg: 0.6087, mask: 0.3676\n",
      "step:    11660, time: 0.738, loss: 1.2114, l1: 0.2449, vgg: 0.6031, mask: 0.3634\n",
      "step:    11680, time: 0.730, loss: 1.2191, l1: 0.2223, vgg: 0.6270, mask: 0.3699\n",
      "step:    11700, time: 0.739, loss: 1.1639, l1: 0.2287, vgg: 0.5812, mask: 0.3541\n",
      "step:    11720, time: 0.737, loss: 1.3025, l1: 0.2749, vgg: 0.6361, mask: 0.3915\n",
      "step:    11740, time: 0.761, loss: 1.0706, l1: 0.1901, vgg: 0.5193, mask: 0.3613\n",
      "step:    11760, time: 0.705, loss: 1.1964, l1: 0.2443, vgg: 0.5986, mask: 0.3535\n",
      "step:    11780, time: 0.764, loss: 1.2114, l1: 0.2447, vgg: 0.6166, mask: 0.3501\n",
      "step:    11800, time: 0.822, loss: 1.4497, l1: 0.3187, vgg: 0.7401, mask: 0.3908\n",
      "step:    11820, time: 0.696, loss: 1.1738, l1: 0.2210, vgg: 0.6003, mask: 0.3524\n",
      "step:    11840, time: 0.759, loss: 1.3430, l1: 0.2853, vgg: 0.6711, mask: 0.3866\n",
      "step:    11860, time: 0.764, loss: 1.3230, l1: 0.2584, vgg: 0.6676, mask: 0.3970\n",
      "step:    11880, time: 0.770, loss: 1.2712, l1: 0.2389, vgg: 0.6720, mask: 0.3602\n",
      "step:    11900, time: 0.759, loss: 1.2927, l1: 0.2538, vgg: 0.6603, mask: 0.3786\n",
      "step:    11920, time: 0.736, loss: 1.3395, l1: 0.2805, vgg: 0.6910, mask: 0.3679\n",
      "step:    11940, time: 0.775, loss: 1.2511, l1: 0.2350, vgg: 0.6529, mask: 0.3632\n",
      "step:    11960, time: 0.762, loss: 1.1544, l1: 0.2145, vgg: 0.5916, mask: 0.3484\n",
      "step:    11980, time: 0.728, loss: 1.2799, l1: 0.2968, vgg: 0.5817, mask: 0.4014\n",
      "step:    12000, time: 0.726, loss: 1.2608, l1: 0.2713, vgg: 0.5904, mask: 0.3990\n",
      "step:    12020, time: 0.751, loss: 1.1256, l1: 0.2176, vgg: 0.5382, mask: 0.3698\n",
      "step:    12040, time: 0.744, loss: 1.2362, l1: 0.2435, vgg: 0.6346, mask: 0.3581\n",
      "step:    12060, time: 0.744, loss: 1.2803, l1: 0.2667, vgg: 0.6328, mask: 0.3807\n",
      "step:    12080, time: 0.737, loss: 1.2593, l1: 0.2506, vgg: 0.6695, mask: 0.3392\n",
      "step:    12100, time: 0.746, loss: 1.1793, l1: 0.2092, vgg: 0.6265, mask: 0.3437\n",
      "step:    12120, time: 0.753, loss: 1.3032, l1: 0.2942, vgg: 0.6415, mask: 0.3675\n",
      "step:    12140, time: 0.728, loss: 1.1073, l1: 0.2431, vgg: 0.5011, mask: 0.3631\n",
      "step:    12160, time: 0.779, loss: 1.2600, l1: 0.2285, vgg: 0.6818, mask: 0.3497\n",
      "step:    12180, time: 0.736, loss: 1.1983, l1: 0.2403, vgg: 0.5810, mask: 0.3770\n",
      "step:    12200, time: 0.722, loss: 1.2482, l1: 0.2473, vgg: 0.6341, mask: 0.3668\n",
      "step:    12220, time: 0.725, loss: 1.1258, l1: 0.1935, vgg: 0.6018, mask: 0.3305\n",
      "step:    12240, time: 0.743, loss: 1.2183, l1: 0.2233, vgg: 0.6352, mask: 0.3598\n",
      "step:    12260, time: 0.755, loss: 1.1893, l1: 0.2395, vgg: 0.6033, mask: 0.3466\n",
      "step:    12280, time: 0.754, loss: 1.2117, l1: 0.2318, vgg: 0.6096, mask: 0.3702\n",
      "step:    12300, time: 0.752, loss: 1.1401, l1: 0.1902, vgg: 0.6093, mask: 0.3407\n",
      "step:    12320, time: 0.730, loss: 1.1290, l1: 0.2348, vgg: 0.5471, mask: 0.3470\n",
      "step:    12340, time: 0.727, loss: 1.2151, l1: 0.2496, vgg: 0.6064, mask: 0.3591\n",
      "step:    12360, time: 0.715, loss: 1.1500, l1: 0.2296, vgg: 0.5697, mask: 0.3508\n",
      "step:    12380, time: 0.744, loss: 1.1999, l1: 0.2139, vgg: 0.6043, mask: 0.3818\n",
      "step:    12400, time: 0.801, loss: 1.1819, l1: 0.2572, vgg: 0.5720, mask: 0.3528\n",
      "step:    12420, time: 0.784, loss: 1.3230, l1: 0.2451, vgg: 0.6953, mask: 0.3825\n",
      "step:    12440, time: 0.788, loss: 1.2751, l1: 0.2612, vgg: 0.6329, mask: 0.3811\n",
      "step:    12460, time: 0.732, loss: 1.2293, l1: 0.2432, vgg: 0.6172, mask: 0.3689\n",
      "step:    12480, time: 0.761, loss: 1.3070, l1: 0.2664, vgg: 0.6725, mask: 0.3681\n",
      "step:    12500, time: 0.753, loss: 1.1973, l1: 0.2261, vgg: 0.6017, mask: 0.3695\n",
      "step:    12520, time: 0.728, loss: 1.2085, l1: 0.2320, vgg: 0.5946, mask: 0.3818\n",
      "step:    12540, time: 0.756, loss: 1.1815, l1: 0.2542, vgg: 0.5665, mask: 0.3608\n",
      "step:    12560, time: 0.738, loss: 1.3622, l1: 0.3074, vgg: 0.6427, mask: 0.4121\n",
      "step:    12580, time: 0.816, loss: 1.2993, l1: 0.2426, vgg: 0.6886, mask: 0.3682\n",
      "step:    12600, time: 0.740, loss: 1.1971, l1: 0.2557, vgg: 0.5558, mask: 0.3857\n",
      "step:    12620, time: 0.739, loss: 1.1746, l1: 0.2035, vgg: 0.5644, mask: 0.4067\n",
      "step:    12640, time: 0.715, loss: 1.1712, l1: 0.2167, vgg: 0.5877, mask: 0.3668\n",
      "step:    12660, time: 0.711, loss: 1.2577, l1: 0.2228, vgg: 0.6816, mask: 0.3532\n",
      "step:    12680, time: 0.751, loss: 1.1050, l1: 0.1983, vgg: 0.5723, mask: 0.3344\n",
      "step:    12700, time: 0.711, loss: 1.1873, l1: 0.2244, vgg: 0.5768, mask: 0.3861\n",
      "step:    12720, time: 0.764, loss: 1.3127, l1: 0.2911, vgg: 0.6086, mask: 0.4130\n",
      "step:    12740, time: 0.755, loss: 1.2741, l1: 0.2788, vgg: 0.6004, mask: 0.3949\n",
      "step:    12760, time: 0.743, loss: 1.2488, l1: 0.3006, vgg: 0.5681, mask: 0.3800\n",
      "step:    12780, time: 0.745, loss: 1.2510, l1: 0.2469, vgg: 0.5754, mask: 0.4287\n",
      "step:    12800, time: 0.755, loss: 1.2614, l1: 0.2346, vgg: 0.6356, mask: 0.3913\n",
      "step:    12820, time: 0.756, loss: 1.2177, l1: 0.2251, vgg: 0.6325, mask: 0.3601\n",
      "step:    12840, time: 0.789, loss: 1.3722, l1: 0.2780, vgg: 0.7021, mask: 0.3921\n",
      "step:    12860, time: 0.738, loss: 1.0737, l1: 0.1851, vgg: 0.5756, mask: 0.3131\n",
      "step:    12880, time: 0.774, loss: 1.2057, l1: 0.2068, vgg: 0.6437, mask: 0.3552\n",
      "step:    12900, time: 0.790, loss: 1.1840, l1: 0.2378, vgg: 0.6198, mask: 0.3264\n",
      "step:    12920, time: 0.746, loss: 1.3311, l1: 0.2860, vgg: 0.6751, mask: 0.3700\n",
      "step:    12940, time: 0.711, loss: 1.1101, l1: 0.2269, vgg: 0.5277, mask: 0.3555\n",
      "step:    12960, time: 0.838, loss: 1.4331, l1: 0.3346, vgg: 0.6761, mask: 0.4224\n",
      "step:    12980, time: 0.771, loss: 1.3677, l1: 0.2628, vgg: 0.6990, mask: 0.4059\n",
      "step:    13000, time: 0.773, loss: 1.3565, l1: 0.2684, vgg: 0.6972, mask: 0.3909\n",
      "step:    13020, time: 0.758, loss: 1.3654, l1: 0.2884, vgg: 0.6750, mask: 0.4020\n",
      "step:    13040, time: 0.732, loss: 1.2812, l1: 0.2441, vgg: 0.6660, mask: 0.3711\n",
      "step:    13060, time: 0.741, loss: 1.2599, l1: 0.2470, vgg: 0.6476, mask: 0.3653\n",
      "step:    13080, time: 0.775, loss: 1.4166, l1: 0.2636, vgg: 0.7518, mask: 0.4012\n",
      "step:    13100, time: 0.760, loss: 1.2220, l1: 0.2304, vgg: 0.5995, mask: 0.3921\n",
      "step:    13120, time: 0.730, loss: 1.2463, l1: 0.2416, vgg: 0.6111, mask: 0.3936\n",
      "step:    13140, time: 0.738, loss: 1.1673, l1: 0.2154, vgg: 0.6043, mask: 0.3475\n",
      "step:    13160, time: 0.733, loss: 1.1424, l1: 0.2086, vgg: 0.5691, mask: 0.3647\n",
      "step:    13180, time: 0.743, loss: 1.2855, l1: 0.2759, vgg: 0.6140, mask: 0.3955\n",
      "step:    13200, time: 0.777, loss: 1.3776, l1: 0.2927, vgg: 0.6794, mask: 0.4054\n",
      "step:    13220, time: 0.774, loss: 1.2729, l1: 0.1954, vgg: 0.6736, mask: 0.4039\n",
      "step:    13240, time: 0.744, loss: 1.3581, l1: 0.2902, vgg: 0.6491, mask: 0.4188\n",
      "step:    13260, time: 0.759, loss: 1.0567, l1: 0.1745, vgg: 0.5428, mask: 0.3393\n",
      "step:    13280, time: 0.759, loss: 1.1912, l1: 0.2468, vgg: 0.5837, mask: 0.3607\n",
      "step:    13300, time: 0.753, loss: 1.1745, l1: 0.2322, vgg: 0.5879, mask: 0.3544\n",
      "step:    13320, time: 0.729, loss: 1.2463, l1: 0.2296, vgg: 0.6244, mask: 0.3923\n",
      "step:    13340, time: 0.787, loss: 1.1703, l1: 0.2300, vgg: 0.5726, mask: 0.3678\n",
      "step:    13360, time: 0.753, loss: 1.1838, l1: 0.2215, vgg: 0.6060, mask: 0.3563\n",
      "step:    13380, time: 0.758, loss: 1.2469, l1: 0.2552, vgg: 0.6121, mask: 0.3797\n",
      "step:    13400, time: 0.733, loss: 1.2041, l1: 0.2767, vgg: 0.5318, mask: 0.3956\n",
      "step:    13420, time: 0.731, loss: 1.2338, l1: 0.2217, vgg: 0.6469, mask: 0.3652\n",
      "step:    13440, time: 0.738, loss: 1.1169, l1: 0.2075, vgg: 0.5814, mask: 0.3281\n",
      "step:    13460, time: 0.821, loss: 1.3182, l1: 0.2702, vgg: 0.6456, mask: 0.4025\n",
      "step:    13480, time: 0.762, loss: 1.1394, l1: 0.2295, vgg: 0.5646, mask: 0.3453\n",
      "step:    13500, time: 0.722, loss: 1.1832, l1: 0.2192, vgg: 0.6003, mask: 0.3638\n",
      "step:    13520, time: 0.742, loss: 1.3462, l1: 0.3238, vgg: 0.6246, mask: 0.3977\n",
      "step:    13540, time: 0.739, loss: 1.2589, l1: 0.2721, vgg: 0.5782, mask: 0.4086\n",
      "step:    13560, time: 0.762, loss: 1.1977, l1: 0.2362, vgg: 0.5923, mask: 0.3692\n",
      "step:    13580, time: 0.749, loss: 1.2741, l1: 0.2931, vgg: 0.5888, mask: 0.3921\n",
      "step:    13600, time: 0.755, loss: 1.2512, l1: 0.2527, vgg: 0.6110, mask: 0.3875\n",
      "step:    13620, time: 0.771, loss: 1.3435, l1: 0.3016, vgg: 0.6446, mask: 0.3974\n",
      "step:    13640, time: 0.736, loss: 1.1414, l1: 0.2254, vgg: 0.5589, mask: 0.3571\n",
      "step:    13660, time: 0.762, loss: 1.2373, l1: 0.2377, vgg: 0.6094, mask: 0.3902\n",
      "step:    13680, time: 0.765, loss: 1.3771, l1: 0.2489, vgg: 0.6860, mask: 0.4423\n",
      "step:    13700, time: 0.746, loss: 1.1641, l1: 0.2166, vgg: 0.5929, mask: 0.3545\n",
      "step:    13720, time: 0.748, loss: 1.1280, l1: 0.1903, vgg: 0.5431, mask: 0.3947\n",
      "step:    13740, time: 0.766, loss: 1.3125, l1: 0.2382, vgg: 0.7018, mask: 0.3725\n",
      "step:    13760, time: 0.742, loss: 1.1603, l1: 0.2163, vgg: 0.5992, mask: 0.3448\n",
      "step:    13780, time: 0.745, loss: 1.2294, l1: 0.2608, vgg: 0.6016, mask: 0.3669\n",
      "step:    13800, time: 0.709, loss: 1.2476, l1: 0.2628, vgg: 0.6216, mask: 0.3632\n",
      "step:    13820, time: 0.740, loss: 1.1247, l1: 0.2217, vgg: 0.5478, mask: 0.3552\n",
      "step:    13840, time: 0.762, loss: 1.2333, l1: 0.2350, vgg: 0.6470, mask: 0.3514\n",
      "step:    13860, time: 0.738, loss: 1.3282, l1: 0.2570, vgg: 0.7011, mask: 0.3701\n",
      "step:    13880, time: 0.698, loss: 1.0837, l1: 0.2059, vgg: 0.5499, mask: 0.3280\n",
      "step:    13900, time: 0.785, loss: 1.2487, l1: 0.2557, vgg: 0.5988, mask: 0.3942\n",
      "step:    13920, time: 0.748, loss: 1.1892, l1: 0.2508, vgg: 0.5976, mask: 0.3407\n",
      "step:    13940, time: 0.733, loss: 1.1449, l1: 0.2238, vgg: 0.5850, mask: 0.3361\n",
      "step:    13960, time: 0.740, loss: 1.1720, l1: 0.2233, vgg: 0.5809, mask: 0.3678\n",
      "step:    13980, time: 0.810, loss: 1.2738, l1: 0.2601, vgg: 0.6185, mask: 0.3952\n",
      "step:    14000, time: 0.754, loss: 1.2580, l1: 0.2332, vgg: 0.6577, mask: 0.3671\n",
      "step:    14020, time: 0.784, loss: 1.3128, l1: 0.2600, vgg: 0.6425, mask: 0.4104\n",
      "step:    14040, time: 0.763, loss: 1.2849, l1: 0.2744, vgg: 0.6079, mask: 0.4026\n",
      "step:    14060, time: 0.741, loss: 1.2314, l1: 0.2369, vgg: 0.6374, mask: 0.3570\n",
      "step:    14080, time: 0.745, loss: 1.2364, l1: 0.2327, vgg: 0.6558, mask: 0.3480\n",
      "step:    14100, time: 0.754, loss: 1.2873, l1: 0.2534, vgg: 0.6645, mask: 0.3695\n",
      "step:    14120, time: 0.768, loss: 1.1230, l1: 0.1931, vgg: 0.5871, mask: 0.3428\n",
      "step:    14140, time: 0.761, loss: 1.2708, l1: 0.2325, vgg: 0.6709, mask: 0.3674\n",
      "step:    14160, time: 0.787, loss: 1.2792, l1: 0.2725, vgg: 0.6156, mask: 0.3910\n",
      "step:    14180, time: 0.743, loss: 1.1592, l1: 0.2406, vgg: 0.5475, mask: 0.3712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "step:    14200, time: 0.750, loss: 1.2052, l1: 0.2195, vgg: 0.6212, mask: 0.3645\n",
      "step:    14220, time: 0.762, loss: 1.1648, l1: 0.2384, vgg: 0.5620, mask: 0.3645\n",
      "step:    14240, time: 0.752, loss: 1.2736, l1: 0.2515, vgg: 0.6437, mask: 0.3784\n",
      "step:    14260, time: 0.732, loss: 1.0791, l1: 0.2010, vgg: 0.5427, mask: 0.3355\n",
      "step:    14280, time: 0.755, loss: 1.1194, l1: 0.1903, vgg: 0.5610, mask: 0.3681\n",
      "step:    14300, time: 0.738, loss: 1.2829, l1: 0.2435, vgg: 0.6349, mask: 0.4045\n",
      "step:    14320, time: 0.770, loss: 1.3910, l1: 0.2690, vgg: 0.7388, mask: 0.3833\n",
      "step:    14340, time: 0.735, loss: 1.2648, l1: 0.2773, vgg: 0.5907, mask: 0.3968\n",
      "step:    14360, time: 0.735, loss: 1.1151, l1: 0.1828, vgg: 0.5052, mask: 0.4270\n",
      "step:    14380, time: 0.769, loss: 1.1930, l1: 0.2420, vgg: 0.5955, mask: 0.3554\n",
      "step:    14400, time: 0.775, loss: 1.3314, l1: 0.2971, vgg: 0.6640, mask: 0.3703\n",
      "step:    14420, time: 0.779, loss: 1.2526, l1: 0.2766, vgg: 0.5810, mask: 0.3950\n",
      "step:    14440, time: 0.739, loss: 1.1462, l1: 0.2118, vgg: 0.5790, mask: 0.3554\n",
      "step:    14460, time: 0.763, loss: 1.2207, l1: 0.2615, vgg: 0.5518, mask: 0.4074\n",
      "step:    14480, time: 0.752, loss: 1.1638, l1: 0.2381, vgg: 0.5501, mask: 0.3756\n",
      "step:    14500, time: 0.713, loss: 1.2005, l1: 0.2436, vgg: 0.5970, mask: 0.3599\n",
      "step:    14520, time: 0.785, loss: 1.3318, l1: 0.2841, vgg: 0.6550, mask: 0.3927\n",
      "step:    14540, time: 0.801, loss: 1.2003, l1: 0.2731, vgg: 0.5842, mask: 0.3429\n",
      "step:    14560, time: 0.861, loss: 1.3622, l1: 0.2725, vgg: 0.6877, mask: 0.4021\n",
      "step:    14580, time: 0.799, loss: 1.2676, l1: 0.2887, vgg: 0.5765, mask: 0.4024\n",
      "step:    14600, time: 0.819, loss: 1.1397, l1: 0.1970, vgg: 0.5967, mask: 0.3461\n",
      "step:    14620, time: 0.803, loss: 1.2705, l1: 0.2477, vgg: 0.6097, mask: 0.4130\n",
      "step:    14640, time: 0.796, loss: 1.1647, l1: 0.2093, vgg: 0.6025, mask: 0.3529\n",
      "step:    14660, time: 0.796, loss: 1.1538, l1: 0.2326, vgg: 0.5350, mask: 0.3862\n",
      "step:    14680, time: 0.731, loss: 1.2046, l1: 0.2331, vgg: 0.6149, mask: 0.3566\n",
      "step:    14700, time: 0.770, loss: 1.4229, l1: 0.3215, vgg: 0.6885, mask: 0.4128\n",
      "step:    14720, time: 0.757, loss: 1.0928, l1: 0.1944, vgg: 0.5640, mask: 0.3345\n",
      "step:    14740, time: 0.758, loss: 1.0783, l1: 0.1915, vgg: 0.5423, mask: 0.3445\n",
      "step:    14760, time: 0.748, loss: 1.2170, l1: 0.2236, vgg: 0.6141, mask: 0.3793\n",
      "step:    14780, time: 0.739, loss: 1.2893, l1: 0.3107, vgg: 0.5965, mask: 0.3821\n",
      "step:    14800, time: 0.721, loss: 1.0874, l1: 0.2049, vgg: 0.5558, mask: 0.3268\n",
      "step:    14820, time: 0.747, loss: 1.2604, l1: 0.2328, vgg: 0.6704, mask: 0.3572\n",
      "step:    14840, time: 0.757, loss: 1.1158, l1: 0.2126, vgg: 0.5536, mask: 0.3496\n",
      "step:    14860, time: 0.773, loss: 1.2531, l1: 0.2129, vgg: 0.6749, mask: 0.3652\n",
      "step:    14880, time: 0.731, loss: 1.0873, l1: 0.1932, vgg: 0.5374, mask: 0.3567\n",
      "step:    14900, time: 0.720, loss: 1.2449, l1: 0.2713, vgg: 0.5974, mask: 0.3762\n",
      "step:    14920, time: 0.780, loss: 1.3105, l1: 0.2838, vgg: 0.6432, mask: 0.3834\n",
      "step:    14940, time: 0.743, loss: 1.2354, l1: 0.2419, vgg: 0.6000, mask: 0.3935\n",
      "step:    14960, time: 0.748, loss: 1.2099, l1: 0.2183, vgg: 0.6216, mask: 0.3700\n",
      "step:    14980, time: 0.723, loss: 1.0683, l1: 0.1908, vgg: 0.5453, mask: 0.3323\n",
      "step:    15000, time: 0.719, loss: 1.1369, l1: 0.2400, vgg: 0.5397, mask: 0.3572\n",
      "step:    15020, time: 0.785, loss: 1.3467, l1: 0.2625, vgg: 0.7000, mask: 0.3843\n",
      "step:    15040, time: 0.781, loss: 1.2213, l1: 0.2532, vgg: 0.5684, mask: 0.3998\n",
      "step:    15060, time: 0.820, loss: 1.2866, l1: 0.2374, vgg: 0.6780, mask: 0.3712\n",
      "step:    15080, time: 0.753, loss: 1.2352, l1: 0.2703, vgg: 0.5791, mask: 0.3858\n",
      "step:    15100, time: 0.775, loss: 1.3269, l1: 0.3012, vgg: 0.6258, mask: 0.4000\n",
      "step:    15120, time: 0.836, loss: 1.1219, l1: 0.1766, vgg: 0.6014, mask: 0.3440\n",
      "step:    15140, time: 0.824, loss: 1.1848, l1: 0.2276, vgg: 0.5828, mask: 0.3743\n",
      "step:    15160, time: 0.831, loss: 1.2844, l1: 0.2584, vgg: 0.6496, mask: 0.3764\n",
      "step:    15180, time: 0.769, loss: 1.2362, l1: 0.2590, vgg: 0.5685, mask: 0.4087\n",
      "step:    15200, time: 0.783, loss: 1.1660, l1: 0.1896, vgg: 0.6082, mask: 0.3683\n",
      "step:    15220, time: 0.815, loss: 1.3132, l1: 0.2855, vgg: 0.6096, mask: 0.4182\n",
      "step:    15240, time: 0.747, loss: 1.2929, l1: 0.2605, vgg: 0.6205, mask: 0.4120\n",
      "step:    15260, time: 0.762, loss: 1.2045, l1: 0.2103, vgg: 0.6173, mask: 0.3769\n",
      "step:    15280, time: 0.742, loss: 1.1893, l1: 0.2529, vgg: 0.5679, mask: 0.3685\n",
      "step:    15300, time: 0.781, loss: 1.2602, l1: 0.2935, vgg: 0.5567, mask: 0.4101\n",
      "step:    15320, time: 0.815, loss: 1.1442, l1: 0.2291, vgg: 0.5591, mask: 0.3560\n",
      "step:    15340, time: 0.764, loss: 1.3092, l1: 0.2931, vgg: 0.6476, mask: 0.3685\n",
      "step:    15360, time: 0.751, loss: 1.1349, l1: 0.2216, vgg: 0.5623, mask: 0.3510\n",
      "step:    15380, time: 0.726, loss: 1.1449, l1: 0.2373, vgg: 0.5600, mask: 0.3476\n",
      "step:    15400, time: 0.784, loss: 1.2262, l1: 0.2248, vgg: 0.6298, mask: 0.3716\n",
      "step:    15420, time: 0.749, loss: 1.2300, l1: 0.2126, vgg: 0.6603, mask: 0.3571\n",
      "step:    15440, time: 0.753, loss: 1.2132, l1: 0.2245, vgg: 0.5705, mask: 0.4182\n",
      "step:    15460, time: 0.700, loss: 1.3456, l1: 0.3039, vgg: 0.6524, mask: 0.3893\n",
      "step:    15480, time: 0.757, loss: 1.2134, l1: 0.2529, vgg: 0.5973, mask: 0.3632\n",
      "step:    15500, time: 0.794, loss: 1.3340, l1: 0.2780, vgg: 0.6505, mask: 0.4056\n",
      "step:    15520, time: 0.719, loss: 1.1600, l1: 0.2181, vgg: 0.6141, mask: 0.3278\n",
      "step:    15540, time: 0.797, loss: 1.4387, l1: 0.2726, vgg: 0.7819, mask: 0.3841\n",
      "step:    15560, time: 0.755, loss: 1.2057, l1: 0.2470, vgg: 0.6019, mask: 0.3568\n",
      "step:    15580, time: 0.774, loss: 1.1561, l1: 0.2640, vgg: 0.5371, mask: 0.3550\n",
      "step:    15600, time: 0.807, loss: 1.2655, l1: 0.2555, vgg: 0.6020, mask: 0.4081\n",
      "step:    15620, time: 0.758, loss: 1.3640, l1: 0.2797, vgg: 0.6759, mask: 0.4084\n",
      "step:    15640, time: 0.744, loss: 1.0877, l1: 0.2148, vgg: 0.5379, mask: 0.3350\n",
      "step:    15660, time: 0.754, loss: 1.3067, l1: 0.2833, vgg: 0.6502, mask: 0.3733\n",
      "step:    15680, time: 0.787, loss: 1.2779, l1: 0.2509, vgg: 0.6084, mask: 0.4186\n",
      "step:    15700, time: 0.726, loss: 1.1674, l1: 0.2191, vgg: 0.5457, mask: 0.4026\n",
      "step:    15720, time: 0.752, loss: 1.0900, l1: 0.2220, vgg: 0.5232, mask: 0.3448\n",
      "step:    15740, time: 0.752, loss: 1.2606, l1: 0.2493, vgg: 0.6462, mask: 0.3650\n",
      "step:    15760, time: 0.768, loss: 1.2314, l1: 0.2368, vgg: 0.6317, mask: 0.3628\n",
      "step:    15780, time: 0.749, loss: 1.2448, l1: 0.2450, vgg: 0.6346, mask: 0.3652\n",
      "step:    15800, time: 0.749, loss: 1.2054, l1: 0.2552, vgg: 0.5778, mask: 0.3724\n",
      "step:    15820, time: 0.726, loss: 1.2297, l1: 0.2537, vgg: 0.6159, mask: 0.3600\n",
      "step:    15840, time: 0.746, loss: 1.2589, l1: 0.2428, vgg: 0.6483, mask: 0.3678\n",
      "step:    15860, time: 0.748, loss: 1.2627, l1: 0.2971, vgg: 0.5962, mask: 0.3694\n",
      "step:    15880, time: 0.734, loss: 1.1369, l1: 0.2358, vgg: 0.5444, mask: 0.3567\n",
      "step:    15900, time: 0.755, loss: 1.2991, l1: 0.3063, vgg: 0.5996, mask: 0.3932\n",
      "step:    15920, time: 0.768, loss: 1.3067, l1: 0.2569, vgg: 0.6647, mask: 0.3851\n",
      "step:    15940, time: 0.724, loss: 1.1374, l1: 0.2011, vgg: 0.5825, mask: 0.3538\n",
      "step:    15960, time: 0.740, loss: 1.3205, l1: 0.2626, vgg: 0.6812, mask: 0.3766\n",
      "step:    15980, time: 0.729, loss: 1.1415, l1: 0.2087, vgg: 0.6073, mask: 0.3255\n",
      "step:    16000, time: 0.766, loss: 1.3123, l1: 0.2724, vgg: 0.6493, mask: 0.3906\n",
      "step:    16020, time: 0.758, loss: 1.1601, l1: 0.2095, vgg: 0.5471, mask: 0.4035\n",
      "step:    16040, time: 0.766, loss: 1.2110, l1: 0.2193, vgg: 0.6198, mask: 0.3718\n",
      "step:    16060, time: 0.733, loss: 1.1055, l1: 0.2254, vgg: 0.5252, mask: 0.3549\n",
      "step:    16080, time: 0.749, loss: 1.1473, l1: 0.2365, vgg: 0.5523, mask: 0.3585\n",
      "step:    16100, time: 0.751, loss: 1.1400, l1: 0.2383, vgg: 0.5519, mask: 0.3499\n",
      "step:    16120, time: 0.771, loss: 1.2500, l1: 0.2700, vgg: 0.5790, mask: 0.4010\n",
      "step:    16140, time: 0.751, loss: 1.1864, l1: 0.2326, vgg: 0.5740, mask: 0.3798\n",
      "step:    16160, time: 0.744, loss: 1.1284, l1: 0.2125, vgg: 0.5379, mask: 0.3780\n",
      "step:    16180, time: 0.767, loss: 1.3737, l1: 0.3312, vgg: 0.6317, mask: 0.4107\n",
      "step:    16200, time: 0.718, loss: 1.2031, l1: 0.2255, vgg: 0.5844, mask: 0.3932\n",
      "step:    16220, time: 0.738, loss: 1.1123, l1: 0.2155, vgg: 0.5156, mask: 0.3813\n",
      "step:    16240, time: 0.713, loss: 1.1586, l1: 0.1871, vgg: 0.6074, mask: 0.3642\n",
      "step:    16260, time: 0.778, loss: 1.3627, l1: 0.2596, vgg: 0.6730, mask: 0.4301\n",
      "step:    16280, time: 0.722, loss: 1.1250, l1: 0.2050, vgg: 0.5674, mask: 0.3526\n",
      "step:    16300, time: 0.746, loss: 1.2877, l1: 0.2352, vgg: 0.6914, mask: 0.3611\n",
      "step:    16320, time: 0.726, loss: 1.1355, l1: 0.1892, vgg: 0.6032, mask: 0.3431\n",
      "step:    16340, time: 0.795, loss: 1.2472, l1: 0.2557, vgg: 0.6253, mask: 0.3662\n",
      "step:    16360, time: 0.745, loss: 1.1788, l1: 0.2349, vgg: 0.5983, mask: 0.3456\n",
      "step:    16380, time: 0.764, loss: 1.1482, l1: 0.1937, vgg: 0.5839, mask: 0.3705\n",
      "step:    16400, time: 0.795, loss: 1.2292, l1: 0.2248, vgg: 0.6541, mask: 0.3503\n",
      "step:    16420, time: 0.755, loss: 1.3297, l1: 0.2733, vgg: 0.6813, mask: 0.3750\n",
      "step:    16440, time: 0.762, loss: 1.2207, l1: 0.2284, vgg: 0.6236, mask: 0.3687\n",
      "step:    16460, time: 0.749, loss: 1.2142, l1: 0.2489, vgg: 0.5854, mask: 0.3799\n",
      "step:    16480, time: 0.715, loss: 1.1304, l1: 0.2752, vgg: 0.4952, mask: 0.3600\n",
      "step:    16500, time: 0.753, loss: 1.2614, l1: 0.3129, vgg: 0.5331, mask: 0.4154\n",
      "step:    16520, time: 0.749, loss: 1.2496, l1: 0.2466, vgg: 0.6225, mask: 0.3805\n",
      "step:    16540, time: 0.779, loss: 1.1787, l1: 0.2358, vgg: 0.5640, mask: 0.3789\n",
      "step:    16560, time: 0.763, loss: 1.2711, l1: 0.2790, vgg: 0.5929, mask: 0.3992\n",
      "step:    16580, time: 0.770, loss: 1.1798, l1: 0.2319, vgg: 0.6009, mask: 0.3470\n",
      "step:    16600, time: 0.792, loss: 1.1744, l1: 0.2652, vgg: 0.5461, mask: 0.3632\n",
      "step:    16620, time: 0.741, loss: 1.1737, l1: 0.2622, vgg: 0.5301, mask: 0.3814\n",
      "step:    16640, time: 0.767, loss: 1.1769, l1: 0.2455, vgg: 0.5260, mask: 0.4055\n",
      "step:    16660, time: 0.780, loss: 1.3610, l1: 0.3128, vgg: 0.6660, mask: 0.3822\n",
      "step:    16680, time: 0.802, loss: 1.2323, l1: 0.2387, vgg: 0.6209, mask: 0.3727\n",
      "step:    16700, time: 0.733, loss: 1.2310, l1: 0.1901, vgg: 0.6892, mask: 0.3517\n",
      "step:    16720, time: 0.720, loss: 1.1320, l1: 0.2211, vgg: 0.5192, mask: 0.3918\n",
      "step:    16740, time: 0.745, loss: 1.1857, l1: 0.2379, vgg: 0.5781, mask: 0.3697\n",
      "step:    16760, time: 0.777, loss: 1.2115, l1: 0.2381, vgg: 0.6021, mask: 0.3714\n",
      "step:    16780, time: 0.757, loss: 1.1564, l1: 0.2058, vgg: 0.6197, mask: 0.3309\n",
      "step:    16800, time: 0.722, loss: 1.2344, l1: 0.2826, vgg: 0.5531, mask: 0.3987\n",
      "step:    16820, time: 0.748, loss: 1.1631, l1: 0.2188, vgg: 0.5902, mask: 0.3541\n",
      "step:    16840, time: 0.781, loss: 1.2702, l1: 0.2548, vgg: 0.6498, mask: 0.3656\n",
      "step:    16860, time: 0.733, loss: 1.2831, l1: 0.2526, vgg: 0.6624, mask: 0.3681\n",
      "step:    16880, time: 0.793, loss: 1.3101, l1: 0.2504, vgg: 0.6654, mask: 0.3943\n",
      "step:    16900, time: 0.762, loss: 1.1704, l1: 0.2488, vgg: 0.5722, mask: 0.3494\n",
      "step:    16920, time: 0.746, loss: 1.2166, l1: 0.2202, vgg: 0.5869, mask: 0.4095\n",
      "step:    16940, time: 0.755, loss: 1.3271, l1: 0.2895, vgg: 0.6465, mask: 0.3911\n",
      "step:    16960, time: 0.772, loss: 1.2608, l1: 0.2004, vgg: 0.6986, mask: 0.3619\n",
      "step:    16980, time: 0.743, loss: 1.2428, l1: 0.2683, vgg: 0.5976, mask: 0.3770\n",
      "step:    17000, time: 0.753, loss: 1.1917, l1: 0.2173, vgg: 0.5969, mask: 0.3774\n",
      "step:    17020, time: 0.783, loss: 1.2443, l1: 0.2255, vgg: 0.6285, mask: 0.3903\n",
      "step:    17040, time: 0.764, loss: 1.2210, l1: 0.2600, vgg: 0.5713, mask: 0.3897\n",
      "step:    17060, time: 0.757, loss: 1.1821, l1: 0.2286, vgg: 0.5975, mask: 0.3559\n",
      "step:    17080, time: 0.732, loss: 1.1059, l1: 0.2076, vgg: 0.5484, mask: 0.3500\n",
      "step:    17100, time: 0.773, loss: 1.2828, l1: 0.2796, vgg: 0.6030, mask: 0.4002\n",
      "step:    17120, time: 0.762, loss: 1.2188, l1: 0.2606, vgg: 0.5830, mask: 0.3752\n",
      "step:    17140, time: 0.709, loss: 1.1735, l1: 0.2680, vgg: 0.5438, mask: 0.3617\n",
      "step:    17160, time: 0.733, loss: 1.2196, l1: 0.2296, vgg: 0.6390, mask: 0.3510\n",
      "step:    17180, time: 0.777, loss: 1.3752, l1: 0.2795, vgg: 0.6882, mask: 0.4075\n",
      "step:    17200, time: 0.757, loss: 1.2336, l1: 0.2505, vgg: 0.5902, mask: 0.3930\n",
      "step:    17220, time: 0.774, loss: 1.2893, l1: 0.2574, vgg: 0.6515, mask: 0.3804\n",
      "step:    17240, time: 0.778, loss: 1.3680, l1: 0.2772, vgg: 0.6930, mask: 0.3978\n",
      "step:    17260, time: 0.779, loss: 1.3180, l1: 0.2861, vgg: 0.6166, mask: 0.4152\n",
      "step:    17280, time: 0.727, loss: 1.2092, l1: 0.2710, vgg: 0.5600, mask: 0.3782\n",
      "step:    17300, time: 0.736, loss: 1.1954, l1: 0.2056, vgg: 0.6197, mask: 0.3702\n",
      "step:    17320, time: 0.702, loss: 1.1456, l1: 0.2027, vgg: 0.5803, mask: 0.3626\n",
      "step:    17340, time: 0.769, loss: 1.2602, l1: 0.2214, vgg: 0.6916, mask: 0.3472\n",
      "step:    17360, time: 0.779, loss: 1.1869, l1: 0.2348, vgg: 0.5967, mask: 0.3554\n",
      "step:    17380, time: 0.752, loss: 1.2325, l1: 0.2373, vgg: 0.6282, mask: 0.3671\n",
      "step:    17400, time: 0.768, loss: 1.2132, l1: 0.2543, vgg: 0.5630, mask: 0.3959\n",
      "step:    17420, time: 0.727, loss: 1.1478, l1: 0.2145, vgg: 0.5586, mask: 0.3746\n",
      "step:    17440, time: 0.753, loss: 1.2593, l1: 0.2539, vgg: 0.5892, mask: 0.4162\n",
      "step:    17460, time: 0.723, loss: 1.1653, l1: 0.2295, vgg: 0.5608, mask: 0.3751\n",
      "step:    17480, time: 0.733, loss: 1.2345, l1: 0.2266, vgg: 0.6415, mask: 0.3664\n",
      "step:    17500, time: 0.857, loss: 1.1969, l1: 0.2334, vgg: 0.6257, mask: 0.3378\n",
      "step:    17520, time: 0.858, loss: 1.2256, l1: 0.2422, vgg: 0.6115, mask: 0.3719\n",
      "step:    17540, time: 0.801, loss: 1.2663, l1: 0.3047, vgg: 0.5660, mask: 0.3957\n",
      "step:    17560, time: 0.736, loss: 1.1882, l1: 0.2319, vgg: 0.6040, mask: 0.3523\n",
      "step:    17580, time: 0.772, loss: 1.1867, l1: 0.2506, vgg: 0.5609, mask: 0.3752\n",
      "step:    17600, time: 0.723, loss: 1.1258, l1: 0.2251, vgg: 0.5453, mask: 0.3553\n",
      "step:    17620, time: 0.742, loss: 1.1795, l1: 0.2402, vgg: 0.5733, mask: 0.3661\n",
      "step:    17640, time: 0.756, loss: 1.2087, l1: 0.2148, vgg: 0.6465, mask: 0.3474\n",
      "step:    17660, time: 0.747, loss: 1.1763, l1: 0.2567, vgg: 0.5366, mask: 0.3829\n",
      "step:    17680, time: 0.744, loss: 1.1947, l1: 0.2462, vgg: 0.5749, mask: 0.3737\n",
      "step:    17700, time: 0.803, loss: 1.2233, l1: 0.2202, vgg: 0.5849, mask: 0.4181\n",
      "step:    17720, time: 0.754, loss: 1.3276, l1: 0.2672, vgg: 0.6685, mask: 0.3919\n",
      "step:    17740, time: 0.706, loss: 1.1687, l1: 0.2476, vgg: 0.5541, mask: 0.3670\n",
      "step:    17760, time: 0.750, loss: 1.1977, l1: 0.2358, vgg: 0.5757, mask: 0.3862\n",
      "step:    17780, time: 0.274, loss: 0.9617, l1: 0.2161, vgg: 0.4437, mask: 0.3018\n",
      "step:    17800, time: 0.734, loss: 1.1997, l1: 0.2549, vgg: 0.5461, mask: 0.3986\n",
      "step:    17820, time: 0.754, loss: 1.2103, l1: 0.2501, vgg: 0.5821, mask: 0.3781\n",
      "step:    17840, time: 0.744, loss: 1.3011, l1: 0.2843, vgg: 0.6339, mask: 0.3829\n",
      "step:    17860, time: 0.783, loss: 1.2031, l1: 0.2127, vgg: 0.5766, mask: 0.4138\n",
      "step:    17880, time: 0.747, loss: 1.1568, l1: 0.2227, vgg: 0.5763, mask: 0.3577\n",
      "step:    17900, time: 0.819, loss: 1.2674, l1: 0.2704, vgg: 0.6105, mask: 0.3866\n",
      "step:    17920, time: 0.829, loss: 1.2759, l1: 0.2633, vgg: 0.6317, mask: 0.3809\n",
      "step:    17940, time: 0.869, loss: 1.2268, l1: 0.2656, vgg: 0.5868, mask: 0.3744\n",
      "step:    17960, time: 0.808, loss: 1.2667, l1: 0.2679, vgg: 0.6253, mask: 0.3735\n",
      "step:    17980, time: 0.768, loss: 1.1629, l1: 0.2369, vgg: 0.5738, mask: 0.3522\n",
      "step:    18000, time: 0.765, loss: 1.2653, l1: 0.2355, vgg: 0.6219, mask: 0.4080\n",
      "step:    18020, time: 0.771, loss: 1.2326, l1: 0.2523, vgg: 0.6190, mask: 0.3613\n",
      "step:    18040, time: 0.757, loss: 1.0571, l1: 0.1798, vgg: 0.5394, mask: 0.3379\n",
      "step:    18060, time: 0.756, loss: 1.2623, l1: 0.2838, vgg: 0.5839, mask: 0.3946\n",
      "step:    18080, time: 0.749, loss: 1.1325, l1: 0.1997, vgg: 0.5606, mask: 0.3722\n",
      "step:    18100, time: 0.788, loss: 1.2055, l1: 0.2488, vgg: 0.5815, mask: 0.3752\n",
      "step:    18120, time: 0.773, loss: 1.2084, l1: 0.2366, vgg: 0.5902, mask: 0.3817\n",
      "step:    18140, time: 0.750, loss: 1.1580, l1: 0.2472, vgg: 0.5245, mask: 0.3863\n",
      "step:    18160, time: 0.772, loss: 1.1745, l1: 0.2219, vgg: 0.5703, mask: 0.3823\n",
      "step:    18180, time: 0.758, loss: 1.3072, l1: 0.2710, vgg: 0.6193, mask: 0.4170\n",
      "step:    18200, time: 0.749, loss: 1.1984, l1: 0.2351, vgg: 0.5872, mask: 0.3760\n",
      "step:    18220, time: 0.789, loss: 1.2107, l1: 0.2642, vgg: 0.5460, mask: 0.4005\n",
      "step:    18240, time: 0.792, loss: 1.3401, l1: 0.2969, vgg: 0.6457, mask: 0.3975\n",
      "step:    18260, time: 0.791, loss: 1.2968, l1: 0.2453, vgg: 0.6721, mask: 0.3794\n",
      "step:    18280, time: 0.791, loss: 1.1197, l1: 0.2224, vgg: 0.5290, mask: 0.3683\n",
      "step:    18300, time: 0.747, loss: 1.1914, l1: 0.2673, vgg: 0.5221, mask: 0.4021\n",
      "step:    18320, time: 0.748, loss: 1.2399, l1: 0.2386, vgg: 0.6507, mask: 0.3505\n",
      "step:    18340, time: 0.746, loss: 1.1994, l1: 0.2439, vgg: 0.5533, mask: 0.4022\n",
      "step:    18360, time: 0.766, loss: 1.2294, l1: 0.2550, vgg: 0.5856, mask: 0.3887\n",
      "step:    18380, time: 0.800, loss: 1.2936, l1: 0.2325, vgg: 0.6525, mask: 0.4086\n",
      "step:    18400, time: 0.730, loss: 1.1249, l1: 0.2231, vgg: 0.5378, mask: 0.3640\n",
      "step:    18420, time: 0.736, loss: 1.2109, l1: 0.2355, vgg: 0.5927, mask: 0.3828\n",
      "step:    18440, time: 0.765, loss: 1.2078, l1: 0.2553, vgg: 0.5861, mask: 0.3665\n",
      "step:    18460, time: 0.775, loss: 1.2142, l1: 0.2538, vgg: 0.5985, mask: 0.3619\n",
      "step:    18480, time: 0.753, loss: 1.2679, l1: 0.2421, vgg: 0.6467, mask: 0.3790\n",
      "step:    18500, time: 0.755, loss: 1.2705, l1: 0.2353, vgg: 0.6537, mask: 0.3814\n",
      "step:    18520, time: 0.758, loss: 1.2784, l1: 0.2956, vgg: 0.6078, mask: 0.3750\n",
      "step:    18540, time: 0.730, loss: 1.1737, l1: 0.2584, vgg: 0.5282, mask: 0.3872\n",
      "step:    18560, time: 0.758, loss: 1.2889, l1: 0.2836, vgg: 0.6282, mask: 0.3772\n",
      "step:    18580, time: 0.780, loss: 1.2178, l1: 0.2470, vgg: 0.6126, mask: 0.3582\n",
      "step:    18600, time: 0.756, loss: 1.1170, l1: 0.2077, vgg: 0.5483, mask: 0.3609\n",
      "step:    18620, time: 0.734, loss: 1.1522, l1: 0.2107, vgg: 0.5704, mask: 0.3711\n",
      "step:    18640, time: 0.748, loss: 1.2809, l1: 0.2968, vgg: 0.5721, mask: 0.4121\n",
      "step:    18660, time: 0.736, loss: 1.2554, l1: 0.2725, vgg: 0.5893, mask: 0.3936\n",
      "step:    18680, time: 0.725, loss: 1.2341, l1: 0.2644, vgg: 0.5991, mask: 0.3707\n",
      "step:    18700, time: 0.736, loss: 1.1297, l1: 0.2442, vgg: 0.5354, mask: 0.3501\n",
      "step:    18720, time: 0.839, loss: 1.1679, l1: 0.2426, vgg: 0.5783, mask: 0.3470\n",
      "step:    18740, time: 0.841, loss: 1.1941, l1: 0.2450, vgg: 0.5855, mask: 0.3636\n",
      "step:    18760, time: 0.875, loss: 1.2888, l1: 0.2370, vgg: 0.6604, mask: 0.3914\n",
      "step:    18780, time: 0.838, loss: 1.1326, l1: 0.2396, vgg: 0.5401, mask: 0.3529\n",
      "step:    18800, time: 0.857, loss: 1.2264, l1: 0.2754, vgg: 0.5586, mask: 0.3923\n",
      "step:    18820, time: 0.903, loss: 1.2388, l1: 0.2658, vgg: 0.5819, mask: 0.3911\n",
      "step:    18840, time: 0.753, loss: 1.1197, l1: 0.1832, vgg: 0.5934, mask: 0.3431\n",
      "step:    18860, time: 0.772, loss: 1.2491, l1: 0.2104, vgg: 0.6687, mask: 0.3700\n",
      "step:    18880, time: 0.724, loss: 1.2192, l1: 0.2779, vgg: 0.5311, mask: 0.4102\n",
      "step:    18900, time: 0.772, loss: 1.3548, l1: 0.2918, vgg: 0.6650, mask: 0.3980\n",
      "step:    18920, time: 0.756, loss: 1.3731, l1: 0.3042, vgg: 0.6603, mask: 0.4085\n",
      "step:    18940, time: 0.764, loss: 1.0543, l1: 0.2076, vgg: 0.5095, mask: 0.3372\n",
      "step:    18960, time: 0.868, loss: 1.2455, l1: 0.2418, vgg: 0.6132, mask: 0.3904\n",
      "step:    18980, time: 0.905, loss: 1.1611, l1: 0.2333, vgg: 0.5497, mask: 0.3781\n",
      "step:    19000, time: 0.784, loss: 1.2363, l1: 0.2528, vgg: 0.6239, mask: 0.3596\n",
      "step:    19020, time: 0.756, loss: 1.1463, l1: 0.2384, vgg: 0.5376, mask: 0.3704\n",
      "step:    19040, time: 0.813, loss: 1.2381, l1: 0.2745, vgg: 0.5756, mask: 0.3879\n",
      "step:    19060, time: 0.783, loss: 1.1192, l1: 0.2118, vgg: 0.5387, mask: 0.3688\n",
      "step:    19080, time: 0.738, loss: 1.0666, l1: 0.1602, vgg: 0.4943, mask: 0.4120\n",
      "step:    19100, time: 0.849, loss: 1.1316, l1: 0.2238, vgg: 0.5500, mask: 0.3578\n",
      "step:    19120, time: 0.826, loss: 1.1030, l1: 0.1954, vgg: 0.5700, mask: 0.3375\n",
      "step:    19140, time: 0.768, loss: 1.2184, l1: 0.2546, vgg: 0.5953, mask: 0.3685\n",
      "step:    19160, time: 0.728, loss: 1.0522, l1: 0.1852, vgg: 0.5194, mask: 0.3476\n",
      "step:    19180, time: 0.787, loss: 1.2108, l1: 0.2175, vgg: 0.6328, mask: 0.3606\n",
      "step:    19200, time: 0.733, loss: 1.1648, l1: 0.2462, vgg: 0.5347, mask: 0.3840\n",
      "step:    19220, time: 0.781, loss: 1.2962, l1: 0.3152, vgg: 0.5768, mask: 0.4042\n",
      "step:    19240, time: 0.851, loss: 1.2290, l1: 0.2293, vgg: 0.6023, mask: 0.3975\n",
      "step:    19260, time: 0.764, loss: 1.2179, l1: 0.2805, vgg: 0.5621, mask: 0.3753\n",
      "step:    19280, time: 0.805, loss: 1.3096, l1: 0.2615, vgg: 0.6183, mask: 0.4298\n",
      "step:    19300, time: 0.728, loss: 1.1581, l1: 0.1884, vgg: 0.5840, mask: 0.3857\n",
      "step:    19320, time: 0.767, loss: 1.0712, l1: 0.1873, vgg: 0.5260, mask: 0.3579\n",
      "step:    19340, time: 0.735, loss: 1.1838, l1: 0.2627, vgg: 0.5459, mask: 0.3751\n",
      "step:    19360, time: 0.834, loss: 1.2013, l1: 0.2209, vgg: 0.6367, mask: 0.3436\n",
      "step:    19380, time: 0.860, loss: 1.2314, l1: 0.2361, vgg: 0.6274, mask: 0.3678\n",
      "step:    19400, time: 0.788, loss: 1.1590, l1: 0.2113, vgg: 0.5717, mask: 0.3760\n",
      "step:    19420, time: 0.769, loss: 1.2668, l1: 0.2399, vgg: 0.6723, mask: 0.3546\n",
      "step:    19440, time: 0.793, loss: 1.2295, l1: 0.2347, vgg: 0.6054, mask: 0.3895\n",
      "step:    19460, time: 0.774, loss: 1.1855, l1: 0.2553, vgg: 0.5669, mask: 0.3633\n",
      "step:    19480, time: 0.769, loss: 1.1868, l1: 0.2424, vgg: 0.5773, mask: 0.3671\n",
      "step:    19500, time: 0.736, loss: 1.1801, l1: 0.2164, vgg: 0.6124, mask: 0.3513\n",
      "step:    19520, time: 0.738, loss: 1.3605, l1: 0.3146, vgg: 0.6225, mask: 0.4234\n",
      "step:    19540, time: 0.829, loss: 1.2215, l1: 0.2589, vgg: 0.5919, mask: 0.3707\n",
      "step:    19560, time: 0.758, loss: 1.2602, l1: 0.2789, vgg: 0.6063, mask: 0.3749\n",
      "step:    19580, time: 0.753, loss: 1.1977, l1: 0.2277, vgg: 0.5944, mask: 0.3757\n",
      "step:    19600, time: 0.726, loss: 1.0904, l1: 0.2341, vgg: 0.5099, mask: 0.3464\n",
      "step:    19620, time: 0.758, loss: 1.1891, l1: 0.2547, vgg: 0.5636, mask: 0.3708\n",
      "step:    19640, time: 0.735, loss: 1.0864, l1: 0.1781, vgg: 0.5913, mask: 0.3170\n",
      "step:    19660, time: 0.759, loss: 1.2109, l1: 0.2490, vgg: 0.5748, mask: 0.3871\n",
      "step:    19680, time: 0.777, loss: 1.1182, l1: 0.2049, vgg: 0.5644, mask: 0.3489\n",
      "step:    19700, time: 0.762, loss: 1.2849, l1: 0.2860, vgg: 0.5830, mask: 0.4159\n",
      "step:    19720, time: 0.749, loss: 1.1423, l1: 0.2008, vgg: 0.5762, mask: 0.3653\n",
      "step:    19740, time: 0.754, loss: 1.2187, l1: 0.2424, vgg: 0.5904, mask: 0.3858\n",
      "step:    19760, time: 0.768, loss: 1.2072, l1: 0.2229, vgg: 0.6271, mask: 0.3571\n",
      "step:    19780, time: 0.718, loss: 1.1279, l1: 0.1890, vgg: 0.5604, mask: 0.3785\n",
      "step:    19800, time: 0.781, loss: 1.3076, l1: 0.2508, vgg: 0.6795, mask: 0.3774\n",
      "step:    19820, time: 0.737, loss: 1.2055, l1: 0.2753, vgg: 0.5654, mask: 0.3649\n",
      "step:    19840, time: 0.713, loss: 1.0858, l1: 0.1985, vgg: 0.5144, mask: 0.3728\n",
      "step:    19860, time: 0.709, loss: 1.1927, l1: 0.2438, vgg: 0.5202, mask: 0.4288\n",
      "step:    19880, time: 0.739, loss: 1.1790, l1: 0.2063, vgg: 0.6474, mask: 0.3253\n",
      "step:    19900, time: 0.720, loss: 1.1629, l1: 0.2250, vgg: 0.5560, mask: 0.3819\n",
      "step:    19920, time: 0.762, loss: 1.2487, l1: 0.2595, vgg: 0.5967, mask: 0.3924\n",
      "step:    19940, time: 0.732, loss: 1.1556, l1: 0.2126, vgg: 0.5841, mask: 0.3589\n",
      "step:    19960, time: 0.727, loss: 1.0946, l1: 0.2022, vgg: 0.5304, mask: 0.3620\n",
      "step:    19980, time: 0.786, loss: 1.1907, l1: 0.2181, vgg: 0.5775, mask: 0.3950\n",
      "step:    20000, time: 0.747, loss: 1.1762, l1: 0.2206, vgg: 0.5713, mask: 0.3843\n",
      "step:    20020, time: 0.734, loss: 1.1860, l1: 0.2459, vgg: 0.5521, mask: 0.3880\n",
      "step:    20040, time: 0.773, loss: 1.2837, l1: 0.2825, vgg: 0.6168, mask: 0.3845\n",
      "step:    20060, time: 0.760, loss: 1.2390, l1: 0.2712, vgg: 0.5909, mask: 0.3770\n",
      "step:    20080, time: 0.754, loss: 1.5173, l1: 0.3025, vgg: 0.8313, mask: 0.3834\n",
      "step:    20100, time: 0.752, loss: 1.1498, l1: 0.2465, vgg: 0.5259, mask: 0.3773\n",
      "step:    20120, time: 0.755, loss: 1.2715, l1: 0.2587, vgg: 0.6140, mask: 0.3988\n",
      "step:    20140, time: 0.755, loss: 1.1615, l1: 0.2006, vgg: 0.6161, mask: 0.3448\n",
      "step:    20160, time: 0.812, loss: 1.1861, l1: 0.2224, vgg: 0.5567, mask: 0.4071\n",
      "step:    20180, time: 0.758, loss: 1.2622, l1: 0.2679, vgg: 0.5765, mask: 0.4179\n",
      "step:    20200, time: 0.774, loss: 1.1576, l1: 0.1945, vgg: 0.6312, mask: 0.3319\n",
      "step:    20220, time: 0.763, loss: 1.2370, l1: 0.2533, vgg: 0.6036, mask: 0.3800\n",
      "step:    20240, time: 0.771, loss: 1.4148, l1: 0.2944, vgg: 0.7190, mask: 0.4014\n",
      "step:    20260, time: 0.756, loss: 1.2600, l1: 0.2815, vgg: 0.5749, mask: 0.4036\n",
      "step:    20280, time: 0.728, loss: 1.2116, l1: 0.2540, vgg: 0.5796, mask: 0.3780\n",
      "step:    20300, time: 0.737, loss: 1.1794, l1: 0.2041, vgg: 0.6261, mask: 0.3491\n",
      "step:    20320, time: 0.755, loss: 1.1417, l1: 0.1962, vgg: 0.5881, mask: 0.3574\n",
      "step:    20340, time: 0.773, loss: 1.2300, l1: 0.2230, vgg: 0.6336, mask: 0.3733\n",
      "step:    20360, time: 0.752, loss: 1.1621, l1: 0.2327, vgg: 0.5737, mask: 0.3558\n",
      "step:    20380, time: 0.750, loss: 1.2582, l1: 0.2551, vgg: 0.6126, mask: 0.3905\n",
      "step:    20400, time: 0.812, loss: 1.2473, l1: 0.2805, vgg: 0.5799, mask: 0.3869\n",
      "step:    20420, time: 0.732, loss: 1.0684, l1: 0.1832, vgg: 0.5583, mask: 0.3269\n",
      "step:    20440, time: 0.776, loss: 1.1830, l1: 0.2760, vgg: 0.5459, mask: 0.3612\n",
      "step:    20460, time: 0.752, loss: 1.0742, l1: 0.1922, vgg: 0.5261, mask: 0.3559\n",
      "step:    20480, time: 0.792, loss: 1.3772, l1: 0.2717, vgg: 0.7156, mask: 0.3899\n",
      "step:    20500, time: 0.747, loss: 1.1995, l1: 0.2348, vgg: 0.6132, mask: 0.3516\n",
      "step:    20520, time: 0.721, loss: 1.2453, l1: 0.2659, vgg: 0.6031, mask: 0.3762\n",
      "step:    20540, time: 0.797, loss: 1.2825, l1: 0.2522, vgg: 0.6482, mask: 0.3820\n",
      "step:    20560, time: 0.762, loss: 1.1826, l1: 0.2294, vgg: 0.5753, mask: 0.3779\n",
      "step:    20580, time: 0.736, loss: 1.1991, l1: 0.2719, vgg: 0.5143, mask: 0.4130\n",
      "step:    20600, time: 0.740, loss: 1.1049, l1: 0.2250, vgg: 0.5071, mask: 0.3727\n",
      "step:    20620, time: 0.734, loss: 1.1667, l1: 0.2230, vgg: 0.5550, mask: 0.3886\n",
      "step:    20640, time: 0.735, loss: 1.2405, l1: 0.2229, vgg: 0.6712, mask: 0.3464\n",
      "step:    20660, time: 0.744, loss: 1.0170, l1: 0.1846, vgg: 0.5075, mask: 0.3248\n",
      "step:    20680, time: 0.739, loss: 1.1090, l1: 0.2023, vgg: 0.5276, mask: 0.3792\n",
      "step:    20700, time: 0.731, loss: 1.1417, l1: 0.2066, vgg: 0.5697, mask: 0.3654\n",
      "step:    20720, time: 0.772, loss: 1.2232, l1: 0.2155, vgg: 0.6054, mask: 0.4022\n",
      "step:    20740, time: 0.737, loss: 1.1796, l1: 0.2139, vgg: 0.5810, mask: 0.3847\n",
      "step:    20760, time: 0.725, loss: 1.0539, l1: 0.1905, vgg: 0.5269, mask: 0.3366\n",
      "step:    20780, time: 0.749, loss: 1.1837, l1: 0.2035, vgg: 0.6124, mask: 0.3679\n",
      "step:    20800, time: 0.731, loss: 1.1897, l1: 0.2855, vgg: 0.5266, mask: 0.3776\n",
      "step:    20820, time: 0.762, loss: 1.1094, l1: 0.2218, vgg: 0.5276, mask: 0.3601\n",
      "step:    20840, time: 0.740, loss: 1.2436, l1: 0.2942, vgg: 0.5609, mask: 0.3884\n",
      "step:    20860, time: 0.759, loss: 1.1223, l1: 0.1889, vgg: 0.5782, mask: 0.3552\n",
      "step:    20880, time: 0.734, loss: 1.1841, l1: 0.2277, vgg: 0.5918, mask: 0.3647\n",
      "step:    20900, time: 0.763, loss: 1.1204, l1: 0.1964, vgg: 0.5890, mask: 0.3350\n",
      "step:    20920, time: 0.725, loss: 1.1386, l1: 0.1907, vgg: 0.5691, mask: 0.3788\n",
      "step:    20940, time: 0.757, loss: 1.2390, l1: 0.2429, vgg: 0.6327, mask: 0.3633\n",
      "step:    20960, time: 0.751, loss: 1.1618, l1: 0.2224, vgg: 0.5785, mask: 0.3609\n",
      "step:    20980, time: 0.773, loss: 1.2502, l1: 0.2493, vgg: 0.6352, mask: 0.3657\n",
      "step:    21000, time: 0.755, loss: 1.2154, l1: 0.2353, vgg: 0.6191, mask: 0.3610\n",
      "step:    21020, time: 0.773, loss: 1.2383, l1: 0.2090, vgg: 0.6438, mask: 0.3854\n",
      "step:    21040, time: 0.754, loss: 1.3590, l1: 0.2763, vgg: 0.6915, mask: 0.3912\n",
      "step:    21060, time: 0.761, loss: 1.2813, l1: 0.2954, vgg: 0.5986, mask: 0.3873\n",
      "step:    21080, time: 0.750, loss: 1.1177, l1: 0.2249, vgg: 0.5261, mask: 0.3666\n",
      "step:    21100, time: 0.716, loss: 1.1194, l1: 0.1981, vgg: 0.5263, mask: 0.3950\n",
      "step:    21120, time: 0.766, loss: 1.2798, l1: 0.2391, vgg: 0.6395, mask: 0.4012\n",
      "step:    21140, time: 0.747, loss: 1.1857, l1: 0.2642, vgg: 0.5429, mask: 0.3786\n",
      "step:    21160, time: 0.790, loss: 1.3272, l1: 0.2858, vgg: 0.6451, mask: 0.3963\n",
      "step:    21180, time: 0.746, loss: 1.2129, l1: 0.2775, vgg: 0.5572, mask: 0.3782\n",
      "step:    21200, time: 0.767, loss: 1.3214, l1: 0.2437, vgg: 0.6327, mask: 0.4450\n",
      "step:    21220, time: 0.787, loss: 1.1154, l1: 0.2051, vgg: 0.5380, mask: 0.3724\n",
      "step:    21240, time: 0.809, loss: 1.1895, l1: 0.2402, vgg: 0.5732, mask: 0.3761\n",
      "step:    21260, time: 0.790, loss: 1.0084, l1: 0.1773, vgg: 0.4748, mask: 0.3563\n",
      "step:    21280, time: 0.787, loss: 1.1624, l1: 0.2475, vgg: 0.5704, mask: 0.3446\n",
      "step:    21300, time: 0.790, loss: 1.2051, l1: 0.2327, vgg: 0.6033, mask: 0.3691\n",
      "step:    21320, time: 0.741, loss: 1.1110, l1: 0.2176, vgg: 0.5251, mask: 0.3682\n",
      "step:    21340, time: 0.735, loss: 1.2248, l1: 0.3160, vgg: 0.5308, mask: 0.3780\n",
      "step:    21360, time: 0.792, loss: 1.2248, l1: 0.2427, vgg: 0.5898, mask: 0.3924\n",
      "step:    21380, time: 0.752, loss: 1.2479, l1: 0.2597, vgg: 0.6025, mask: 0.3857\n",
      "step:    21400, time: 0.742, loss: 1.2353, l1: 0.2672, vgg: 0.5501, mask: 0.4180\n",
      "step:    21420, time: 0.734, loss: 1.1376, l1: 0.2354, vgg: 0.5455, mask: 0.3567\n",
      "step:    21440, time: 0.772, loss: 1.1832, l1: 0.2317, vgg: 0.5550, mask: 0.3966\n",
      "step:    21460, time: 0.770, loss: 1.2148, l1: 0.2612, vgg: 0.5806, mask: 0.3730\n",
      "step:    21480, time: 0.785, loss: 1.1781, l1: 0.2350, vgg: 0.5645, mask: 0.3787\n",
      "step:    21500, time: 0.752, loss: 1.1519, l1: 0.2331, vgg: 0.5604, mask: 0.3584\n",
      "step:    21520, time: 0.778, loss: 1.2291, l1: 0.2639, vgg: 0.5980, mask: 0.3672\n",
      "step:    21540, time: 0.763, loss: 1.2165, l1: 0.1940, vgg: 0.6917, mask: 0.3307\n",
      "step:    21560, time: 0.756, loss: 1.2515, l1: 0.2744, vgg: 0.5915, mask: 0.3856\n",
      "step:    21580, time: 0.805, loss: 1.1617, l1: 0.2595, vgg: 0.5198, mask: 0.3825\n",
      "step:    21600, time: 0.786, loss: 1.0467, l1: 0.1691, vgg: 0.5188, mask: 0.3588\n",
      "step:    21620, time: 0.725, loss: 1.1699, l1: 0.2424, vgg: 0.5764, mask: 0.3511\n",
      "step:    21640, time: 0.747, loss: 1.2594, l1: 0.2664, vgg: 0.6004, mask: 0.3926\n",
      "step:    21660, time: 0.782, loss: 1.3098, l1: 0.2822, vgg: 0.6127, mask: 0.4149\n",
      "step:    21680, time: 0.726, loss: 1.1758, l1: 0.2243, vgg: 0.5691, mask: 0.3825\n",
      "step:    21700, time: 0.819, loss: 1.2030, l1: 0.2605, vgg: 0.5660, mask: 0.3765\n",
      "step:    21720, time: 0.867, loss: 1.1879, l1: 0.2275, vgg: 0.5910, mask: 0.3695\n",
      "step:    21740, time: 0.726, loss: 1.1067, l1: 0.2039, vgg: 0.5420, mask: 0.3608\n",
      "step:    21760, time: 0.758, loss: 1.2255, l1: 0.2512, vgg: 0.5706, mask: 0.4037\n",
      "step:    21780, time: 0.730, loss: 1.2923, l1: 0.2969, vgg: 0.6047, mask: 0.3907\n",
      "step:    21800, time: 0.738, loss: 1.1933, l1: 0.2152, vgg: 0.6006, mask: 0.3775\n",
      "step:    21820, time: 0.750, loss: 1.2057, l1: 0.2349, vgg: 0.6257, mask: 0.3452\n",
      "step:    21840, time: 0.767, loss: 1.1840, l1: 0.2291, vgg: 0.5827, mask: 0.3722\n",
      "step:    21860, time: 0.767, loss: 1.2195, l1: 0.2807, vgg: 0.5748, mask: 0.3640\n",
      "step:    21880, time: 0.817, loss: 1.1607, l1: 0.2101, vgg: 0.6049, mask: 0.3458\n",
      "step:    21900, time: 0.745, loss: 1.2103, l1: 0.2545, vgg: 0.5839, mask: 0.3719\n",
      "step:    21920, time: 0.768, loss: 1.1833, l1: 0.2158, vgg: 0.5861, mask: 0.3814\n",
      "step:    21940, time: 0.755, loss: 1.1961, l1: 0.2225, vgg: 0.6278, mask: 0.3459\n",
      "step:    21960, time: 0.775, loss: 1.1629, l1: 0.2059, vgg: 0.5649, mask: 0.3921\n",
      "step:    21980, time: 0.730, loss: 1.1974, l1: 0.2469, vgg: 0.5551, mask: 0.3954\n",
      "step:    22000, time: 0.743, loss: 1.0609, l1: 0.1675, vgg: 0.5237, mask: 0.3697\n",
      "step:    22020, time: 0.778, loss: 1.1329, l1: 0.2125, vgg: 0.5671, mask: 0.3534\n",
      "step:    22040, time: 0.764, loss: 1.3824, l1: 0.3103, vgg: 0.6543, mask: 0.4178\n",
      "step:    22060, time: 0.766, loss: 1.2161, l1: 0.2241, vgg: 0.6278, mask: 0.3641\n",
      "step:    22080, time: 0.733, loss: 1.0439, l1: 0.1862, vgg: 0.5053, mask: 0.3525\n",
      "step:    22100, time: 0.751, loss: 1.0947, l1: 0.1811, vgg: 0.5545, mask: 0.3591\n",
      "step:    22120, time: 0.744, loss: 1.2758, l1: 0.2613, vgg: 0.6375, mask: 0.3770\n",
      "step:    22140, time: 0.738, loss: 1.0615, l1: 0.2127, vgg: 0.5103, mask: 0.3385\n",
      "step:    22160, time: 0.769, loss: 1.0735, l1: 0.1712, vgg: 0.5477, mask: 0.3545\n",
      "step:    22180, time: 0.764, loss: 1.1112, l1: 0.1818, vgg: 0.5757, mask: 0.3536\n",
      "step:    22200, time: 0.796, loss: 1.3402, l1: 0.2928, vgg: 0.6601, mask: 0.3873\n",
      "step:    22220, time: 0.725, loss: 1.0301, l1: 0.1771, vgg: 0.5255, mask: 0.3275\n",
      "step:    22240, time: 0.727, loss: 1.1530, l1: 0.2606, vgg: 0.5189, mask: 0.3735\n",
      "step:    22260, time: 0.763, loss: 1.1622, l1: 0.2172, vgg: 0.5762, mask: 0.3688\n",
      "step:    22280, time: 0.728, loss: 1.2470, l1: 0.2258, vgg: 0.6252, mask: 0.3960\n",
      "step:    22300, time: 0.794, loss: 1.3315, l1: 0.2567, vgg: 0.6891, mask: 0.3858\n",
      "step:    22320, time: 0.748, loss: 1.2001, l1: 0.2597, vgg: 0.5448, mask: 0.3957\n",
      "step:    22340, time: 0.736, loss: 1.1835, l1: 0.2383, vgg: 0.5820, mask: 0.3631\n",
      "step:    22360, time: 0.806, loss: 1.2812, l1: 0.2480, vgg: 0.6216, mask: 0.4117\n",
      "step:    22380, time: 0.837, loss: 1.2322, l1: 0.2504, vgg: 0.6036, mask: 0.3782\n",
      "step:    22400, time: 0.792, loss: 1.1072, l1: 0.2001, vgg: 0.5599, mask: 0.3473\n",
      "step:    22420, time: 0.795, loss: 1.1616, l1: 0.2082, vgg: 0.5865, mask: 0.3669\n",
      "step:    22440, time: 0.742, loss: 1.2286, l1: 0.2305, vgg: 0.6086, mask: 0.3895\n",
      "step:    22460, time: 0.743, loss: 1.0663, l1: 0.2187, vgg: 0.4835, mask: 0.3641\n",
      "step:    22480, time: 0.747, loss: 1.1094, l1: 0.2178, vgg: 0.5566, mask: 0.3350\n",
      "step:    22500, time: 0.744, loss: 1.1785, l1: 0.2393, vgg: 0.5723, mask: 0.3669\n",
      "step:    22520, time: 0.764, loss: 1.2408, l1: 0.2241, vgg: 0.6430, mask: 0.3737\n",
      "step:    22540, time: 0.748, loss: 1.1668, l1: 0.2429, vgg: 0.5253, mask: 0.3986\n",
      "step:    22560, time: 0.731, loss: 1.1102, l1: 0.1895, vgg: 0.5714, mask: 0.3494\n",
      "step:    22580, time: 0.752, loss: 1.0680, l1: 0.1938, vgg: 0.5239, mask: 0.3503\n",
      "step:    22600, time: 0.749, loss: 1.2611, l1: 0.2877, vgg: 0.5890, mask: 0.3844\n",
      "step:    22620, time: 0.790, loss: 1.2477, l1: 0.2553, vgg: 0.5966, mask: 0.3957\n",
      "step:    22640, time: 0.707, loss: 1.1042, l1: 0.2178, vgg: 0.5005, mask: 0.3859\n",
      "step:    22660, time: 0.750, loss: 1.0847, l1: 0.1913, vgg: 0.5471, mask: 0.3463\n",
      "step:    22680, time: 0.756, loss: 1.1080, l1: 0.1912, vgg: 0.5883, mask: 0.3284\n",
      "step:    22700, time: 0.741, loss: 1.1193, l1: 0.2058, vgg: 0.5559, mask: 0.3576\n",
      "step:    22720, time: 0.768, loss: 1.3001, l1: 0.2927, vgg: 0.5859, mask: 0.4215\n",
      "step:    22740, time: 0.774, loss: 1.1701, l1: 0.2126, vgg: 0.5914, mask: 0.3662\n",
      "step:    22760, time: 0.775, loss: 1.2150, l1: 0.2404, vgg: 0.5857, mask: 0.3889\n",
      "step:    22780, time: 0.757, loss: 1.2362, l1: 0.2781, vgg: 0.5630, mask: 0.3951\n",
      "step:    22800, time: 0.763, loss: 1.1623, l1: 0.2295, vgg: 0.5324, mask: 0.4003\n",
      "step:    22820, time: 0.740, loss: 1.1444, l1: 0.1945, vgg: 0.5643, mask: 0.3856\n",
      "step:    22840, time: 0.740, loss: 1.2132, l1: 0.2233, vgg: 0.6254, mask: 0.3645\n",
      "step:    22860, time: 0.726, loss: 1.2009, l1: 0.2321, vgg: 0.6094, mask: 0.3594\n",
      "step:    22880, time: 0.739, loss: 1.2078, l1: 0.2278, vgg: 0.5679, mask: 0.4121\n",
      "step:    22900, time: 0.769, loss: 1.3019, l1: 0.2458, vgg: 0.6504, mask: 0.4057\n",
      "step:    22920, time: 0.769, loss: 1.2422, l1: 0.2371, vgg: 0.6212, mask: 0.3839\n",
      "step:    22940, time: 0.750, loss: 1.2415, l1: 0.2352, vgg: 0.6452, mask: 0.3610\n",
      "step:    22960, time: 0.733, loss: 1.1786, l1: 0.2859, vgg: 0.5155, mask: 0.3772\n",
      "step:    22980, time: 0.729, loss: 1.2122, l1: 0.2599, vgg: 0.5809, mask: 0.3713\n",
      "step:    23000, time: 0.766, loss: 1.1479, l1: 0.2153, vgg: 0.5665, mask: 0.3662\n",
      "step:    23020, time: 0.719, loss: 1.1826, l1: 0.2240, vgg: 0.5888, mask: 0.3698\n",
      "step:    23040, time: 0.757, loss: 1.1585, l1: 0.2506, vgg: 0.5385, mask: 0.3694\n",
      "step:    23060, time: 0.743, loss: 1.1814, l1: 0.2377, vgg: 0.5800, mask: 0.3637\n",
      "step:    23080, time: 0.742, loss: 1.1187, l1: 0.2117, vgg: 0.5433, mask: 0.3637\n",
      "step:    23100, time: 0.800, loss: 1.2717, l1: 0.2790, vgg: 0.6017, mask: 0.3911\n",
      "step:    23120, time: 0.761, loss: 1.2214, l1: 0.2467, vgg: 0.5478, mask: 0.4270\n",
      "step:    23140, time: 0.749, loss: 1.2549, l1: 0.2624, vgg: 0.6222, mask: 0.3703\n",
      "step:    23160, time: 0.727, loss: 1.2697, l1: 0.2800, vgg: 0.5731, mask: 0.4166\n",
      "step:    23180, time: 0.722, loss: 1.2169, l1: 0.2505, vgg: 0.6075, mask: 0.3589\n",
      "step:    23200, time: 0.787, loss: 1.2051, l1: 0.2674, vgg: 0.5489, mask: 0.3887\n",
      "step:    23220, time: 0.737, loss: 1.1142, l1: 0.2345, vgg: 0.5083, mask: 0.3715\n",
      "step:    23240, time: 0.758, loss: 1.1967, l1: 0.2394, vgg: 0.5614, mask: 0.3959\n",
      "step:    23260, time: 0.744, loss: 1.1991, l1: 0.2814, vgg: 0.5415, mask: 0.3762\n",
      "step:    23280, time: 0.758, loss: 1.2074, l1: 0.2512, vgg: 0.5821, mask: 0.3741\n",
      "step:    23300, time: 0.731, loss: 1.1610, l1: 0.2266, vgg: 0.5712, mask: 0.3632\n",
      "step:    23320, time: 0.760, loss: 1.1616, l1: 0.2424, vgg: 0.5703, mask: 0.3489\n",
      "step:    23340, time: 0.761, loss: 1.1610, l1: 0.1915, vgg: 0.6208, mask: 0.3486\n",
      "step:    23360, time: 0.762, loss: 1.1409, l1: 0.2213, vgg: 0.5528, mask: 0.3668\n",
      "step:    23380, time: 0.762, loss: 1.2762, l1: 0.2762, vgg: 0.5945, mask: 0.4055\n",
      "step:    23400, time: 0.750, loss: 1.1205, l1: 0.1954, vgg: 0.5838, mask: 0.3413\n",
      "step:    23420, time: 0.768, loss: 1.2308, l1: 0.2458, vgg: 0.6184, mask: 0.3666\n",
      "step:    23440, time: 0.759, loss: 1.2324, l1: 0.2214, vgg: 0.6435, mask: 0.3675\n",
      "step:    23460, time: 0.771, loss: 1.0852, l1: 0.1906, vgg: 0.5505, mask: 0.3441\n",
      "step:    23480, time: 0.780, loss: 1.2579, l1: 0.2828, vgg: 0.6137, mask: 0.3614\n",
      "step:    23500, time: 0.743, loss: 1.1054, l1: 0.2173, vgg: 0.5256, mask: 0.3625\n",
      "step:    23520, time: 0.725, loss: 1.1491, l1: 0.2317, vgg: 0.5409, mask: 0.3765\n",
      "step:    23540, time: 0.767, loss: 1.2810, l1: 0.2367, vgg: 0.6536, mask: 0.3907\n",
      "step:    23560, time: 0.773, loss: 1.1775, l1: 0.2267, vgg: 0.5962, mask: 0.3546\n",
      "step:    23580, time: 0.791, loss: 1.2285, l1: 0.2451, vgg: 0.5911, mask: 0.3924\n",
      "step:    23600, time: 0.763, loss: 1.2952, l1: 0.2745, vgg: 0.6195, mask: 0.4012\n",
      "step:    23620, time: 0.735, loss: 1.0874, l1: 0.1907, vgg: 0.5274, mask: 0.3693\n",
      "step:    23640, time: 0.780, loss: 1.3217, l1: 0.2728, vgg: 0.6538, mask: 0.3950\n",
      "step:    23660, time: 0.759, loss: 1.1533, l1: 0.2073, vgg: 0.5935, mask: 0.3525\n",
      "step:    23680, time: 0.737, loss: 1.0601, l1: 0.2041, vgg: 0.5055, mask: 0.3505\n",
      "step:    23700, time: 0.771, loss: 1.2042, l1: 0.2504, vgg: 0.5552, mask: 0.3987\n",
      "step:    23720, time: 0.781, loss: 1.3651, l1: 0.2824, vgg: 0.6733, mask: 0.4093\n",
      "step:    23740, time: 0.785, loss: 1.2061, l1: 0.2231, vgg: 0.5932, mask: 0.3898\n",
      "step:    23760, time: 0.737, loss: 1.1502, l1: 0.2573, vgg: 0.5422, mask: 0.3507\n",
      "step:    23780, time: 0.743, loss: 1.1382, l1: 0.2505, vgg: 0.5350, mask: 0.3527\n",
      "step:    23800, time: 0.762, loss: 1.1570, l1: 0.2247, vgg: 0.5618, mask: 0.3704\n",
      "step:    23820, time: 0.813, loss: 1.2170, l1: 0.2428, vgg: 0.6076, mask: 0.3666\n",
      "step:    23840, time: 0.747, loss: 1.2134, l1: 0.2301, vgg: 0.5741, mask: 0.4092\n",
      "step:    23860, time: 0.778, loss: 1.1943, l1: 0.2431, vgg: 0.5694, mask: 0.3819\n",
      "step:    23880, time: 0.751, loss: 1.1933, l1: 0.2184, vgg: 0.5988, mask: 0.3760\n",
      "step:    23900, time: 0.739, loss: 1.2361, l1: 0.2692, vgg: 0.5738, mask: 0.3930\n",
      "step:    23920, time: 0.768, loss: 1.2178, l1: 0.2475, vgg: 0.5823, mask: 0.3879\n",
      "step:    23940, time: 0.778, loss: 1.1826, l1: 0.2447, vgg: 0.5831, mask: 0.3549\n",
      "step:    23960, time: 0.793, loss: 1.2837, l1: 0.2541, vgg: 0.6596, mask: 0.3701\n",
      "step:    23980, time: 0.725, loss: 1.0431, l1: 0.1407, vgg: 0.5502, mask: 0.3522\n",
      "step:    24000, time: 0.779, loss: 1.1775, l1: 0.1985, vgg: 0.6246, mask: 0.3543\n",
      "step:    24020, time: 0.748, loss: 1.1836, l1: 0.2263, vgg: 0.5996, mask: 0.3577\n",
      "step:    24040, time: 0.735, loss: 1.1455, l1: 0.2167, vgg: 0.5554, mask: 0.3733\n",
      "step:    24060, time: 0.760, loss: 1.2742, l1: 0.2219, vgg: 0.6945, mask: 0.3578\n",
      "step:    24080, time: 0.808, loss: 1.1881, l1: 0.2200, vgg: 0.5575, mask: 0.4105\n",
      "step:    24100, time: 0.789, loss: 1.1801, l1: 0.1983, vgg: 0.6227, mask: 0.3591\n",
      "step:    24120, time: 0.761, loss: 1.2785, l1: 0.2956, vgg: 0.5803, mask: 0.4026\n",
      "step:    24140, time: 0.738, loss: 1.1710, l1: 0.2204, vgg: 0.5592, mask: 0.3914\n",
      "step:    24160, time: 0.745, loss: 1.2120, l1: 0.2331, vgg: 0.6250, mask: 0.3539\n",
      "step:    24180, time: 0.736, loss: 1.1292, l1: 0.2036, vgg: 0.5853, mask: 0.3403\n",
      "step:    24200, time: 0.752, loss: 1.1266, l1: 0.2287, vgg: 0.5332, mask: 0.3648\n",
      "step:    24220, time: 0.752, loss: 1.1365, l1: 0.2403, vgg: 0.5319, mask: 0.3643\n",
      "step:    24240, time: 0.773, loss: 1.2993, l1: 0.2658, vgg: 0.6325, mask: 0.4011\n",
      "step:    24260, time: 0.726, loss: 1.1313, l1: 0.1993, vgg: 0.5759, mask: 0.3561\n",
      "step:    24280, time: 0.773, loss: 1.5524, l1: 0.3575, vgg: 0.7696, mask: 0.4253\n",
      "step:    24300, time: 0.745, loss: 1.1798, l1: 0.2487, vgg: 0.5423, mask: 0.3888\n",
      "step:    24320, time: 0.779, loss: 1.2475, l1: 0.2654, vgg: 0.5970, mask: 0.3851\n",
      "step:    24340, time: 0.722, loss: 1.1213, l1: 0.2354, vgg: 0.5170, mask: 0.3690\n",
      "step:    24360, time: 0.755, loss: 1.1804, l1: 0.2296, vgg: 0.5790, mask: 0.3718\n",
      "step:    24380, time: 0.734, loss: 1.0733, l1: 0.1817, vgg: 0.5279, mask: 0.3637\n",
      "step:    24400, time: 0.738, loss: 1.1942, l1: 0.2517, vgg: 0.5906, mask: 0.3519\n",
      "step:    24420, time: 0.734, loss: 1.1873, l1: 0.2056, vgg: 0.6470, mask: 0.3347\n",
      "step:    24440, time: 0.725, loss: 1.0952, l1: 0.2048, vgg: 0.5301, mask: 0.3603\n",
      "step:    24460, time: 0.740, loss: 1.1502, l1: 0.2208, vgg: 0.5257, mask: 0.4037\n",
      "step:    24480, time: 0.742, loss: 1.2170, l1: 0.2498, vgg: 0.5747, mask: 0.3925\n",
      "step:    24500, time: 0.718, loss: 1.1296, l1: 0.2571, vgg: 0.5072, mask: 0.3653\n",
      "step:    24520, time: 0.753, loss: 1.2957, l1: 0.2785, vgg: 0.6185, mask: 0.3987\n",
      "step:    24540, time: 0.779, loss: 1.2838, l1: 0.2719, vgg: 0.6180, mask: 0.3939\n",
      "step:    24560, time: 0.851, loss: 1.2854, l1: 0.2742, vgg: 0.6357, mask: 0.3755\n",
      "step:    24580, time: 0.807, loss: 1.1193, l1: 0.2424, vgg: 0.5178, mask: 0.3591\n",
      "step:    24600, time: 0.788, loss: 1.0915, l1: 0.2296, vgg: 0.4870, mask: 0.3750\n",
      "step:    24620, time: 0.850, loss: 1.2214, l1: 0.2563, vgg: 0.5791, mask: 0.3860\n",
      "step:    24640, time: 0.811, loss: 1.2081, l1: 0.2373, vgg: 0.5834, mask: 0.3874\n",
      "step:    24660, time: 0.751, loss: 1.0415, l1: 0.1698, vgg: 0.5207, mask: 0.3509\n",
      "step:    24680, time: 0.775, loss: 1.2299, l1: 0.2618, vgg: 0.6053, mask: 0.3627\n",
      "step:    24700, time: 0.809, loss: 1.1221, l1: 0.2133, vgg: 0.5373, mask: 0.3715\n",
      "step:    24720, time: 0.736, loss: 1.1962, l1: 0.2124, vgg: 0.6370, mask: 0.3468\n",
      "step:    24740, time: 0.769, loss: 1.3182, l1: 0.3154, vgg: 0.5951, mask: 0.4077\n",
      "step:    24760, time: 0.719, loss: 1.1848, l1: 0.2199, vgg: 0.5741, mask: 0.3908\n",
      "step:    24780, time: 0.789, loss: 1.1048, l1: 0.2003, vgg: 0.5590, mask: 0.3455\n",
      "step:    24800, time: 0.727, loss: 1.1664, l1: 0.2568, vgg: 0.5369, mask: 0.3727\n",
      "step:    24820, time: 0.728, loss: 1.1789, l1: 0.2107, vgg: 0.5641, mask: 0.4040\n",
      "step:    24840, time: 0.723, loss: 1.2815, l1: 0.2676, vgg: 0.6219, mask: 0.3920\n",
      "step:    24860, time: 0.742, loss: 1.1290, l1: 0.2151, vgg: 0.5669, mask: 0.3469\n",
      "step:    24880, time: 0.759, loss: 1.2468, l1: 0.2418, vgg: 0.6181, mask: 0.3868\n",
      "step:    24900, time: 0.780, loss: 1.1791, l1: 0.2359, vgg: 0.5642, mask: 0.3790\n",
      "step:    24920, time: 0.790, loss: 1.0940, l1: 0.1809, vgg: 0.5272, mask: 0.3859\n",
      "step:    24940, time: 0.758, loss: 1.0770, l1: 0.1890, vgg: 0.5123, mask: 0.3757\n",
      "step:    24960, time: 0.737, loss: 1.0808, l1: 0.2380, vgg: 0.4668, mask: 0.3760\n",
      "step:    24980, time: 0.772, loss: 1.2189, l1: 0.2325, vgg: 0.5974, mask: 0.3890\n",
      "step:    25000, time: 0.764, loss: 1.0888, l1: 0.2030, vgg: 0.5340, mask: 0.3518\n",
      "step:    25020, time: 0.764, loss: 1.2201, l1: 0.2522, vgg: 0.6048, mask: 0.3630\n",
      "step:    25040, time: 0.785, loss: 1.1880, l1: 0.2736, vgg: 0.5367, mask: 0.3777\n",
      "step:    25060, time: 0.759, loss: 1.1869, l1: 0.2275, vgg: 0.5946, mask: 0.3649\n",
      "step:    25080, time: 0.752, loss: 1.2177, l1: 0.2718, vgg: 0.5355, mask: 0.4104\n",
      "step:    25100, time: 0.762, loss: 1.1003, l1: 0.2021, vgg: 0.5644, mask: 0.3338\n",
      "step:    25120, time: 0.766, loss: 1.1589, l1: 0.2476, vgg: 0.5458, mask: 0.3654\n",
      "step:    25140, time: 0.767, loss: 1.1751, l1: 0.2457, vgg: 0.5540, mask: 0.3754\n",
      "step:    25160, time: 0.747, loss: 1.2460, l1: 0.2640, vgg: 0.5631, mask: 0.4189\n",
      "step:    25180, time: 0.758, loss: 1.3023, l1: 0.3032, vgg: 0.5929, mask: 0.4062\n",
      "step:    25200, time: 0.783, loss: 1.2131, l1: 0.2416, vgg: 0.6104, mask: 0.3611\n",
      "step:    25220, time: 0.761, loss: 1.1562, l1: 0.2294, vgg: 0.5498, mask: 0.3771\n",
      "step:    25240, time: 0.797, loss: 1.2075, l1: 0.2276, vgg: 0.6315, mask: 0.3484\n",
      "step:    25260, time: 0.762, loss: 1.3193, l1: 0.2598, vgg: 0.6530, mask: 0.4064\n",
      "step:    25280, time: 0.762, loss: 1.2066, l1: 0.2670, vgg: 0.5666, mask: 0.3730\n",
      "step:    25300, time: 0.757, loss: 1.2223, l1: 0.2135, vgg: 0.6673, mask: 0.3415\n",
      "step:    25320, time: 0.833, loss: 1.1396, l1: 0.1969, vgg: 0.5497, mask: 0.3930\n",
      "step:    25340, time: 0.778, loss: 1.2962, l1: 0.2903, vgg: 0.6067, mask: 0.3992\n",
      "step:    25360, time: 0.762, loss: 1.1047, l1: 0.2126, vgg: 0.5492, mask: 0.3429\n",
      "step:    25380, time: 0.757, loss: 1.0646, l1: 0.1748, vgg: 0.5296, mask: 0.3601\n",
      "step:    25400, time: 0.756, loss: 1.2221, l1: 0.2215, vgg: 0.6540, mask: 0.3466\n",
      "step:    25420, time: 0.785, loss: 1.1467, l1: 0.2125, vgg: 0.5423, mask: 0.3918\n",
      "step:    25440, time: 0.771, loss: 1.1706, l1: 0.1931, vgg: 0.5968, mask: 0.3806\n",
      "step:    25460, time: 0.760, loss: 1.2716, l1: 0.2942, vgg: 0.5876, mask: 0.3897\n",
      "step:    25480, time: 0.776, loss: 1.1060, l1: 0.2339, vgg: 0.5095, mask: 0.3627\n",
      "step:    25500, time: 0.791, loss: 1.2379, l1: 0.2907, vgg: 0.5759, mask: 0.3713\n",
      "step:    25520, time: 0.745, loss: 1.1369, l1: 0.2252, vgg: 0.5439, mask: 0.3678\n",
      "step:    25540, time: 0.769, loss: 1.0891, l1: 0.1915, vgg: 0.5269, mask: 0.3706\n",
      "step:    25560, time: 0.818, loss: 1.2819, l1: 0.2210, vgg: 0.6652, mask: 0.3957\n",
      "step:    25580, time: 0.741, loss: 1.3331, l1: 0.2950, vgg: 0.6197, mask: 0.4185\n",
      "step:    25600, time: 0.757, loss: 1.1574, l1: 0.2129, vgg: 0.5971, mask: 0.3474\n",
      "step:    25620, time: 0.750, loss: 1.1834, l1: 0.2003, vgg: 0.5986, mask: 0.3845\n",
      "step:    25640, time: 0.752, loss: 1.2181, l1: 0.2253, vgg: 0.6111, mask: 0.3817\n",
      "step:    25660, time: 0.746, loss: 1.2139, l1: 0.2165, vgg: 0.6550, mask: 0.3424\n",
      "step:    25680, time: 0.776, loss: 1.2165, l1: 0.2930, vgg: 0.5329, mask: 0.3906\n",
      "step:    25700, time: 0.719, loss: 1.1012, l1: 0.2179, vgg: 0.5047, mask: 0.3787\n",
      "step:    25720, time: 0.750, loss: 1.1067, l1: 0.1971, vgg: 0.5827, mask: 0.3269\n",
      "step:    25740, time: 0.732, loss: 1.1950, l1: 0.2146, vgg: 0.5661, mask: 0.4144\n",
      "step:    25760, time: 0.768, loss: 1.3496, l1: 0.3052, vgg: 0.6519, mask: 0.3924\n",
      "step:    25780, time: 0.725, loss: 1.0754, l1: 0.1747, vgg: 0.5553, mask: 0.3454\n",
      "step:    25800, time: 0.769, loss: 1.1061, l1: 0.1880, vgg: 0.5471, mask: 0.3710\n",
      "step:    25820, time: 0.750, loss: 1.2497, l1: 0.2763, vgg: 0.5801, mask: 0.3934\n",
      "step:    25840, time: 0.746, loss: 1.1198, l1: 0.2208, vgg: 0.5174, mask: 0.3815\n",
      "step:    25860, time: 0.751, loss: 1.2032, l1: 0.2557, vgg: 0.5981, mask: 0.3494\n",
      "step:    25880, time: 0.745, loss: 1.0566, l1: 0.1971, vgg: 0.5288, mask: 0.3307\n",
      "step:    25900, time: 0.746, loss: 1.1414, l1: 0.2145, vgg: 0.5357, mask: 0.3913\n",
      "step:    25920, time: 0.792, loss: 1.2039, l1: 0.2389, vgg: 0.5815, mask: 0.3835\n",
      "step:    25940, time: 0.760, loss: 1.1600, l1: 0.2419, vgg: 0.5561, mask: 0.3619\n",
      "step:    25960, time: 0.784, loss: 1.1366, l1: 0.2253, vgg: 0.5471, mask: 0.3642\n",
      "step:    25980, time: 0.796, loss: 1.2284, l1: 0.2377, vgg: 0.6029, mask: 0.3878\n",
      "step:    26000, time: 0.770, loss: 1.0626, l1: 0.2181, vgg: 0.4934, mask: 0.3511\n",
      "step:    26020, time: 0.752, loss: 1.3494, l1: 0.2761, vgg: 0.6478, mask: 0.4255\n",
      "step:    26040, time: 0.750, loss: 1.2518, l1: 0.2714, vgg: 0.5952, mask: 0.3851\n",
      "step:    26060, time: 0.790, loss: 1.1904, l1: 0.2075, vgg: 0.5744, mask: 0.4085\n",
      "step:    26080, time: 0.753, loss: 1.2023, l1: 0.2420, vgg: 0.5832, mask: 0.3771\n",
      "step:    26100, time: 0.766, loss: 1.0977, l1: 0.2043, vgg: 0.5190, mask: 0.3745\n",
      "step:    26120, time: 0.752, loss: 1.1278, l1: 0.2056, vgg: 0.5693, mask: 0.3528\n",
      "step:    26140, time: 0.780, loss: 1.3243, l1: 0.2911, vgg: 0.6056, mask: 0.4275\n",
      "step:    26160, time: 0.804, loss: 1.2391, l1: 0.2363, vgg: 0.5848, mask: 0.4180\n",
      "step:    26180, time: 0.725, loss: 1.0388, l1: 0.1863, vgg: 0.5281, mask: 0.3243\n",
      "step:    26200, time: 0.778, loss: 1.1268, l1: 0.1816, vgg: 0.5910, mask: 0.3542\n",
      "step:    26220, time: 0.795, loss: 1.2294, l1: 0.2911, vgg: 0.5374, mask: 0.4010\n",
      "step:    26240, time: 0.802, loss: 1.1975, l1: 0.2049, vgg: 0.6171, mask: 0.3755\n",
      "step:    26260, time: 0.743, loss: 1.1260, l1: 0.2127, vgg: 0.5410, mask: 0.3722\n",
      "step:    26280, time: 0.758, loss: 1.2774, l1: 0.2532, vgg: 0.5942, mask: 0.4299\n",
      "step:    26300, time: 0.766, loss: 1.2309, l1: 0.2035, vgg: 0.6739, mask: 0.3534\n",
      "step:    26320, time: 0.769, loss: 1.1669, l1: 0.2120, vgg: 0.5594, mask: 0.3955\n",
      "step:    26340, time: 0.786, loss: 1.2283, l1: 0.2198, vgg: 0.6400, mask: 0.3685\n",
      "step:    26360, time: 0.766, loss: 1.1893, l1: 0.2122, vgg: 0.5871, mask: 0.3900\n",
      "step:    26380, time: 0.781, loss: 1.2203, l1: 0.2576, vgg: 0.5827, mask: 0.3800\n",
      "step:    26400, time: 0.780, loss: 1.2696, l1: 0.2751, vgg: 0.5863, mask: 0.4082\n",
      "step:    26420, time: 0.750, loss: 1.1453, l1: 0.2133, vgg: 0.5442, mask: 0.3878\n",
      "step:    26440, time: 0.736, loss: 1.0733, l1: 0.2165, vgg: 0.4948, mask: 0.3621\n",
      "step:    26460, time: 0.760, loss: 1.0985, l1: 0.1658, vgg: 0.5633, mask: 0.3695\n",
      "step:    26480, time: 0.773, loss: 1.2593, l1: 0.2533, vgg: 0.6236, mask: 0.3824\n",
      "step:    26500, time: 0.760, loss: 1.1646, l1: 0.2143, vgg: 0.5759, mask: 0.3743\n",
      "step:    26520, time: 0.754, loss: 1.1692, l1: 0.2101, vgg: 0.5811, mask: 0.3780\n",
      "step:    26540, time: 0.745, loss: 1.1624, l1: 0.2463, vgg: 0.5304, mask: 0.3858\n",
      "step:    26560, time: 0.756, loss: 1.2174, l1: 0.2535, vgg: 0.5755, mask: 0.3883\n",
      "step:    26580, time: 0.769, loss: 1.1493, l1: 0.2342, vgg: 0.5496, mask: 0.3655\n",
      "step:    26600, time: 0.770, loss: 1.0969, l1: 0.2166, vgg: 0.5404, mask: 0.3400\n",
      "step:    26620, time: 0.771, loss: 1.2403, l1: 0.2295, vgg: 0.6323, mask: 0.3784\n",
      "step:    26640, time: 0.767, loss: 1.2812, l1: 0.3045, vgg: 0.5720, mask: 0.4047\n",
      "step:    26660, time: 0.783, loss: 1.2017, l1: 0.2660, vgg: 0.5380, mask: 0.3978\n",
      "step:    26680, time: 0.792, loss: 1.1215, l1: 0.1892, vgg: 0.5451, mask: 0.3872\n",
      "step:    26700, time: 0.798, loss: 1.0076, l1: 0.1880, vgg: 0.4539, mask: 0.3656\n",
      "step:    26720, time: 0.737, loss: 1.0854, l1: 0.2099, vgg: 0.5182, mask: 0.3573\n",
      "step:    26740, time: 0.786, loss: 1.2835, l1: 0.2769, vgg: 0.5792, mask: 0.4274\n",
      "step:    26760, time: 0.776, loss: 1.2071, l1: 0.2197, vgg: 0.6179, mask: 0.3695\n",
      "step:    26780, time: 0.763, loss: 1.1094, l1: 0.2092, vgg: 0.5586, mask: 0.3416\n",
      "step:    26800, time: 0.744, loss: 1.1222, l1: 0.2241, vgg: 0.5309, mask: 0.3672\n",
      "step:    26820, time: 0.794, loss: 1.2927, l1: 0.2534, vgg: 0.6494, mask: 0.3899\n",
      "step:    26840, time: 0.739, loss: 1.0597, l1: 0.2156, vgg: 0.4836, mask: 0.3606\n",
      "step:    26860, time: 0.757, loss: 1.2554, l1: 0.2590, vgg: 0.6163, mask: 0.3801\n",
      "step:    26880, time: 0.792, loss: 1.2841, l1: 0.2933, vgg: 0.5737, mask: 0.4171\n",
      "step:    26900, time: 0.764, loss: 1.1310, l1: 0.2090, vgg: 0.5809, mask: 0.3412\n",
      "step:    26920, time: 0.790, loss: 1.2703, l1: 0.2443, vgg: 0.6189, mask: 0.4072\n",
      "step:    26940, time: 0.763, loss: 1.1705, l1: 0.2157, vgg: 0.5570, mask: 0.3978\n",
      "step:    26960, time: 0.758, loss: 1.2597, l1: 0.2575, vgg: 0.6214, mask: 0.3809\n",
      "step:    26980, time: 0.877, loss: 1.0580, l1: 0.1895, vgg: 0.4835, mask: 0.3850\n",
      "step:    27000, time: 0.837, loss: 1.0644, l1: 0.2008, vgg: 0.5003, mask: 0.3634\n",
      "step:    27020, time: 0.784, loss: 1.1438, l1: 0.2206, vgg: 0.5633, mask: 0.3599\n",
      "step:    27040, time: 0.776, loss: 1.2687, l1: 0.2760, vgg: 0.5905, mask: 0.4022\n",
      "step:    27060, time: 0.827, loss: 1.3715, l1: 0.3117, vgg: 0.6136, mask: 0.4462\n",
      "step:    27080, time: 0.812, loss: 1.2747, l1: 0.2553, vgg: 0.6458, mask: 0.3736\n",
      "step:    27100, time: 0.755, loss: 1.2754, l1: 0.2774, vgg: 0.5793, mask: 0.4186\n",
      "step:    27120, time: 0.790, loss: 1.3101, l1: 0.3054, vgg: 0.6090, mask: 0.3957\n",
      "step:    27140, time: 0.813, loss: 1.2946, l1: 0.2648, vgg: 0.6461, mask: 0.3837\n",
      "step:    27160, time: 0.797, loss: 1.1907, l1: 0.2205, vgg: 0.6012, mask: 0.3690\n",
      "step:    27180, time: 0.812, loss: 1.2370, l1: 0.2182, vgg: 0.6368, mask: 0.3821\n",
      "step:    27200, time: 0.784, loss: 1.1585, l1: 0.2160, vgg: 0.5564, mask: 0.3862\n",
      "step:    27220, time: 0.790, loss: 1.2602, l1: 0.2783, vgg: 0.5812, mask: 0.4007\n",
      "step:    27240, time: 0.758, loss: 1.0709, l1: 0.2100, vgg: 0.5041, mask: 0.3567\n",
      "step:    27260, time: 0.773, loss: 1.2026, l1: 0.2129, vgg: 0.6218, mask: 0.3679\n",
      "step:    27280, time: 0.809, loss: 1.1393, l1: 0.2296, vgg: 0.5508, mask: 0.3589\n",
      "step:    27300, time: 0.757, loss: 1.1566, l1: 0.2646, vgg: 0.5064, mask: 0.3856\n",
      "step:    27320, time: 0.774, loss: 1.1191, l1: 0.2146, vgg: 0.5404, mask: 0.3641\n",
      "step:    27340, time: 0.835, loss: 1.1667, l1: 0.2071, vgg: 0.5891, mask: 0.3705\n",
      "step:    27360, time: 0.754, loss: 1.1065, l1: 0.2348, vgg: 0.4930, mask: 0.3787\n",
      "step:    27380, time: 0.772, loss: 1.2303, l1: 0.2627, vgg: 0.5885, mask: 0.3791\n",
      "step:    27400, time: 0.789, loss: 1.0695, l1: 0.2121, vgg: 0.5023, mask: 0.3551\n",
      "step:    27420, time: 0.744, loss: 1.1494, l1: 0.2114, vgg: 0.5630, mask: 0.3750\n",
      "step:    27440, time: 0.759, loss: 1.2278, l1: 0.3076, vgg: 0.5385, mask: 0.3817\n",
      "step:    27460, time: 0.763, loss: 1.2185, l1: 0.2899, vgg: 0.5449, mask: 0.3837\n",
      "step:    27480, time: 0.808, loss: 1.3131, l1: 0.2749, vgg: 0.6188, mask: 0.4195\n",
      "step:    27500, time: 0.726, loss: 1.1552, l1: 0.2127, vgg: 0.6036, mask: 0.3389\n",
      "step:    27520, time: 0.759, loss: 1.0475, l1: 0.1830, vgg: 0.5349, mask: 0.3296\n",
      "step:    27540, time: 0.794, loss: 1.2757, l1: 0.2476, vgg: 0.6304, mask: 0.3977\n",
      "step:    27560, time: 0.749, loss: 1.1735, l1: 0.2312, vgg: 0.5664, mask: 0.3759\n",
      "step:    27580, time: 0.729, loss: 1.1380, l1: 0.1918, vgg: 0.5576, mask: 0.3887\n",
      "step:    27600, time: 0.748, loss: 1.3094, l1: 0.2781, vgg: 0.6198, mask: 0.4115\n",
      "step:    27620, time: 0.750, loss: 1.1444, l1: 0.2058, vgg: 0.5735, mask: 0.3650\n",
      "step:    27640, time: 0.726, loss: 1.1824, l1: 0.2590, vgg: 0.5425, mask: 0.3810\n",
      "step:    27660, time: 0.739, loss: 1.1428, l1: 0.2344, vgg: 0.5266, mask: 0.3818\n",
      "step:    27680, time: 0.751, loss: 1.1515, l1: 0.2353, vgg: 0.5555, mask: 0.3607\n",
      "step:    27700, time: 0.758, loss: 1.1441, l1: 0.2199, vgg: 0.5634, mask: 0.3608\n",
      "step:    27720, time: 0.727, loss: 1.0024, l1: 0.1580, vgg: 0.5296, mask: 0.3148\n",
      "step:    27740, time: 0.748, loss: 1.0996, l1: 0.1662, vgg: 0.5502, mask: 0.3832\n",
      "step:    27760, time: 0.770, loss: 1.1208, l1: 0.2374, vgg: 0.5414, mask: 0.3420\n",
      "step:    27780, time: 0.768, loss: 1.2891, l1: 0.2931, vgg: 0.5817, mask: 0.4144\n",
      "step:    27800, time: 0.786, loss: 1.0758, l1: 0.2081, vgg: 0.4946, mask: 0.3732\n",
      "step:    27820, time: 0.799, loss: 1.1527, l1: 0.2207, vgg: 0.5737, mask: 0.3584\n",
      "step:    27840, time: 0.735, loss: 1.2811, l1: 0.2637, vgg: 0.6190, mask: 0.3983\n",
      "step:    27860, time: 0.816, loss: 1.1484, l1: 0.1982, vgg: 0.6160, mask: 0.3341\n",
      "step:    27880, time: 0.863, loss: 1.2406, l1: 0.2551, vgg: 0.6131, mask: 0.3725\n",
      "step:    27900, time: 0.747, loss: 1.2148, l1: 0.2725, vgg: 0.5645, mask: 0.3779\n",
      "step:    27920, time: 0.751, loss: 1.2044, l1: 0.2158, vgg: 0.6213, mask: 0.3674\n",
      "step:    27940, time: 0.771, loss: 0.9770, l1: 0.1552, vgg: 0.5039, mask: 0.3179\n",
      "step:    27960, time: 0.809, loss: 1.1199, l1: 0.2004, vgg: 0.5673, mask: 0.3522\n",
      "step:    27980, time: 0.768, loss: 1.1592, l1: 0.2097, vgg: 0.5977, mask: 0.3518\n",
      "step:    28000, time: 0.742, loss: 1.0485, l1: 0.1726, vgg: 0.5394, mask: 0.3366\n",
      "step:    28020, time: 0.758, loss: 1.1873, l1: 0.2444, vgg: 0.5668, mask: 0.3760\n",
      "step:    28040, time: 0.727, loss: 1.0320, l1: 0.1916, vgg: 0.4902, mask: 0.3502\n",
      "step:    28060, time: 0.779, loss: 1.1192, l1: 0.2442, vgg: 0.4860, mask: 0.3891\n",
      "step:    28080, time: 0.714, loss: 1.1960, l1: 0.2376, vgg: 0.5883, mask: 0.3701\n",
      "step:    28100, time: 0.755, loss: 1.2940, l1: 0.2440, vgg: 0.6869, mask: 0.3631\n",
      "step:    28120, time: 0.743, loss: 1.1188, l1: 0.2267, vgg: 0.5014, mask: 0.3907\n",
      "step:    28140, time: 0.771, loss: 1.2703, l1: 0.2592, vgg: 0.6216, mask: 0.3895\n",
      "step:    28160, time: 0.801, loss: 1.2392, l1: 0.2227, vgg: 0.6481, mask: 0.3683\n",
      "step:    28180, time: 0.745, loss: 1.1567, l1: 0.2357, vgg: 0.5792, mask: 0.3419\n",
      "step:    28200, time: 0.738, loss: 1.1151, l1: 0.2298, vgg: 0.5377, mask: 0.3476\n",
      "step:    28220, time: 0.753, loss: 1.1321, l1: 0.2401, vgg: 0.5391, mask: 0.3529\n",
      "step:    28240, time: 0.751, loss: 1.1434, l1: 0.2427, vgg: 0.5286, mask: 0.3721\n",
      "step:    28260, time: 0.758, loss: 1.2211, l1: 0.2527, vgg: 0.5935, mask: 0.3749\n",
      "step:    28280, time: 0.813, loss: 1.1824, l1: 0.2145, vgg: 0.6215, mask: 0.3464\n",
      "step:    28300, time: 0.762, loss: 1.1381, l1: 0.2308, vgg: 0.5555, mask: 0.3517\n",
      "step:    28320, time: 0.777, loss: 1.2353, l1: 0.2533, vgg: 0.5825, mask: 0.3996\n",
      "step:    28340, time: 0.767, loss: 1.1643, l1: 0.2117, vgg: 0.5593, mask: 0.3934\n",
      "step:    28360, time: 0.725, loss: 1.1376, l1: 0.2201, vgg: 0.5186, mask: 0.3989\n",
      "step:    28380, time: 0.755, loss: 1.1340, l1: 0.2260, vgg: 0.5509, mask: 0.3572\n",
      "step:    28400, time: 0.785, loss: 1.3150, l1: 0.2159, vgg: 0.6978, mask: 0.4014\n",
      "step:    28420, time: 0.769, loss: 1.1934, l1: 0.1912, vgg: 0.6095, mask: 0.3926\n",
      "step:    28440, time: 0.749, loss: 1.1473, l1: 0.2179, vgg: 0.5777, mask: 0.3518\n",
      "step:    28460, time: 0.730, loss: 1.0886, l1: 0.2192, vgg: 0.5143, mask: 0.3551\n",
      "step:    28480, time: 0.752, loss: 1.0776, l1: 0.1838, vgg: 0.5160, mask: 0.3778\n",
      "step:    28500, time: 0.777, loss: 1.1139, l1: 0.2139, vgg: 0.5384, mask: 0.3616\n",
      "step:    28520, time: 0.763, loss: 1.2948, l1: 0.3080, vgg: 0.5438, mask: 0.4430\n",
      "step:    28540, time: 0.759, loss: 1.1173, l1: 0.2120, vgg: 0.5367, mask: 0.3686\n",
      "step:    28560, time: 0.787, loss: 1.1324, l1: 0.2252, vgg: 0.5388, mask: 0.3684\n",
      "step:    28580, time: 0.842, loss: 1.1281, l1: 0.2118, vgg: 0.5424, mask: 0.3739\n",
      "step:    28600, time: 0.828, loss: 1.1309, l1: 0.2075, vgg: 0.5501, mask: 0.3733\n",
      "step:    28620, time: 0.781, loss: 1.1360, l1: 0.2115, vgg: 0.5512, mask: 0.3734\n",
      "step:    28640, time: 0.750, loss: 1.1822, l1: 0.2187, vgg: 0.6212, mask: 0.3424\n",
      "step:    28660, time: 0.786, loss: 1.2072, l1: 0.2501, vgg: 0.5712, mask: 0.3859\n",
      "step:    28680, time: 0.791, loss: 1.3320, l1: 0.3007, vgg: 0.6153, mask: 0.4160\n",
      "step:    28700, time: 0.786, loss: 1.0432, l1: 0.1883, vgg: 0.5148, mask: 0.3402\n",
      "step:    28720, time: 0.725, loss: 1.0061, l1: 0.1818, vgg: 0.4777, mask: 0.3466\n",
      "step:    28740, time: 0.793, loss: 1.2504, l1: 0.3060, vgg: 0.5328, mask: 0.4116\n",
      "step:    28760, time: 0.760, loss: 1.1716, l1: 0.2122, vgg: 0.5757, mask: 0.3838\n",
      "step:    28780, time: 0.737, loss: 1.1565, l1: 0.2461, vgg: 0.5269, mask: 0.3834\n",
      "step:    28800, time: 0.762, loss: 1.1333, l1: 0.2429, vgg: 0.5464, mask: 0.3440\n",
      "step:    28820, time: 0.775, loss: 1.2469, l1: 0.2925, vgg: 0.5422, mask: 0.4122\n",
      "step:    28840, time: 0.819, loss: 1.1877, l1: 0.1904, vgg: 0.6013, mask: 0.3960\n",
      "step:    28860, time: 0.755, loss: 1.0901, l1: 0.1867, vgg: 0.5565, mask: 0.3469\n",
      "step:    28880, time: 0.794, loss: 1.1677, l1: 0.2102, vgg: 0.5717, mask: 0.3857\n",
      "step:    28900, time: 0.780, loss: 1.2676, l1: 0.2658, vgg: 0.5921, mask: 0.4097\n",
      "step:    28920, time: 0.747, loss: 1.0968, l1: 0.1856, vgg: 0.5646, mask: 0.3465\n",
      "step:    28940, time: 0.855, loss: 1.1274, l1: 0.2045, vgg: 0.5368, mask: 0.3862\n",
      "step:    28960, time: 0.726, loss: 1.0148, l1: 0.1664, vgg: 0.5302, mask: 0.3182\n",
      "step:    28980, time: 0.800, loss: 1.2317, l1: 0.2498, vgg: 0.5930, mask: 0.3889\n",
      "step:    29000, time: 0.746, loss: 1.2049, l1: 0.2735, vgg: 0.5337, mask: 0.3976\n",
      "step:    29020, time: 0.779, loss: 1.2574, l1: 0.2983, vgg: 0.5820, mask: 0.3771\n",
      "step:    29040, time: 0.770, loss: 1.1734, l1: 0.2437, vgg: 0.5320, mask: 0.3977\n",
      "step:    29060, time: 0.724, loss: 1.2068, l1: 0.2496, vgg: 0.5561, mask: 0.4012\n",
      "step:    29080, time: 0.733, loss: 0.9867, l1: 0.1606, vgg: 0.4711, mask: 0.3550\n",
      "step:    29100, time: 0.815, loss: 1.1160, l1: 0.2320, vgg: 0.5295, mask: 0.3545\n",
      "step:    29120, time: 0.784, loss: 1.1083, l1: 0.2084, vgg: 0.5194, mask: 0.3804\n",
      "step:    29140, time: 0.757, loss: 1.2390, l1: 0.2257, vgg: 0.6056, mask: 0.4077\n",
      "step:    29160, time: 0.785, loss: 1.1593, l1: 0.2373, vgg: 0.5203, mask: 0.4018\n",
      "step:    29180, time: 0.751, loss: 1.1374, l1: 0.2453, vgg: 0.5303, mask: 0.3618\n",
      "step:    29200, time: 0.757, loss: 1.2137, l1: 0.2508, vgg: 0.5689, mask: 0.3941\n",
      "step:    29220, time: 0.774, loss: 1.1277, l1: 0.2284, vgg: 0.5114, mask: 0.3879\n",
      "step:    29240, time: 0.856, loss: 1.3109, l1: 0.2680, vgg: 0.6586, mask: 0.3844\n",
      "step:    29260, time: 0.782, loss: 1.0595, l1: 0.1914, vgg: 0.5221, mask: 0.3460\n",
      "step:    29280, time: 0.827, loss: 1.2722, l1: 0.2395, vgg: 0.6211, mask: 0.4116\n",
      "step:    29300, time: 0.849, loss: 1.2228, l1: 0.2127, vgg: 0.6319, mask: 0.3783\n",
      "step:    29320, time: 0.806, loss: 1.2444, l1: 0.2252, vgg: 0.6532, mask: 0.3660\n",
      "step:    29340, time: 0.836, loss: 1.1940, l1: 0.2235, vgg: 0.5864, mask: 0.3841\n",
      "step:    29360, time: 0.749, loss: 1.1108, l1: 0.2294, vgg: 0.4972, mask: 0.3841\n",
      "step:    29380, time: 0.765, loss: 1.1300, l1: 0.2069, vgg: 0.5357, mask: 0.3874\n",
      "step:    29400, time: 0.742, loss: 1.1388, l1: 0.2313, vgg: 0.5265, mask: 0.3810\n",
      "step:    29420, time: 0.768, loss: 1.3876, l1: 0.3267, vgg: 0.6652, mask: 0.3958\n",
      "step:    29440, time: 0.785, loss: 1.1477, l1: 0.2311, vgg: 0.5470, mask: 0.3696\n",
      "step:    29460, time: 0.756, loss: 1.2046, l1: 0.2647, vgg: 0.5565, mask: 0.3834\n",
      "step:    29480, time: 0.754, loss: 1.1045, l1: 0.2060, vgg: 0.5393, mask: 0.3592\n",
      "step:    29500, time: 0.770, loss: 1.0931, l1: 0.2217, vgg: 0.5159, mask: 0.3555\n",
      "step:    29520, time: 0.763, loss: 1.1370, l1: 0.1991, vgg: 0.5236, mask: 0.4143\n",
      "step:    29540, time: 0.774, loss: 1.2277, l1: 0.2531, vgg: 0.5952, mask: 0.3794\n",
      "step:    29560, time: 0.735, loss: 1.0866, l1: 0.2357, vgg: 0.4868, mask: 0.3642\n",
      "step:    29580, time: 0.803, loss: 1.2222, l1: 0.2649, vgg: 0.5548, mask: 0.4025\n",
      "step:    29600, time: 0.764, loss: 1.0899, l1: 0.2510, vgg: 0.4692, mask: 0.3697\n",
      "step:    29620, time: 0.737, loss: 1.0972, l1: 0.1973, vgg: 0.5636, mask: 0.3363\n",
      "step:    29640, time: 0.793, loss: 1.1370, l1: 0.2373, vgg: 0.5267, mask: 0.3731\n",
      "step:    29660, time: 0.752, loss: 1.1312, l1: 0.1888, vgg: 0.5385, mask: 0.4039\n",
      "step:    29680, time: 0.749, loss: 1.1954, l1: 0.2580, vgg: 0.5641, mask: 0.3733\n",
      "step:    29700, time: 0.799, loss: 1.1735, l1: 0.2887, vgg: 0.5130, mask: 0.3719\n",
      "step:    29720, time: 0.809, loss: 1.3282, l1: 0.2565, vgg: 0.6654, mask: 0.4063\n",
      "step:    29740, time: 0.752, loss: 1.2091, l1: 0.2268, vgg: 0.6079, mask: 0.3744\n",
      "step:    29760, time: 0.712, loss: 1.1488, l1: 0.2124, vgg: 0.5414, mask: 0.3950\n",
      "step:    29780, time: 0.751, loss: 1.0744, l1: 0.2243, vgg: 0.4966, mask: 0.3535\n",
      "step:    29800, time: 0.799, loss: 1.1589, l1: 0.2217, vgg: 0.5519, mask: 0.3853\n",
      "step:    29820, time: 0.730, loss: 1.1712, l1: 0.2307, vgg: 0.5515, mask: 0.3890\n",
      "step:    29840, time: 0.782, loss: 1.1796, l1: 0.2462, vgg: 0.5760, mask: 0.3575\n",
      "step:    29860, time: 0.711, loss: 1.2061, l1: 0.2145, vgg: 0.5930, mask: 0.3986\n",
      "step:    29880, time: 0.721, loss: 1.1546, l1: 0.2431, vgg: 0.5324, mask: 0.3790\n",
      "step:    29900, time: 0.753, loss: 1.0879, l1: 0.1657, vgg: 0.5682, mask: 0.3540\n",
      "step:    29920, time: 0.784, loss: 1.1186, l1: 0.1818, vgg: 0.5952, mask: 0.3416\n",
      "step:    29940, time: 0.761, loss: 0.9922, l1: 0.1751, vgg: 0.4829, mask: 0.3341\n",
      "step:    29960, time: 0.779, loss: 1.2972, l1: 0.3255, vgg: 0.5465, mask: 0.4252\n",
      "step:    29980, time: 0.774, loss: 1.2758, l1: 0.2492, vgg: 0.6570, mask: 0.3696\n",
      "step:    30000, time: 0.749, loss: 1.3351, l1: 0.2773, vgg: 0.6439, mask: 0.4139\n",
      "step:    30020, time: 0.791, loss: 1.1880, l1: 0.2917, vgg: 0.4719, mask: 0.4244\n",
      "step:    30040, time: 0.761, loss: 1.1321, l1: 0.2200, vgg: 0.5243, mask: 0.3877\n",
      "step:    30060, time: 0.733, loss: 1.0665, l1: 0.1893, vgg: 0.5245, mask: 0.3527\n",
      "step:    30080, time: 0.737, loss: 1.0646, l1: 0.2009, vgg: 0.5099, mask: 0.3538\n",
      "step:    30100, time: 0.738, loss: 1.1803, l1: 0.2088, vgg: 0.6150, mask: 0.3565\n",
      "step:    30120, time: 0.740, loss: 1.0420, l1: 0.1571, vgg: 0.5526, mask: 0.3323\n",
      "step:    30140, time: 0.744, loss: 1.1435, l1: 0.2078, vgg: 0.5442, mask: 0.3916\n",
      "step:    30160, time: 0.691, loss: 1.0761, l1: 0.2098, vgg: 0.5185, mask: 0.3478\n",
      "step:    30180, time: 0.737, loss: 1.1088, l1: 0.1907, vgg: 0.5728, mask: 0.3453\n",
      "step:    30200, time: 0.761, loss: 1.1059, l1: 0.2047, vgg: 0.5050, mask: 0.3963\n",
      "step:    30220, time: 0.716, loss: 1.1919, l1: 0.2102, vgg: 0.6129, mask: 0.3688\n",
      "step:    30240, time: 0.780, loss: 1.2180, l1: 0.2155, vgg: 0.6095, mask: 0.3930\n",
      "step:    30260, time: 0.716, loss: 1.2235, l1: 0.2861, vgg: 0.5116, mask: 0.4258\n",
      "step:    30280, time: 0.744, loss: 1.0316, l1: 0.1867, vgg: 0.4991, mask: 0.3459\n",
      "step:    30300, time: 0.748, loss: 1.1664, l1: 0.2280, vgg: 0.5662, mask: 0.3722\n",
      "step:    30320, time: 0.783, loss: 1.2317, l1: 0.2614, vgg: 0.5627, mask: 0.4077\n",
      "step:    30340, time: 0.773, loss: 1.0760, l1: 0.2097, vgg: 0.5137, mask: 0.3526\n",
      "step:    30360, time: 0.768, loss: 1.0850, l1: 0.2176, vgg: 0.4912, mask: 0.3761\n",
      "step:    30380, time: 0.758, loss: 1.1186, l1: 0.2135, vgg: 0.5497, mask: 0.3555\n",
      "step:    30400, time: 0.701, loss: 1.1191, l1: 0.2382, vgg: 0.4967, mask: 0.3842\n",
      "step:    30420, time: 0.772, loss: 1.1315, l1: 0.2271, vgg: 0.5345, mask: 0.3700\n",
      "step:    30440, time: 0.734, loss: 1.1874, l1: 0.2371, vgg: 0.5545, mask: 0.3958\n",
      "step:    30460, time: 0.762, loss: 1.1979, l1: 0.2276, vgg: 0.5983, mask: 0.3720\n",
      "step:    30480, time: 0.740, loss: 1.0972, l1: 0.2141, vgg: 0.5149, mask: 0.3682\n",
      "step:    30500, time: 0.793, loss: 1.1493, l1: 0.2510, vgg: 0.5156, mask: 0.3826\n",
      "step:    30520, time: 0.827, loss: 1.1811, l1: 0.2329, vgg: 0.5859, mask: 0.3623\n",
      "step:    30540, time: 0.760, loss: 1.1317, l1: 0.2122, vgg: 0.5569, mask: 0.3626\n",
      "step:    30560, time: 0.753, loss: 1.1475, l1: 0.2437, vgg: 0.5157, mask: 0.3881\n",
      "step:    30580, time: 0.770, loss: 1.1120, l1: 0.2368, vgg: 0.4778, mask: 0.3974\n",
      "step:    30600, time: 0.790, loss: 1.2479, l1: 0.2656, vgg: 0.5336, mask: 0.4487\n",
      "step:    30620, time: 0.730, loss: 1.0629, l1: 0.1763, vgg: 0.5391, mask: 0.3474\n",
      "step:    30640, time: 0.714, loss: 1.0762, l1: 0.2182, vgg: 0.4841, mask: 0.3739\n",
      "step:    30660, time: 0.777, loss: 1.2853, l1: 0.2598, vgg: 0.6106, mask: 0.4149\n",
      "step:    30680, time: 0.772, loss: 1.2724, l1: 0.2925, vgg: 0.5941, mask: 0.3858\n",
      "step:    30700, time: 0.725, loss: 1.0396, l1: 0.1853, vgg: 0.4898, mask: 0.3645\n",
      "step:    30720, time: 0.780, loss: 1.1626, l1: 0.2198, vgg: 0.5684, mask: 0.3744\n",
      "step:    30740, time: 0.754, loss: 1.3397, l1: 0.2326, vgg: 0.7253, mask: 0.3817\n",
      "step:    30760, time: 0.745, loss: 1.1151, l1: 0.1909, vgg: 0.5690, mask: 0.3553\n",
      "step:    30780, time: 0.748, loss: 1.0519, l1: 0.1964, vgg: 0.4986, mask: 0.3569\n",
      "step:    30800, time: 0.800, loss: 1.1242, l1: 0.2307, vgg: 0.5263, mask: 0.3672\n",
      "step:    30820, time: 0.789, loss: 1.1648, l1: 0.2116, vgg: 0.5682, mask: 0.3850\n",
      "step:    30840, time: 0.714, loss: 1.0548, l1: 0.1873, vgg: 0.5092, mask: 0.3583\n",
      "step:    30860, time: 0.718, loss: 1.0525, l1: 0.2020, vgg: 0.5054, mask: 0.3450\n",
      "step:    30880, time: 0.764, loss: 1.1050, l1: 0.1976, vgg: 0.5344, mask: 0.3730\n",
      "step:    30900, time: 0.785, loss: 1.2031, l1: 0.2830, vgg: 0.5309, mask: 0.3892\n",
      "step:    30920, time: 0.756, loss: 1.1338, l1: 0.3013, vgg: 0.4528, mask: 0.3796\n",
      "step:    30940, time: 0.737, loss: 1.1785, l1: 0.2415, vgg: 0.5535, mask: 0.3835\n",
      "step:    30960, time: 0.807, loss: 1.0768, l1: 0.1986, vgg: 0.5351, mask: 0.3432\n",
      "step:    30980, time: 0.790, loss: 1.3216, l1: 0.3202, vgg: 0.5835, mask: 0.4179\n",
      "step:    31000, time: 0.769, loss: 1.2708, l1: 0.2393, vgg: 0.6426, mask: 0.3890\n",
      "step:    31020, time: 0.827, loss: 1.1927, l1: 0.2278, vgg: 0.6058, mask: 0.3592\n",
      "step:    31040, time: 0.743, loss: 1.2112, l1: 0.2579, vgg: 0.5482, mask: 0.4051\n",
      "step:    31060, time: 0.751, loss: 1.0354, l1: 0.1524, vgg: 0.4727, mask: 0.4104\n",
      "step:    31080, time: 0.725, loss: 1.0451, l1: 0.2098, vgg: 0.4816, mask: 0.3537\n",
      "step:    31100, time: 0.750, loss: 1.1433, l1: 0.2171, vgg: 0.5521, mask: 0.3741\n",
      "step:    31120, time: 0.761, loss: 1.0813, l1: 0.1980, vgg: 0.5558, mask: 0.3274\n",
      "step:    31140, time: 0.754, loss: 1.1587, l1: 0.2508, vgg: 0.5251, mask: 0.3828\n",
      "step:    31160, time: 0.752, loss: 1.1388, l1: 0.1958, vgg: 0.5568, mask: 0.3862\n",
      "step:    31180, time: 0.782, loss: 1.1620, l1: 0.2064, vgg: 0.5910, mask: 0.3645\n",
      "step:    31200, time: 0.781, loss: 1.2615, l1: 0.2515, vgg: 0.5703, mask: 0.4397\n",
      "step:    31220, time: 0.754, loss: 1.0836, l1: 0.2293, vgg: 0.5028, mask: 0.3515\n",
      "step:    31240, time: 0.813, loss: 1.0262, l1: 0.1631, vgg: 0.5175, mask: 0.3456\n",
      "step:    31260, time: 0.786, loss: 1.1368, l1: 0.2263, vgg: 0.5237, mask: 0.3868\n",
      "step:    31280, time: 0.746, loss: 1.1962, l1: 0.2477, vgg: 0.5699, mask: 0.3786\n",
      "step:    31300, time: 0.756, loss: 1.2455, l1: 0.2502, vgg: 0.5742, mask: 0.4211\n",
      "step:    31320, time: 0.759, loss: 1.0723, l1: 0.2024, vgg: 0.5212, mask: 0.3487\n",
      "step:    31340, time: 0.752, loss: 1.1390, l1: 0.2092, vgg: 0.5786, mask: 0.3512\n",
      "step:    31360, time: 0.787, loss: 1.3787, l1: 0.2671, vgg: 0.7261, mask: 0.3855\n",
      "step:    31380, time: 0.805, loss: 1.2223, l1: 0.2770, vgg: 0.5456, mask: 0.3998\n",
      "step:    31400, time: 0.761, loss: 1.2511, l1: 0.2849, vgg: 0.5745, mask: 0.3917\n",
      "step:    31420, time: 0.769, loss: 1.0688, l1: 0.2170, vgg: 0.5063, mask: 0.3455\n",
      "step:    31440, time: 0.765, loss: 1.2320, l1: 0.2351, vgg: 0.6154, mask: 0.3815\n",
      "step:    31460, time: 0.753, loss: 1.2610, l1: 0.2557, vgg: 0.6056, mask: 0.3997\n",
      "step:    31480, time: 0.769, loss: 1.1697, l1: 0.2194, vgg: 0.5642, mask: 0.3861\n",
      "step:    31500, time: 0.768, loss: 1.1803, l1: 0.2602, vgg: 0.5547, mask: 0.3654\n",
      "step:    31520, time: 0.770, loss: 1.1042, l1: 0.2048, vgg: 0.5347, mask: 0.3647\n",
      "step:    31540, time: 0.764, loss: 1.1353, l1: 0.1658, vgg: 0.5514, mask: 0.4181\n",
      "step:    31560, time: 0.852, loss: 1.2615, l1: 0.2476, vgg: 0.5887, mask: 0.4252\n",
      "step:    31580, time: 0.819, loss: 1.1571, l1: 0.2622, vgg: 0.5127, mask: 0.3821\n",
      "step:    31600, time: 0.775, loss: 1.0956, l1: 0.2019, vgg: 0.5369, mask: 0.3568\n",
      "step:    31620, time: 0.765, loss: 1.1313, l1: 0.2191, vgg: 0.5074, mask: 0.4047\n",
      "step:    31640, time: 0.835, loss: 1.2515, l1: 0.2607, vgg: 0.5949, mask: 0.3958\n",
      "step:    31660, time: 0.767, loss: 1.1364, l1: 0.2501, vgg: 0.5171, mask: 0.3692\n",
      "step:    31680, time: 0.739, loss: 1.0567, l1: 0.2036, vgg: 0.5050, mask: 0.3481\n",
      "step:    31700, time: 0.744, loss: 1.1622, l1: 0.2332, vgg: 0.5374, mask: 0.3915\n",
      "step:    31720, time: 0.694, loss: 1.0093, l1: 0.1581, vgg: 0.5217, mask: 0.3295\n",
      "step:    31740, time: 0.772, loss: 1.1901, l1: 0.1974, vgg: 0.5939, mask: 0.3988\n",
      "step:    31760, time: 0.743, loss: 1.0577, l1: 0.2067, vgg: 0.4752, mask: 0.3758\n",
      "step:    31780, time: 0.742, loss: 1.1062, l1: 0.2012, vgg: 0.5524, mask: 0.3525\n",
      "step:    31800, time: 0.754, loss: 1.1664, l1: 0.2242, vgg: 0.5871, mask: 0.3551\n",
      "step:    31820, time: 0.769, loss: 1.2312, l1: 0.2698, vgg: 0.5378, mask: 0.4236\n",
      "step:    31840, time: 0.734, loss: 1.0543, l1: 0.1965, vgg: 0.4825, mask: 0.3752\n",
      "step:    31860, time: 0.739, loss: 1.0666, l1: 0.1886, vgg: 0.5412, mask: 0.3368\n",
      "step:    31880, time: 0.768, loss: 1.1718, l1: 0.2476, vgg: 0.5554, mask: 0.3687\n",
      "step:    31900, time: 0.753, loss: 1.1679, l1: 0.2478, vgg: 0.5514, mask: 0.3687\n",
      "step:    31920, time: 0.743, loss: 1.1141, l1: 0.2349, vgg: 0.4928, mask: 0.3864\n",
      "step:    31940, time: 0.743, loss: 1.1349, l1: 0.2061, vgg: 0.5620, mask: 0.3668\n",
      "step:    31960, time: 0.742, loss: 1.0688, l1: 0.1911, vgg: 0.4917, mask: 0.3860\n",
      "step:    31980, time: 0.758, loss: 1.1636, l1: 0.2692, vgg: 0.5194, mask: 0.3750\n",
      "step:    32000, time: 0.716, loss: 1.2351, l1: 0.2640, vgg: 0.5541, mask: 0.4170\n",
      "step:    32020, time: 0.761, loss: 1.2024, l1: 0.2512, vgg: 0.5575, mask: 0.3937\n",
      "step:    32040, time: 0.763, loss: 1.1524, l1: 0.2138, vgg: 0.5674, mask: 0.3713\n",
      "step:    32060, time: 0.735, loss: 1.1695, l1: 0.2750, vgg: 0.5173, mask: 0.3772\n",
      "step:    32080, time: 0.711, loss: 0.9964, l1: 0.1790, vgg: 0.5047, mask: 0.3126\n",
      "step:    32100, time: 0.733, loss: 1.1333, l1: 0.2198, vgg: 0.5105, mask: 0.4030\n",
      "step:    32120, time: 0.807, loss: 1.2154, l1: 0.2455, vgg: 0.5973, mask: 0.3726\n",
      "step:    32140, time: 0.795, loss: 1.3233, l1: 0.2904, vgg: 0.6265, mask: 0.4064\n",
      "step:    32160, time: 0.766, loss: 1.0612, l1: 0.1774, vgg: 0.5377, mask: 0.3462\n",
      "step:    32180, time: 0.754, loss: 1.2056, l1: 0.2578, vgg: 0.5721, mask: 0.3756\n",
      "step:    32200, time: 0.773, loss: 1.1420, l1: 0.2074, vgg: 0.5566, mask: 0.3779\n",
      "step:    32220, time: 0.808, loss: 1.3063, l1: 0.3075, vgg: 0.5880, mask: 0.4109\n",
      "step:    32240, time: 0.751, loss: 1.2274, l1: 0.2120, vgg: 0.6204, mask: 0.3950\n",
      "step:    32260, time: 0.756, loss: 1.1378, l1: 0.2175, vgg: 0.5514, mask: 0.3689\n",
      "step:    32280, time: 0.758, loss: 1.1717, l1: 0.2428, vgg: 0.5641, mask: 0.3648\n",
      "step:    32300, time: 0.733, loss: 1.1982, l1: 0.2816, vgg: 0.5237, mask: 0.3928\n",
      "step:    32320, time: 0.753, loss: 1.0399, l1: 0.2040, vgg: 0.4807, mask: 0.3552\n",
      "step:    32340, time: 0.783, loss: 1.1537, l1: 0.2452, vgg: 0.5586, mask: 0.3499\n",
      "step:    32360, time: 0.760, loss: 1.1383, l1: 0.2283, vgg: 0.5169, mask: 0.3931\n",
      "step:    32380, time: 0.752, loss: 0.9946, l1: 0.1773, vgg: 0.4672, mask: 0.3501\n",
      "step:    32400, time: 0.800, loss: 1.2207, l1: 0.2908, vgg: 0.5629, mask: 0.3670\n",
      "step:    32420, time: 0.743, loss: 1.1008, l1: 0.2035, vgg: 0.5124, mask: 0.3849\n",
      "step:    32440, time: 0.768, loss: 1.0869, l1: 0.1917, vgg: 0.5379, mask: 0.3572\n",
      "step:    32460, time: 0.761, loss: 1.0541, l1: 0.1832, vgg: 0.5340, mask: 0.3369\n",
      "step:    32480, time: 0.742, loss: 1.1809, l1: 0.2441, vgg: 0.5653, mask: 0.3714\n",
      "step:    32500, time: 0.780, loss: 1.2538, l1: 0.2657, vgg: 0.5969, mask: 0.3913\n",
      "step:    32520, time: 0.750, loss: 1.1368, l1: 0.2288, vgg: 0.5486, mask: 0.3595\n",
      "step:    32540, time: 0.796, loss: 1.1062, l1: 0.2167, vgg: 0.5317, mask: 0.3578\n",
      "step:    32560, time: 0.748, loss: 1.1532, l1: 0.2447, vgg: 0.5328, mask: 0.3757\n",
      "step:    32580, time: 0.764, loss: 1.1657, l1: 0.2532, vgg: 0.5295, mask: 0.3830\n",
      "step:    32600, time: 0.757, loss: 1.1345, l1: 0.2309, vgg: 0.5376, mask: 0.3660\n",
      "step:    32620, time: 0.737, loss: 1.1171, l1: 0.2007, vgg: 0.5717, mask: 0.3446\n",
      "step:    32640, time: 0.743, loss: 1.1845, l1: 0.2216, vgg: 0.5870, mask: 0.3758\n",
      "step:    32660, time: 0.725, loss: 1.1470, l1: 0.1808, vgg: 0.5676, mask: 0.3986\n",
      "step:    32680, time: 0.759, loss: 1.2225, l1: 0.2935, vgg: 0.5571, mask: 0.3719\n",
      "step:    32700, time: 0.758, loss: 1.1562, l1: 0.2285, vgg: 0.5448, mask: 0.3829\n",
      "step:    32720, time: 0.777, loss: 1.0473, l1: 0.2005, vgg: 0.4842, mask: 0.3626\n",
      "step:    32740, time: 0.765, loss: 1.2203, l1: 0.2539, vgg: 0.5369, mask: 0.4295\n",
      "step:    32760, time: 0.734, loss: 1.1055, l1: 0.2087, vgg: 0.5228, mask: 0.3740\n",
      "step:    32780, time: 0.771, loss: 1.0166, l1: 0.1802, vgg: 0.4940, mask: 0.3425\n",
      "step:    32800, time: 0.742, loss: 1.1944, l1: 0.2382, vgg: 0.5383, mask: 0.4179\n",
      "step:    32820, time: 0.757, loss: 1.1719, l1: 0.2105, vgg: 0.5873, mask: 0.3741\n",
      "step:    32840, time: 0.782, loss: 1.0992, l1: 0.2133, vgg: 0.5381, mask: 0.3478\n",
      "step:    32860, time: 0.726, loss: 1.2237, l1: 0.2257, vgg: 0.5947, mask: 0.4033\n",
      "step:    32880, time: 0.761, loss: 1.1805, l1: 0.2454, vgg: 0.5324, mask: 0.4027\n",
      "step:    32900, time: 0.749, loss: 1.2186, l1: 0.2510, vgg: 0.5799, mask: 0.3876\n",
      "step:    32920, time: 0.732, loss: 1.0869, l1: 0.2049, vgg: 0.4734, mask: 0.4086\n",
      "step:    32940, time: 0.773, loss: 1.0956, l1: 0.2589, vgg: 0.4288, mask: 0.4079\n",
      "step:    32960, time: 0.781, loss: 1.1206, l1: 0.2259, vgg: 0.5341, mask: 0.3605\n",
      "step:    32980, time: 0.764, loss: 1.1871, l1: 0.2235, vgg: 0.5549, mask: 0.4087\n",
      "step:    33000, time: 0.725, loss: 1.2574, l1: 0.2383, vgg: 0.6264, mask: 0.3927\n",
      "step:    33020, time: 0.771, loss: 1.2300, l1: 0.2653, vgg: 0.5417, mask: 0.4230\n",
      "step:    33040, time: 0.745, loss: 1.0371, l1: 0.1802, vgg: 0.4645, mask: 0.3924\n",
      "step:    33060, time: 0.735, loss: 1.1190, l1: 0.1930, vgg: 0.5666, mask: 0.3594\n",
      "step:    33080, time: 0.787, loss: 1.0748, l1: 0.1955, vgg: 0.5160, mask: 0.3632\n",
      "step:    33100, time: 0.759, loss: 1.2144, l1: 0.2460, vgg: 0.5629, mask: 0.4055\n",
      "step:    33120, time: 0.768, loss: 1.1645, l1: 0.2150, vgg: 0.5647, mask: 0.3847\n",
      "step:    33140, time: 0.767, loss: 1.3195, l1: 0.3224, vgg: 0.5753, mask: 0.4218\n",
      "step:    33160, time: 0.733, loss: 1.1368, l1: 0.2524, vgg: 0.5001, mask: 0.3843\n",
      "step:    33180, time: 0.726, loss: 1.1073, l1: 0.2212, vgg: 0.5353, mask: 0.3508\n",
      "step:    33200, time: 0.765, loss: 1.0710, l1: 0.2287, vgg: 0.4634, mask: 0.3789\n",
      "step:    33220, time: 0.769, loss: 1.1537, l1: 0.2173, vgg: 0.5921, mask: 0.3443\n",
      "step:    33240, time: 0.787, loss: 1.1737, l1: 0.2238, vgg: 0.5571, mask: 0.3928\n",
      "step:    33260, time: 0.752, loss: 1.0863, l1: 0.2093, vgg: 0.5230, mask: 0.3540\n",
      "step:    33280, time: 0.768, loss: 1.1781, l1: 0.2545, vgg: 0.5182, mask: 0.4054\n",
      "step:    33300, time: 0.803, loss: 1.1882, l1: 0.2354, vgg: 0.5871, mask: 0.3656\n",
      "step:    33320, time: 0.724, loss: 1.1238, l1: 0.2176, vgg: 0.5025, mask: 0.4038\n",
      "step:    33340, time: 0.786, loss: 1.2398, l1: 0.2583, vgg: 0.6038, mask: 0.3778\n",
      "step:    33360, time: 0.743, loss: 1.0387, l1: 0.1569, vgg: 0.4842, mask: 0.3975\n",
      "step:    33380, time: 0.737, loss: 1.1682, l1: 0.2399, vgg: 0.5585, mask: 0.3698\n",
      "step:    33400, time: 0.750, loss: 1.1094, l1: 0.2182, vgg: 0.4988, mask: 0.3924\n",
      "step:    33420, time: 0.763, loss: 1.1348, l1: 0.2331, vgg: 0.5176, mask: 0.3840\n",
      "step:    33440, time: 0.751, loss: 1.1948, l1: 0.2273, vgg: 0.5536, mask: 0.4139\n",
      "step:    33460, time: 0.776, loss: 1.1928, l1: 0.2282, vgg: 0.5861, mask: 0.3786\n",
      "step:    33480, time: 0.728, loss: 1.1360, l1: 0.2225, vgg: 0.5371, mask: 0.3765\n",
      "step:    33500, time: 0.785, loss: 1.2125, l1: 0.2532, vgg: 0.5531, mask: 0.4061\n",
      "step:    33520, time: 0.801, loss: 1.2173, l1: 0.2338, vgg: 0.5960, mask: 0.3875\n",
      "step:    33540, time: 0.740, loss: 1.1537, l1: 0.2482, vgg: 0.5391, mask: 0.3664\n",
      "step:    33560, time: 0.773, loss: 1.1927, l1: 0.2419, vgg: 0.5725, mask: 0.3782\n",
      "step:    33580, time: 0.723, loss: 1.0499, l1: 0.1844, vgg: 0.5096, mask: 0.3559\n",
      "step:    33600, time: 0.708, loss: 0.9932, l1: 0.1869, vgg: 0.4597, mask: 0.3466\n",
      "step:    33620, time: 0.755, loss: 1.2451, l1: 0.2735, vgg: 0.5855, mask: 0.3861\n",
      "step:    33640, time: 0.775, loss: 1.2570, l1: 0.2773, vgg: 0.5750, mask: 0.4047\n",
      "step:    33660, time: 0.730, loss: 1.0934, l1: 0.2025, vgg: 0.5081, mask: 0.3828\n",
      "step:    33680, time: 0.764, loss: 1.3192, l1: 0.2626, vgg: 0.6564, mask: 0.4002\n",
      "step:    33700, time: 0.719, loss: 1.1153, l1: 0.2621, vgg: 0.4542, mask: 0.3990\n",
      "step:    33720, time: 0.791, loss: 1.1087, l1: 0.1986, vgg: 0.5639, mask: 0.3462\n",
      "step:    33740, time: 0.740, loss: 1.1166, l1: 0.2513, vgg: 0.4653, mask: 0.4000\n",
      "step:    33760, time: 0.745, loss: 1.0025, l1: 0.1856, vgg: 0.4777, mask: 0.3392\n",
      "step:    33780, time: 0.796, loss: 1.2171, l1: 0.2566, vgg: 0.5645, mask: 0.3960\n",
      "step:    33800, time: 0.817, loss: 1.2086, l1: 0.2554, vgg: 0.5574, mask: 0.3958\n",
      "step:    33820, time: 0.748, loss: 1.0903, l1: 0.2229, vgg: 0.4993, mask: 0.3681\n",
      "step:    33840, time: 0.768, loss: 1.2084, l1: 0.2275, vgg: 0.5941, mask: 0.3867\n",
      "step:    33860, time: 0.720, loss: 1.0902, l1: 0.2154, vgg: 0.5140, mask: 0.3609\n",
      "step:    33880, time: 0.747, loss: 1.0216, l1: 0.1787, vgg: 0.5177, mask: 0.3253\n",
      "step:    33900, time: 0.796, loss: 1.1567, l1: 0.2192, vgg: 0.5553, mask: 0.3822\n",
      "step:    33920, time: 0.738, loss: 1.2927, l1: 0.3133, vgg: 0.5655, mask: 0.4139\n",
      "step:    33940, time: 0.728, loss: 1.2171, l1: 0.2542, vgg: 0.5508, mask: 0.4120\n",
      "step:    33960, time: 0.739, loss: 1.0381, l1: 0.1869, vgg: 0.4984, mask: 0.3528\n",
      "step:    33980, time: 0.770, loss: 1.0518, l1: 0.2150, vgg: 0.4668, mask: 0.3700\n",
      "step:    34000, time: 0.753, loss: 1.1608, l1: 0.2580, vgg: 0.5307, mask: 0.3722\n",
      "step:    34020, time: 0.770, loss: 1.1193, l1: 0.2313, vgg: 0.5108, mask: 0.3771\n",
      "step:    34040, time: 0.785, loss: 1.1771, l1: 0.2173, vgg: 0.5987, mask: 0.3612\n",
      "step:    34060, time: 0.785, loss: 1.2559, l1: 0.2443, vgg: 0.6233, mask: 0.3883\n",
      "step:    34080, time: 0.757, loss: 1.1702, l1: 0.2690, vgg: 0.5127, mask: 0.3886\n",
      "step:    34100, time: 0.738, loss: 1.0847, l1: 0.1970, vgg: 0.5330, mask: 0.3548\n",
      "step:    34120, time: 0.732, loss: 1.1776, l1: 0.2273, vgg: 0.5838, mask: 0.3666\n",
      "step:    34140, time: 0.781, loss: 1.2391, l1: 0.2573, vgg: 0.5849, mask: 0.3969\n",
      "step:    34160, time: 0.757, loss: 1.0805, l1: 0.1831, vgg: 0.5524, mask: 0.3450\n",
      "step:    34180, time: 0.728, loss: 0.9592, l1: 0.1565, vgg: 0.4617, mask: 0.3410\n",
      "step:    34200, time: 0.787, loss: 1.0510, l1: 0.2250, vgg: 0.4489, mask: 0.3770\n",
      "step:    34220, time: 0.745, loss: 1.0093, l1: 0.1660, vgg: 0.5061, mask: 0.3372\n",
      "step:    34240, time: 0.731, loss: 1.1778, l1: 0.2419, vgg: 0.5362, mask: 0.3996\n",
      "step:    34260, time: 0.750, loss: 1.2282, l1: 0.2864, vgg: 0.5410, mask: 0.4008\n",
      "step:    34280, time: 0.777, loss: 1.0681, l1: 0.2036, vgg: 0.5391, mask: 0.3253\n",
      "step:    34300, time: 0.768, loss: 1.0030, l1: 0.1675, vgg: 0.4993, mask: 0.3362\n",
      "step:    34320, time: 0.716, loss: 1.1353, l1: 0.1893, vgg: 0.5694, mask: 0.3767\n",
      "step:    34340, time: 0.779, loss: 1.3110, l1: 0.2707, vgg: 0.6379, mask: 0.4025\n",
      "step:    34360, time: 0.763, loss: 1.1430, l1: 0.2121, vgg: 0.5734, mask: 0.3574\n",
      "step:    34380, time: 0.803, loss: 1.2737, l1: 0.2319, vgg: 0.6335, mask: 0.4083\n",
      "step:    34400, time: 0.744, loss: 1.1768, l1: 0.2496, vgg: 0.5649, mask: 0.3623\n",
      "step:    34420, time: 0.748, loss: 1.1205, l1: 0.1920, vgg: 0.5340, mask: 0.3945\n",
      "step:    34440, time: 0.777, loss: 1.1009, l1: 0.2261, vgg: 0.4984, mask: 0.3764\n",
      "step:    34460, time: 0.813, loss: 1.2476, l1: 0.2180, vgg: 0.6183, mask: 0.4113\n",
      "step:    34480, time: 0.786, loss: 1.1818, l1: 0.2517, vgg: 0.5580, mask: 0.3722\n",
      "step:    34500, time: 0.757, loss: 1.1177, l1: 0.1779, vgg: 0.5187, mask: 0.4211\n",
      "step:    34520, time: 0.794, loss: 1.0498, l1: 0.1959, vgg: 0.4834, mask: 0.3704\n",
      "step:    34540, time: 0.761, loss: 1.2536, l1: 0.2360, vgg: 0.6370, mask: 0.3806\n",
      "step:    34560, time: 0.764, loss: 1.2549, l1: 0.2782, vgg: 0.5592, mask: 0.4174\n",
      "step:    34580, time: 0.750, loss: 1.1743, l1: 0.2521, vgg: 0.5491, mask: 0.3730\n",
      "step:    34600, time: 0.780, loss: 1.0670, l1: 0.1949, vgg: 0.5318, mask: 0.3403\n",
      "step:    34620, time: 0.769, loss: 1.1574, l1: 0.2381, vgg: 0.5684, mask: 0.3509\n",
      "step:    34640, time: 0.757, loss: 1.0328, l1: 0.1987, vgg: 0.4789, mask: 0.3553\n",
      "step:    34660, time: 0.777, loss: 1.0988, l1: 0.2357, vgg: 0.4910, mask: 0.3720\n",
      "step:    34680, time: 0.742, loss: 1.2009, l1: 0.2578, vgg: 0.5673, mask: 0.3757\n",
      "step:    34700, time: 0.752, loss: 1.2222, l1: 0.2707, vgg: 0.5928, mask: 0.3587\n",
      "step:    34720, time: 0.751, loss: 1.1320, l1: 0.1987, vgg: 0.5870, mask: 0.3464\n",
      "step:    34740, time: 0.772, loss: 1.0862, l1: 0.2131, vgg: 0.5288, mask: 0.3444\n",
      "step:    34760, time: 0.740, loss: 1.1739, l1: 0.2190, vgg: 0.5697, mask: 0.3852\n",
      "step:    34780, time: 0.765, loss: 1.0591, l1: 0.1897, vgg: 0.5214, mask: 0.3480\n",
      "step:    34800, time: 0.747, loss: 1.1527, l1: 0.2357, vgg: 0.5535, mask: 0.3635\n",
      "step:    34820, time: 0.752, loss: 1.2617, l1: 0.2221, vgg: 0.6691, mask: 0.3705\n",
      "step:    34840, time: 0.753, loss: 1.1398, l1: 0.1820, vgg: 0.6061, mask: 0.3517\n",
      "step:    34860, time: 0.770, loss: 1.1750, l1: 0.2339, vgg: 0.5774, mask: 0.3637\n",
      "step:    34880, time: 0.757, loss: 1.1134, l1: 0.2206, vgg: 0.5148, mask: 0.3780\n",
      "step:    34900, time: 0.771, loss: 1.2210, l1: 0.2377, vgg: 0.5704, mask: 0.4130\n",
      "step:    34920, time: 0.769, loss: 1.0866, l1: 0.1966, vgg: 0.5230, mask: 0.3670\n",
      "step:    34940, time: 0.768, loss: 1.1163, l1: 0.2201, vgg: 0.5215, mask: 0.3747\n",
      "step:    34960, time: 0.758, loss: 1.0282, l1: 0.2094, vgg: 0.4757, mask: 0.3432\n",
      "step:    34980, time: 0.800, loss: 1.1328, l1: 0.2058, vgg: 0.5263, mask: 0.4007\n",
      "step:    35000, time: 0.765, loss: 1.1801, l1: 0.2596, vgg: 0.5590, mask: 0.3614\n",
      "step:    35020, time: 0.724, loss: 1.0091, l1: 0.1754, vgg: 0.4825, mask: 0.3512\n",
      "step:    35040, time: 0.765, loss: 1.1912, l1: 0.2065, vgg: 0.5999, mask: 0.3848\n",
      "step:    35060, time: 0.738, loss: 1.1386, l1: 0.2449, vgg: 0.5399, mask: 0.3538\n",
      "step:    35080, time: 0.757, loss: 1.1433, l1: 0.2000, vgg: 0.5813, mask: 0.3620\n",
      "step:    35100, time: 0.767, loss: 1.0741, l1: 0.2015, vgg: 0.5078, mask: 0.3648\n",
      "step:    35120, time: 0.742, loss: 1.1333, l1: 0.2698, vgg: 0.4724, mask: 0.3910\n",
      "step:    35140, time: 0.758, loss: 1.2116, l1: 0.2591, vgg: 0.5567, mask: 0.3958\n",
      "step:    35160, time: 0.753, loss: 1.2527, l1: 0.2586, vgg: 0.6280, mask: 0.3661\n",
      "step:    35180, time: 0.767, loss: 1.2201, l1: 0.2641, vgg: 0.5502, mask: 0.4058\n",
      "step:    35200, time: 0.756, loss: 1.1017, l1: 0.1996, vgg: 0.5192, mask: 0.3829\n",
      "step:    35220, time: 0.771, loss: 1.2161, l1: 0.2938, vgg: 0.5347, mask: 0.3877\n",
      "step:    35240, time: 0.787, loss: 1.1651, l1: 0.2147, vgg: 0.5903, mask: 0.3601\n",
      "step:    35260, time: 0.742, loss: 1.0984, l1: 0.1999, vgg: 0.5392, mask: 0.3593\n",
      "step:    35280, time: 0.783, loss: 1.1759, l1: 0.2295, vgg: 0.5721, mask: 0.3742\n",
      "step:    35300, time: 0.740, loss: 1.1775, l1: 0.2604, vgg: 0.4981, mask: 0.4190\n",
      "step:    35320, time: 0.763, loss: 1.2016, l1: 0.2506, vgg: 0.5667, mask: 0.3842\n",
      "step:    35340, time: 0.786, loss: 1.2441, l1: 0.2664, vgg: 0.6141, mask: 0.3636\n",
      "step:    35360, time: 0.734, loss: 1.1957, l1: 0.2519, vgg: 0.5609, mask: 0.3829\n",
      "step:    35380, time: 0.799, loss: 1.1433, l1: 0.2113, vgg: 0.5783, mask: 0.3538\n",
      "step:    35400, time: 0.730, loss: 1.0519, l1: 0.1855, vgg: 0.4949, mask: 0.3714\n",
      "step:    35420, time: 0.762, loss: 1.0884, l1: 0.1898, vgg: 0.5579, mask: 0.3407\n",
      "step:    35440, time: 0.739, loss: 1.1665, l1: 0.2501, vgg: 0.5692, mask: 0.3471\n",
      "step:    35460, time: 0.731, loss: 1.2215, l1: 0.2961, vgg: 0.5217, mask: 0.4036\n",
      "step:    35480, time: 0.743, loss: 1.0909, l1: 0.2094, vgg: 0.5131, mask: 0.3685\n",
      "step:    35500, time: 0.724, loss: 1.0542, l1: 0.2242, vgg: 0.4535, mask: 0.3765\n",
      "step:    35520, time: 0.770, loss: 1.1147, l1: 0.2213, vgg: 0.5097, mask: 0.3836\n",
      "step:    35540, time: 0.733, loss: 1.1609, l1: 0.2495, vgg: 0.5508, mask: 0.3606\n",
      "step:    35560, time: 0.311, loss: 0.8806, l1: 0.1374, vgg: 0.4041, mask: 0.3391\n",
      "step:    35580, time: 0.739, loss: 1.1073, l1: 0.2016, vgg: 0.5690, mask: 0.3367\n",
      "step:    35600, time: 0.758, loss: 1.0538, l1: 0.2092, vgg: 0.4556, mask: 0.3890\n",
      "step:    35620, time: 0.740, loss: 0.9739, l1: 0.1658, vgg: 0.4509, mask: 0.3573\n",
      "step:    35640, time: 0.799, loss: 1.0807, l1: 0.2193, vgg: 0.4668, mask: 0.3946\n",
      "step:    35660, time: 0.743, loss: 1.1374, l1: 0.2352, vgg: 0.5260, mask: 0.3761\n",
      "step:    35680, time: 0.753, loss: 1.0195, l1: 0.1534, vgg: 0.5292, mask: 0.3368\n",
      "step:    35700, time: 0.769, loss: 1.1184, l1: 0.2166, vgg: 0.5448, mask: 0.3570\n",
      "step:    35720, time: 0.767, loss: 1.1630, l1: 0.2462, vgg: 0.5439, mask: 0.3729\n",
      "step:    35740, time: 0.753, loss: 1.1622, l1: 0.2668, vgg: 0.4917, mask: 0.4037\n",
      "step:    35760, time: 0.802, loss: 1.2638, l1: 0.2728, vgg: 0.5604, mask: 0.4305\n",
      "step:    35780, time: 0.757, loss: 1.1695, l1: 0.2374, vgg: 0.5577, mask: 0.3744\n",
      "step:    35800, time: 0.733, loss: 1.1261, l1: 0.2351, vgg: 0.5156, mask: 0.3754\n",
      "step:    35820, time: 0.768, loss: 1.1205, l1: 0.2044, vgg: 0.5345, mask: 0.3817\n",
      "step:    35840, time: 0.754, loss: 1.1450, l1: 0.2508, vgg: 0.5214, mask: 0.3728\n",
      "step:    35860, time: 0.753, loss: 1.2792, l1: 0.2559, vgg: 0.6311, mask: 0.3922\n",
      "step:    35880, time: 0.802, loss: 1.0680, l1: 0.1895, vgg: 0.5348, mask: 0.3437\n",
      "step:    35900, time: 0.755, loss: 1.1864, l1: 0.2552, vgg: 0.5295, mask: 0.4016\n",
      "step:    35920, time: 0.765, loss: 1.1428, l1: 0.2403, vgg: 0.5249, mask: 0.3776\n",
      "step:    35940, time: 0.728, loss: 1.0947, l1: 0.2207, vgg: 0.4863, mask: 0.3877\n",
      "step:    35960, time: 0.762, loss: 1.2709, l1: 0.2637, vgg: 0.6208, mask: 0.3863\n",
      "step:    35980, time: 0.774, loss: 1.1932, l1: 0.2621, vgg: 0.5427, mask: 0.3884\n",
      "step:    36000, time: 0.741, loss: 1.0991, l1: 0.2248, vgg: 0.5054, mask: 0.3689\n",
      "step:    36020, time: 0.723, loss: 1.0275, l1: 0.1759, vgg: 0.4596, mask: 0.3921\n",
      "step:    36040, time: 0.764, loss: 1.1904, l1: 0.2227, vgg: 0.5998, mask: 0.3679\n",
      "step:    36060, time: 0.773, loss: 1.1005, l1: 0.2310, vgg: 0.4521, mask: 0.4174\n",
      "step:    36080, time: 0.760, loss: 1.1618, l1: 0.2101, vgg: 0.5847, mask: 0.3669\n",
      "step:    36100, time: 0.727, loss: 1.0149, l1: 0.1871, vgg: 0.4816, mask: 0.3463\n",
      "step:    36120, time: 0.772, loss: 1.1102, l1: 0.1935, vgg: 0.5459, mask: 0.3708\n",
      "step:    36140, time: 0.766, loss: 1.0052, l1: 0.1851, vgg: 0.4842, mask: 0.3359\n",
      "step:    36160, time: 0.754, loss: 1.2308, l1: 0.2493, vgg: 0.5903, mask: 0.3912\n",
      "step:    36180, time: 0.782, loss: 1.1462, l1: 0.2408, vgg: 0.5150, mask: 0.3904\n",
      "step:    36200, time: 0.736, loss: 1.0810, l1: 0.1977, vgg: 0.5351, mask: 0.3482\n",
      "step:    36220, time: 0.785, loss: 1.2128, l1: 0.2151, vgg: 0.5863, mask: 0.4114\n",
      "step:    36240, time: 0.742, loss: 1.2293, l1: 0.2606, vgg: 0.5468, mask: 0.4219\n",
      "step:    36260, time: 0.775, loss: 1.2622, l1: 0.2515, vgg: 0.6384, mask: 0.3723\n",
      "step:    36280, time: 0.732, loss: 1.1965, l1: 0.2874, vgg: 0.5249, mask: 0.3841\n",
      "step:    36300, time: 0.781, loss: 1.1668, l1: 0.2305, vgg: 0.5967, mask: 0.3395\n",
      "step:    36320, time: 0.871, loss: 1.1705, l1: 0.1978, vgg: 0.6092, mask: 0.3635\n",
      "step:    36340, time: 0.776, loss: 1.1542, l1: 0.3012, vgg: 0.4903, mask: 0.3626\n",
      "step:    36360, time: 0.813, loss: 1.1111, l1: 0.2535, vgg: 0.5019, mask: 0.3557\n",
      "step:    36380, time: 0.778, loss: 1.1159, l1: 0.2136, vgg: 0.5631, mask: 0.3392\n",
      "step:    36400, time: 0.785, loss: 1.2315, l1: 0.2497, vgg: 0.5778, mask: 0.4040\n",
      "step:    36420, time: 0.817, loss: 1.1188, l1: 0.2360, vgg: 0.4811, mask: 0.4017\n",
      "step:    36440, time: 0.769, loss: 1.1374, l1: 0.2272, vgg: 0.5416, mask: 0.3687\n",
      "step:    36460, time: 0.769, loss: 1.1322, l1: 0.2260, vgg: 0.5239, mask: 0.3823\n",
      "step:    36480, time: 0.766, loss: 1.1190, l1: 0.2625, vgg: 0.4895, mask: 0.3670\n",
      "step:    36500, time: 0.775, loss: 1.2358, l1: 0.2562, vgg: 0.5794, mask: 0.4002\n",
      "step:    36520, time: 0.792, loss: 1.0726, l1: 0.1959, vgg: 0.5265, mask: 0.3502\n",
      "step:    36540, time: 0.767, loss: 1.0793, l1: 0.1951, vgg: 0.5423, mask: 0.3419\n",
      "step:    36560, time: 0.767, loss: 1.1734, l1: 0.2489, vgg: 0.5426, mask: 0.3819\n",
      "step:    36580, time: 0.757, loss: 1.0577, l1: 0.1848, vgg: 0.5405, mask: 0.3324\n",
      "step:    36600, time: 0.759, loss: 1.1466, l1: 0.2043, vgg: 0.5756, mask: 0.3667\n",
      "step:    36620, time: 0.824, loss: 1.1695, l1: 0.2291, vgg: 0.5582, mask: 0.3821\n",
      "step:    36640, time: 0.770, loss: 1.1288, l1: 0.2225, vgg: 0.5365, mask: 0.3697\n",
      "step:    36660, time: 0.828, loss: 1.1768, l1: 0.2563, vgg: 0.5259, mask: 0.3946\n",
      "step:    36680, time: 0.727, loss: 1.1726, l1: 0.2708, vgg: 0.5132, mask: 0.3886\n",
      "step:    36700, time: 0.754, loss: 1.0744, l1: 0.2093, vgg: 0.4885, mask: 0.3766\n",
      "step:    36720, time: 0.787, loss: 1.2517, l1: 0.2630, vgg: 0.5859, mask: 0.4028\n",
      "step:    36740, time: 0.802, loss: 1.3635, l1: 0.2186, vgg: 0.7505, mask: 0.3944\n",
      "step:    36760, time: 0.724, loss: 1.0909, l1: 0.2348, vgg: 0.5072, mask: 0.3489\n",
      "step:    36780, time: 0.730, loss: 1.1281, l1: 0.2042, vgg: 0.5482, mask: 0.3757\n",
      "step:    36800, time: 0.775, loss: 0.9847, l1: 0.1641, vgg: 0.4935, mask: 0.3272\n",
      "step:    36820, time: 0.777, loss: 1.1580, l1: 0.2444, vgg: 0.5231, mask: 0.3905\n",
      "step:    36840, time: 0.746, loss: 1.0127, l1: 0.2018, vgg: 0.4702, mask: 0.3407\n",
      "step:    36860, time: 0.794, loss: 1.1138, l1: 0.2312, vgg: 0.5069, mask: 0.3758\n",
      "step:    36880, time: 0.740, loss: 1.0774, l1: 0.2248, vgg: 0.4737, mask: 0.3789\n",
      "step:    36900, time: 0.759, loss: 1.1512, l1: 0.2276, vgg: 0.5556, mask: 0.3680\n",
      "step:    36920, time: 0.748, loss: 1.1395, l1: 0.2249, vgg: 0.5402, mask: 0.3744\n",
      "step:    36940, time: 0.784, loss: 1.2569, l1: 0.2532, vgg: 0.6083, mask: 0.3955\n",
      "step:    36960, time: 0.770, loss: 1.1526, l1: 0.2061, vgg: 0.5783, mask: 0.3682\n",
      "step:    36980, time: 0.778, loss: 1.1409, l1: 0.2492, vgg: 0.5324, mask: 0.3593\n",
      "step:    37000, time: 0.765, loss: 1.0860, l1: 0.2462, vgg: 0.4639, mask: 0.3758\n",
      "step:    37020, time: 0.770, loss: 1.1868, l1: 0.2285, vgg: 0.5905, mask: 0.3678\n",
      "step:    37040, time: 0.776, loss: 1.0971, l1: 0.2306, vgg: 0.5060, mask: 0.3605\n",
      "step:    37060, time: 0.750, loss: 1.1074, l1: 0.1714, vgg: 0.5880, mask: 0.3479\n",
      "step:    37080, time: 0.805, loss: 1.2176, l1: 0.2468, vgg: 0.6078, mask: 0.3631\n",
      "step:    37100, time: 0.774, loss: 1.1878, l1: 0.2428, vgg: 0.5126, mask: 0.4323\n",
      "step:    37120, time: 0.774, loss: 1.0716, l1: 0.1825, vgg: 0.5026, mask: 0.3865\n",
      "step:    37140, time: 0.758, loss: 1.0189, l1: 0.1828, vgg: 0.4970, mask: 0.3391\n",
      "step:    37160, time: 0.754, loss: 1.0887, l1: 0.1772, vgg: 0.4943, mask: 0.4173\n",
      "step:    37180, time: 0.756, loss: 1.1705, l1: 0.2200, vgg: 0.6059, mask: 0.3447\n",
      "step:    37200, time: 0.747, loss: 1.1677, l1: 0.2447, vgg: 0.5351, mask: 0.3879\n",
      "step:    37220, time: 0.726, loss: 1.1610, l1: 0.2472, vgg: 0.5440, mask: 0.3699\n",
      "step:    37240, time: 0.780, loss: 1.2180, l1: 0.2562, vgg: 0.5726, mask: 0.3891\n",
      "step:    37260, time: 0.746, loss: 1.2221, l1: 0.2349, vgg: 0.6018, mask: 0.3854\n",
      "step:    37280, time: 0.753, loss: 1.0920, l1: 0.1979, vgg: 0.5186, mask: 0.3755\n",
      "step:    37300, time: 0.755, loss: 1.0711, l1: 0.1958, vgg: 0.5304, mask: 0.3449\n",
      "step:    37320, time: 0.779, loss: 1.1465, l1: 0.2482, vgg: 0.5202, mask: 0.3781\n",
      "step:    37340, time: 0.792, loss: 1.1343, l1: 0.2872, vgg: 0.4751, mask: 0.3719\n",
      "step:    37360, time: 0.757, loss: 1.2673, l1: 0.2533, vgg: 0.6243, mask: 0.3898\n",
      "step:    37380, time: 0.763, loss: 1.0841, l1: 0.1789, vgg: 0.5522, mask: 0.3530\n",
      "step:    37400, time: 0.725, loss: 1.0922, l1: 0.2016, vgg: 0.5178, mask: 0.3728\n",
      "step:    37420, time: 0.777, loss: 1.2417, l1: 0.2430, vgg: 0.6327, mask: 0.3660\n",
      "step:    37440, time: 0.758, loss: 1.0795, l1: 0.1839, vgg: 0.5438, mask: 0.3518\n",
      "step:    37460, time: 0.818, loss: 1.2466, l1: 0.2087, vgg: 0.6548, mask: 0.3831\n",
      "step:    37480, time: 0.729, loss: 1.0549, l1: 0.2059, vgg: 0.5003, mask: 0.3488\n",
      "step:    37500, time: 0.750, loss: 1.1131, l1: 0.1983, vgg: 0.5417, mask: 0.3731\n",
      "step:    37520, time: 0.717, loss: 0.9691, l1: 0.1743, vgg: 0.4562, mask: 0.3386\n",
      "step:    37540, time: 0.751, loss: 1.0521, l1: 0.1864, vgg: 0.4808, mask: 0.3849\n",
      "step:    37560, time: 0.805, loss: 1.1167, l1: 0.1980, vgg: 0.5849, mask: 0.3338\n",
      "step:    37580, time: 0.726, loss: 1.0057, l1: 0.1801, vgg: 0.5020, mask: 0.3237\n",
      "step:    37600, time: 0.792, loss: 1.0305, l1: 0.1753, vgg: 0.4984, mask: 0.3568\n",
      "step:    37620, time: 0.721, loss: 1.2586, l1: 0.2623, vgg: 0.5948, mask: 0.4015\n",
      "step:    37640, time: 0.749, loss: 1.1292, l1: 0.2097, vgg: 0.5618, mask: 0.3577\n",
      "step:    37660, time: 0.776, loss: 1.2058, l1: 0.2319, vgg: 0.6060, mask: 0.3679\n",
      "step:    37680, time: 0.780, loss: 1.0803, l1: 0.1850, vgg: 0.5399, mask: 0.3554\n",
      "step:    37700, time: 0.766, loss: 1.2000, l1: 0.2515, vgg: 0.5597, mask: 0.3888\n",
      "step:    37720, time: 0.726, loss: 1.0330, l1: 0.1774, vgg: 0.5107, mask: 0.3449\n",
      "step:    37740, time: 0.714, loss: 1.0475, l1: 0.1931, vgg: 0.4988, mask: 0.3556\n",
      "step:    37760, time: 0.786, loss: 1.2864, l1: 0.2894, vgg: 0.5908, mask: 0.4062\n",
      "step:    37780, time: 0.771, loss: 1.1152, l1: 0.1937, vgg: 0.5553, mask: 0.3663\n",
      "step:    37800, time: 0.769, loss: 1.1181, l1: 0.2049, vgg: 0.5741, mask: 0.3391\n",
      "step:    37820, time: 0.814, loss: 1.1486, l1: 0.2283, vgg: 0.5701, mask: 0.3502\n",
      "step:    37840, time: 0.770, loss: 1.0680, l1: 0.2225, vgg: 0.4768, mask: 0.3686\n",
      "step:    37860, time: 0.758, loss: 1.0922, l1: 0.1943, vgg: 0.5337, mask: 0.3643\n",
      "step:    37880, time: 0.771, loss: 1.2563, l1: 0.2623, vgg: 0.5859, mask: 0.4081\n",
      "step:    37900, time: 0.763, loss: 1.1447, l1: 0.2273, vgg: 0.5324, mask: 0.3850\n",
      "step:    37920, time: 0.768, loss: 1.1120, l1: 0.2076, vgg: 0.5338, mask: 0.3706\n",
      "step:    37940, time: 0.792, loss: 1.0908, l1: 0.2393, vgg: 0.4791, mask: 0.3725\n",
      "step:    37960, time: 0.784, loss: 1.1823, l1: 0.2412, vgg: 0.5778, mask: 0.3634\n",
      "step:    37980, time: 0.757, loss: 1.1269, l1: 0.2173, vgg: 0.5338, mask: 0.3758\n",
      "step:    38000, time: 0.767, loss: 1.0926, l1: 0.2186, vgg: 0.4797, mask: 0.3943\n",
      "step:    38020, time: 0.778, loss: 1.0326, l1: 0.1769, vgg: 0.5077, mask: 0.3481\n",
      "step:    38040, time: 0.775, loss: 1.1556, l1: 0.2214, vgg: 0.5514, mask: 0.3828\n",
      "step:    38060, time: 0.775, loss: 1.1474, l1: 0.2329, vgg: 0.5457, mask: 0.3688\n",
      "step:    38080, time: 0.758, loss: 1.0634, l1: 0.1683, vgg: 0.5331, mask: 0.3620\n",
      "step:    38100, time: 0.832, loss: 1.1971, l1: 0.2501, vgg: 0.5825, mask: 0.3645\n",
      "step:    38120, time: 0.743, loss: 1.0151, l1: 0.1933, vgg: 0.4473, mask: 0.3745\n",
      "step:    38140, time: 0.788, loss: 1.2116, l1: 0.2416, vgg: 0.5874, mask: 0.3826\n",
      "step:    38160, time: 0.792, loss: 1.1938, l1: 0.2790, vgg: 0.5482, mask: 0.3667\n",
      "step:    38180, time: 0.766, loss: 1.1949, l1: 0.2791, vgg: 0.5166, mask: 0.3992\n",
      "step:    38200, time: 0.824, loss: 1.1546, l1: 0.2125, vgg: 0.5538, mask: 0.3883\n",
      "step:    38220, time: 0.764, loss: 1.0453, l1: 0.2008, vgg: 0.4869, mask: 0.3576\n",
      "step:    38240, time: 0.754, loss: 1.1203, l1: 0.2408, vgg: 0.5126, mask: 0.3669\n",
      "step:    38260, time: 0.788, loss: 1.0384, l1: 0.1977, vgg: 0.4845, mask: 0.3561\n",
      "step:    38280, time: 0.783, loss: 1.1854, l1: 0.2345, vgg: 0.5690, mask: 0.3819\n",
      "step:    38300, time: 0.742, loss: 1.0649, l1: 0.1954, vgg: 0.5206, mask: 0.3489\n",
      "step:    38320, time: 0.769, loss: 1.1827, l1: 0.2336, vgg: 0.5765, mask: 0.3726\n",
      "step:    38340, time: 0.814, loss: 1.2107, l1: 0.2593, vgg: 0.5727, mask: 0.3787\n",
      "step:    38360, time: 0.774, loss: 1.1131, l1: 0.2307, vgg: 0.4697, mask: 0.4126\n",
      "step:    38380, time: 0.741, loss: 1.1033, l1: 0.2502, vgg: 0.4523, mask: 0.4008\n",
      "step:    38400, time: 0.776, loss: 1.2256, l1: 0.2404, vgg: 0.6166, mask: 0.3686\n",
      "step:    38420, time: 0.734, loss: 1.1278, l1: 0.2038, vgg: 0.4982, mask: 0.4259\n",
      "step:    38440, time: 0.782, loss: 1.0712, l1: 0.2041, vgg: 0.5218, mask: 0.3453\n",
      "step:    38460, time: 0.775, loss: 1.1450, l1: 0.2066, vgg: 0.5808, mask: 0.3576\n",
      "step:    38480, time: 0.757, loss: 1.2289, l1: 0.2508, vgg: 0.5908, mask: 0.3873\n",
      "step:    38500, time: 0.779, loss: 1.2081, l1: 0.2763, vgg: 0.5380, mask: 0.3938\n",
      "step:    38520, time: 0.779, loss: 1.1171, l1: 0.2111, vgg: 0.5401, mask: 0.3660\n",
      "step:    38540, time: 0.775, loss: 1.0764, l1: 0.2264, vgg: 0.4877, mask: 0.3623\n",
      "step:    38560, time: 0.745, loss: 1.0829, l1: 0.2200, vgg: 0.4910, mask: 0.3719\n",
      "step:    38580, time: 0.750, loss: 1.1958, l1: 0.2574, vgg: 0.5311, mask: 0.4072\n",
      "step:    38600, time: 0.761, loss: 1.2299, l1: 0.2704, vgg: 0.5746, mask: 0.3849\n",
      "step:    38620, time: 0.756, loss: 1.0922, l1: 0.1949, vgg: 0.5333, mask: 0.3640\n",
      "step:    38640, time: 0.807, loss: 1.2560, l1: 0.2550, vgg: 0.5848, mask: 0.4162\n",
      "step:    38660, time: 0.764, loss: 1.1097, l1: 0.2433, vgg: 0.4809, mask: 0.3855\n",
      "step:    38680, time: 0.739, loss: 1.0595, l1: 0.1966, vgg: 0.4953, mask: 0.3676\n",
      "step:    38700, time: 0.743, loss: 1.1065, l1: 0.2362, vgg: 0.4835, mask: 0.3868\n",
      "step:    38720, time: 0.825, loss: 1.2071, l1: 0.2368, vgg: 0.5838, mask: 0.3865\n",
      "step:    38740, time: 0.761, loss: 1.0882, l1: 0.2299, vgg: 0.4878, mask: 0.3704\n",
      "step:    38760, time: 0.724, loss: 1.0705, l1: 0.1852, vgg: 0.5168, mask: 0.3685\n",
      "step:    38780, time: 0.784, loss: 1.1612, l1: 0.2411, vgg: 0.5487, mask: 0.3714\n",
      "step:    38800, time: 0.739, loss: 1.0278, l1: 0.1603, vgg: 0.4883, mask: 0.3791\n",
      "step:    38820, time: 0.737, loss: 1.0831, l1: 0.2508, vgg: 0.4855, mask: 0.3468\n",
      "step:    38840, time: 0.812, loss: 1.0767, l1: 0.2287, vgg: 0.4376, mask: 0.4104\n",
      "step:    38860, time: 0.743, loss: 1.0964, l1: 0.2114, vgg: 0.4919, mask: 0.3931\n",
      "step:    38880, time: 0.778, loss: 1.1585, l1: 0.2337, vgg: 0.5634, mask: 0.3614\n",
      "step:    38900, time: 0.793, loss: 1.2456, l1: 0.2501, vgg: 0.6083, mask: 0.3873\n",
      "step:    38920, time: 0.768, loss: 1.0834, l1: 0.2049, vgg: 0.5223, mask: 0.3562\n",
      "step:    38940, time: 0.736, loss: 1.1168, l1: 0.2089, vgg: 0.5021, mask: 0.4057\n",
      "step:    38960, time: 0.754, loss: 1.1927, l1: 0.2247, vgg: 0.5803, mask: 0.3876\n",
      "step:    38980, time: 0.807, loss: 1.2876, l1: 0.2933, vgg: 0.6107, mask: 0.3836\n",
      "step:    39000, time: 0.770, loss: 1.2315, l1: 0.2704, vgg: 0.5448, mask: 0.4164\n",
      "step:    39020, time: 0.808, loss: 1.2211, l1: 0.2527, vgg: 0.5709, mask: 0.3976\n",
      "step:    39040, time: 0.749, loss: 1.0489, l1: 0.1935, vgg: 0.5175, mask: 0.3379\n",
      "step:    39060, time: 0.788, loss: 1.1002, l1: 0.1988, vgg: 0.5457, mask: 0.3558\n",
      "step:    39080, time: 0.725, loss: 0.9796, l1: 0.1689, vgg: 0.4904, mask: 0.3202\n",
      "step:    39100, time: 0.779, loss: 1.2396, l1: 0.2502, vgg: 0.6135, mask: 0.3759\n",
      "step:    39120, time: 0.785, loss: 1.0800, l1: 0.2091, vgg: 0.5135, mask: 0.3575\n",
      "step:    39140, time: 0.763, loss: 1.2761, l1: 0.3316, vgg: 0.5305, mask: 0.4140\n",
      "step:    39160, time: 0.768, loss: 1.1188, l1: 0.1995, vgg: 0.5081, mask: 0.4111\n",
      "step:    39180, time: 0.766, loss: 1.0107, l1: 0.1872, vgg: 0.4672, mask: 0.3563\n",
      "step:    39200, time: 0.790, loss: 1.0479, l1: 0.1867, vgg: 0.4714, mask: 0.3897\n",
      "step:    39220, time: 0.725, loss: 1.2067, l1: 0.2531, vgg: 0.5631, mask: 0.3905\n",
      "step:    39240, time: 0.765, loss: 1.1458, l1: 0.2582, vgg: 0.5224, mask: 0.3652\n",
      "step:    39260, time: 0.749, loss: 1.1084, l1: 0.2185, vgg: 0.5244, mask: 0.3654\n",
      "step:    39280, time: 0.758, loss: 1.0944, l1: 0.2200, vgg: 0.4622, mask: 0.4123\n",
      "step:    39300, time: 0.792, loss: 1.1252, l1: 0.2355, vgg: 0.4883, mask: 0.4014\n",
      "step:    39320, time: 0.755, loss: 1.2016, l1: 0.2412, vgg: 0.5566, mask: 0.4037\n",
      "step:    39340, time: 0.777, loss: 1.0785, l1: 0.2175, vgg: 0.5062, mask: 0.3548\n",
      "step:    39360, time: 0.789, loss: 1.2553, l1: 0.2348, vgg: 0.6449, mask: 0.3755\n",
      "step:    39380, time: 0.763, loss: 1.2183, l1: 0.2579, vgg: 0.5951, mask: 0.3654\n",
      "step:    39400, time: 0.784, loss: 1.1084, l1: 0.2533, vgg: 0.4883, mask: 0.3669\n",
      "step:    39420, time: 0.733, loss: 1.0591, l1: 0.2015, vgg: 0.4766, mask: 0.3810\n",
      "step:    39440, time: 0.760, loss: 1.0773, l1: 0.2244, vgg: 0.4834, mask: 0.3695\n",
      "step:    39460, time: 0.737, loss: 1.0800, l1: 0.2028, vgg: 0.5138, mask: 0.3634\n",
      "step:    39480, time: 0.736, loss: 1.0046, l1: 0.1622, vgg: 0.4846, mask: 0.3577\n",
      "step:    39500, time: 0.754, loss: 1.2135, l1: 0.2908, vgg: 0.5175, mask: 0.4052\n",
      "step:    39520, time: 0.739, loss: 1.0191, l1: 0.1846, vgg: 0.5041, mask: 0.3304\n",
      "step:    39540, time: 0.756, loss: 1.0927, l1: 0.1852, vgg: 0.5194, mask: 0.3881\n",
      "step:    39560, time: 0.776, loss: 1.2509, l1: 0.2519, vgg: 0.6125, mask: 0.3864\n",
      "step:    39580, time: 0.725, loss: 0.9418, l1: 0.1824, vgg: 0.4473, mask: 0.3121\n",
      "step:    39600, time: 0.754, loss: 1.1803, l1: 0.2479, vgg: 0.5644, mask: 0.3680\n",
      "step:    39620, time: 0.756, loss: 1.2097, l1: 0.2632, vgg: 0.5537, mask: 0.3928\n",
      "step:    39640, time: 0.741, loss: 1.0893, l1: 0.1751, vgg: 0.5690, mask: 0.3452\n",
      "step:    39660, time: 0.762, loss: 1.1266, l1: 0.2367, vgg: 0.4924, mask: 0.3976\n",
      "step:    39680, time: 0.715, loss: 1.0959, l1: 0.2336, vgg: 0.4666, mask: 0.3957\n",
      "step:    39700, time: 0.759, loss: 1.2065, l1: 0.2546, vgg: 0.5559, mask: 0.3960\n",
      "step:    39720, time: 0.750, loss: 1.2105, l1: 0.2366, vgg: 0.5957, mask: 0.3782\n",
      "step:    39740, time: 0.751, loss: 1.1736, l1: 0.2430, vgg: 0.5508, mask: 0.3798\n",
      "step:    39760, time: 0.819, loss: 1.3862, l1: 0.2514, vgg: 0.7172, mask: 0.4177\n",
      "step:    39780, time: 0.777, loss: 1.1333, l1: 0.2304, vgg: 0.5000, mask: 0.4029\n",
      "step:    39800, time: 0.776, loss: 1.1100, l1: 0.2204, vgg: 0.5132, mask: 0.3764\n",
      "step:    39820, time: 0.782, loss: 1.1543, l1: 0.2262, vgg: 0.5512, mask: 0.3769\n",
      "step:    39840, time: 0.783, loss: 1.2221, l1: 0.2408, vgg: 0.5546, mask: 0.4267\n",
      "step:    39860, time: 0.790, loss: 1.2681, l1: 0.2854, vgg: 0.5717, mask: 0.4110\n",
      "step:    39880, time: 0.773, loss: 1.1190, l1: 0.2288, vgg: 0.5055, mask: 0.3847\n",
      "step:    39900, time: 0.783, loss: 1.2699, l1: 0.2736, vgg: 0.5985, mask: 0.3978\n",
      "step:    39920, time: 0.747, loss: 1.1742, l1: 0.1859, vgg: 0.6086, mask: 0.3796\n",
      "step:    39940, time: 0.778, loss: 1.1108, l1: 0.2236, vgg: 0.4869, mask: 0.4002\n",
      "step:    39960, time: 0.744, loss: 1.2053, l1: 0.2367, vgg: 0.6094, mask: 0.3592\n",
      "step:    39980, time: 0.724, loss: 1.0664, l1: 0.1961, vgg: 0.5074, mask: 0.3629\n",
      "step:    40000, time: 0.780, loss: 1.0639, l1: 0.1985, vgg: 0.5073, mask: 0.3582\n",
      "step:    40020, time: 0.738, loss: 1.1213, l1: 0.2800, vgg: 0.4489, mask: 0.3924\n",
      "step:    40040, time: 0.777, loss: 1.2659, l1: 0.2615, vgg: 0.5921, mask: 0.4123\n",
      "step:    40060, time: 0.825, loss: 1.1440, l1: 0.2293, vgg: 0.5573, mask: 0.3574\n",
      "step:    40080, time: 0.775, loss: 1.3053, l1: 0.2931, vgg: 0.5821, mask: 0.4301\n",
      "step:    40100, time: 0.738, loss: 1.0639, l1: 0.2359, vgg: 0.4534, mask: 0.3746\n",
      "step:    40120, time: 0.813, loss: 1.0820, l1: 0.1866, vgg: 0.5492, mask: 0.3462\n",
      "step:    40140, time: 0.780, loss: 1.1751, l1: 0.2390, vgg: 0.5337, mask: 0.4024\n",
      "step:    40160, time: 0.770, loss: 1.1996, l1: 0.2236, vgg: 0.5980, mask: 0.3781\n",
      "step:    40180, time: 0.738, loss: 1.1557, l1: 0.2704, vgg: 0.5119, mask: 0.3735\n",
      "step:    40200, time: 0.766, loss: 1.0914, l1: 0.1558, vgg: 0.5634, mask: 0.3722\n",
      "step:    40220, time: 0.745, loss: 1.1009, l1: 0.2438, vgg: 0.4776, mask: 0.3796\n",
      "step:    40240, time: 0.779, loss: 1.1145, l1: 0.1994, vgg: 0.4998, mask: 0.4153\n",
      "step:    40260, time: 0.780, loss: 1.1536, l1: 0.2385, vgg: 0.5340, mask: 0.3810\n",
      "step:    40280, time: 0.735, loss: 1.1029, l1: 0.2244, vgg: 0.5324, mask: 0.3461\n",
      "step:    40300, time: 0.755, loss: 1.1047, l1: 0.2165, vgg: 0.5240, mask: 0.3642\n",
      "step:    40320, time: 0.767, loss: 1.1423, l1: 0.1951, vgg: 0.5802, mask: 0.3670\n",
      "step:    40340, time: 0.765, loss: 1.2280, l1: 0.2498, vgg: 0.5786, mask: 0.3996\n",
      "step:    40360, time: 0.737, loss: 1.1963, l1: 0.2668, vgg: 0.5129, mask: 0.4166\n",
      "step:    40380, time: 0.746, loss: 1.0867, l1: 0.2257, vgg: 0.4354, mask: 0.4256\n",
      "step:    40400, time: 0.766, loss: 1.1308, l1: 0.1994, vgg: 0.5506, mask: 0.3808\n",
      "step:    40420, time: 0.765, loss: 1.0904, l1: 0.2159, vgg: 0.5225, mask: 0.3519\n",
      "step:    40440, time: 0.844, loss: 1.1775, l1: 0.2551, vgg: 0.5286, mask: 0.3939\n",
      "step:    40460, time: 0.795, loss: 1.0884, l1: 0.1945, vgg: 0.5595, mask: 0.3343\n",
      "step:    40480, time: 0.797, loss: 1.1968, l1: 0.2181, vgg: 0.6092, mask: 0.3696\n",
      "step:    40500, time: 0.749, loss: 1.0604, l1: 0.1827, vgg: 0.5262, mask: 0.3516\n",
      "step:    40520, time: 0.789, loss: 1.1200, l1: 0.2222, vgg: 0.5349, mask: 0.3629\n",
      "step:    40540, time: 0.741, loss: 1.1076, l1: 0.2205, vgg: 0.5086, mask: 0.3785\n",
      "step:    40560, time: 0.772, loss: 1.0661, l1: 0.1808, vgg: 0.5062, mask: 0.3790\n",
      "step:    40580, time: 0.811, loss: 1.1794, l1: 0.2194, vgg: 0.5549, mask: 0.4050\n",
      "step:    40600, time: 0.740, loss: 1.1056, l1: 0.2132, vgg: 0.5246, mask: 0.3678\n",
      "step:    40620, time: 0.745, loss: 1.0380, l1: 0.2160, vgg: 0.4652, mask: 0.3568\n",
      "step:    40640, time: 0.809, loss: 1.2207, l1: 0.2722, vgg: 0.5419, mask: 0.4067\n",
      "step:    40660, time: 0.729, loss: 1.1517, l1: 0.2653, vgg: 0.4712, mask: 0.4151\n",
      "step:    40680, time: 0.807, loss: 1.0595, l1: 0.1772, vgg: 0.5219, mask: 0.3604\n",
      "step:    40700, time: 0.747, loss: 1.0896, l1: 0.2024, vgg: 0.5167, mask: 0.3705\n",
      "step:    40720, time: 0.746, loss: 1.3238, l1: 0.3128, vgg: 0.5982, mask: 0.4128\n",
      "step:    40740, time: 0.786, loss: 1.2153, l1: 0.2172, vgg: 0.5878, mask: 0.4103\n",
      "step:    40760, time: 0.765, loss: 1.0884, l1: 0.1995, vgg: 0.4986, mask: 0.3903\n",
      "step:    40780, time: 0.822, loss: 1.1203, l1: 0.2081, vgg: 0.5440, mask: 0.3682\n",
      "step:    40800, time: 0.774, loss: 1.1750, l1: 0.2426, vgg: 0.5467, mask: 0.3858\n",
      "step:    40820, time: 0.783, loss: 1.0856, l1: 0.2575, vgg: 0.4417, mask: 0.3863\n",
      "step:    40840, time: 0.856, loss: 1.1785, l1: 0.2037, vgg: 0.5794, mask: 0.3954\n",
      "step:    40860, time: 0.785, loss: 1.0897, l1: 0.2238, vgg: 0.4703, mask: 0.3955\n",
      "step:    40880, time: 0.828, loss: 1.0004, l1: 0.1620, vgg: 0.5173, mask: 0.3211\n",
      "step:    40900, time: 0.741, loss: 1.0213, l1: 0.1903, vgg: 0.4792, mask: 0.3518\n",
      "step:    40920, time: 0.752, loss: 1.0689, l1: 0.1940, vgg: 0.4392, mask: 0.4357\n",
      "step:    40940, time: 0.760, loss: 1.2429, l1: 0.2818, vgg: 0.5592, mask: 0.4020\n",
      "step:    40960, time: 0.751, loss: 1.1363, l1: 0.2268, vgg: 0.5438, mask: 0.3656\n",
      "step:    40980, time: 0.733, loss: 1.0140, l1: 0.2082, vgg: 0.4657, mask: 0.3401\n",
      "step:    41000, time: 0.741, loss: 1.0916, l1: 0.2087, vgg: 0.5433, mask: 0.3397\n",
      "step:    41020, time: 0.816, loss: 1.1377, l1: 0.2444, vgg: 0.5159, mask: 0.3775\n",
      "step:    41040, time: 0.717, loss: 1.0432, l1: 0.2090, vgg: 0.4814, mask: 0.3527\n",
      "step:    41060, time: 0.767, loss: 1.1954, l1: 0.2178, vgg: 0.6357, mask: 0.3419\n",
      "step:    41080, time: 0.756, loss: 1.2011, l1: 0.2355, vgg: 0.5680, mask: 0.3976\n",
      "step:    41100, time: 0.763, loss: 1.2248, l1: 0.2768, vgg: 0.5490, mask: 0.3991\n",
      "step:    41120, time: 0.755, loss: 1.2247, l1: 0.2618, vgg: 0.5561, mask: 0.4068\n",
      "step:    41140, time: 0.762, loss: 1.1793, l1: 0.2081, vgg: 0.5514, mask: 0.4198\n",
      "step:    41160, time: 0.754, loss: 1.0617, l1: 0.2002, vgg: 0.4981, mask: 0.3633\n",
      "step:    41180, time: 0.750, loss: 1.0778, l1: 0.2315, vgg: 0.4729, mask: 0.3734\n",
      "step:    41200, time: 0.751, loss: 1.0956, l1: 0.2104, vgg: 0.5300, mask: 0.3552\n",
      "step:    41220, time: 0.750, loss: 1.1072, l1: 0.2288, vgg: 0.5275, mask: 0.3509\n",
      "step:    41240, time: 0.764, loss: 1.1849, l1: 0.2459, vgg: 0.5397, mask: 0.3993\n",
      "step:    41260, time: 0.786, loss: 1.3169, l1: 0.2857, vgg: 0.6154, mask: 0.4158\n",
      "step:    41280, time: 0.742, loss: 1.0484, l1: 0.1897, vgg: 0.5146, mask: 0.3441\n",
      "step:    41300, time: 0.773, loss: 1.1226, l1: 0.2259, vgg: 0.5325, mask: 0.3642\n",
      "step:    41320, time: 0.747, loss: 1.1443, l1: 0.2221, vgg: 0.5674, mask: 0.3548\n",
      "step:    41340, time: 0.740, loss: 1.2097, l1: 0.2724, vgg: 0.5537, mask: 0.3837\n",
      "step:    41360, time: 0.751, loss: 1.1861, l1: 0.2791, vgg: 0.4952, mask: 0.4117\n",
      "step:    41380, time: 0.748, loss: 1.1190, l1: 0.2118, vgg: 0.5022, mask: 0.4050\n",
      "step:    41400, time: 0.775, loss: 1.1726, l1: 0.2475, vgg: 0.5501, mask: 0.3749\n",
      "step:    41420, time: 0.785, loss: 1.2359, l1: 0.2918, vgg: 0.5349, mask: 0.4091\n",
      "step:    41440, time: 0.806, loss: 1.1641, l1: 0.2153, vgg: 0.6074, mask: 0.3413\n",
      "step:    41460, time: 0.789, loss: 1.1816, l1: 0.2886, vgg: 0.4980, mask: 0.3949\n",
      "step:    41480, time: 0.740, loss: 1.0632, l1: 0.1796, vgg: 0.5114, mask: 0.3722\n",
      "step:    41500, time: 0.725, loss: 1.0061, l1: 0.1632, vgg: 0.5156, mask: 0.3273\n",
      "step:    41520, time: 0.746, loss: 1.1428, l1: 0.2300, vgg: 0.5457, mask: 0.3672\n",
      "step:    41540, time: 0.763, loss: 1.1474, l1: 0.1806, vgg: 0.5540, mask: 0.4128\n",
      "step:    41560, time: 0.730, loss: 1.1569, l1: 0.2672, vgg: 0.5070, mask: 0.3826\n",
      "step:    41580, time: 0.747, loss: 1.0753, l1: 0.2092, vgg: 0.4925, mask: 0.3736\n",
      "step:    41600, time: 0.750, loss: 1.1487, l1: 0.2345, vgg: 0.5374, mask: 0.3768\n",
      "step:    41620, time: 0.759, loss: 1.0868, l1: 0.2289, vgg: 0.4790, mask: 0.3789\n",
      "step:    41640, time: 0.754, loss: 1.1405, l1: 0.2231, vgg: 0.5425, mask: 0.3749\n",
      "step:    41660, time: 0.748, loss: 1.1717, l1: 0.2810, vgg: 0.4953, mask: 0.3953\n",
      "step:    41680, time: 0.743, loss: 1.1180, l1: 0.2196, vgg: 0.5244, mask: 0.3740\n",
      "step:    41700, time: 0.756, loss: 1.1842, l1: 0.2337, vgg: 0.5685, mask: 0.3819\n",
      "step:    41720, time: 0.789, loss: 1.1652, l1: 0.2304, vgg: 0.5241, mask: 0.4107\n",
      "step:    41740, time: 0.733, loss: 1.1975, l1: 0.2085, vgg: 0.6298, mask: 0.3591\n",
      "step:    41760, time: 0.728, loss: 1.1367, l1: 0.2400, vgg: 0.5101, mask: 0.3866\n",
      "step:    41780, time: 0.744, loss: 1.2649, l1: 0.2471, vgg: 0.6221, mask: 0.3957\n",
      "step:    41800, time: 0.784, loss: 1.1769, l1: 0.2361, vgg: 0.5681, mask: 0.3728\n",
      "step:    41820, time: 0.785, loss: 1.1379, l1: 0.2075, vgg: 0.5610, mask: 0.3694\n",
      "step:    41840, time: 0.801, loss: 1.2158, l1: 0.2502, vgg: 0.5936, mask: 0.3721\n",
      "step:    41860, time: 0.817, loss: 1.1706, l1: 0.2469, vgg: 0.5555, mask: 0.3683\n",
      "step:    41880, time: 0.788, loss: 1.0286, l1: 0.1841, vgg: 0.4728, mask: 0.3718\n",
      "step:    41900, time: 0.742, loss: 1.1658, l1: 0.2305, vgg: 0.5346, mask: 0.4007\n",
      "step:    41920, time: 0.760, loss: 1.1994, l1: 0.2398, vgg: 0.5925, mask: 0.3671\n",
      "step:    41940, time: 0.776, loss: 1.1444, l1: 0.2096, vgg: 0.5473, mask: 0.3875\n",
      "step:    41960, time: 0.760, loss: 0.9961, l1: 0.1557, vgg: 0.5168, mask: 0.3237\n",
      "step:    41980, time: 0.728, loss: 1.1741, l1: 0.2188, vgg: 0.5543, mask: 0.4009\n",
      "step:    42000, time: 0.778, loss: 0.9918, l1: 0.1667, vgg: 0.4845, mask: 0.3406\n",
      "step:    42020, time: 0.725, loss: 1.0644, l1: 0.1721, vgg: 0.5439, mask: 0.3483\n",
      "step:    42040, time: 0.769, loss: 1.0982, l1: 0.2004, vgg: 0.5288, mask: 0.3689\n",
      "step:    42060, time: 0.750, loss: 1.2068, l1: 0.2248, vgg: 0.6304, mask: 0.3516\n",
      "step:    42080, time: 0.734, loss: 1.1026, l1: 0.2207, vgg: 0.5093, mask: 0.3727\n",
      "step:    42100, time: 0.795, loss: 1.1591, l1: 0.1997, vgg: 0.5953, mask: 0.3640\n",
      "step:    42120, time: 0.752, loss: 1.0867, l1: 0.2100, vgg: 0.5379, mask: 0.3388\n",
      "step:    42140, time: 0.746, loss: 1.1439, l1: 0.2278, vgg: 0.5176, mask: 0.3985\n",
      "step:    42160, time: 0.772, loss: 1.0442, l1: 0.1832, vgg: 0.4820, mask: 0.3790\n",
      "step:    42180, time: 0.753, loss: 1.0794, l1: 0.1750, vgg: 0.5518, mask: 0.3525\n",
      "step:    42200, time: 0.758, loss: 1.1277, l1: 0.2295, vgg: 0.5138, mask: 0.3845\n",
      "step:    42220, time: 0.758, loss: 1.0877, l1: 0.2002, vgg: 0.5082, mask: 0.3792\n",
      "step:    42240, time: 0.757, loss: 1.2140, l1: 0.2640, vgg: 0.5337, mask: 0.4163\n",
      "step:    42260, time: 0.756, loss: 1.2175, l1: 0.2754, vgg: 0.5310, mask: 0.4111\n",
      "step:    42280, time: 0.798, loss: 1.1250, l1: 0.2138, vgg: 0.5358, mask: 0.3755\n",
      "step:    42300, time: 0.748, loss: 1.1412, l1: 0.1903, vgg: 0.5799, mask: 0.3711\n",
      "step:    42320, time: 0.737, loss: 1.0556, l1: 0.1725, vgg: 0.4899, mask: 0.3933\n",
      "step:    42340, time: 0.751, loss: 1.1858, l1: 0.2510, vgg: 0.5632, mask: 0.3716\n",
      "step:    42360, time: 0.767, loss: 1.0517, l1: 0.1884, vgg: 0.4912, mask: 0.3720\n",
      "step:    42380, time: 0.780, loss: 1.1137, l1: 0.2070, vgg: 0.5429, mask: 0.3638\n",
      "step:    42400, time: 0.728, loss: 1.1149, l1: 0.2557, vgg: 0.4401, mask: 0.4191\n",
      "step:    42420, time: 0.765, loss: 1.1993, l1: 0.2581, vgg: 0.5458, mask: 0.3954\n",
      "step:    42440, time: 0.774, loss: 1.1447, l1: 0.2431, vgg: 0.5308, mask: 0.3708\n",
      "step:    42460, time: 0.720, loss: 1.1186, l1: 0.1940, vgg: 0.5379, mask: 0.3866\n",
      "step:    42480, time: 0.740, loss: 1.0608, l1: 0.1709, vgg: 0.5272, mask: 0.3627\n",
      "step:    42500, time: 0.751, loss: 1.1754, l1: 0.2566, vgg: 0.5212, mask: 0.3976\n",
      "step:    42520, time: 0.721, loss: 1.1085, l1: 0.2044, vgg: 0.5334, mask: 0.3707\n",
      "step:    42540, time: 0.725, loss: 1.1605, l1: 0.2474, vgg: 0.5469, mask: 0.3661\n",
      "step:    42560, time: 0.758, loss: 1.2632, l1: 0.2310, vgg: 0.6284, mask: 0.4038\n",
      "step:    42580, time: 0.783, loss: 1.2202, l1: 0.2296, vgg: 0.6180, mask: 0.3727\n",
      "step:    42600, time: 0.744, loss: 1.0727, l1: 0.2002, vgg: 0.4933, mask: 0.3791\n",
      "step:    42620, time: 0.734, loss: 1.0204, l1: 0.1715, vgg: 0.5144, mask: 0.3345\n",
      "step:    42640, time: 0.767, loss: 1.1698, l1: 0.2013, vgg: 0.5613, mask: 0.4073\n",
      "step:    42660, time: 0.749, loss: 1.2151, l1: 0.2429, vgg: 0.5683, mask: 0.4039\n",
      "step:    42680, time: 0.716, loss: 0.9798, l1: 0.1640, vgg: 0.4593, mask: 0.3565\n",
      "step:    42700, time: 0.748, loss: 1.1164, l1: 0.2189, vgg: 0.5279, mask: 0.3696\n",
      "step:    42720, time: 0.774, loss: 1.2117, l1: 0.2297, vgg: 0.5635, mask: 0.4184\n",
      "step:    42740, time: 0.752, loss: 1.1166, l1: 0.2267, vgg: 0.5252, mask: 0.3646\n",
      "step:    42760, time: 0.747, loss: 1.2067, l1: 0.2587, vgg: 0.5389, mask: 0.4090\n",
      "step:    42780, time: 0.774, loss: 1.2419, l1: 0.2375, vgg: 0.6141, mask: 0.3903\n",
      "step:    42800, time: 0.745, loss: 1.3002, l1: 0.2917, vgg: 0.6046, mask: 0.4039\n",
      "step:    42820, time: 0.747, loss: 1.1357, l1: 0.2350, vgg: 0.5215, mask: 0.3792\n",
      "step:    42840, time: 0.759, loss: 1.2065, l1: 0.2187, vgg: 0.6166, mask: 0.3712\n",
      "step:    42860, time: 0.751, loss: 1.0753, l1: 0.2117, vgg: 0.4997, mask: 0.3638\n",
      "step:    42880, time: 0.756, loss: 1.0233, l1: 0.1857, vgg: 0.4907, mask: 0.3468\n",
      "step:    42900, time: 0.742, loss: 1.1505, l1: 0.2378, vgg: 0.5377, mask: 0.3750\n",
      "step:    42920, time: 0.753, loss: 1.0812, l1: 0.2154, vgg: 0.5067, mask: 0.3591\n",
      "step:    42940, time: 0.783, loss: 1.1742, l1: 0.2684, vgg: 0.5263, mask: 0.3794\n",
      "step:    42960, time: 0.771, loss: 1.0398, l1: 0.2431, vgg: 0.4584, mask: 0.3383\n",
      "step:    42980, time: 0.772, loss: 1.0447, l1: 0.1926, vgg: 0.5017, mask: 0.3504\n",
      "step:    43000, time: 0.783, loss: 1.1481, l1: 0.2050, vgg: 0.5727, mask: 0.3704\n",
      "step:    43020, time: 0.739, loss: 1.0806, l1: 0.1847, vgg: 0.5357, mask: 0.3602\n",
      "step:    43040, time: 0.744, loss: 1.0270, l1: 0.2014, vgg: 0.4667, mask: 0.3589\n",
      "step:    43060, time: 0.744, loss: 1.1189, l1: 0.2115, vgg: 0.5188, mask: 0.3886\n",
      "step:    43080, time: 0.769, loss: 1.1181, l1: 0.2117, vgg: 0.5358, mask: 0.3706\n",
      "step:    43100, time: 0.716, loss: 1.0552, l1: 0.2073, vgg: 0.5046, mask: 0.3433\n",
      "step:    43120, time: 0.807, loss: 1.1172, l1: 0.2212, vgg: 0.5092, mask: 0.3868\n",
      "step:    43140, time: 0.745, loss: 1.1742, l1: 0.2477, vgg: 0.5501, mask: 0.3764\n",
      "step:    43160, time: 0.775, loss: 1.1258, l1: 0.2042, vgg: 0.5242, mask: 0.3974\n",
      "step:    43180, time: 0.727, loss: 0.9719, l1: 0.1778, vgg: 0.4356, mask: 0.3585\n",
      "step:    43200, time: 0.750, loss: 1.0521, l1: 0.1974, vgg: 0.5228, mask: 0.3319\n",
      "step:    43220, time: 0.772, loss: 1.1245, l1: 0.2205, vgg: 0.5733, mask: 0.3307\n",
      "step:    43240, time: 0.772, loss: 1.1943, l1: 0.2356, vgg: 0.5800, mask: 0.3787\n",
      "step:    43260, time: 0.796, loss: 1.2496, l1: 0.2542, vgg: 0.6293, mask: 0.3661\n",
      "step:    43280, time: 0.801, loss: 1.1175, l1: 0.2114, vgg: 0.5105, mask: 0.3956\n",
      "step:    43300, time: 0.758, loss: 1.1799, l1: 0.2544, vgg: 0.5570, mask: 0.3685\n",
      "step:    43320, time: 0.814, loss: 1.0126, l1: 0.1734, vgg: 0.5008, mask: 0.3384\n",
      "step:    43340, time: 0.742, loss: 1.0931, l1: 0.2427, vgg: 0.4677, mask: 0.3827\n",
      "step:    43360, time: 0.788, loss: 1.1935, l1: 0.2395, vgg: 0.5779, mask: 0.3760\n",
      "step:    43380, time: 0.764, loss: 1.0754, l1: 0.2248, vgg: 0.5101, mask: 0.3405\n",
      "step:    43400, time: 0.757, loss: 1.1933, l1: 0.2694, vgg: 0.5271, mask: 0.3968\n",
      "step:    43420, time: 0.761, loss: 1.0826, l1: 0.2059, vgg: 0.5171, mask: 0.3596\n",
      "step:    43440, time: 0.783, loss: 1.1256, l1: 0.2571, vgg: 0.4837, mask: 0.3848\n",
      "step:    43460, time: 0.730, loss: 1.0102, l1: 0.1875, vgg: 0.4694, mask: 0.3533\n",
      "step:    43480, time: 0.749, loss: 1.0473, l1: 0.1904, vgg: 0.4924, mask: 0.3645\n",
      "step:    43500, time: 0.758, loss: 1.1560, l1: 0.2199, vgg: 0.5388, mask: 0.3972\n",
      "step:    43520, time: 0.761, loss: 1.2020, l1: 0.2152, vgg: 0.6065, mask: 0.3803\n",
      "step:    43540, time: 0.757, loss: 1.1890, l1: 0.2818, vgg: 0.4850, mask: 0.4223\n",
      "step:    43560, time: 0.788, loss: 1.0508, l1: 0.1867, vgg: 0.4979, mask: 0.3661\n",
      "step:    43580, time: 0.745, loss: 1.1368, l1: 0.2418, vgg: 0.5161, mask: 0.3788\n",
      "step:    43600, time: 0.788, loss: 1.1669, l1: 0.2555, vgg: 0.5006, mask: 0.4108\n",
      "step:    43620, time: 0.780, loss: 1.0756, l1: 0.1919, vgg: 0.5181, mask: 0.3656\n",
      "step:    43640, time: 0.787, loss: 1.1685, l1: 0.2467, vgg: 0.5292, mask: 0.3926\n",
      "step:    43660, time: 0.763, loss: 1.1671, l1: 0.2329, vgg: 0.5479, mask: 0.3862\n",
      "step:    43680, time: 0.774, loss: 1.1161, l1: 0.2050, vgg: 0.5351, mask: 0.3760\n",
      "step:    43700, time: 0.775, loss: 1.0328, l1: 0.2156, vgg: 0.4314, mask: 0.3857\n",
      "step:    43720, time: 0.761, loss: 1.0860, l1: 0.2151, vgg: 0.5228, mask: 0.3481\n",
      "step:    43740, time: 0.749, loss: 1.1366, l1: 0.2307, vgg: 0.4940, mask: 0.4119\n",
      "step:    43760, time: 0.741, loss: 1.0533, l1: 0.2077, vgg: 0.5016, mask: 0.3441\n",
      "step:    43780, time: 0.759, loss: 1.0746, l1: 0.1877, vgg: 0.5350, mask: 0.3518\n",
      "step:    43800, time: 0.775, loss: 1.1493, l1: 0.2477, vgg: 0.5126, mask: 0.3890\n",
      "step:    43820, time: 0.767, loss: 1.0836, l1: 0.2119, vgg: 0.5204, mask: 0.3512\n",
      "step:    43840, time: 0.780, loss: 1.1519, l1: 0.2239, vgg: 0.5472, mask: 0.3808\n",
      "step:    43860, time: 0.753, loss: 1.1748, l1: 0.2325, vgg: 0.5423, mask: 0.4000\n",
      "step:    43880, time: 0.738, loss: 0.9930, l1: 0.1594, vgg: 0.4706, mask: 0.3630\n",
      "step:    43900, time: 0.762, loss: 1.1507, l1: 0.2195, vgg: 0.5440, mask: 0.3873\n",
      "step:    43920, time: 0.780, loss: 1.1008, l1: 0.1943, vgg: 0.5644, mask: 0.3420\n",
      "step:    43940, time: 0.768, loss: 1.1780, l1: 0.2001, vgg: 0.5417, mask: 0.4363\n",
      "step:    43960, time: 0.742, loss: 1.0352, l1: 0.2026, vgg: 0.4805, mask: 0.3521\n",
      "step:    43980, time: 0.802, loss: 1.0773, l1: 0.1837, vgg: 0.5127, mask: 0.3808\n",
      "step:    44000, time: 0.764, loss: 1.0905, l1: 0.1874, vgg: 0.5315, mask: 0.3716\n",
      "step:    44020, time: 0.794, loss: 1.2284, l1: 0.2653, vgg: 0.5826, mask: 0.3806\n",
      "step:    44040, time: 0.754, loss: 1.1159, l1: 0.2361, vgg: 0.5100, mask: 0.3698\n",
      "step:    44060, time: 0.785, loss: 1.1577, l1: 0.3019, vgg: 0.4774, mask: 0.3785\n",
      "step:    44080, time: 0.749, loss: 1.0719, l1: 0.2150, vgg: 0.5065, mask: 0.3504\n",
      "step:    44100, time: 0.851, loss: 1.0861, l1: 0.1998, vgg: 0.5159, mask: 0.3704\n",
      "step:    44120, time: 0.763, loss: 1.1515, l1: 0.2353, vgg: 0.5609, mask: 0.3553\n",
      "step:    44140, time: 0.731, loss: 1.0735, l1: 0.2154, vgg: 0.5070, mask: 0.3510\n",
      "step:    44160, time: 0.803, loss: 1.0909, l1: 0.2173, vgg: 0.5238, mask: 0.3498\n",
      "step:    44180, time: 0.778, loss: 1.1777, l1: 0.2375, vgg: 0.5546, mask: 0.3855\n",
      "step:    44200, time: 0.767, loss: 0.9784, l1: 0.2019, vgg: 0.4331, mask: 0.3433\n",
      "step:    44220, time: 0.818, loss: 1.0746, l1: 0.2147, vgg: 0.4902, mask: 0.3698\n",
      "step:    44240, time: 0.767, loss: 1.1943, l1: 0.2101, vgg: 0.6201, mask: 0.3640\n",
      "step:    44260, time: 0.749, loss: 1.1088, l1: 0.2254, vgg: 0.5121, mask: 0.3714\n",
      "step:    44280, time: 0.730, loss: 1.0880, l1: 0.2087, vgg: 0.4980, mask: 0.3813\n",
      "step:    44300, time: 0.764, loss: 1.1785, l1: 0.2217, vgg: 0.5807, mask: 0.3760\n",
      "step:    44320, time: 0.805, loss: 1.1224, l1: 0.2042, vgg: 0.5387, mask: 0.3794\n",
      "step:    44340, time: 0.736, loss: 1.0291, l1: 0.1765, vgg: 0.4832, mask: 0.3694\n",
      "step:    44360, time: 0.730, loss: 1.0594, l1: 0.1823, vgg: 0.5215, mask: 0.3556\n",
      "step:    44380, time: 0.742, loss: 1.3294, l1: 0.2963, vgg: 0.6162, mask: 0.4169\n",
      "step:    44400, time: 0.745, loss: 1.1782, l1: 0.2607, vgg: 0.5036, mask: 0.4139\n",
      "step:    44420, time: 0.748, loss: 1.0218, l1: 0.1819, vgg: 0.4827, mask: 0.3572\n",
      "step:    44440, time: 0.757, loss: 1.0941, l1: 0.1783, vgg: 0.5710, mask: 0.3447\n",
      "step:    44460, time: 0.749, loss: 1.1460, l1: 0.2366, vgg: 0.5096, mask: 0.3998\n",
      "step:    44480, time: 0.802, loss: 1.3466, l1: 0.2636, vgg: 0.6873, mask: 0.3956\n",
      "step:    44500, time: 0.768, loss: 1.2045, l1: 0.2351, vgg: 0.6053, mask: 0.3642\n",
      "step:    44520, time: 0.769, loss: 1.1163, l1: 0.2164, vgg: 0.5280, mask: 0.3718\n",
      "step:    44540, time: 0.732, loss: 1.1044, l1: 0.2367, vgg: 0.4718, mask: 0.3958\n",
      "step:    44560, time: 0.772, loss: 1.3316, l1: 0.2648, vgg: 0.6604, mask: 0.4064\n",
      "step:    44580, time: 0.775, loss: 1.1635, l1: 0.2266, vgg: 0.5732, mask: 0.3637\n",
      "step:    44600, time: 0.781, loss: 1.1739, l1: 0.2447, vgg: 0.5359, mask: 0.3932\n",
      "step:    44620, time: 0.758, loss: 1.0801, l1: 0.2267, vgg: 0.4723, mask: 0.3811\n",
      "step:    44640, time: 0.819, loss: 1.2976, l1: 0.3095, vgg: 0.5703, mask: 0.4179\n",
      "step:    44660, time: 0.762, loss: 1.0977, l1: 0.1911, vgg: 0.5285, mask: 0.3781\n",
      "step:    44680, time: 0.744, loss: 1.0985, l1: 0.1778, vgg: 0.5523, mask: 0.3683\n",
      "step:    44700, time: 0.777, loss: 1.1148, l1: 0.2760, vgg: 0.4596, mask: 0.3792\n",
      "step:    44720, time: 0.780, loss: 1.2608, l1: 0.2535, vgg: 0.6286, mask: 0.3786\n",
      "step:    44740, time: 0.748, loss: 1.0578, l1: 0.1670, vgg: 0.5336, mask: 0.3572\n",
      "step:    44760, time: 0.765, loss: 1.1510, l1: 0.2831, vgg: 0.4970, mask: 0.3708\n",
      "step:    44780, time: 0.758, loss: 1.1819, l1: 0.2282, vgg: 0.5711, mask: 0.3825\n",
      "step:    44800, time: 0.765, loss: 1.1129, l1: 0.2355, vgg: 0.4886, mask: 0.3888\n",
      "step:    44820, time: 0.751, loss: 1.0126, l1: 0.2009, vgg: 0.4725, mask: 0.3392\n",
      "step:    44840, time: 0.754, loss: 1.0660, l1: 0.1981, vgg: 0.5126, mask: 0.3553\n",
      "step:    44860, time: 0.783, loss: 1.0726, l1: 0.2124, vgg: 0.4908, mask: 0.3694\n",
      "step:    44880, time: 0.733, loss: 0.9832, l1: 0.1614, vgg: 0.4829, mask: 0.3389\n",
      "step:    44900, time: 0.781, loss: 1.1054, l1: 0.2118, vgg: 0.5162, mask: 0.3774\n",
      "step:    44920, time: 0.816, loss: 1.1139, l1: 0.2000, vgg: 0.5431, mask: 0.3709\n",
      "step:    44940, time: 0.775, loss: 1.1164, l1: 0.2244, vgg: 0.5057, mask: 0.3863\n",
      "step:    44960, time: 0.759, loss: 1.0667, l1: 0.1789, vgg: 0.5365, mask: 0.3514\n",
      "step:    44980, time: 0.758, loss: 1.1089, l1: 0.2105, vgg: 0.5259, mask: 0.3724\n",
      "step:    45000, time: 0.761, loss: 1.1012, l1: 0.2016, vgg: 0.5465, mask: 0.3531\n",
      "step:    45020, time: 0.773, loss: 1.1180, l1: 0.2109, vgg: 0.5247, mask: 0.3824\n",
      "step:    45040, time: 0.737, loss: 1.2430, l1: 0.2719, vgg: 0.5596, mask: 0.4114\n",
      "step:    45060, time: 0.722, loss: 1.1568, l1: 0.2385, vgg: 0.5254, mask: 0.3928\n",
      "step:    45080, time: 0.809, loss: 1.2676, l1: 0.2456, vgg: 0.6183, mask: 0.4038\n",
      "step:    45100, time: 0.797, loss: 1.0430, l1: 0.1690, vgg: 0.4997, mask: 0.3743\n",
      "step:    45120, time: 0.804, loss: 1.0934, l1: 0.1829, vgg: 0.5544, mask: 0.3561\n",
      "step:    45140, time: 0.722, loss: 1.0217, l1: 0.1715, vgg: 0.4845, mask: 0.3656\n",
      "step:    45160, time: 0.784, loss: 1.0944, l1: 0.2388, vgg: 0.5084, mask: 0.3471\n",
      "step:    45180, time: 0.767, loss: 1.1813, l1: 0.2090, vgg: 0.6096, mask: 0.3628\n",
      "step:    45200, time: 0.762, loss: 1.1308, l1: 0.2490, vgg: 0.5113, mask: 0.3705\n",
      "step:    45220, time: 0.780, loss: 1.1917, l1: 0.2410, vgg: 0.5617, mask: 0.3891\n",
      "step:    45240, time: 0.796, loss: 1.0154, l1: 0.1749, vgg: 0.4905, mask: 0.3500\n",
      "step:    45260, time: 0.739, loss: 1.0987, l1: 0.1729, vgg: 0.5576, mask: 0.3682\n",
      "step:    45280, time: 0.743, loss: 1.2183, l1: 0.2609, vgg: 0.5423, mask: 0.4151\n",
      "step:    45300, time: 0.786, loss: 1.2844, l1: 0.3100, vgg: 0.5670, mask: 0.4074\n",
      "step:    45320, time: 0.735, loss: 1.0904, l1: 0.2268, vgg: 0.4782, mask: 0.3854\n",
      "step:    45340, time: 0.736, loss: 1.0708, l1: 0.2205, vgg: 0.5101, mask: 0.3402\n",
      "step:    45360, time: 0.794, loss: 1.0965, l1: 0.1937, vgg: 0.5529, mask: 0.3499\n",
      "step:    45380, time: 0.772, loss: 1.0569, l1: 0.1872, vgg: 0.5035, mask: 0.3662\n",
      "step:    45400, time: 0.728, loss: 1.0360, l1: 0.1848, vgg: 0.4918, mask: 0.3594\n",
      "step:    45420, time: 0.767, loss: 1.1696, l1: 0.2389, vgg: 0.5674, mask: 0.3634\n",
      "step:    45440, time: 0.746, loss: 1.1413, l1: 0.2706, vgg: 0.4815, mask: 0.3892\n",
      "step:    45460, time: 0.797, loss: 1.1831, l1: 0.2678, vgg: 0.5251, mask: 0.3902\n",
      "step:    45480, time: 0.798, loss: 1.2069, l1: 0.2710, vgg: 0.5186, mask: 0.4172\n",
      "step:    45500, time: 0.740, loss: 1.0892, l1: 0.2413, vgg: 0.4607, mask: 0.3872\n",
      "step:    45520, time: 0.730, loss: 1.1295, l1: 0.2039, vgg: 0.5257, mask: 0.4000\n",
      "step:    45540, time: 0.748, loss: 1.1529, l1: 0.2489, vgg: 0.5116, mask: 0.3925\n",
      "step:    45560, time: 0.748, loss: 1.0631, l1: 0.1980, vgg: 0.4900, mask: 0.3752\n",
      "step:    45580, time: 0.781, loss: 1.2407, l1: 0.2643, vgg: 0.6006, mask: 0.3759\n",
      "step:    45600, time: 0.748, loss: 1.1376, l1: 0.1984, vgg: 0.5521, mask: 0.3872\n",
      "step:    45620, time: 0.759, loss: 1.1638, l1: 0.2274, vgg: 0.5753, mask: 0.3611\n",
      "step:    45640, time: 0.769, loss: 1.1694, l1: 0.2371, vgg: 0.5504, mask: 0.3819\n",
      "step:    45660, time: 0.745, loss: 1.0444, l1: 0.2034, vgg: 0.4856, mask: 0.3554\n",
      "step:    45680, time: 0.754, loss: 1.1195, l1: 0.1968, vgg: 0.5357, mask: 0.3870\n",
      "step:    45700, time: 0.757, loss: 1.1090, l1: 0.1757, vgg: 0.5440, mask: 0.3893\n",
      "step:    45720, time: 0.767, loss: 1.1817, l1: 0.2286, vgg: 0.5446, mask: 0.4085\n",
      "step:    45740, time: 0.824, loss: 1.1921, l1: 0.2189, vgg: 0.5737, mask: 0.3995\n",
      "step:    45760, time: 0.759, loss: 1.2066, l1: 0.2508, vgg: 0.5786, mask: 0.3772\n",
      "step:    45780, time: 0.776, loss: 1.1665, l1: 0.2142, vgg: 0.5769, mask: 0.3754\n",
      "step:    45800, time: 0.746, loss: 1.1020, l1: 0.2414, vgg: 0.4692, mask: 0.3915\n",
      "step:    45820, time: 0.762, loss: 1.2481, l1: 0.2517, vgg: 0.6127, mask: 0.3836\n",
      "step:    45840, time: 0.768, loss: 1.1096, l1: 0.2092, vgg: 0.5362, mask: 0.3642\n",
      "step:    45860, time: 0.763, loss: 1.1337, l1: 0.2103, vgg: 0.5302, mask: 0.3932\n",
      "step:    45880, time: 0.801, loss: 1.1476, l1: 0.2180, vgg: 0.5580, mask: 0.3716\n",
      "step:    45900, time: 0.787, loss: 1.1345, l1: 0.2209, vgg: 0.5364, mask: 0.3772\n",
      "step:    45920, time: 0.783, loss: 1.1268, l1: 0.2287, vgg: 0.4988, mask: 0.3993\n",
      "step:    45940, time: 0.780, loss: 1.0524, l1: 0.1885, vgg: 0.4858, mask: 0.3781\n",
      "step:    45960, time: 0.749, loss: 1.1169, l1: 0.2463, vgg: 0.4987, mask: 0.3720\n",
      "step:    45980, time: 0.742, loss: 1.0707, l1: 0.2247, vgg: 0.4727, mask: 0.3733\n",
      "step:    46000, time: 0.780, loss: 1.2004, l1: 0.2348, vgg: 0.5806, mask: 0.3850\n",
      "step:    46020, time: 0.773, loss: 1.1630, l1: 0.2458, vgg: 0.5396, mask: 0.3776\n",
      "step:    46040, time: 0.794, loss: 1.1361, l1: 0.2159, vgg: 0.5685, mask: 0.3517\n",
      "step:    46060, time: 0.813, loss: 1.2230, l1: 0.2312, vgg: 0.6304, mask: 0.3613\n",
      "step:    46080, time: 0.761, loss: 1.1337, l1: 0.2364, vgg: 0.5009, mask: 0.3964\n",
      "step:    46100, time: 0.795, loss: 1.2338, l1: 0.2382, vgg: 0.5642, mask: 0.4314\n",
      "step:    46120, time: 0.764, loss: 1.1103, l1: 0.2307, vgg: 0.5169, mask: 0.3627\n",
      "step:    46140, time: 0.741, loss: 1.1615, l1: 0.2403, vgg: 0.5409, mask: 0.3803\n",
      "step:    46160, time: 0.794, loss: 1.1614, l1: 0.2255, vgg: 0.5436, mask: 0.3924\n",
      "step:    46180, time: 0.738, loss: 1.1216, l1: 0.2113, vgg: 0.5524, mask: 0.3579\n",
      "step:    46200, time: 0.792, loss: 1.1065, l1: 0.2233, vgg: 0.5147, mask: 0.3685\n",
      "step:    46220, time: 0.772, loss: 1.1983, l1: 0.2201, vgg: 0.6276, mask: 0.3506\n",
      "step:    46240, time: 0.773, loss: 1.3019, l1: 0.2688, vgg: 0.6262, mask: 0.4069\n",
      "step:    46260, time: 0.822, loss: 1.1570, l1: 0.2510, vgg: 0.5276, mask: 0.3784\n",
      "step:    46280, time: 0.752, loss: 1.2620, l1: 0.2807, vgg: 0.5460, mask: 0.4353\n",
      "step:    46300, time: 0.771, loss: 1.0507, l1: 0.1875, vgg: 0.5174, mask: 0.3458\n",
      "step:    46320, time: 0.753, loss: 0.9939, l1: 0.1916, vgg: 0.4604, mask: 0.3419\n",
      "step:    46340, time: 0.794, loss: 1.0535, l1: 0.1826, vgg: 0.5281, mask: 0.3428\n",
      "step:    46360, time: 0.765, loss: 1.0696, l1: 0.2477, vgg: 0.4722, mask: 0.3497\n",
      "step:    46380, time: 0.734, loss: 1.0820, l1: 0.1897, vgg: 0.5176, mask: 0.3747\n",
      "step:    46400, time: 0.750, loss: 0.9645, l1: 0.1702, vgg: 0.4529, mask: 0.3414\n",
      "step:    46420, time: 0.756, loss: 1.0828, l1: 0.2089, vgg: 0.5106, mask: 0.3633\n",
      "step:    46440, time: 0.788, loss: 1.0425, l1: 0.1802, vgg: 0.4769, mask: 0.3854\n",
      "step:    46460, time: 0.734, loss: 1.0020, l1: 0.1673, vgg: 0.4716, mask: 0.3631\n",
      "step:    46480, time: 0.731, loss: 1.0676, l1: 0.1698, vgg: 0.5575, mask: 0.3402\n",
      "step:    46500, time: 0.785, loss: 1.2197, l1: 0.2146, vgg: 0.6462, mask: 0.3589\n",
      "step:    46520, time: 0.743, loss: 1.1416, l1: 0.2234, vgg: 0.5426, mask: 0.3755\n",
      "step:    46540, time: 0.799, loss: 1.1037, l1: 0.2121, vgg: 0.5022, mask: 0.3894\n",
      "step:    46560, time: 0.742, loss: 1.1262, l1: 0.2330, vgg: 0.5022, mask: 0.3910\n",
      "step:    46580, time: 0.766, loss: 1.1177, l1: 0.2476, vgg: 0.4751, mask: 0.3950\n",
      "step:    46600, time: 0.754, loss: 1.2167, l1: 0.2753, vgg: 0.5482, mask: 0.3932\n",
      "step:    46620, time: 0.744, loss: 1.0291, l1: 0.1870, vgg: 0.4966, mask: 0.3455\n",
      "step:    46640, time: 0.789, loss: 1.0982, l1: 0.2188, vgg: 0.5114, mask: 0.3681\n",
      "step:    46660, time: 0.763, loss: 1.1594, l1: 0.2714, vgg: 0.5094, mask: 0.3785\n",
      "step:    46680, time: 0.722, loss: 1.1199, l1: 0.2445, vgg: 0.4620, mask: 0.4134\n",
      "step:    46700, time: 0.759, loss: 1.0233, l1: 0.2094, vgg: 0.4636, mask: 0.3503\n",
      "step:    46720, time: 0.742, loss: 1.1024, l1: 0.2142, vgg: 0.4847, mask: 0.4034\n",
      "step:    46740, time: 0.800, loss: 1.1254, l1: 0.2338, vgg: 0.5136, mask: 0.3779\n",
      "step:    46760, time: 0.786, loss: 1.0118, l1: 0.2115, vgg: 0.4690, mask: 0.3313\n",
      "step:    46780, time: 0.783, loss: 1.2020, l1: 0.2601, vgg: 0.5695, mask: 0.3724\n",
      "step:    46800, time: 0.730, loss: 1.1768, l1: 0.2481, vgg: 0.5266, mask: 0.4022\n",
      "step:    46820, time: 0.772, loss: 1.1881, l1: 0.2245, vgg: 0.5963, mask: 0.3673\n",
      "step:    46840, time: 0.759, loss: 1.1978, l1: 0.2529, vgg: 0.5173, mask: 0.4276\n",
      "step:    46860, time: 0.794, loss: 1.0855, l1: 0.2036, vgg: 0.5080, mask: 0.3738\n",
      "step:    46880, time: 0.748, loss: 1.2405, l1: 0.2714, vgg: 0.5688, mask: 0.4004\n",
      "step:    46900, time: 0.757, loss: 1.0774, l1: 0.1904, vgg: 0.5335, mask: 0.3534\n",
      "step:    46920, time: 0.771, loss: 1.3135, l1: 0.2662, vgg: 0.6528, mask: 0.3946\n",
      "step:    46940, time: 0.746, loss: 1.0522, l1: 0.1916, vgg: 0.4845, mask: 0.3761\n",
      "step:    46960, time: 0.788, loss: 1.0121, l1: 0.2019, vgg: 0.4254, mask: 0.3847\n",
      "step:    46980, time: 0.791, loss: 1.0394, l1: 0.1566, vgg: 0.5212, mask: 0.3616\n",
      "step:    47000, time: 0.773, loss: 1.1925, l1: 0.2227, vgg: 0.5672, mask: 0.4026\n",
      "step:    47020, time: 0.768, loss: 1.0322, l1: 0.1806, vgg: 0.4841, mask: 0.3675\n",
      "step:    47040, time: 0.769, loss: 1.0104, l1: 0.1589, vgg: 0.5116, mask: 0.3399\n",
      "step:    47060, time: 0.788, loss: 1.0740, l1: 0.1881, vgg: 0.5294, mask: 0.3565\n",
      "step:    47080, time: 0.758, loss: 1.1325, l1: 0.2213, vgg: 0.4753, mask: 0.4359\n",
      "step:    47100, time: 0.770, loss: 1.1708, l1: 0.2374, vgg: 0.5487, mask: 0.3846\n",
      "step:    47120, time: 0.761, loss: 1.0897, l1: 0.2060, vgg: 0.5335, mask: 0.3502\n",
      "step:    47140, time: 0.741, loss: 0.9919, l1: 0.1690, vgg: 0.4709, mask: 0.3520\n",
      "step:    47160, time: 0.754, loss: 1.2749, l1: 0.3034, vgg: 0.5952, mask: 0.3763\n",
      "step:    47180, time: 0.805, loss: 1.0267, l1: 0.1684, vgg: 0.5039, mask: 0.3544\n",
      "step:    47200, time: 0.811, loss: 1.1327, l1: 0.2860, vgg: 0.4566, mask: 0.3901\n",
      "step:    47220, time: 0.761, loss: 1.0447, l1: 0.2287, vgg: 0.4430, mask: 0.3730\n",
      "step:    47240, time: 0.787, loss: 1.0758, l1: 0.2016, vgg: 0.5011, mask: 0.3732\n",
      "step:    47260, time: 0.722, loss: 1.0542, l1: 0.2288, vgg: 0.4363, mask: 0.3891\n",
      "step:    47280, time: 0.773, loss: 1.1940, l1: 0.2266, vgg: 0.5691, mask: 0.3983\n",
      "step:    47300, time: 0.761, loss: 1.0691, l1: 0.2238, vgg: 0.4583, mask: 0.3870\n",
      "step:    47320, time: 0.755, loss: 1.0706, l1: 0.2017, vgg: 0.4885, mask: 0.3804\n",
      "step:    47340, time: 0.763, loss: 1.0758, l1: 0.2011, vgg: 0.4753, mask: 0.3994\n",
      "step:    47360, time: 0.767, loss: 1.1202, l1: 0.2589, vgg: 0.4720, mask: 0.3892\n",
      "step:    47380, time: 0.773, loss: 1.1078, l1: 0.2287, vgg: 0.5007, mask: 0.3784\n",
      "step:    47400, time: 0.722, loss: 1.0069, l1: 0.1866, vgg: 0.4584, mask: 0.3619\n",
      "step:    47420, time: 0.767, loss: 1.2531, l1: 0.2503, vgg: 0.6310, mask: 0.3718\n",
      "step:    47440, time: 0.738, loss: 1.1383, l1: 0.2399, vgg: 0.5118, mask: 0.3865\n",
      "step:    47460, time: 0.764, loss: 1.1033, l1: 0.2262, vgg: 0.5042, mask: 0.3729\n",
      "step:    47480, time: 0.755, loss: 1.1330, l1: 0.2113, vgg: 0.5389, mask: 0.3828\n",
      "step:    47500, time: 0.786, loss: 1.0618, l1: 0.1940, vgg: 0.5111, mask: 0.3567\n",
      "step:    47520, time: 0.722, loss: 0.9474, l1: 0.1861, vgg: 0.4309, mask: 0.3305\n",
      "step:    47540, time: 0.740, loss: 1.0665, l1: 0.1768, vgg: 0.5085, mask: 0.3812\n",
      "step:    47560, time: 0.753, loss: 1.2121, l1: 0.2870, vgg: 0.5235, mask: 0.4016\n",
      "step:    47580, time: 0.753, loss: 0.9972, l1: 0.2208, vgg: 0.4546, mask: 0.3219\n",
      "step:    47600, time: 0.745, loss: 1.1600, l1: 0.2164, vgg: 0.5757, mask: 0.3679\n",
      "step:    47620, time: 0.735, loss: 1.0708, l1: 0.2216, vgg: 0.4761, mask: 0.3731\n",
      "step:    47640, time: 0.749, loss: 1.0603, l1: 0.2213, vgg: 0.4563, mask: 0.3828\n",
      "step:    47660, time: 0.751, loss: 1.1470, l1: 0.2108, vgg: 0.5748, mask: 0.3614\n",
      "step:    47680, time: 0.756, loss: 1.2515, l1: 0.2498, vgg: 0.5706, mask: 0.4312\n",
      "step:    47700, time: 0.759, loss: 1.2011, l1: 0.2907, vgg: 0.4822, mask: 0.4282\n",
      "step:    47720, time: 0.837, loss: 1.2467, l1: 0.2605, vgg: 0.6095, mask: 0.3768\n",
      "step:    47740, time: 0.773, loss: 1.2514, l1: 0.2681, vgg: 0.5755, mask: 0.4078\n",
      "step:    47760, time: 0.770, loss: 1.1380, l1: 0.2393, vgg: 0.5296, mask: 0.3691\n",
      "step:    47780, time: 0.781, loss: 1.1284, l1: 0.1900, vgg: 0.5599, mask: 0.3785\n",
      "step:    47800, time: 0.775, loss: 1.1946, l1: 0.2508, vgg: 0.5680, mask: 0.3758\n",
      "step:    47820, time: 0.804, loss: 1.2177, l1: 0.2528, vgg: 0.5635, mask: 0.4014\n",
      "step:    47840, time: 0.789, loss: 1.2177, l1: 0.2681, vgg: 0.5372, mask: 0.4124\n",
      "step:    47860, time: 0.773, loss: 1.2481, l1: 0.2607, vgg: 0.5656, mask: 0.4218\n",
      "step:    47880, time: 0.783, loss: 1.1115, l1: 0.2292, vgg: 0.5190, mask: 0.3633\n",
      "step:    47900, time: 0.768, loss: 1.1606, l1: 0.2383, vgg: 0.5343, mask: 0.3880\n",
      "step:    47920, time: 0.773, loss: 1.1520, l1: 0.2211, vgg: 0.5527, mask: 0.3782\n",
      "step:    47940, time: 0.828, loss: 1.1825, l1: 0.2914, vgg: 0.5012, mask: 0.3899\n",
      "step:    47960, time: 0.749, loss: 1.2102, l1: 0.2735, vgg: 0.5429, mask: 0.3938\n",
      "step:    47980, time: 0.768, loss: 1.1476, l1: 0.2293, vgg: 0.5281, mask: 0.3902\n",
      "step:    48000, time: 0.781, loss: 1.1927, l1: 0.2436, vgg: 0.5694, mask: 0.3798\n",
      "step:    48020, time: 0.755, loss: 1.1086, l1: 0.2116, vgg: 0.5301, mask: 0.3668\n",
      "step:    48040, time: 0.753, loss: 1.1085, l1: 0.1981, vgg: 0.5607, mask: 0.3497\n",
      "step:    48060, time: 0.742, loss: 0.9343, l1: 0.1343, vgg: 0.4820, mask: 0.3181\n",
      "step:    48080, time: 0.787, loss: 1.1917, l1: 0.2130, vgg: 0.6067, mask: 0.3720\n",
      "step:    48100, time: 0.745, loss: 1.1936, l1: 0.2506, vgg: 0.5373, mask: 0.4057\n",
      "step:    48120, time: 0.763, loss: 1.1061, l1: 0.2061, vgg: 0.5235, mask: 0.3766\n",
      "step:    48140, time: 0.794, loss: 1.0744, l1: 0.2050, vgg: 0.5294, mask: 0.3399\n",
      "step:    48160, time: 0.762, loss: 1.1438, l1: 0.2450, vgg: 0.5035, mask: 0.3953\n",
      "step:    48180, time: 0.756, loss: 1.0902, l1: 0.2365, vgg: 0.4911, mask: 0.3625\n",
      "step:    48200, time: 0.773, loss: 1.0221, l1: 0.1830, vgg: 0.4691, mask: 0.3699\n",
      "step:    48220, time: 0.782, loss: 1.1068, l1: 0.2401, vgg: 0.4804, mask: 0.3863\n",
      "step:    48240, time: 0.775, loss: 1.1131, l1: 0.2078, vgg: 0.5328, mask: 0.3725\n",
      "step:    48260, time: 0.791, loss: 1.0045, l1: 0.1779, vgg: 0.4794, mask: 0.3472\n",
      "step:    48280, time: 0.823, loss: 1.3047, l1: 0.2712, vgg: 0.6141, mask: 0.4195\n",
      "step:    48300, time: 0.742, loss: 1.0493, l1: 0.2416, vgg: 0.4262, mask: 0.3816\n",
      "step:    48320, time: 0.782, loss: 1.0441, l1: 0.2056, vgg: 0.4743, mask: 0.3642\n",
      "step:    48340, time: 0.786, loss: 1.0513, l1: 0.1912, vgg: 0.5186, mask: 0.3415\n",
      "step:    48360, time: 0.768, loss: 1.1292, l1: 0.2294, vgg: 0.5284, mask: 0.3714\n",
      "step:    48380, time: 0.756, loss: 1.0955, l1: 0.2113, vgg: 0.4806, mask: 0.4035\n",
      "step:    48400, time: 0.785, loss: 1.2102, l1: 0.2694, vgg: 0.5243, mask: 0.4164\n",
      "step:    48420, time: 0.758, loss: 1.1354, l1: 0.2537, vgg: 0.4822, mask: 0.3995\n",
      "step:    48440, time: 0.775, loss: 1.2555, l1: 0.2696, vgg: 0.5938, mask: 0.3920\n",
      "step:    48460, time: 0.737, loss: 1.0407, l1: 0.1951, vgg: 0.5047, mask: 0.3409\n",
      "step:    48480, time: 0.734, loss: 1.0618, l1: 0.2078, vgg: 0.4797, mask: 0.3743\n",
      "step:    48500, time: 0.758, loss: 1.0596, l1: 0.1750, vgg: 0.5504, mask: 0.3342\n",
      "step:    48520, time: 0.755, loss: 1.1879, l1: 0.2404, vgg: 0.5298, mask: 0.4177\n",
      "step:    48540, time: 0.779, loss: 1.1561, l1: 0.2114, vgg: 0.5660, mask: 0.3788\n",
      "step:    48560, time: 0.784, loss: 1.0900, l1: 0.1957, vgg: 0.5309, mask: 0.3635\n",
      "step:    48580, time: 0.736, loss: 0.9819, l1: 0.1523, vgg: 0.4992, mask: 0.3303\n",
      "step:    48600, time: 0.768, loss: 1.1218, l1: 0.2084, vgg: 0.5243, mask: 0.3891\n",
      "step:    48620, time: 0.758, loss: 1.1828, l1: 0.2801, vgg: 0.5150, mask: 0.3877\n",
      "step:    48640, time: 0.716, loss: 1.1224, l1: 0.2155, vgg: 0.5229, mask: 0.3840\n",
      "step:    48660, time: 0.764, loss: 0.9905, l1: 0.1927, vgg: 0.4696, mask: 0.3282\n",
      "step:    48680, time: 0.750, loss: 1.0862, l1: 0.2065, vgg: 0.5107, mask: 0.3690\n",
      "step:    48700, time: 0.753, loss: 1.0355, l1: 0.2060, vgg: 0.4779, mask: 0.3516\n",
      "step:    48720, time: 0.761, loss: 1.1404, l1: 0.2551, vgg: 0.4975, mask: 0.3879\n",
      "step:    48740, time: 0.752, loss: 1.1217, l1: 0.2321, vgg: 0.5207, mask: 0.3690\n",
      "step:    48760, time: 0.771, loss: 1.2050, l1: 0.2824, vgg: 0.5468, mask: 0.3758\n",
      "step:    48780, time: 0.772, loss: 1.1859, l1: 0.2692, vgg: 0.5762, mask: 0.3405\n",
      "step:    48800, time: 0.800, loss: 1.0957, l1: 0.2138, vgg: 0.5510, mask: 0.3309\n",
      "step:    48820, time: 0.838, loss: 1.0803, l1: 0.2098, vgg: 0.4939, mask: 0.3767\n",
      "step:    48840, time: 0.746, loss: 1.1619, l1: 0.1869, vgg: 0.6114, mask: 0.3636\n",
      "step:    48860, time: 0.818, loss: 1.3474, l1: 0.2928, vgg: 0.6304, mask: 0.4242\n",
      "step:    48880, time: 0.806, loss: 1.0829, l1: 0.1929, vgg: 0.5212, mask: 0.3688\n",
      "step:    48900, time: 0.796, loss: 1.0764, l1: 0.1683, vgg: 0.5366, mask: 0.3716\n",
      "step:    48920, time: 0.776, loss: 1.1299, l1: 0.2270, vgg: 0.5407, mask: 0.3622\n",
      "step:    48940, time: 0.751, loss: 1.1518, l1: 0.2939, vgg: 0.4749, mask: 0.3831\n",
      "step:    48960, time: 0.774, loss: 1.1576, l1: 0.2496, vgg: 0.5533, mask: 0.3548\n",
      "step:    48980, time: 0.740, loss: 1.1460, l1: 0.2474, vgg: 0.5226, mask: 0.3759\n",
      "step:    49000, time: 0.759, loss: 1.0876, l1: 0.1961, vgg: 0.5228, mask: 0.3688\n",
      "step:    49020, time: 0.769, loss: 1.2283, l1: 0.2561, vgg: 0.5453, mask: 0.4269\n",
      "step:    49040, time: 0.735, loss: 1.0904, l1: 0.2216, vgg: 0.4982, mask: 0.3706\n",
      "step:    49060, time: 0.746, loss: 1.2383, l1: 0.2782, vgg: 0.5217, mask: 0.4384\n",
      "step:    49080, time: 0.803, loss: 1.0531, l1: 0.1661, vgg: 0.5278, mask: 0.3592\n",
      "step:    49100, time: 0.768, loss: 0.9616, l1: 0.1653, vgg: 0.4619, mask: 0.3343\n",
      "step:    49120, time: 0.724, loss: 1.0916, l1: 0.1718, vgg: 0.4980, mask: 0.4218\n",
      "step:    49140, time: 0.750, loss: 1.1625, l1: 0.2032, vgg: 0.5635, mask: 0.3958\n",
      "step:    49160, time: 0.760, loss: 1.2599, l1: 0.3163, vgg: 0.5278, mask: 0.4158\n",
      "step:    49180, time: 0.718, loss: 1.0918, l1: 0.2372, vgg: 0.4734, mask: 0.3812\n",
      "step:    49200, time: 0.717, loss: 0.9908, l1: 0.1764, vgg: 0.4613, mask: 0.3531\n",
      "step:    49220, time: 0.750, loss: 1.0247, l1: 0.1810, vgg: 0.4788, mask: 0.3648\n",
      "step:    49240, time: 0.792, loss: 1.0887, l1: 0.2092, vgg: 0.5075, mask: 0.3720\n",
      "step:    49260, time: 0.763, loss: 1.2433, l1: 0.2117, vgg: 0.6539, mask: 0.3777\n",
      "step:    49280, time: 0.769, loss: 1.1058, l1: 0.1996, vgg: 0.4852, mask: 0.4210\n",
      "step:    49300, time: 0.758, loss: 1.0461, l1: 0.2091, vgg: 0.4772, mask: 0.3599\n",
      "step:    49320, time: 0.778, loss: 1.0429, l1: 0.2110, vgg: 0.4649, mask: 0.3670\n",
      "step:    49340, time: 0.756, loss: 1.1614, l1: 0.2042, vgg: 0.5823, mask: 0.3748\n",
      "step:    49360, time: 0.751, loss: 1.1186, l1: 0.2408, vgg: 0.4926, mask: 0.3852\n",
      "step:    49380, time: 0.763, loss: 1.1238, l1: 0.2257, vgg: 0.5064, mask: 0.3917\n",
      "step:    49400, time: 0.740, loss: 1.1082, l1: 0.2163, vgg: 0.5283, mask: 0.3636\n",
      "step:    49420, time: 0.764, loss: 1.0142, l1: 0.1937, vgg: 0.4739, mask: 0.3466\n",
      "step:    49440, time: 0.875, loss: 1.1375, l1: 0.2280, vgg: 0.5443, mask: 0.3653\n",
      "step:    49460, time: 0.789, loss: 1.1511, l1: 0.2603, vgg: 0.5066, mask: 0.3843\n",
      "step:    49480, time: 0.752, loss: 1.0008, l1: 0.2062, vgg: 0.4438, mask: 0.3507\n",
      "step:    49500, time: 0.762, loss: 1.0875, l1: 0.2159, vgg: 0.4546, mask: 0.4171\n",
      "step:    49520, time: 0.800, loss: 1.2274, l1: 0.2489, vgg: 0.5841, mask: 0.3944\n",
      "step:    49540, time: 0.794, loss: 1.0665, l1: 0.1839, vgg: 0.5406, mask: 0.3420\n",
      "step:    49560, time: 0.779, loss: 1.1574, l1: 0.2668, vgg: 0.4839, mask: 0.4068\n",
      "step:    49580, time: 0.766, loss: 1.2120, l1: 0.2675, vgg: 0.5612, mask: 0.3833\n",
      "step:    49600, time: 0.745, loss: 0.9620, l1: 0.1731, vgg: 0.4482, mask: 0.3406\n",
      "step:    49620, time: 0.814, loss: 1.0226, l1: 0.2104, vgg: 0.4685, mask: 0.3437\n",
      "step:    49640, time: 0.780, loss: 1.0908, l1: 0.2321, vgg: 0.4920, mask: 0.3667\n",
      "step:    49660, time: 0.747, loss: 1.1719, l1: 0.2388, vgg: 0.5255, mask: 0.4075\n",
      "step:    49680, time: 0.754, loss: 1.0803, l1: 0.2105, vgg: 0.4884, mask: 0.3814\n",
      "step:    49700, time: 0.766, loss: 1.1310, l1: 0.2470, vgg: 0.5105, mask: 0.3734\n",
      "step:    49720, time: 0.787, loss: 1.3740, l1: 0.3317, vgg: 0.6302, mask: 0.4121\n",
      "step:    49740, time: 0.754, loss: 1.1743, l1: 0.2811, vgg: 0.5049, mask: 0.3883\n",
      "step:    49760, time: 0.768, loss: 1.0480, l1: 0.1907, vgg: 0.4903, mask: 0.3670\n",
      "step:    49780, time: 0.756, loss: 1.2286, l1: 0.2392, vgg: 0.5960, mask: 0.3934\n",
      "step:    49800, time: 0.742, loss: 1.0261, l1: 0.2054, vgg: 0.4668, mask: 0.3539\n",
      "step:    49820, time: 0.757, loss: 1.1434, l1: 0.2170, vgg: 0.5533, mask: 0.3731\n",
      "step:    49840, time: 0.757, loss: 1.2289, l1: 0.2628, vgg: 0.5367, mask: 0.4294\n",
      "step:    49860, time: 0.769, loss: 1.1939, l1: 0.2287, vgg: 0.5491, mask: 0.4161\n",
      "step:    49880, time: 0.789, loss: 1.1047, l1: 0.1858, vgg: 0.5483, mask: 0.3706\n",
      "step:    49900, time: 0.740, loss: 1.1227, l1: 0.2135, vgg: 0.4970, mask: 0.4122\n",
      "step:    49920, time: 0.762, loss: 1.0585, l1: 0.1964, vgg: 0.4691, mask: 0.3931\n",
      "step:    49940, time: 0.767, loss: 1.1252, l1: 0.2022, vgg: 0.5511, mask: 0.3720\n",
      "step:    49960, time: 0.766, loss: 0.9850, l1: 0.1804, vgg: 0.4572, mask: 0.3474\n",
      "step:    49980, time: 0.780, loss: 1.1714, l1: 0.2412, vgg: 0.5629, mask: 0.3673\n",
      "step:    50000, time: 0.809, loss: 1.2676, l1: 0.2461, vgg: 0.5925, mask: 0.4290\n",
      "step:    50020, time: 0.751, loss: 1.0089, l1: 0.1853, vgg: 0.4990, mask: 0.3245\n",
      "step:    50040, time: 0.761, loss: 1.0867, l1: 0.2068, vgg: 0.5069, mask: 0.3729\n",
      "step:    50060, time: 0.752, loss: 1.1519, l1: 0.2253, vgg: 0.5259, mask: 0.4007\n",
      "step:    50080, time: 0.816, loss: 1.1853, l1: 0.2333, vgg: 0.5333, mask: 0.4187\n",
      "step:    50100, time: 0.778, loss: 1.0699, l1: 0.2505, vgg: 0.4400, mask: 0.3794\n",
      "step:    50120, time: 0.764, loss: 1.1920, l1: 0.2730, vgg: 0.5357, mask: 0.3833\n",
      "step:    50140, time: 0.807, loss: 1.0621, l1: 0.2021, vgg: 0.5094, mask: 0.3506\n",
      "step:    50160, time: 0.762, loss: 1.1234, l1: 0.2058, vgg: 0.5419, mask: 0.3758\n",
      "step:    50180, time: 0.802, loss: 1.2216, l1: 0.3053, vgg: 0.5173, mask: 0.3990\n",
      "step:    50200, time: 0.762, loss: 1.1648, l1: 0.2713, vgg: 0.4935, mask: 0.4000\n",
      "step:    50220, time: 0.767, loss: 1.0897, l1: 0.2255, vgg: 0.4755, mask: 0.3888\n",
      "step:    50240, time: 0.768, loss: 1.0399, l1: 0.1814, vgg: 0.5071, mask: 0.3515\n",
      "step:    50260, time: 0.797, loss: 1.1894, l1: 0.2523, vgg: 0.5175, mask: 0.4196\n",
      "step:    50280, time: 0.806, loss: 1.0685, l1: 0.2002, vgg: 0.4852, mask: 0.3830\n",
      "step:    50300, time: 0.831, loss: 1.1054, l1: 0.1810, vgg: 0.5592, mask: 0.3652\n",
      "step:    50320, time: 0.756, loss: 1.1427, l1: 0.2095, vgg: 0.5707, mask: 0.3625\n",
      "step:    50340, time: 0.745, loss: 1.0007, l1: 0.2033, vgg: 0.4535, mask: 0.3439\n",
      "step:    50360, time: 0.761, loss: 1.1256, l1: 0.2522, vgg: 0.4709, mask: 0.4025\n",
      "step:    50380, time: 0.834, loss: 1.2408, l1: 0.2333, vgg: 0.5848, mask: 0.4227\n",
      "step:    50400, time: 0.795, loss: 1.1969, l1: 0.2259, vgg: 0.5986, mask: 0.3724\n",
      "step:    50420, time: 0.778, loss: 1.1054, l1: 0.1826, vgg: 0.5275, mask: 0.3953\n",
      "step:    50440, time: 0.770, loss: 1.1636, l1: 0.2248, vgg: 0.5350, mask: 0.4038\n",
      "step:    50460, time: 0.784, loss: 1.0490, l1: 0.2276, vgg: 0.4366, mask: 0.3847\n",
      "step:    50480, time: 0.780, loss: 1.1260, l1: 0.2382, vgg: 0.5093, mask: 0.3786\n",
      "step:    50500, time: 0.789, loss: 1.0998, l1: 0.2622, vgg: 0.4466, mask: 0.3910\n",
      "step:    50520, time: 0.846, loss: 1.0859, l1: 0.2137, vgg: 0.5128, mask: 0.3593\n",
      "step:    50540, time: 0.834, loss: 1.1376, l1: 0.2161, vgg: 0.5265, mask: 0.3951\n",
      "step:    50560, time: 0.798, loss: 1.0516, l1: 0.2109, vgg: 0.4695, mask: 0.3712\n",
      "step:    50580, time: 0.763, loss: 1.0731, l1: 0.2141, vgg: 0.4760, mask: 0.3831\n",
      "step:    50600, time: 0.769, loss: 1.1342, l1: 0.2120, vgg: 0.5414, mask: 0.3808\n",
      "step:    50620, time: 0.756, loss: 1.0535, l1: 0.1973, vgg: 0.4689, mask: 0.3873\n",
      "step:    50640, time: 0.760, loss: 1.2218, l1: 0.2378, vgg: 0.5552, mask: 0.4289\n",
      "step:    50660, time: 0.762, loss: 0.9820, l1: 0.1920, vgg: 0.4435, mask: 0.3465\n",
      "step:    50680, time: 0.724, loss: 1.0162, l1: 0.1747, vgg: 0.4785, mask: 0.3630\n",
      "step:    50700, time: 0.733, loss: 0.9491, l1: 0.1490, vgg: 0.4459, mask: 0.3543\n",
      "step:    50720, time: 0.774, loss: 1.2196, l1: 0.2474, vgg: 0.5900, mask: 0.3822\n",
      "step:    50740, time: 0.801, loss: 1.0079, l1: 0.1721, vgg: 0.4726, mask: 0.3633\n",
      "step:    50760, time: 0.747, loss: 1.0453, l1: 0.1926, vgg: 0.4911, mask: 0.3616\n",
      "step:    50780, time: 0.783, loss: 1.1028, l1: 0.1960, vgg: 0.4919, mask: 0.4149\n",
      "step:    50800, time: 0.760, loss: 1.0604, l1: 0.2032, vgg: 0.5226, mask: 0.3345\n",
      "step:    50820, time: 0.785, loss: 1.1478, l1: 0.2759, vgg: 0.4557, mask: 0.4162\n",
      "step:    50840, time: 0.783, loss: 1.0354, l1: 0.1834, vgg: 0.5174, mask: 0.3346\n",
      "step:    50860, time: 0.771, loss: 1.1854, l1: 0.2738, vgg: 0.5224, mask: 0.3892\n",
      "step:    50880, time: 0.757, loss: 1.0706, l1: 0.1896, vgg: 0.5041, mask: 0.3768\n",
      "step:    50900, time: 0.784, loss: 1.1821, l1: 0.2330, vgg: 0.5368, mask: 0.4124\n",
      "step:    50920, time: 0.779, loss: 1.0085, l1: 0.1884, vgg: 0.4867, mask: 0.3334\n",
      "step:    50940, time: 0.813, loss: 1.2286, l1: 0.2834, vgg: 0.5557, mask: 0.3896\n",
      "step:    50960, time: 0.784, loss: 1.0864, l1: 0.2101, vgg: 0.5160, mask: 0.3603\n",
      "step:    50980, time: 0.789, loss: 1.0266, l1: 0.2146, vgg: 0.4634, mask: 0.3486\n",
      "step:    51000, time: 0.791, loss: 1.0853, l1: 0.2143, vgg: 0.4821, mask: 0.3889\n",
      "step:    51020, time: 0.789, loss: 1.2278, l1: 0.2516, vgg: 0.5862, mask: 0.3901\n",
      "step:    51040, time: 0.745, loss: 1.1246, l1: 0.2775, vgg: 0.4411, mask: 0.4059\n",
      "step:    51060, time: 0.771, loss: 1.0788, l1: 0.1916, vgg: 0.5094, mask: 0.3778\n",
      "step:    51080, time: 0.746, loss: 1.0507, l1: 0.1736, vgg: 0.5141, mask: 0.3630\n",
      "step:    51100, time: 0.776, loss: 1.1530, l1: 0.2531, vgg: 0.5173, mask: 0.3826\n",
      "step:    51120, time: 0.831, loss: 1.2730, l1: 0.2647, vgg: 0.6115, mask: 0.3968\n",
      "step:    51140, time: 0.790, loss: 1.1850, l1: 0.2429, vgg: 0.5434, mask: 0.3988\n",
      "step:    51160, time: 0.732, loss: 1.1329, l1: 0.2895, vgg: 0.4694, mask: 0.3740\n",
      "step:    51180, time: 0.745, loss: 1.0980, l1: 0.2088, vgg: 0.5007, mask: 0.3886\n",
      "step:    51200, time: 0.774, loss: 1.0605, l1: 0.2409, vgg: 0.4606, mask: 0.3589\n",
      "step:    51220, time: 0.744, loss: 1.1973, l1: 0.2552, vgg: 0.5208, mask: 0.4214\n",
      "step:    51240, time: 0.788, loss: 1.0432, l1: 0.2093, vgg: 0.4994, mask: 0.3344\n",
      "step:    51260, time: 0.755, loss: 1.1597, l1: 0.2361, vgg: 0.5385, mask: 0.3851\n",
      "step:    51280, time: 0.783, loss: 1.1428, l1: 0.2510, vgg: 0.5050, mask: 0.3868\n",
      "step:    51300, time: 0.735, loss: 1.0419, l1: 0.1744, vgg: 0.4892, mask: 0.3783\n",
      "step:    51320, time: 0.787, loss: 1.1903, l1: 0.2543, vgg: 0.5389, mask: 0.3971\n",
      "step:    51340, time: 0.780, loss: 1.1032, l1: 0.2026, vgg: 0.5088, mask: 0.3919\n",
      "step:    51360, time: 0.813, loss: 1.0934, l1: 0.2282, vgg: 0.4953, mask: 0.3699\n",
      "step:    51380, time: 0.758, loss: 1.0843, l1: 0.2348, vgg: 0.4602, mask: 0.3893\n",
      "step:    51400, time: 0.767, loss: 1.2075, l1: 0.2431, vgg: 0.5686, mask: 0.3959\n",
      "step:    51420, time: 0.804, loss: 1.1528, l1: 0.2404, vgg: 0.5412, mask: 0.3712\n",
      "step:    51440, time: 0.833, loss: 1.0431, l1: 0.1944, vgg: 0.4802, mask: 0.3685\n",
      "step:    51460, time: 0.785, loss: 1.1572, l1: 0.2315, vgg: 0.5517, mask: 0.3740\n",
      "step:    51480, time: 0.771, loss: 1.3413, l1: 0.3371, vgg: 0.5863, mask: 0.4180\n",
      "step:    51500, time: 0.763, loss: 1.1345, l1: 0.2492, vgg: 0.5144, mask: 0.3709\n",
      "step:    51520, time: 0.802, loss: 1.1539, l1: 0.2345, vgg: 0.5400, mask: 0.3794\n",
      "step:    51540, time: 0.770, loss: 1.1145, l1: 0.1924, vgg: 0.5606, mask: 0.3615\n",
      "step:    51560, time: 0.747, loss: 1.0273, l1: 0.1845, vgg: 0.4869, mask: 0.3558\n",
      "step:    51580, time: 0.829, loss: 1.1883, l1: 0.2497, vgg: 0.5670, mask: 0.3716\n",
      "step:    51600, time: 0.757, loss: 1.1576, l1: 0.2269, vgg: 0.5410, mask: 0.3896\n",
      "step:    51620, time: 0.730, loss: 1.1763, l1: 0.2341, vgg: 0.5140, mask: 0.4282\n",
      "step:    51640, time: 0.743, loss: 1.0446, l1: 0.1789, vgg: 0.4997, mask: 0.3659\n",
      "step:    51660, time: 0.767, loss: 1.0579, l1: 0.1923, vgg: 0.5111, mask: 0.3544\n",
      "step:    51680, time: 0.746, loss: 1.1665, l1: 0.2598, vgg: 0.4969, mask: 0.4099\n",
      "step:    51700, time: 0.814, loss: 1.2464, l1: 0.2639, vgg: 0.5863, mask: 0.3962\n",
      "step:    51720, time: 0.791, loss: 1.1143, l1: 0.2183, vgg: 0.5254, mask: 0.3706\n",
      "step:    51740, time: 0.750, loss: 1.0536, l1: 0.1946, vgg: 0.4852, mask: 0.3739\n",
      "step:    51760, time: 0.836, loss: 1.1081, l1: 0.2305, vgg: 0.4857, mask: 0.3919\n",
      "step:    51780, time: 0.783, loss: 1.2500, l1: 0.2605, vgg: 0.5645, mask: 0.4250\n",
      "step:    51800, time: 0.766, loss: 1.0414, l1: 0.2126, vgg: 0.4540, mask: 0.3748\n",
      "step:    51820, time: 0.781, loss: 1.2371, l1: 0.2867, vgg: 0.5326, mask: 0.4178\n",
      "step:    51840, time: 0.739, loss: 1.2777, l1: 0.3320, vgg: 0.5206, mask: 0.4251\n",
      "step:    51860, time: 0.797, loss: 1.1572, l1: 0.2494, vgg: 0.4552, mask: 0.4526\n",
      "step:    51880, time: 0.779, loss: 1.1958, l1: 0.1916, vgg: 0.5960, mask: 0.4082\n",
      "step:    51900, time: 0.737, loss: 1.1150, l1: 0.2425, vgg: 0.5017, mask: 0.3709\n",
      "step:    51920, time: 0.775, loss: 1.2058, l1: 0.2653, vgg: 0.5412, mask: 0.3994\n",
      "step:    51940, time: 0.734, loss: 1.1322, l1: 0.2719, vgg: 0.4772, mask: 0.3831\n",
      "step:    51960, time: 0.751, loss: 1.0797, l1: 0.2178, vgg: 0.5022, mask: 0.3598\n",
      "step:    51980, time: 0.767, loss: 1.0579, l1: 0.2075, vgg: 0.4936, mask: 0.3568\n",
      "step:    52000, time: 0.775, loss: 1.2422, l1: 0.2702, vgg: 0.5642, mask: 0.4077\n",
      "step:    52020, time: 0.767, loss: 1.0864, l1: 0.2172, vgg: 0.5049, mask: 0.3643\n",
      "step:    52040, time: 0.765, loss: 1.1877, l1: 0.1976, vgg: 0.6595, mask: 0.3307\n",
      "step:    52060, time: 0.734, loss: 1.0056, l1: 0.1595, vgg: 0.4955, mask: 0.3506\n",
      "step:    52080, time: 0.770, loss: 1.0979, l1: 0.2519, vgg: 0.4553, mask: 0.3907\n",
      "step:    52100, time: 0.759, loss: 1.0530, l1: 0.1985, vgg: 0.4879, mask: 0.3666\n",
      "step:    52120, time: 0.764, loss: 1.1471, l1: 0.2372, vgg: 0.5190, mask: 0.3909\n",
      "step:    52140, time: 0.737, loss: 1.1331, l1: 0.2338, vgg: 0.5166, mask: 0.3826\n",
      "step:    52160, time: 0.770, loss: 1.1500, l1: 0.1966, vgg: 0.5952, mask: 0.3582\n",
      "step:    52180, time: 0.754, loss: 1.1778, l1: 0.2853, vgg: 0.5150, mask: 0.3775\n",
      "step:    52200, time: 0.790, loss: 1.0303, l1: 0.1766, vgg: 0.4930, mask: 0.3607\n",
      "step:    52220, time: 0.733, loss: 1.0832, l1: 0.2032, vgg: 0.5158, mask: 0.3642\n",
      "step:    52240, time: 0.764, loss: 1.2887, l1: 0.3001, vgg: 0.5615, mask: 0.4271\n",
      "step:    52260, time: 0.756, loss: 1.1360, l1: 0.2338, vgg: 0.5262, mask: 0.3761\n",
      "step:    52280, time: 0.781, loss: 1.1433, l1: 0.2180, vgg: 0.5466, mask: 0.3787\n",
      "step:    52300, time: 0.800, loss: 1.3277, l1: 0.3004, vgg: 0.6241, mask: 0.4033\n",
      "step:    52320, time: 0.768, loss: 1.2037, l1: 0.2573, vgg: 0.5403, mask: 0.4061\n",
      "step:    52340, time: 0.764, loss: 1.0714, l1: 0.2353, vgg: 0.4792, mask: 0.3569\n",
      "step:    52360, time: 0.746, loss: 1.1607, l1: 0.2478, vgg: 0.5575, mask: 0.3554\n",
      "step:    52380, time: 0.775, loss: 1.0549, l1: 0.1727, vgg: 0.4872, mask: 0.3950\n",
      "step:    52400, time: 0.741, loss: 1.0900, l1: 0.2255, vgg: 0.4966, mask: 0.3679\n",
      "step:    52420, time: 0.763, loss: 1.2573, l1: 0.2789, vgg: 0.5577, mask: 0.4207\n",
      "step:    52440, time: 0.752, loss: 1.1085, l1: 0.2514, vgg: 0.4908, mask: 0.3663\n",
      "step:    52460, time: 0.753, loss: 1.0323, l1: 0.1922, vgg: 0.4689, mask: 0.3713\n",
      "step:    52480, time: 0.737, loss: 1.1118, l1: 0.2445, vgg: 0.4954, mask: 0.3719\n",
      "step:    52500, time: 0.731, loss: 0.9636, l1: 0.1731, vgg: 0.4550, mask: 0.3355\n",
      "step:    52520, time: 0.755, loss: 1.1540, l1: 0.2360, vgg: 0.5363, mask: 0.3816\n",
      "step:    52540, time: 0.765, loss: 1.2621, l1: 0.2881, vgg: 0.5492, mask: 0.4248\n",
      "step:    52560, time: 0.782, loss: 1.2306, l1: 0.2771, vgg: 0.5303, mask: 0.4231\n",
      "step:    52580, time: 0.752, loss: 1.2935, l1: 0.3057, vgg: 0.5951, mask: 0.3927\n",
      "step:    52600, time: 0.731, loss: 1.1053, l1: 0.2663, vgg: 0.4583, mask: 0.3807\n",
      "step:    52620, time: 0.819, loss: 1.1843, l1: 0.2223, vgg: 0.5483, mask: 0.4137\n",
      "step:    52640, time: 0.731, loss: 1.0649, l1: 0.1989, vgg: 0.4785, mask: 0.3874\n",
      "step:    52660, time: 0.785, loss: 1.0720, l1: 0.2187, vgg: 0.4873, mask: 0.3660\n",
      "step:    52680, time: 0.743, loss: 1.1182, l1: 0.2097, vgg: 0.5234, mask: 0.3851\n",
      "step:    52700, time: 0.827, loss: 1.1671, l1: 0.2217, vgg: 0.5887, mask: 0.3568\n",
      "step:    52720, time: 0.732, loss: 1.0590, l1: 0.2019, vgg: 0.5061, mask: 0.3510\n",
      "step:    52740, time: 0.752, loss: 1.0476, l1: 0.2295, vgg: 0.4832, mask: 0.3348\n",
      "step:    52760, time: 0.762, loss: 1.0625, l1: 0.1677, vgg: 0.5368, mask: 0.3580\n",
      "step:    52780, time: 0.764, loss: 1.1535, l1: 0.2386, vgg: 0.5105, mask: 0.4045\n",
      "step:    52800, time: 0.781, loss: 1.1524, l1: 0.2273, vgg: 0.5404, mask: 0.3847\n",
      "step:    52820, time: 0.740, loss: 1.1255, l1: 0.2072, vgg: 0.5205, mask: 0.3979\n",
      "step:    52840, time: 0.755, loss: 1.1667, l1: 0.2831, vgg: 0.4853, mask: 0.3982\n",
      "step:    52860, time: 0.735, loss: 1.0229, l1: 0.1823, vgg: 0.4963, mask: 0.3443\n",
      "step:    52880, time: 0.758, loss: 1.0836, l1: 0.2116, vgg: 0.5029, mask: 0.3691\n",
      "step:    52900, time: 0.785, loss: 0.9938, l1: 0.2054, vgg: 0.4388, mask: 0.3497\n",
      "step:    52920, time: 0.760, loss: 1.0566, l1: 0.1959, vgg: 0.5253, mask: 0.3354\n",
      "step:    52940, time: 0.745, loss: 1.0514, l1: 0.1889, vgg: 0.4823, mask: 0.3802\n",
      "step:    52960, time: 0.759, loss: 1.1217, l1: 0.2212, vgg: 0.5210, mask: 0.3795\n",
      "step:    52980, time: 0.809, loss: 1.2956, l1: 0.2808, vgg: 0.5918, mask: 0.4230\n",
      "step:    53000, time: 0.744, loss: 1.0110, l1: 0.1847, vgg: 0.4561, mask: 0.3703\n",
      "step:    53020, time: 0.784, loss: 1.1808, l1: 0.2269, vgg: 0.5589, mask: 0.3950\n",
      "step:    53040, time: 0.753, loss: 1.0690, l1: 0.2276, vgg: 0.4524, mask: 0.3889\n",
      "step:    53060, time: 0.771, loss: 1.0903, l1: 0.1944, vgg: 0.5477, mask: 0.3483\n",
      "step:    53080, time: 0.774, loss: 1.1617, l1: 0.2660, vgg: 0.4738, mask: 0.4219\n",
      "step:    53100, time: 0.748, loss: 1.1471, l1: 0.2522, vgg: 0.5027, mask: 0.3922\n",
      "step:    53120, time: 0.770, loss: 1.2332, l1: 0.2129, vgg: 0.6415, mask: 0.3787\n",
      "step:    53140, time: 0.802, loss: 1.0943, l1: 0.1997, vgg: 0.5203, mask: 0.3744\n",
      "step:    53160, time: 0.789, loss: 1.2669, l1: 0.2723, vgg: 0.5760, mask: 0.4186\n",
      "step:    53180, time: 0.721, loss: 1.1123, l1: 0.2073, vgg: 0.5575, mask: 0.3475\n",
      "step:    53200, time: 0.772, loss: 1.0325, l1: 0.2172, vgg: 0.4421, mask: 0.3732\n",
      "step:    53220, time: 0.772, loss: 1.1717, l1: 0.2541, vgg: 0.5484, mask: 0.3691\n",
      "step:    53240, time: 0.748, loss: 1.0609, l1: 0.2078, vgg: 0.5109, mask: 0.3422\n",
      "step:    53260, time: 0.753, loss: 1.1225, l1: 0.2469, vgg: 0.5147, mask: 0.3610\n",
      "step:    53280, time: 0.773, loss: 1.1397, l1: 0.2683, vgg: 0.4987, mask: 0.3727\n",
      "step:    53300, time: 0.755, loss: 1.1316, l1: 0.2327, vgg: 0.4794, mask: 0.4195\n",
      "step:    53320, time: 0.750, loss: 1.0847, l1: 0.1925, vgg: 0.5123, mask: 0.3799\n",
      "step:    53340, time: 0.271, loss: 1.0063, l1: 0.1661, vgg: 0.5116, mask: 0.3286\n",
      "step:    53360, time: 0.742, loss: 1.2280, l1: 0.3004, vgg: 0.5327, mask: 0.3949\n",
      "step:    53380, time: 0.729, loss: 1.1267, l1: 0.2562, vgg: 0.4820, mask: 0.3886\n",
      "step:    53400, time: 0.783, loss: 1.1376, l1: 0.2490, vgg: 0.4907, mask: 0.3979\n",
      "step:    53420, time: 0.723, loss: 1.0184, l1: 0.2010, vgg: 0.4427, mask: 0.3747\n",
      "step:    53440, time: 0.741, loss: 1.0597, l1: 0.2256, vgg: 0.4695, mask: 0.3646\n",
      "step:    53460, time: 0.767, loss: 1.2488, l1: 0.3194, vgg: 0.5262, mask: 0.4032\n",
      "step:    53480, time: 0.730, loss: 1.0640, l1: 0.2092, vgg: 0.4808, mask: 0.3740\n",
      "step:    53500, time: 0.770, loss: 1.1464, l1: 0.2507, vgg: 0.4864, mask: 0.4093\n",
      "step:    53520, time: 0.768, loss: 1.2276, l1: 0.2302, vgg: 0.5747, mask: 0.4227\n",
      "step:    53540, time: 0.728, loss: 1.2685, l1: 0.3283, vgg: 0.5316, mask: 0.4086\n",
      "step:    53560, time: 0.755, loss: 1.1324, l1: 0.2343, vgg: 0.5252, mask: 0.3728\n",
      "step:    53580, time: 0.767, loss: 1.0800, l1: 0.2378, vgg: 0.4661, mask: 0.3762\n",
      "step:    53600, time: 0.757, loss: 1.0379, l1: 0.1783, vgg: 0.4954, mask: 0.3642\n",
      "step:    53620, time: 0.767, loss: 1.0870, l1: 0.2572, vgg: 0.4785, mask: 0.3513\n",
      "step:    53640, time: 0.753, loss: 1.2313, l1: 0.2710, vgg: 0.5408, mask: 0.4195\n",
      "step:    53660, time: 0.772, loss: 1.1120, l1: 0.2457, vgg: 0.4935, mask: 0.3728\n",
      "step:    53680, time: 0.745, loss: 0.9843, l1: 0.1801, vgg: 0.4574, mask: 0.3468\n",
      "step:    53700, time: 0.753, loss: 1.0801, l1: 0.2400, vgg: 0.4651, mask: 0.3750\n",
      "step:    53720, time: 0.761, loss: 1.1210, l1: 0.2554, vgg: 0.4723, mask: 0.3933\n",
      "step:    53740, time: 0.789, loss: 1.2441, l1: 0.2199, vgg: 0.6428, mask: 0.3814\n",
      "step:    53760, time: 0.796, loss: 1.0973, l1: 0.2252, vgg: 0.4893, mask: 0.3828\n",
      "step:    53780, time: 0.736, loss: 1.1717, l1: 0.2665, vgg: 0.5152, mask: 0.3901\n",
      "step:    53800, time: 0.716, loss: 1.1685, l1: 0.2656, vgg: 0.5149, mask: 0.3881\n",
      "step:    53820, time: 0.764, loss: 1.0110, l1: 0.1845, vgg: 0.4663, mask: 0.3602\n",
      "step:    53840, time: 0.756, loss: 1.0888, l1: 0.2669, vgg: 0.4439, mask: 0.3779\n",
      "step:    53860, time: 0.798, loss: 1.1545, l1: 0.2392, vgg: 0.5214, mask: 0.3939\n",
      "step:    53880, time: 0.801, loss: 1.1022, l1: 0.1950, vgg: 0.5675, mask: 0.3398\n",
      "step:    53900, time: 0.766, loss: 1.1435, l1: 0.2705, vgg: 0.5082, mask: 0.3648\n",
      "step:    53920, time: 0.767, loss: 1.0585, l1: 0.2151, vgg: 0.4812, mask: 0.3621\n",
      "step:    53940, time: 0.785, loss: 1.0881, l1: 0.2468, vgg: 0.4590, mask: 0.3823\n",
      "step:    53960, time: 0.768, loss: 1.1165, l1: 0.2234, vgg: 0.4723, mask: 0.4207\n",
      "step:    53980, time: 0.736, loss: 0.9549, l1: 0.1613, vgg: 0.4739, mask: 0.3197\n",
      "step:    54000, time: 0.792, loss: 1.0876, l1: 0.1930, vgg: 0.5241, mask: 0.3705\n",
      "step:    54020, time: 0.762, loss: 1.2853, l1: 0.3417, vgg: 0.5039, mask: 0.4398\n",
      "step:    54040, time: 0.732, loss: 1.0435, l1: 0.1848, vgg: 0.5082, mask: 0.3505\n",
      "step:    54060, time: 0.787, loss: 1.2154, l1: 0.2408, vgg: 0.5784, mask: 0.3962\n",
      "step:    54080, time: 0.763, loss: 1.1440, l1: 0.2292, vgg: 0.5382, mask: 0.3766\n",
      "step:    54100, time: 0.792, loss: 1.0117, l1: 0.2201, vgg: 0.4131, mask: 0.3786\n",
      "step:    54120, time: 0.782, loss: 1.1297, l1: 0.2488, vgg: 0.5141, mask: 0.3669\n",
      "step:    54140, time: 0.765, loss: 1.1155, l1: 0.2187, vgg: 0.5151, mask: 0.3817\n",
      "step:    54160, time: 0.753, loss: 1.0519, l1: 0.1986, vgg: 0.4856, mask: 0.3676\n",
      "step:    54180, time: 0.770, loss: 1.1244, l1: 0.2133, vgg: 0.5314, mask: 0.3796\n",
      "step:    54200, time: 0.807, loss: 1.1185, l1: 0.2407, vgg: 0.4996, mask: 0.3782\n",
      "step:    54220, time: 0.750, loss: 1.0109, l1: 0.1600, vgg: 0.4922, mask: 0.3586\n",
      "step:    54240, time: 0.774, loss: 1.1123, l1: 0.2474, vgg: 0.4786, mask: 0.3863\n",
      "step:    54260, time: 0.805, loss: 1.0207, l1: 0.2149, vgg: 0.4585, mask: 0.3472\n",
      "step:    54280, time: 0.765, loss: 1.0758, l1: 0.2044, vgg: 0.5106, mask: 0.3608\n",
      "step:    54300, time: 0.768, loss: 1.0291, l1: 0.1680, vgg: 0.4894, mask: 0.3717\n",
      "step:    54320, time: 0.730, loss: 1.0617, l1: 0.2108, vgg: 0.4304, mask: 0.4204\n",
      "step:    54340, time: 0.755, loss: 1.1486, l1: 0.2353, vgg: 0.5304, mask: 0.3829\n",
      "step:    54360, time: 0.765, loss: 0.9487, l1: 0.1673, vgg: 0.4463, mask: 0.3351\n",
      "step:    54380, time: 0.752, loss: 1.0389, l1: 0.1914, vgg: 0.4977, mask: 0.3498\n",
      "step:    54400, time: 0.750, loss: 1.1285, l1: 0.2418, vgg: 0.4961, mask: 0.3906\n",
      "step:    54420, time: 0.758, loss: 1.1417, l1: 0.2112, vgg: 0.5193, mask: 0.4112\n",
      "step:    54440, time: 0.749, loss: 1.0235, l1: 0.1851, vgg: 0.4857, mask: 0.3526\n",
      "step:    54460, time: 0.755, loss: 1.0087, l1: 0.2029, vgg: 0.4519, mask: 0.3538\n",
      "step:    54480, time: 0.788, loss: 1.2246, l1: 0.2990, vgg: 0.5154, mask: 0.4102\n",
      "step:    54500, time: 0.755, loss: 1.0717, l1: 0.2351, vgg: 0.4626, mask: 0.3741\n",
      "step:    54520, time: 0.759, loss: 1.2051, l1: 0.2864, vgg: 0.5183, mask: 0.4004\n",
      "step:    54540, time: 0.752, loss: 1.1957, l1: 0.2447, vgg: 0.5357, mask: 0.4152\n",
      "step:    54560, time: 0.803, loss: 1.2088, l1: 0.2711, vgg: 0.5311, mask: 0.4066\n",
      "step:    54580, time: 0.752, loss: 1.1273, l1: 0.1913, vgg: 0.5289, mask: 0.4071\n",
      "step:    54600, time: 0.757, loss: 1.1144, l1: 0.2201, vgg: 0.4924, mask: 0.4018\n",
      "step:    54620, time: 0.748, loss: 1.1048, l1: 0.2407, vgg: 0.4893, mask: 0.3747\n",
      "step:    54640, time: 0.746, loss: 1.0219, l1: 0.1962, vgg: 0.4056, mask: 0.4201\n",
      "step:    54660, time: 0.792, loss: 1.1227, l1: 0.2335, vgg: 0.4915, mask: 0.3977\n",
      "step:    54680, time: 0.776, loss: 1.0706, l1: 0.2316, vgg: 0.4688, mask: 0.3701\n",
      "step:    54700, time: 0.742, loss: 1.0422, l1: 0.2113, vgg: 0.4631, mask: 0.3678\n",
      "step:    54720, time: 0.735, loss: 1.1201, l1: 0.2424, vgg: 0.4927, mask: 0.3851\n",
      "step:    54740, time: 0.789, loss: 1.1811, l1: 0.2569, vgg: 0.5491, mask: 0.3751\n",
      "step:    54760, time: 0.731, loss: 0.9455, l1: 0.1624, vgg: 0.4519, mask: 0.3313\n",
      "step:    54780, time: 0.745, loss: 1.0355, l1: 0.1846, vgg: 0.4978, mask: 0.3532\n",
      "step:    54800, time: 0.771, loss: 1.0633, l1: 0.2173, vgg: 0.4913, mask: 0.3548\n",
      "step:    54820, time: 0.737, loss: 1.1380, l1: 0.2661, vgg: 0.4776, mask: 0.3943\n",
      "step:    54840, time: 0.772, loss: 1.1631, l1: 0.2060, vgg: 0.5728, mask: 0.3843\n",
      "step:    54860, time: 0.788, loss: 1.0951, l1: 0.2009, vgg: 0.5157, mask: 0.3785\n",
      "step:    54880, time: 0.759, loss: 1.0875, l1: 0.2040, vgg: 0.5315, mask: 0.3520\n",
      "step:    54900, time: 0.755, loss: 0.9738, l1: 0.1484, vgg: 0.4928, mask: 0.3326\n",
      "step:    54920, time: 0.803, loss: 1.2456, l1: 0.2561, vgg: 0.5914, mask: 0.3981\n",
      "step:    54940, time: 0.760, loss: 1.1446, l1: 0.2485, vgg: 0.5161, mask: 0.3799\n",
      "step:    54960, time: 0.754, loss: 0.9389, l1: 0.1481, vgg: 0.4736, mask: 0.3172\n",
      "step:    54980, time: 0.749, loss: 1.1325, l1: 0.2117, vgg: 0.4900, mask: 0.4309\n",
      "step:    55000, time: 0.806, loss: 1.2658, l1: 0.3263, vgg: 0.5235, mask: 0.4160\n",
      "step:    55020, time: 0.739, loss: 1.1019, l1: 0.2532, vgg: 0.4784, mask: 0.3704\n",
      "step:    55040, time: 0.766, loss: 1.0835, l1: 0.2480, vgg: 0.4415, mask: 0.3940\n",
      "step:    55060, time: 0.770, loss: 1.1638, l1: 0.2017, vgg: 0.5475, mask: 0.4146\n",
      "step:    55080, time: 0.769, loss: 1.1097, l1: 0.2262, vgg: 0.5112, mask: 0.3723\n",
      "step:    55100, time: 0.788, loss: 1.0779, l1: 0.2166, vgg: 0.4871, mask: 0.3742\n",
      "step:    55120, time: 0.753, loss: 1.0371, l1: 0.1734, vgg: 0.5101, mask: 0.3536\n",
      "step:    55140, time: 0.820, loss: 1.0829, l1: 0.1779, vgg: 0.4903, mask: 0.4148\n",
      "step:    55160, time: 0.750, loss: 1.1517, l1: 0.2674, vgg: 0.4846, mask: 0.3997\n",
      "step:    55180, time: 0.758, loss: 1.1290, l1: 0.2132, vgg: 0.5490, mask: 0.3667\n",
      "step:    55200, time: 0.740, loss: 1.0649, l1: 0.2064, vgg: 0.4754, mask: 0.3830\n",
      "step:    55220, time: 0.751, loss: 1.0322, l1: 0.2097, vgg: 0.4527, mask: 0.3698\n",
      "step:    55240, time: 0.735, loss: 1.0849, l1: 0.1874, vgg: 0.4942, mask: 0.4033\n",
      "step:    55260, time: 0.729, loss: 0.9460, l1: 0.1819, vgg: 0.4177, mask: 0.3464\n",
      "step:    55280, time: 0.777, loss: 1.2014, l1: 0.2368, vgg: 0.5713, mask: 0.3933\n",
      "step:    55300, time: 0.757, loss: 1.2866, l1: 0.2794, vgg: 0.5781, mask: 0.4291\n",
      "step:    55320, time: 0.723, loss: 1.1827, l1: 0.2526, vgg: 0.5415, mask: 0.3886\n",
      "step:    55340, time: 0.810, loss: 1.1017, l1: 0.2520, vgg: 0.4800, mask: 0.3697\n",
      "step:    55360, time: 0.761, loss: 0.9263, l1: 0.1551, vgg: 0.4233, mask: 0.3479\n",
      "step:    55380, time: 0.764, loss: 1.0408, l1: 0.1912, vgg: 0.4695, mask: 0.3801\n",
      "step:    55400, time: 0.726, loss: 0.9568, l1: 0.1778, vgg: 0.4467, mask: 0.3324\n",
      "step:    55420, time: 0.764, loss: 1.1148, l1: 0.2296, vgg: 0.5227, mask: 0.3625\n",
      "step:    55440, time: 0.741, loss: 1.1374, l1: 0.2440, vgg: 0.5114, mask: 0.3820\n",
      "step:    55460, time: 0.779, loss: 1.1658, l1: 0.2759, vgg: 0.4636, mask: 0.4263\n",
      "step:    55480, time: 0.792, loss: 1.1281, l1: 0.1951, vgg: 0.5626, mask: 0.3703\n",
      "step:    55500, time: 0.750, loss: 1.0927, l1: 0.2227, vgg: 0.4909, mask: 0.3791\n",
      "step:    55520, time: 0.811, loss: 1.2129, l1: 0.2546, vgg: 0.5553, mask: 0.4031\n",
      "step:    55540, time: 0.777, loss: 1.0856, l1: 0.2048, vgg: 0.5234, mask: 0.3574\n",
      "step:    55560, time: 0.760, loss: 1.2175, l1: 0.2946, vgg: 0.5311, mask: 0.3918\n",
      "step:    55580, time: 0.733, loss: 1.1109, l1: 0.2390, vgg: 0.5054, mask: 0.3664\n",
      "step:    55600, time: 0.757, loss: 1.0986, l1: 0.2062, vgg: 0.5110, mask: 0.3814\n",
      "step:    55620, time: 0.764, loss: 1.1963, l1: 0.2561, vgg: 0.5376, mask: 0.4026\n",
      "step:    55640, time: 0.732, loss: 0.9993, l1: 0.1726, vgg: 0.4908, mask: 0.3359\n",
      "step:    55660, time: 0.737, loss: 1.0689, l1: 0.2193, vgg: 0.4827, mask: 0.3669\n",
      "step:    55680, time: 0.828, loss: 1.1899, l1: 0.2315, vgg: 0.6113, mask: 0.3471\n",
      "step:    55700, time: 0.766, loss: 1.0614, l1: 0.2207, vgg: 0.4481, mask: 0.3925\n",
      "step:    55720, time: 0.760, loss: 1.2362, l1: 0.2517, vgg: 0.5667, mask: 0.4178\n",
      "step:    55740, time: 0.747, loss: 1.0844, l1: 0.2156, vgg: 0.4524, mask: 0.4164\n",
      "step:    55760, time: 0.754, loss: 1.0732, l1: 0.2603, vgg: 0.4549, mask: 0.3580\n",
      "step:    55780, time: 0.742, loss: 0.9927, l1: 0.2118, vgg: 0.4114, mask: 0.3695\n",
      "step:    55800, time: 0.773, loss: 1.1220, l1: 0.2038, vgg: 0.5298, mask: 0.3884\n",
      "step:    55820, time: 0.752, loss: 1.0650, l1: 0.1947, vgg: 0.5082, mask: 0.3621\n",
      "step:    55840, time: 0.781, loss: 1.0642, l1: 0.2313, vgg: 0.4772, mask: 0.3558\n",
      "step:    55860, time: 0.741, loss: 1.0954, l1: 0.1799, vgg: 0.5711, mask: 0.3444\n",
      "step:    55880, time: 0.824, loss: 1.1610, l1: 0.2821, vgg: 0.4831, mask: 0.3958\n",
      "step:    55900, time: 0.752, loss: 1.1478, l1: 0.2833, vgg: 0.4892, mask: 0.3753\n",
      "step:    55920, time: 0.777, loss: 1.2230, l1: 0.2474, vgg: 0.5774, mask: 0.3982\n",
      "step:    55940, time: 0.764, loss: 1.0290, l1: 0.1964, vgg: 0.4693, mask: 0.3633\n",
      "step:    55960, time: 0.767, loss: 1.2300, l1: 0.2775, vgg: 0.5670, mask: 0.3855\n",
      "step:    55980, time: 0.776, loss: 1.1300, l1: 0.2004, vgg: 0.5406, mask: 0.3890\n",
      "step:    56000, time: 0.746, loss: 1.1368, l1: 0.2720, vgg: 0.4614, mask: 0.4034\n",
      "step:    56020, time: 0.813, loss: 1.1976, l1: 0.2641, vgg: 0.5337, mask: 0.3999\n",
      "step:    56040, time: 0.780, loss: 1.2024, l1: 0.2282, vgg: 0.6049, mask: 0.3693\n",
      "step:    56060, time: 0.782, loss: 1.1168, l1: 0.2761, vgg: 0.4575, mask: 0.3833\n",
      "step:    56080, time: 0.752, loss: 1.1032, l1: 0.1916, vgg: 0.5381, mask: 0.3736\n",
      "step:    56100, time: 0.750, loss: 1.0551, l1: 0.2059, vgg: 0.4919, mask: 0.3572\n",
      "step:    56120, time: 0.748, loss: 1.0740, l1: 0.2017, vgg: 0.5157, mask: 0.3566\n",
      "step:    56140, time: 0.802, loss: 1.1905, l1: 0.2551, vgg: 0.5372, mask: 0.3982\n",
      "step:    56160, time: 0.760, loss: 1.0752, l1: 0.2132, vgg: 0.5049, mask: 0.3571\n",
      "step:    56180, time: 0.745, loss: 1.1867, l1: 0.2530, vgg: 0.5461, mask: 0.3876\n",
      "step:    56200, time: 0.786, loss: 1.2711, l1: 0.2524, vgg: 0.6229, mask: 0.3957\n",
      "step:    56220, time: 0.794, loss: 1.2638, l1: 0.2780, vgg: 0.5907, mask: 0.3951\n",
      "step:    56240, time: 0.762, loss: 1.1253, l1: 0.2543, vgg: 0.5025, mask: 0.3685\n",
      "step:    56260, time: 0.771, loss: 1.1693, l1: 0.2245, vgg: 0.5817, mask: 0.3630\n",
      "step:    56280, time: 0.779, loss: 1.0971, l1: 0.2260, vgg: 0.4986, mask: 0.3725\n",
      "step:    56300, time: 0.774, loss: 1.0383, l1: 0.2038, vgg: 0.4844, mask: 0.3501\n",
      "step:    56320, time: 0.776, loss: 1.1052, l1: 0.2134, vgg: 0.4890, mask: 0.4029\n",
      "step:    56340, time: 0.772, loss: 1.1968, l1: 0.2100, vgg: 0.5854, mask: 0.4015\n",
      "step:    56360, time: 0.749, loss: 1.0636, l1: 0.1946, vgg: 0.5185, mask: 0.3505\n",
      "step:    56380, time: 0.739, loss: 1.1138, l1: 0.2012, vgg: 0.5211, mask: 0.3915\n",
      "step:    56400, time: 0.771, loss: 1.1907, l1: 0.2506, vgg: 0.5462, mask: 0.3939\n",
      "step:    56420, time: 0.747, loss: 0.9683, l1: 0.1573, vgg: 0.4885, mask: 0.3225\n",
      "step:    56440, time: 0.760, loss: 1.0384, l1: 0.2360, vgg: 0.4232, mask: 0.3792\n",
      "step:    56460, time: 0.745, loss: 1.0290, l1: 0.2028, vgg: 0.4495, mask: 0.3767\n",
      "step:    56480, time: 0.758, loss: 1.0330, l1: 0.2344, vgg: 0.4150, mask: 0.3835\n",
      "step:    56500, time: 0.792, loss: 1.2350, l1: 0.2497, vgg: 0.5982, mask: 0.3871\n",
      "step:    56520, time: 0.747, loss: 1.1390, l1: 0.2377, vgg: 0.4996, mask: 0.4017\n",
      "step:    56540, time: 0.745, loss: 1.0588, l1: 0.2183, vgg: 0.4556, mask: 0.3849\n",
      "step:    56560, time: 0.783, loss: 1.2581, l1: 0.2614, vgg: 0.5967, mask: 0.3999\n",
      "step:    56580, time: 0.741, loss: 0.9759, l1: 0.1603, vgg: 0.4720, mask: 0.3436\n",
      "step:    56600, time: 0.730, loss: 1.0066, l1: 0.2046, vgg: 0.4469, mask: 0.3550\n",
      "step:    56620, time: 0.752, loss: 1.0630, l1: 0.1861, vgg: 0.5075, mask: 0.3694\n",
      "step:    56640, time: 0.739, loss: 1.1850, l1: 0.2356, vgg: 0.5606, mask: 0.3888\n",
      "step:    56660, time: 0.733, loss: 1.0741, l1: 0.1944, vgg: 0.5127, mask: 0.3671\n",
      "step:    56680, time: 0.856, loss: 1.0631, l1: 0.1806, vgg: 0.5120, mask: 0.3704\n",
      "step:    56700, time: 0.721, loss: 1.1449, l1: 0.2503, vgg: 0.5190, mask: 0.3756\n",
      "step:    56720, time: 0.749, loss: 1.1366, l1: 0.2258, vgg: 0.5538, mask: 0.3570\n",
      "step:    56740, time: 0.762, loss: 1.3020, l1: 0.2784, vgg: 0.6523, mask: 0.3713\n",
      "step:    56760, time: 0.736, loss: 1.0298, l1: 0.1957, vgg: 0.4793, mask: 0.3548\n",
      "step:    56780, time: 0.733, loss: 0.9632, l1: 0.1660, vgg: 0.4686, mask: 0.3286\n",
      "step:    56800, time: 0.751, loss: 1.0378, l1: 0.2327, vgg: 0.4529, mask: 0.3522\n",
      "step:    56820, time: 0.740, loss: 1.1168, l1: 0.2418, vgg: 0.5310, mask: 0.3439\n",
      "step:    56840, time: 0.748, loss: 1.0453, l1: 0.1739, vgg: 0.5068, mask: 0.3646\n",
      "step:    56860, time: 0.755, loss: 1.1918, l1: 0.2638, vgg: 0.5196, mask: 0.4084\n",
      "step:    56880, time: 0.752, loss: 1.1111, l1: 0.2351, vgg: 0.5063, mask: 0.3697\n",
      "step:    56900, time: 0.761, loss: 1.1488, l1: 0.2376, vgg: 0.5390, mask: 0.3721\n",
      "step:    56920, time: 0.795, loss: 1.1258, l1: 0.2312, vgg: 0.5258, mask: 0.3688\n",
      "step:    56940, time: 0.760, loss: 1.1089, l1: 0.2669, vgg: 0.4404, mask: 0.4016\n",
      "step:    56960, time: 0.795, loss: 1.1677, l1: 0.2335, vgg: 0.5533, mask: 0.3808\n",
      "step:    56980, time: 0.741, loss: 1.1039, l1: 0.2251, vgg: 0.4983, mask: 0.3804\n",
      "step:    57000, time: 0.744, loss: 1.1461, l1: 0.2114, vgg: 0.5662, mask: 0.3685\n",
      "step:    57020, time: 0.757, loss: 1.0657, l1: 0.2223, vgg: 0.4776, mask: 0.3658\n",
      "step:    57040, time: 0.746, loss: 1.1833, l1: 0.2802, vgg: 0.5077, mask: 0.3954\n",
      "step:    57060, time: 0.754, loss: 1.0092, l1: 0.1904, vgg: 0.4505, mask: 0.3682\n",
      "step:    57080, time: 0.737, loss: 1.1198, l1: 0.2306, vgg: 0.5182, mask: 0.3710\n",
      "step:    57100, time: 0.734, loss: 0.9270, l1: 0.1683, vgg: 0.4147, mask: 0.3440\n",
      "step:    57120, time: 0.785, loss: 1.1327, l1: 0.2453, vgg: 0.5050, mask: 0.3825\n",
      "step:    57140, time: 0.771, loss: 1.0680, l1: 0.1715, vgg: 0.5140, mask: 0.3825\n",
      "step:    57160, time: 0.748, loss: 1.1322, l1: 0.2889, vgg: 0.4337, mask: 0.4096\n",
      "step:    57180, time: 0.793, loss: 1.1179, l1: 0.1989, vgg: 0.5143, mask: 0.4048\n",
      "step:    57200, time: 0.756, loss: 1.1775, l1: 0.2816, vgg: 0.5078, mask: 0.3881\n",
      "step:    57220, time: 0.766, loss: 1.1736, l1: 0.2488, vgg: 0.5519, mask: 0.3729\n",
      "step:    57240, time: 0.792, loss: 1.1788, l1: 0.2389, vgg: 0.5275, mask: 0.4125\n",
      "step:    57260, time: 0.757, loss: 1.0381, l1: 0.2003, vgg: 0.4784, mask: 0.3594\n",
      "step:    57280, time: 0.776, loss: 1.0121, l1: 0.1661, vgg: 0.4921, mask: 0.3539\n",
      "step:    57300, time: 0.776, loss: 1.1301, l1: 0.2263, vgg: 0.5266, mask: 0.3772\n",
      "step:    57320, time: 0.756, loss: 1.1263, l1: 0.2295, vgg: 0.5166, mask: 0.3802\n",
      "step:    57340, time: 0.796, loss: 1.1679, l1: 0.2200, vgg: 0.5138, mask: 0.4342\n",
      "step:    57360, time: 0.759, loss: 1.2962, l1: 0.2658, vgg: 0.6092, mask: 0.4212\n",
      "step:    57380, time: 0.763, loss: 1.1987, l1: 0.2611, vgg: 0.5490, mask: 0.3887\n",
      "step:    57400, time: 0.748, loss: 1.0725, l1: 0.2289, vgg: 0.5010, mask: 0.3425\n",
      "step:    57420, time: 0.773, loss: 0.9960, l1: 0.2035, vgg: 0.4699, mask: 0.3227\n",
      "step:    57440, time: 0.731, loss: 1.1046, l1: 0.2219, vgg: 0.5144, mask: 0.3683\n",
      "step:    57460, time: 0.752, loss: 0.9631, l1: 0.1963, vgg: 0.4297, mask: 0.3371\n",
      "step:    57480, time: 0.768, loss: 1.1412, l1: 0.2547, vgg: 0.4844, mask: 0.4022\n",
      "step:    57500, time: 0.765, loss: 1.1785, l1: 0.2488, vgg: 0.5574, mask: 0.3722\n",
      "step:    57520, time: 0.758, loss: 1.0405, l1: 0.2006, vgg: 0.4805, mask: 0.3594\n",
      "step:    57540, time: 0.757, loss: 1.0520, l1: 0.2081, vgg: 0.4606, mask: 0.3833\n",
      "step:    57560, time: 0.740, loss: 1.2074, l1: 0.2773, vgg: 0.5232, mask: 0.4070\n",
      "step:    57580, time: 0.776, loss: 1.0680, l1: 0.2179, vgg: 0.4766, mask: 0.3735\n",
      "step:    57600, time: 0.780, loss: 1.1461, l1: 0.2282, vgg: 0.5299, mask: 0.3881\n",
      "step:    57620, time: 0.786, loss: 1.1376, l1: 0.2293, vgg: 0.5440, mask: 0.3643\n",
      "step:    57640, time: 0.754, loss: 1.0735, l1: 0.2266, vgg: 0.4617, mask: 0.3851\n",
      "step:    57660, time: 0.791, loss: 1.1649, l1: 0.2337, vgg: 0.5607, mask: 0.3705\n",
      "step:    57680, time: 0.722, loss: 0.9832, l1: 0.1963, vgg: 0.4431, mask: 0.3438\n",
      "step:    57700, time: 0.752, loss: 1.1733, l1: 0.2455, vgg: 0.5357, mask: 0.3922\n",
      "step:    57720, time: 0.792, loss: 0.9917, l1: 0.1917, vgg: 0.4691, mask: 0.3308\n",
      "step:    57740, time: 0.735, loss: 1.0660, l1: 0.2074, vgg: 0.4622, mask: 0.3965\n",
      "step:    57760, time: 0.755, loss: 1.0263, l1: 0.2025, vgg: 0.4621, mask: 0.3618\n",
      "step:    57780, time: 0.758, loss: 1.1692, l1: 0.2473, vgg: 0.5314, mask: 0.3905\n",
      "step:    57800, time: 0.794, loss: 1.1466, l1: 0.2376, vgg: 0.5318, mask: 0.3772\n",
      "step:    57820, time: 0.767, loss: 1.1345, l1: 0.2347, vgg: 0.4594, mask: 0.4404\n",
      "step:    57840, time: 0.753, loss: 1.0746, l1: 0.2138, vgg: 0.4968, mask: 0.3640\n",
      "step:    57860, time: 0.781, loss: 1.0644, l1: 0.2211, vgg: 0.4515, mask: 0.3918\n",
      "step:    57880, time: 0.718, loss: 1.1460, l1: 0.2874, vgg: 0.4498, mask: 0.4087\n",
      "step:    57900, time: 0.742, loss: 1.0885, l1: 0.2519, vgg: 0.4876, mask: 0.3490\n",
      "step:    57920, time: 0.769, loss: 1.2520, l1: 0.3020, vgg: 0.5075, mask: 0.4425\n",
      "step:    57940, time: 0.751, loss: 1.1238, l1: 0.2011, vgg: 0.5538, mask: 0.3690\n",
      "step:    57960, time: 0.787, loss: 1.1934, l1: 0.2654, vgg: 0.5198, mask: 0.4083\n",
      "step:    57980, time: 0.739, loss: 1.0052, l1: 0.1917, vgg: 0.4639, mask: 0.3497\n",
      "step:    58000, time: 0.777, loss: 1.2462, l1: 0.2566, vgg: 0.6174, mask: 0.3722\n",
      "step:    58020, time: 0.766, loss: 1.1217, l1: 0.1903, vgg: 0.5862, mask: 0.3453\n",
      "step:    58040, time: 0.778, loss: 1.0945, l1: 0.2290, vgg: 0.5041, mask: 0.3614\n",
      "step:    58060, time: 0.765, loss: 1.1816, l1: 0.2703, vgg: 0.5332, mask: 0.3782\n",
      "step:    58080, time: 0.761, loss: 1.0791, l1: 0.2340, vgg: 0.4842, mask: 0.3609\n",
      "step:    58100, time: 0.766, loss: 1.0100, l1: 0.2074, vgg: 0.4332, mask: 0.3694\n",
      "step:    58120, time: 0.799, loss: 1.1216, l1: 0.2069, vgg: 0.5280, mask: 0.3867\n",
      "step:    58140, time: 0.793, loss: 1.1627, l1: 0.2405, vgg: 0.5098, mask: 0.4123\n",
      "step:    58160, time: 0.733, loss: 0.9994, l1: 0.1735, vgg: 0.4736, mask: 0.3524\n",
      "step:    58180, time: 0.772, loss: 1.1361, l1: 0.2238, vgg: 0.5505, mask: 0.3618\n",
      "step:    58200, time: 0.779, loss: 1.1091, l1: 0.1993, vgg: 0.5296, mask: 0.3803\n",
      "step:    58220, time: 0.793, loss: 1.0679, l1: 0.2608, vgg: 0.4385, mask: 0.3686\n",
      "step:    58240, time: 0.749, loss: 1.0241, l1: 0.2219, vgg: 0.4506, mask: 0.3516\n",
      "step:    58260, time: 0.759, loss: 1.1604, l1: 0.2714, vgg: 0.4962, mask: 0.3928\n",
      "step:    58280, time: 0.789, loss: 1.1048, l1: 0.2229, vgg: 0.5042, mask: 0.3778\n",
      "step:    58300, time: 0.731, loss: 1.0409, l1: 0.1749, vgg: 0.5216, mask: 0.3444\n",
      "step:    58320, time: 0.793, loss: 1.1778, l1: 0.2389, vgg: 0.5264, mask: 0.4125\n",
      "step:    58340, time: 0.796, loss: 1.1134, l1: 0.1842, vgg: 0.5276, mask: 0.4017\n",
      "step:    58360, time: 0.754, loss: 1.1002, l1: 0.2386, vgg: 0.5097, mask: 0.3519\n",
      "step:    58380, time: 0.735, loss: 0.9779, l1: 0.1524, vgg: 0.4987, mask: 0.3268\n",
      "step:    58400, time: 0.766, loss: 0.9955, l1: 0.1938, vgg: 0.4604, mask: 0.3413\n",
      "step:    58420, time: 0.787, loss: 1.1417, l1: 0.1813, vgg: 0.5695, mask: 0.3910\n",
      "step:    58440, time: 0.758, loss: 1.0750, l1: 0.2062, vgg: 0.4995, mask: 0.3692\n",
      "step:    58460, time: 0.790, loss: 1.1785, l1: 0.2464, vgg: 0.5290, mask: 0.4031\n",
      "step:    58480, time: 0.730, loss: 1.1056, l1: 0.2694, vgg: 0.4400, mask: 0.3962\n",
      "step:    58500, time: 0.836, loss: 1.3279, l1: 0.3221, vgg: 0.5886, mask: 0.4172\n",
      "step:    58520, time: 0.742, loss: 0.9995, l1: 0.1807, vgg: 0.4794, mask: 0.3394\n",
      "step:    58540, time: 0.745, loss: 0.9609, l1: 0.1577, vgg: 0.4800, mask: 0.3232\n",
      "step:    58560, time: 0.762, loss: 1.2277, l1: 0.2947, vgg: 0.4968, mask: 0.4361\n",
      "step:    58580, time: 0.755, loss: 1.1195, l1: 0.2486, vgg: 0.4642, mask: 0.4067\n",
      "step:    58600, time: 0.791, loss: 1.1079, l1: 0.2605, vgg: 0.4735, mask: 0.3739\n",
      "step:    58620, time: 0.765, loss: 1.2117, l1: 0.2848, vgg: 0.5341, mask: 0.3928\n",
      "step:    58640, time: 0.776, loss: 0.9857, l1: 0.1487, vgg: 0.4668, mask: 0.3702\n",
      "step:    58660, time: 0.749, loss: 1.1313, l1: 0.2606, vgg: 0.4802, mask: 0.3905\n",
      "step:    58680, time: 0.764, loss: 1.1192, l1: 0.2205, vgg: 0.5329, mask: 0.3657\n",
      "step:    58700, time: 0.717, loss: 1.0306, l1: 0.2201, vgg: 0.4655, mask: 0.3451\n",
      "step:    58720, time: 0.748, loss: 1.0934, l1: 0.2501, vgg: 0.4392, mask: 0.4041\n",
      "step:    58740, time: 0.768, loss: 1.2136, l1: 0.2654, vgg: 0.5553, mask: 0.3929\n",
      "step:    58760, time: 0.739, loss: 1.1133, l1: 0.1846, vgg: 0.5684, mask: 0.3603\n",
      "step:    58780, time: 0.780, loss: 1.1378, l1: 0.2106, vgg: 0.5575, mask: 0.3698\n",
      "step:    58800, time: 0.800, loss: 1.1811, l1: 0.2583, vgg: 0.5243, mask: 0.3986\n",
      "step:    58820, time: 0.723, loss: 1.0210, l1: 0.1811, vgg: 0.4921, mask: 0.3478\n",
      "step:    58840, time: 0.740, loss: 1.1434, l1: 0.2585, vgg: 0.5036, mask: 0.3814\n",
      "step:    58860, time: 0.722, loss: 1.0604, l1: 0.2392, vgg: 0.4427, mask: 0.3785\n",
      "step:    58880, time: 0.772, loss: 1.2864, l1: 0.2285, vgg: 0.6712, mask: 0.3867\n",
      "step:    58900, time: 0.747, loss: 1.1793, l1: 0.2433, vgg: 0.5525, mask: 0.3836\n",
      "step:    58920, time: 0.764, loss: 1.1476, l1: 0.2471, vgg: 0.5117, mask: 0.3887\n",
      "step:    58940, time: 0.764, loss: 1.2055, l1: 0.2424, vgg: 0.5723, mask: 0.3908\n",
      "step:    58960, time: 0.753, loss: 1.0686, l1: 0.2086, vgg: 0.5243, mask: 0.3358\n",
      "step:    58980, time: 0.738, loss: 1.1225, l1: 0.2103, vgg: 0.5457, mask: 0.3665\n",
      "step:    59000, time: 0.715, loss: 1.1215, l1: 0.2188, vgg: 0.5222, mask: 0.3805\n",
      "step:    59020, time: 0.734, loss: 1.0193, l1: 0.1682, vgg: 0.4750, mask: 0.3762\n",
      "step:    59040, time: 0.715, loss: 1.1072, l1: 0.2279, vgg: 0.4922, mask: 0.3871\n",
      "step:    59060, time: 0.760, loss: 1.0684, l1: 0.2060, vgg: 0.5023, mask: 0.3602\n",
      "step:    59080, time: 0.764, loss: 1.1467, l1: 0.2362, vgg: 0.5392, mask: 0.3713\n",
      "step:    59100, time: 0.770, loss: 1.0693, l1: 0.2192, vgg: 0.4777, mask: 0.3723\n",
      "step:    59120, time: 0.795, loss: 1.0909, l1: 0.2025, vgg: 0.5220, mask: 0.3665\n",
      "step:    59140, time: 0.744, loss: 1.1612, l1: 0.2295, vgg: 0.5019, mask: 0.4298\n",
      "step:    59160, time: 0.736, loss: 1.0162, l1: 0.2174, vgg: 0.4330, mask: 0.3658\n",
      "step:    59180, time: 0.753, loss: 1.1418, l1: 0.2349, vgg: 0.5119, mask: 0.3950\n",
      "step:    59200, time: 0.751, loss: 1.1703, l1: 0.2571, vgg: 0.5092, mask: 0.4039\n",
      "step:    59220, time: 0.734, loss: 1.0122, l1: 0.2065, vgg: 0.4523, mask: 0.3534\n",
      "step:    59240, time: 0.753, loss: 1.1970, l1: 0.2879, vgg: 0.4915, mask: 0.4176\n",
      "step:    59260, time: 0.718, loss: 1.2616, l1: 0.3277, vgg: 0.5225, mask: 0.4114\n",
      "step:    59280, time: 0.775, loss: 1.0848, l1: 0.1846, vgg: 0.5406, mask: 0.3596\n",
      "step:    59300, time: 0.723, loss: 1.1842, l1: 0.2542, vgg: 0.5404, mask: 0.3896\n",
      "step:    59320, time: 0.768, loss: 1.1931, l1: 0.2369, vgg: 0.6013, mask: 0.3550\n",
      "step:    59340, time: 0.832, loss: 1.1976, l1: 0.2564, vgg: 0.5435, mask: 0.3977\n",
      "step:    59360, time: 0.781, loss: 0.9576, l1: 0.1793, vgg: 0.4500, mask: 0.3283\n",
      "step:    59380, time: 0.762, loss: 1.1532, l1: 0.2619, vgg: 0.4910, mask: 0.4004\n",
      "step:    59400, time: 0.757, loss: 1.1056, l1: 0.2195, vgg: 0.5066, mask: 0.3795\n",
      "step:    59420, time: 0.726, loss: 0.9934, l1: 0.1793, vgg: 0.4758, mask: 0.3383\n",
      "step:    59440, time: 0.769, loss: 1.1165, l1: 0.2378, vgg: 0.5003, mask: 0.3784\n",
      "step:    59460, time: 0.797, loss: 1.0897, l1: 0.2397, vgg: 0.4907, mask: 0.3593\n",
      "step:    59480, time: 0.772, loss: 1.1716, l1: 0.2554, vgg: 0.5395, mask: 0.3767\n",
      "step:    59500, time: 0.751, loss: 1.1244, l1: 0.2148, vgg: 0.5324, mask: 0.3771\n",
      "step:    59520, time: 0.752, loss: 1.0701, l1: 0.2318, vgg: 0.4618, mask: 0.3765\n",
      "step:    59540, time: 0.766, loss: 1.0734, l1: 0.2001, vgg: 0.4898, mask: 0.3835\n",
      "step:    59560, time: 0.805, loss: 1.1953, l1: 0.2470, vgg: 0.5485, mask: 0.3997\n",
      "step:    59580, time: 0.772, loss: 0.9494, l1: 0.1675, vgg: 0.3956, mask: 0.3864\n",
      "step:    59600, time: 0.736, loss: 1.0933, l1: 0.2117, vgg: 0.5058, mask: 0.3757\n",
      "step:    59620, time: 0.786, loss: 1.1636, l1: 0.2280, vgg: 0.5053, mask: 0.4303\n",
      "step:    59640, time: 0.850, loss: 1.1466, l1: 0.2433, vgg: 0.4997, mask: 0.4037\n",
      "step:    59660, time: 0.787, loss: 1.1291, l1: 0.2364, vgg: 0.4715, mask: 0.4212\n",
      "step:    59680, time: 0.816, loss: 1.1938, l1: 0.2370, vgg: 0.5530, mask: 0.4038\n",
      "step:    59700, time: 0.827, loss: 1.1634, l1: 0.2410, vgg: 0.5366, mask: 0.3857\n",
      "step:    59720, time: 0.755, loss: 1.0535, l1: 0.1878, vgg: 0.5021, mask: 0.3636\n",
      "step:    59740, time: 0.842, loss: 1.0963, l1: 0.2491, vgg: 0.4653, mask: 0.3820\n",
      "step:    59760, time: 0.742, loss: 1.0495, l1: 0.2084, vgg: 0.4941, mask: 0.3470\n",
      "step:    59780, time: 0.826, loss: 1.2753, l1: 0.2545, vgg: 0.6141, mask: 0.4068\n",
      "step:    59800, time: 0.759, loss: 1.0801, l1: 0.2439, vgg: 0.4609, mask: 0.3752\n",
      "step:    59820, time: 0.809, loss: 1.2789, l1: 0.2792, vgg: 0.5923, mask: 0.4074\n",
      "step:    59840, time: 0.765, loss: 1.0102, l1: 0.2046, vgg: 0.4340, mask: 0.3716\n",
      "step:    59860, time: 0.780, loss: 1.0706, l1: 0.1997, vgg: 0.4671, mask: 0.4038\n",
      "step:    59880, time: 0.765, loss: 1.0758, l1: 0.2022, vgg: 0.5152, mask: 0.3583\n",
      "step:    59900, time: 0.757, loss: 1.1083, l1: 0.2089, vgg: 0.5228, mask: 0.3765\n",
      "step:    59920, time: 0.731, loss: 1.0132, l1: 0.1905, vgg: 0.4627, mask: 0.3601\n",
      "step:    59940, time: 0.745, loss: 1.1553, l1: 0.2363, vgg: 0.5424, mask: 0.3767\n",
      "step:    59960, time: 0.781, loss: 1.0161, l1: 0.1789, vgg: 0.4957, mask: 0.3415\n",
      "step:    59980, time: 0.756, loss: 1.0730, l1: 0.2155, vgg: 0.4866, mask: 0.3710\n",
      "step:    60000, time: 0.783, loss: 1.1145, l1: 0.2043, vgg: 0.5289, mask: 0.3813\n",
      "step:    60020, time: 0.797, loss: 1.0289, l1: 0.1961, vgg: 0.4958, mask: 0.3371\n",
      "step:    60040, time: 0.747, loss: 1.0269, l1: 0.1957, vgg: 0.4656, mask: 0.3655\n",
      "step:    60060, time: 0.768, loss: 1.2836, l1: 0.2706, vgg: 0.6425, mask: 0.3706\n",
      "step:    60080, time: 0.763, loss: 1.2882, l1: 0.2883, vgg: 0.5674, mask: 0.4326\n",
      "step:    60100, time: 0.764, loss: 1.2223, l1: 0.2702, vgg: 0.5570, mask: 0.3951\n",
      "step:    60120, time: 0.762, loss: 1.0598, l1: 0.2041, vgg: 0.4946, mask: 0.3610\n",
      "step:    60140, time: 0.725, loss: 1.0101, l1: 0.1431, vgg: 0.4769, mask: 0.3901\n",
      "step:    60160, time: 0.784, loss: 1.0581, l1: 0.2234, vgg: 0.4555, mask: 0.3792\n",
      "step:    60180, time: 0.769, loss: 0.9999, l1: 0.1728, vgg: 0.4759, mask: 0.3512\n",
      "step:    60200, time: 0.715, loss: 0.9715, l1: 0.1912, vgg: 0.3941, mask: 0.3862\n",
      "step:    60220, time: 0.738, loss: 1.0454, l1: 0.1987, vgg: 0.5060, mask: 0.3407\n",
      "step:    60240, time: 0.757, loss: 1.1847, l1: 0.2734, vgg: 0.4983, mask: 0.4131\n",
      "step:    60260, time: 0.738, loss: 1.0307, l1: 0.1522, vgg: 0.5423, mask: 0.3362\n",
      "step:    60280, time: 0.760, loss: 1.2018, l1: 0.2530, vgg: 0.5552, mask: 0.3935\n",
      "step:    60300, time: 0.775, loss: 1.1995, l1: 0.2728, vgg: 0.5166, mask: 0.4101\n",
      "step:    60320, time: 0.751, loss: 1.0649, l1: 0.2045, vgg: 0.4974, mask: 0.3630\n",
      "step:    60340, time: 0.746, loss: 1.1080, l1: 0.2459, vgg: 0.4583, mask: 0.4037\n",
      "step:    60360, time: 0.736, loss: 1.1690, l1: 0.2182, vgg: 0.5757, mask: 0.3752\n",
      "step:    60380, time: 0.757, loss: 1.1264, l1: 0.2489, vgg: 0.5180, mask: 0.3594\n",
      "step:    60400, time: 0.749, loss: 1.0912, l1: 0.2127, vgg: 0.5058, mask: 0.3727\n",
      "step:    60420, time: 0.761, loss: 1.0513, l1: 0.2040, vgg: 0.4744, mask: 0.3729\n",
      "step:    60440, time: 0.736, loss: 1.0556, l1: 0.2243, vgg: 0.4614, mask: 0.3699\n",
      "step:    60460, time: 0.743, loss: 1.1158, l1: 0.1895, vgg: 0.5552, mask: 0.3711\n",
      "step:    60480, time: 0.784, loss: 1.0979, l1: 0.2278, vgg: 0.4578, mask: 0.4123\n",
      "step:    60500, time: 0.771, loss: 1.1445, l1: 0.2079, vgg: 0.5020, mask: 0.4346\n",
      "step:    60520, time: 0.732, loss: 0.9601, l1: 0.1644, vgg: 0.4400, mask: 0.3557\n",
      "step:    60540, time: 0.774, loss: 1.0721, l1: 0.2290, vgg: 0.4583, mask: 0.3849\n",
      "step:    60560, time: 0.764, loss: 1.3331, l1: 0.3180, vgg: 0.5546, mask: 0.4605\n",
      "step:    60580, time: 0.786, loss: 1.0958, l1: 0.2392, vgg: 0.4835, mask: 0.3731\n",
      "step:    60600, time: 0.809, loss: 1.0700, l1: 0.2103, vgg: 0.4951, mask: 0.3645\n",
      "step:    60620, time: 0.768, loss: 1.0712, l1: 0.2033, vgg: 0.5181, mask: 0.3498\n",
      "step:    60640, time: 0.727, loss: 1.1260, l1: 0.2487, vgg: 0.4836, mask: 0.3936\n",
      "step:    60660, time: 0.762, loss: 1.0828, l1: 0.2280, vgg: 0.4704, mask: 0.3843\n",
      "step:    60680, time: 0.779, loss: 0.9834, l1: 0.1831, vgg: 0.4331, mask: 0.3672\n",
      "step:    60700, time: 0.843, loss: 1.1679, l1: 0.2489, vgg: 0.5222, mask: 0.3968\n",
      "step:    60720, time: 0.754, loss: 1.2709, l1: 0.2748, vgg: 0.5982, mask: 0.3979\n",
      "step:    60740, time: 0.744, loss: 1.1347, l1: 0.2414, vgg: 0.4767, mask: 0.4166\n",
      "step:    60760, time: 0.729, loss: 1.0578, l1: 0.1938, vgg: 0.4906, mask: 0.3734\n",
      "step:    60780, time: 0.773, loss: 1.0229, l1: 0.1737, vgg: 0.4817, mask: 0.3675\n",
      "step:    60800, time: 0.766, loss: 1.0664, l1: 0.1901, vgg: 0.5175, mask: 0.3588\n",
      "step:    60820, time: 0.727, loss: 0.9814, l1: 0.1432, vgg: 0.4664, mask: 0.3719\n",
      "step:    60840, time: 0.764, loss: 1.2318, l1: 0.2700, vgg: 0.5674, mask: 0.3944\n",
      "step:    60860, time: 0.744, loss: 1.0651, l1: 0.2094, vgg: 0.4895, mask: 0.3663\n",
      "step:    60880, time: 0.745, loss: 1.1633, l1: 0.2526, vgg: 0.5476, mask: 0.3631\n",
      "step:    60900, time: 0.783, loss: 1.0759, l1: 0.2129, vgg: 0.5012, mask: 0.3617\n",
      "step:    60920, time: 0.760, loss: 1.0689, l1: 0.2014, vgg: 0.5176, mask: 0.3499\n",
      "step:    60940, time: 0.774, loss: 1.2347, l1: 0.2721, vgg: 0.5498, mask: 0.4128\n",
      "step:    60960, time: 0.772, loss: 0.9835, l1: 0.1997, vgg: 0.4226, mask: 0.3612\n",
      "step:    60980, time: 0.783, loss: 1.0724, l1: 0.1943, vgg: 0.5148, mask: 0.3634\n",
      "step:    61000, time: 0.741, loss: 1.1438, l1: 0.2407, vgg: 0.4870, mask: 0.4160\n",
      "step:    61020, time: 0.753, loss: 1.1682, l1: 0.2504, vgg: 0.5015, mask: 0.4163\n",
      "step:    61040, time: 0.742, loss: 1.0115, l1: 0.1749, vgg: 0.4804, mask: 0.3562\n",
      "step:    61060, time: 0.745, loss: 1.0631, l1: 0.1981, vgg: 0.5108, mask: 0.3543\n",
      "step:    61080, time: 0.774, loss: 1.2231, l1: 0.2552, vgg: 0.5683, mask: 0.3996\n",
      "step:    61100, time: 0.751, loss: 1.1614, l1: 0.2239, vgg: 0.5438, mask: 0.3937\n",
      "step:    61120, time: 0.733, loss: 1.0415, l1: 0.1923, vgg: 0.4539, mask: 0.3953\n",
      "step:    61140, time: 0.746, loss: 1.1972, l1: 0.2729, vgg: 0.5012, mask: 0.4230\n",
      "step:    61160, time: 0.761, loss: 1.1113, l1: 0.1804, vgg: 0.5292, mask: 0.4017\n",
      "step:    61180, time: 0.743, loss: 1.1223, l1: 0.2553, vgg: 0.4828, mask: 0.3842\n",
      "step:    61200, time: 0.757, loss: 1.1056, l1: 0.2145, vgg: 0.4929, mask: 0.3982\n",
      "step:    61220, time: 0.741, loss: 1.0732, l1: 0.2109, vgg: 0.4880, mask: 0.3743\n",
      "step:    61240, time: 0.766, loss: 1.0638, l1: 0.2252, vgg: 0.4649, mask: 0.3737\n",
      "step:    61260, time: 0.796, loss: 1.2434, l1: 0.2541, vgg: 0.6073, mask: 0.3820\n",
      "step:    61280, time: 0.751, loss: 0.9937, l1: 0.2113, vgg: 0.4518, mask: 0.3306\n",
      "step:    61300, time: 0.753, loss: 1.1166, l1: 0.2169, vgg: 0.5347, mask: 0.3650\n",
      "step:    61320, time: 0.760, loss: 1.0769, l1: 0.1931, vgg: 0.5088, mask: 0.3750\n",
      "step:    61340, time: 0.781, loss: 1.0474, l1: 0.1968, vgg: 0.4901, mask: 0.3604\n",
      "step:    61360, time: 0.738, loss: 1.1575, l1: 0.2278, vgg: 0.5377, mask: 0.3921\n",
      "step:    61380, time: 0.755, loss: 1.0990, l1: 0.1993, vgg: 0.5405, mask: 0.3592\n",
      "step:    61400, time: 0.789, loss: 1.2609, l1: 0.3117, vgg: 0.5572, mask: 0.3920\n",
      "step:    61420, time: 0.731, loss: 1.1091, l1: 0.2197, vgg: 0.5257, mask: 0.3637\n",
      "step:    61440, time: 0.774, loss: 1.2222, l1: 0.2715, vgg: 0.5819, mask: 0.3688\n",
      "step:    61460, time: 0.719, loss: 0.9997, l1: 0.1591, vgg: 0.4329, mask: 0.4077\n",
      "step:    61480, time: 0.746, loss: 1.0863, l1: 0.2431, vgg: 0.4295, mask: 0.4138\n",
      "step:    61500, time: 0.734, loss: 1.1638, l1: 0.2593, vgg: 0.5012, mask: 0.4034\n",
      "step:    61520, time: 0.754, loss: 1.1249, l1: 0.2026, vgg: 0.5084, mask: 0.4139\n",
      "step:    61540, time: 0.778, loss: 1.1366, l1: 0.2125, vgg: 0.5371, mask: 0.3870\n",
      "step:    61560, time: 0.794, loss: 1.1780, l1: 0.2416, vgg: 0.5067, mask: 0.4297\n",
      "step:    61580, time: 0.726, loss: 1.0780, l1: 0.2049, vgg: 0.4669, mask: 0.4062\n",
      "step:    61600, time: 0.786, loss: 1.1324, l1: 0.2040, vgg: 0.5327, mask: 0.3956\n",
      "step:    61620, time: 0.745, loss: 1.1535, l1: 0.2389, vgg: 0.5042, mask: 0.4103\n",
      "step:    61640, time: 0.730, loss: 1.1732, l1: 0.2510, vgg: 0.5037, mask: 0.4184\n",
      "step:    61660, time: 0.793, loss: 1.0901, l1: 0.1830, vgg: 0.5487, mask: 0.3584\n",
      "step:    61680, time: 0.768, loss: 1.1535, l1: 0.2263, vgg: 0.5505, mask: 0.3767\n",
      "step:    61700, time: 0.752, loss: 1.1346, l1: 0.2114, vgg: 0.5475, mask: 0.3757\n",
      "step:    61720, time: 0.698, loss: 0.9979, l1: 0.2077, vgg: 0.4090, mask: 0.3812\n",
      "step:    61740, time: 0.750, loss: 1.1782, l1: 0.2315, vgg: 0.5058, mask: 0.4409\n",
      "step:    61760, time: 0.734, loss: 1.0463, l1: 0.2037, vgg: 0.4601, mask: 0.3824\n",
      "step:    61780, time: 0.776, loss: 1.0669, l1: 0.2366, vgg: 0.4415, mask: 0.3887\n",
      "step:    61800, time: 0.766, loss: 1.1804, l1: 0.2596, vgg: 0.5457, mask: 0.3750\n",
      "step:    61820, time: 0.748, loss: 1.1086, l1: 0.2203, vgg: 0.5069, mask: 0.3813\n",
      "step:    61840, time: 0.791, loss: 1.2395, l1: 0.2828, vgg: 0.5622, mask: 0.3945\n",
      "step:    61860, time: 0.755, loss: 0.9849, l1: 0.1721, vgg: 0.4752, mask: 0.3376\n",
      "step:    61880, time: 0.760, loss: 1.1138, l1: 0.2177, vgg: 0.5250, mask: 0.3711\n",
      "step:    61900, time: 0.738, loss: 1.0353, l1: 0.2078, vgg: 0.4607, mask: 0.3669\n",
      "step:    61920, time: 0.739, loss: 1.0739, l1: 0.1842, vgg: 0.5281, mask: 0.3617\n",
      "step:    61940, time: 0.744, loss: 1.0311, l1: 0.2209, vgg: 0.4405, mask: 0.3697\n",
      "step:    61960, time: 0.825, loss: 1.2466, l1: 0.2482, vgg: 0.5888, mask: 0.4096\n",
      "step:    61980, time: 0.743, loss: 1.1404, l1: 0.2368, vgg: 0.5240, mask: 0.3796\n",
      "step:    62000, time: 0.774, loss: 1.0617, l1: 0.2034, vgg: 0.5117, mask: 0.3466\n",
      "step:    62020, time: 0.746, loss: 1.0129, l1: 0.1946, vgg: 0.4457, mask: 0.3725\n",
      "step:    62040, time: 0.757, loss: 1.0873, l1: 0.1773, vgg: 0.5577, mask: 0.3523\n",
      "step:    62060, time: 0.745, loss: 1.0328, l1: 0.1876, vgg: 0.4862, mask: 0.3590\n",
      "step:    62080, time: 0.779, loss: 1.2741, l1: 0.2974, vgg: 0.5534, mask: 0.4233\n",
      "step:    62100, time: 0.771, loss: 1.1556, l1: 0.2598, vgg: 0.5238, mask: 0.3721\n",
      "step:    62120, time: 0.743, loss: 1.0718, l1: 0.2032, vgg: 0.5072, mask: 0.3615\n",
      "step:    62140, time: 0.776, loss: 1.2301, l1: 0.2911, vgg: 0.5367, mask: 0.4023\n",
      "step:    62160, time: 0.749, loss: 1.1752, l1: 0.2602, vgg: 0.5102, mask: 0.4048\n",
      "step:    62180, time: 0.743, loss: 1.0498, l1: 0.2052, vgg: 0.4440, mask: 0.4005\n",
      "step:    62200, time: 0.771, loss: 1.1170, l1: 0.2133, vgg: 0.5088, mask: 0.3949\n",
      "step:    62220, time: 0.804, loss: 1.2138, l1: 0.2283, vgg: 0.5830, mask: 0.4026\n",
      "step:    62240, time: 0.743, loss: 1.1016, l1: 0.2360, vgg: 0.4826, mask: 0.3830\n",
      "step:    62260, time: 0.743, loss: 1.1333, l1: 0.2160, vgg: 0.5438, mask: 0.3735\n",
      "step:    62280, time: 0.796, loss: 1.1373, l1: 0.2478, vgg: 0.5021, mask: 0.3873\n",
      "step:    62300, time: 0.748, loss: 1.0590, l1: 0.2241, vgg: 0.4439, mask: 0.3911\n",
      "step:    62320, time: 0.752, loss: 1.1754, l1: 0.2505, vgg: 0.5224, mask: 0.4025\n",
      "step:    62340, time: 0.773, loss: 1.1965, l1: 0.2873, vgg: 0.4888, mask: 0.4203\n",
      "step:    62360, time: 0.773, loss: 1.0933, l1: 0.2209, vgg: 0.4877, mask: 0.3847\n",
      "step:    62380, time: 0.767, loss: 1.0017, l1: 0.2249, vgg: 0.4203, mask: 0.3565\n",
      "step:    62400, time: 0.787, loss: 1.2111, l1: 0.2349, vgg: 0.5907, mask: 0.3854\n",
      "step:    62420, time: 0.757, loss: 1.1099, l1: 0.1981, vgg: 0.5415, mask: 0.3703\n",
      "step:    62440, time: 0.783, loss: 1.2768, l1: 0.3017, vgg: 0.5448, mask: 0.4304\n",
      "step:    62460, time: 0.770, loss: 1.1201, l1: 0.1915, vgg: 0.5695, mask: 0.3590\n",
      "step:    62480, time: 0.765, loss: 1.0947, l1: 0.2228, vgg: 0.5015, mask: 0.3704\n",
      "step:    62500, time: 0.769, loss: 1.1154, l1: 0.2004, vgg: 0.5286, mask: 0.3864\n",
      "step:    62520, time: 0.754, loss: 1.0788, l1: 0.2354, vgg: 0.4574, mask: 0.3860\n",
      "step:    62540, time: 0.756, loss: 0.9963, l1: 0.1920, vgg: 0.4418, mask: 0.3625\n",
      "step:    62560, time: 0.733, loss: 1.1559, l1: 0.2373, vgg: 0.5208, mask: 0.3978\n",
      "step:    62580, time: 0.735, loss: 1.0300, l1: 0.2030, vgg: 0.4905, mask: 0.3365\n",
      "step:    62600, time: 0.762, loss: 1.2454, l1: 0.2601, vgg: 0.5877, mask: 0.3976\n",
      "step:    62620, time: 0.754, loss: 1.0936, l1: 0.2224, vgg: 0.4304, mask: 0.4409\n",
      "step:    62640, time: 0.732, loss: 1.0835, l1: 0.2415, vgg: 0.4330, mask: 0.4090\n",
      "step:    62660, time: 0.760, loss: 0.9849, l1: 0.1814, vgg: 0.4584, mask: 0.3451\n",
      "step:    62680, time: 0.750, loss: 1.0161, l1: 0.2104, vgg: 0.4438, mask: 0.3619\n",
      "step:    62700, time: 0.765, loss: 1.0554, l1: 0.2043, vgg: 0.4826, mask: 0.3684\n",
      "step:    62720, time: 0.806, loss: 1.1266, l1: 0.2205, vgg: 0.5249, mask: 0.3811\n",
      "step:    62740, time: 0.739, loss: 1.0368, l1: 0.2066, vgg: 0.4773, mask: 0.3529\n",
      "step:    62760, time: 0.750, loss: 1.0794, l1: 0.2480, vgg: 0.4081, mask: 0.4234\n",
      "step:    62780, time: 0.740, loss: 1.0753, l1: 0.1999, vgg: 0.5057, mask: 0.3697\n",
      "step:    62800, time: 0.746, loss: 1.0444, l1: 0.2104, vgg: 0.4561, mask: 0.3779\n",
      "step:    62820, time: 0.788, loss: 1.1588, l1: 0.2681, vgg: 0.4779, mask: 0.4127\n",
      "step:    62840, time: 0.771, loss: 1.0806, l1: 0.2247, vgg: 0.4929, mask: 0.3630\n",
      "step:    62860, time: 0.742, loss: 1.0947, l1: 0.2222, vgg: 0.5215, mask: 0.3509\n",
      "step:    62880, time: 0.788, loss: 1.0776, l1: 0.1866, vgg: 0.5049, mask: 0.3862\n",
      "step:    62900, time: 0.741, loss: 1.0059, l1: 0.1769, vgg: 0.4648, mask: 0.3642\n",
      "step:    62920, time: 0.753, loss: 1.1566, l1: 0.2300, vgg: 0.5551, mask: 0.3715\n",
      "step:    62940, time: 0.755, loss: 1.0274, l1: 0.1772, vgg: 0.4860, mask: 0.3642\n",
      "step:    62960, time: 0.742, loss: 1.1477, l1: 0.2162, vgg: 0.5762, mask: 0.3553\n",
      "step:    62980, time: 0.752, loss: 1.0827, l1: 0.2364, vgg: 0.4650, mask: 0.3814\n",
      "step:    63000, time: 0.776, loss: 1.1379, l1: 0.2444, vgg: 0.4982, mask: 0.3954\n",
      "step:    63020, time: 0.762, loss: 1.1644, l1: 0.2457, vgg: 0.5037, mask: 0.4150\n",
      "step:    63040, time: 0.752, loss: 1.2165, l1: 0.2601, vgg: 0.5341, mask: 0.4223\n",
      "step:    63060, time: 0.771, loss: 1.0599, l1: 0.2063, vgg: 0.4711, mask: 0.3825\n",
      "step:    63080, time: 0.797, loss: 1.1367, l1: 0.2493, vgg: 0.4605, mask: 0.4269\n",
      "step:    63100, time: 0.778, loss: 1.1466, l1: 0.2550, vgg: 0.4786, mask: 0.4130\n",
      "step:    63120, time: 0.792, loss: 1.0593, l1: 0.1894, vgg: 0.5083, mask: 0.3615\n",
      "step:    63140, time: 0.763, loss: 0.9924, l1: 0.1904, vgg: 0.4842, mask: 0.3179\n",
      "step:    63160, time: 0.760, loss: 1.0308, l1: 0.1936, vgg: 0.4799, mask: 0.3573\n",
      "step:    63180, time: 0.772, loss: 1.0313, l1: 0.2254, vgg: 0.4310, mask: 0.3749\n",
      "step:    63200, time: 0.714, loss: 0.9356, l1: 0.1582, vgg: 0.4523, mask: 0.3252\n",
      "step:    63220, time: 0.716, loss: 1.0711, l1: 0.2171, vgg: 0.4434, mask: 0.4105\n",
      "step:    63240, time: 0.753, loss: 1.0547, l1: 0.2197, vgg: 0.4600, mask: 0.3750\n",
      "step:    63260, time: 0.814, loss: 1.2126, l1: 0.3128, vgg: 0.4894, mask: 0.4104\n",
      "step:    63280, time: 0.754, loss: 1.0485, l1: 0.2341, vgg: 0.4492, mask: 0.3653\n",
      "step:    63300, time: 0.775, loss: 1.0701, l1: 0.2208, vgg: 0.4835, mask: 0.3658\n",
      "step:    63320, time: 0.757, loss: 1.0520, l1: 0.2281, vgg: 0.4275, mask: 0.3965\n",
      "step:    63340, time: 0.822, loss: 1.0304, l1: 0.1627, vgg: 0.4874, mask: 0.3804\n",
      "step:    63360, time: 0.740, loss: 1.1065, l1: 0.2397, vgg: 0.4767, mask: 0.3902\n",
      "step:    63380, time: 0.747, loss: 0.9814, l1: 0.1631, vgg: 0.4806, mask: 0.3376\n",
      "step:    63400, time: 0.768, loss: 1.1004, l1: 0.2434, vgg: 0.4712, mask: 0.3858\n",
      "step:    63420, time: 0.752, loss: 1.1810, l1: 0.2831, vgg: 0.4910, mask: 0.4069\n",
      "step:    63440, time: 0.773, loss: 1.1156, l1: 0.2302, vgg: 0.4870, mask: 0.3983\n",
      "step:    63460, time: 0.772, loss: 1.0436, l1: 0.2130, vgg: 0.4152, mask: 0.4153\n",
      "step:    63480, time: 0.732, loss: 1.1520, l1: 0.2706, vgg: 0.5104, mask: 0.3710\n",
      "step:    63500, time: 0.752, loss: 1.2022, l1: 0.2319, vgg: 0.6015, mask: 0.3688\n",
      "step:    63520, time: 0.762, loss: 1.1127, l1: 0.2058, vgg: 0.5094, mask: 0.3974\n",
      "step:    63540, time: 0.754, loss: 1.1892, l1: 0.2741, vgg: 0.5123, mask: 0.4027\n",
      "step:    63560, time: 0.747, loss: 1.1422, l1: 0.2784, vgg: 0.4643, mask: 0.3995\n",
      "step:    63580, time: 0.757, loss: 1.0340, l1: 0.2468, vgg: 0.4203, mask: 0.3669\n",
      "step:    63600, time: 0.741, loss: 1.1373, l1: 0.2549, vgg: 0.5135, mask: 0.3688\n",
      "step:    63620, time: 0.768, loss: 1.1207, l1: 0.2268, vgg: 0.5265, mask: 0.3673\n",
      "step:    63640, time: 0.728, loss: 1.1113, l1: 0.1978, vgg: 0.5244, mask: 0.3890\n",
      "step:    63660, time: 0.761, loss: 1.1955, l1: 0.2934, vgg: 0.4896, mask: 0.4125\n",
      "step:    63680, time: 0.763, loss: 1.1151, l1: 0.1842, vgg: 0.5169, mask: 0.4140\n",
      "step:    63700, time: 0.744, loss: 1.1718, l1: 0.2142, vgg: 0.5573, mask: 0.4003\n",
      "step:    63720, time: 0.793, loss: 1.0289, l1: 0.1861, vgg: 0.4838, mask: 0.3590\n",
      "step:    63740, time: 0.739, loss: 0.9213, l1: 0.1646, vgg: 0.4177, mask: 0.3390\n",
      "step:    63760, time: 0.747, loss: 1.2371, l1: 0.2600, vgg: 0.5617, mask: 0.4154\n",
      "step:    63780, time: 0.768, loss: 1.0954, l1: 0.2091, vgg: 0.4983, mask: 0.3880\n",
      "step:    63800, time: 0.756, loss: 1.0601, l1: 0.2143, vgg: 0.4679, mask: 0.3779\n",
      "step:    63820, time: 0.735, loss: 1.0369, l1: 0.2038, vgg: 0.4797, mask: 0.3534\n",
      "step:    63840, time: 0.729, loss: 0.9842, l1: 0.1918, vgg: 0.4482, mask: 0.3443\n",
      "step:    63860, time: 0.748, loss: 1.1835, l1: 0.2456, vgg: 0.5520, mask: 0.3859\n",
      "step:    63880, time: 0.785, loss: 1.1410, l1: 0.2220, vgg: 0.5240, mask: 0.3949\n",
      "step:    63900, time: 0.784, loss: 1.2593, l1: 0.2832, vgg: 0.5345, mask: 0.4416\n",
      "step:    63920, time: 0.740, loss: 1.0341, l1: 0.2069, vgg: 0.4521, mask: 0.3751\n",
      "step:    63940, time: 0.762, loss: 1.2595, l1: 0.2889, vgg: 0.5618, mask: 0.4088\n",
      "step:    63960, time: 0.784, loss: 1.0381, l1: 0.2220, vgg: 0.4551, mask: 0.3610\n",
      "step:    63980, time: 0.748, loss: 1.0557, l1: 0.1879, vgg: 0.5040, mask: 0.3638\n",
      "step:    64000, time: 0.763, loss: 1.1596, l1: 0.2201, vgg: 0.5469, mask: 0.3926\n",
      "step:    64020, time: 0.726, loss: 1.1394, l1: 0.2885, vgg: 0.4540, mask: 0.3969\n",
      "step:    64040, time: 0.802, loss: 1.1181, l1: 0.2373, vgg: 0.4509, mask: 0.4300\n",
      "step:    64060, time: 0.732, loss: 1.1221, l1: 0.2529, vgg: 0.5191, mask: 0.3501\n",
      "step:    64080, time: 0.745, loss: 0.9658, l1: 0.2101, vgg: 0.4190, mask: 0.3367\n",
      "step:    64100, time: 0.754, loss: 1.1199, l1: 0.2290, vgg: 0.5199, mask: 0.3710\n",
      "step:    64120, time: 0.735, loss: 1.0181, l1: 0.2037, vgg: 0.4568, mask: 0.3576\n",
      "step:    64140, time: 0.750, loss: 1.1311, l1: 0.2340, vgg: 0.4863, mask: 0.4108\n",
      "step:    64160, time: 0.740, loss: 1.1171, l1: 0.2073, vgg: 0.5236, mask: 0.3863\n",
      "step:    64180, time: 0.750, loss: 1.0005, l1: 0.2071, vgg: 0.4511, mask: 0.3423\n",
      "step:    64200, time: 0.738, loss: 1.1903, l1: 0.2602, vgg: 0.5324, mask: 0.3977\n",
      "step:    64220, time: 0.759, loss: 1.0620, l1: 0.2382, vgg: 0.4417, mask: 0.3821\n",
      "step:    64240, time: 0.725, loss: 1.0392, l1: 0.1885, vgg: 0.4991, mask: 0.3517\n",
      "step:    64260, time: 0.744, loss: 1.0515, l1: 0.1867, vgg: 0.4646, mask: 0.4002\n",
      "step:    64280, time: 0.792, loss: 1.0875, l1: 0.2135, vgg: 0.4897, mask: 0.3843\n",
      "step:    64300, time: 0.826, loss: 1.0518, l1: 0.2055, vgg: 0.4927, mask: 0.3535\n",
      "step:    64320, time: 0.866, loss: 0.9958, l1: 0.2053, vgg: 0.4483, mask: 0.3422\n",
      "step:    64340, time: 0.820, loss: 1.0708, l1: 0.2351, vgg: 0.4683, mask: 0.3673\n",
      "step:    64360, time: 0.782, loss: 1.2280, l1: 0.2594, vgg: 0.5384, mask: 0.4302\n",
      "step:    64380, time: 0.761, loss: 1.1816, l1: 0.3017, vgg: 0.4742, mask: 0.4057\n",
      "step:    64400, time: 0.768, loss: 1.0373, l1: 0.2299, vgg: 0.4384, mask: 0.3689\n",
      "step:    64420, time: 0.774, loss: 1.1055, l1: 0.2282, vgg: 0.5118, mask: 0.3655\n",
      "step:    64440, time: 0.777, loss: 1.1597, l1: 0.2331, vgg: 0.5576, mask: 0.3690\n",
      "step:    64460, time: 0.781, loss: 1.0786, l1: 0.2133, vgg: 0.5196, mask: 0.3457\n",
      "step:    64480, time: 0.773, loss: 1.2574, l1: 0.3215, vgg: 0.5261, mask: 0.4097\n",
      "step:    64500, time: 0.777, loss: 1.0459, l1: 0.1967, vgg: 0.4852, mask: 0.3639\n",
      "step:    64520, time: 0.758, loss: 1.0637, l1: 0.2626, vgg: 0.4417, mask: 0.3594\n",
      "step:    64540, time: 0.716, loss: 1.0028, l1: 0.2001, vgg: 0.4331, mask: 0.3695\n",
      "step:    64560, time: 0.759, loss: 1.1522, l1: 0.2793, vgg: 0.4781, mask: 0.3948\n",
      "step:    64580, time: 0.799, loss: 1.1500, l1: 0.2599, vgg: 0.4655, mask: 0.4246\n",
      "step:    64600, time: 0.775, loss: 1.0853, l1: 0.2040, vgg: 0.5073, mask: 0.3740\n",
      "step:    64620, time: 0.756, loss: 0.9844, l1: 0.1914, vgg: 0.4248, mask: 0.3681\n",
      "step:    64640, time: 0.723, loss: 1.0270, l1: 0.1936, vgg: 0.4861, mask: 0.3473\n",
      "step:    64660, time: 0.780, loss: 1.2941, l1: 0.2886, vgg: 0.5910, mask: 0.4145\n",
      "step:    64680, time: 0.738, loss: 1.1167, l1: 0.2266, vgg: 0.5109, mask: 0.3792\n",
      "step:    64700, time: 0.732, loss: 1.0145, l1: 0.1963, vgg: 0.4576, mask: 0.3606\n",
      "step:    64720, time: 0.741, loss: 1.0681, l1: 0.2332, vgg: 0.4579, mask: 0.3770\n",
      "step:    64740, time: 0.780, loss: 1.1371, l1: 0.2423, vgg: 0.4951, mask: 0.3997\n",
      "step:    64760, time: 0.723, loss: 1.0689, l1: 0.2272, vgg: 0.4812, mask: 0.3606\n",
      "step:    64780, time: 0.776, loss: 1.0105, l1: 0.1720, vgg: 0.4974, mask: 0.3411\n",
      "step:    64800, time: 0.742, loss: 1.1660, l1: 0.2676, vgg: 0.4849, mask: 0.4136\n",
      "step:    64820, time: 0.750, loss: 1.1403, l1: 0.2464, vgg: 0.5063, mask: 0.3875\n",
      "step:    64840, time: 0.757, loss: 1.1354, l1: 0.2071, vgg: 0.5891, mask: 0.3391\n",
      "step:    64860, time: 0.819, loss: 1.0280, l1: 0.1854, vgg: 0.4830, mask: 0.3596\n",
      "step:    64880, time: 0.736, loss: 0.9331, l1: 0.1469, vgg: 0.4319, mask: 0.3542\n",
      "step:    64900, time: 0.836, loss: 1.0745, l1: 0.2308, vgg: 0.4832, mask: 0.3606\n",
      "step:    64920, time: 0.754, loss: 1.0822, l1: 0.2021, vgg: 0.5150, mask: 0.3651\n",
      "step:    64940, time: 0.778, loss: 1.3071, l1: 0.2978, vgg: 0.6207, mask: 0.3886\n",
      "step:    64960, time: 0.744, loss: 1.0701, l1: 0.1720, vgg: 0.5470, mask: 0.3511\n",
      "step:    64980, time: 0.789, loss: 1.2041, l1: 0.2433, vgg: 0.5318, mask: 0.4289\n",
      "step:    65000, time: 0.842, loss: 1.0937, l1: 0.2049, vgg: 0.5016, mask: 0.3872\n",
      "step:    65020, time: 0.759, loss: 1.0703, l1: 0.2056, vgg: 0.4596, mask: 0.4051\n",
      "step:    65040, time: 0.777, loss: 1.0492, l1: 0.2086, vgg: 0.4584, mask: 0.3822\n",
      "step:    65060, time: 0.719, loss: 0.9627, l1: 0.1515, vgg: 0.4643, mask: 0.3470\n",
      "step:    65080, time: 0.774, loss: 1.0095, l1: 0.2063, vgg: 0.4400, mask: 0.3632\n",
      "step:    65100, time: 0.768, loss: 0.9538, l1: 0.1708, vgg: 0.4245, mask: 0.3585\n",
      "step:    65120, time: 0.765, loss: 1.1355, l1: 0.2088, vgg: 0.5406, mask: 0.3860\n",
      "step:    65140, time: 0.782, loss: 1.0741, l1: 0.1855, vgg: 0.5408, mask: 0.3479\n",
      "step:    65160, time: 0.748, loss: 1.0607, l1: 0.1965, vgg: 0.4971, mask: 0.3672\n",
      "step:    65180, time: 0.856, loss: 1.1798, l1: 0.2404, vgg: 0.5221, mask: 0.4173\n",
      "step:    65200, time: 0.774, loss: 1.0553, l1: 0.2616, vgg: 0.4246, mask: 0.3691\n",
      "step:    65220, time: 0.767, loss: 1.1101, l1: 0.2270, vgg: 0.5104, mask: 0.3726\n",
      "step:    65240, time: 0.754, loss: 1.1726, l1: 0.2766, vgg: 0.5000, mask: 0.3960\n",
      "step:    65260, time: 0.886, loss: 1.2864, l1: 0.3037, vgg: 0.5867, mask: 0.3960\n",
      "step:    65280, time: 0.838, loss: 1.0225, l1: 0.1739, vgg: 0.4715, mask: 0.3772\n",
      "step:    65300, time: 0.748, loss: 1.0729, l1: 0.2207, vgg: 0.4864, mask: 0.3657\n",
      "step:    65320, time: 0.781, loss: 1.0699, l1: 0.2276, vgg: 0.4683, mask: 0.3740\n",
      "step:    65340, time: 0.760, loss: 1.1319, l1: 0.2338, vgg: 0.5265, mask: 0.3716\n",
      "step:    65360, time: 0.780, loss: 1.1685, l1: 0.2470, vgg: 0.5425, mask: 0.3790\n",
      "step:    65380, time: 0.823, loss: 0.8969, l1: 0.1585, vgg: 0.3912, mask: 0.3471\n",
      "step:    65400, time: 0.736, loss: 0.9560, l1: 0.1813, vgg: 0.4277, mask: 0.3470\n",
      "step:    65420, time: 0.787, loss: 1.0829, l1: 0.1974, vgg: 0.5211, mask: 0.3645\n",
      "step:    65440, time: 0.821, loss: 1.1275, l1: 0.2055, vgg: 0.5630, mask: 0.3590\n",
      "step:    65460, time: 0.816, loss: 1.1293, l1: 0.2121, vgg: 0.5199, mask: 0.3973\n",
      "step:    65480, time: 0.776, loss: 1.1133, l1: 0.2364, vgg: 0.4790, mask: 0.3979\n",
      "step:    65500, time: 0.749, loss: 1.1741, l1: 0.2970, vgg: 0.4899, mask: 0.3871\n",
      "step:    65520, time: 0.742, loss: 1.2376, l1: 0.2933, vgg: 0.5197, mask: 0.4247\n",
      "step:    65540, time: 0.779, loss: 1.1901, l1: 0.2478, vgg: 0.5513, mask: 0.3910\n",
      "step:    65560, time: 0.775, loss: 1.1305, l1: 0.2184, vgg: 0.5399, mask: 0.3722\n",
      "step:    65580, time: 0.737, loss: 1.0934, l1: 0.2448, vgg: 0.4580, mask: 0.3906\n",
      "step:    65600, time: 0.777, loss: 1.0621, l1: 0.1998, vgg: 0.5022, mask: 0.3600\n",
      "step:    65620, time: 0.810, loss: 1.1781, l1: 0.2020, vgg: 0.5581, mask: 0.4180\n",
      "step:    65640, time: 0.727, loss: 0.9384, l1: 0.1338, vgg: 0.4500, mask: 0.3545\n",
      "step:    65660, time: 0.808, loss: 1.1883, l1: 0.2293, vgg: 0.5553, mask: 0.4037\n",
      "step:    65680, time: 0.756, loss: 1.0780, l1: 0.2241, vgg: 0.4886, mask: 0.3653\n",
      "step:    65700, time: 0.755, loss: 0.9861, l1: 0.1758, vgg: 0.4567, mask: 0.3536\n",
      "step:    65720, time: 0.762, loss: 1.2200, l1: 0.2325, vgg: 0.6172, mask: 0.3702\n",
      "step:    65740, time: 0.770, loss: 1.0233, l1: 0.1754, vgg: 0.4760, mask: 0.3719\n",
      "step:    65760, time: 0.732, loss: 0.9634, l1: 0.1911, vgg: 0.4207, mask: 0.3516\n",
      "step:    65780, time: 0.754, loss: 1.0259, l1: 0.2321, vgg: 0.4417, mask: 0.3521\n",
      "step:    65800, time: 0.765, loss: 1.0610, l1: 0.2115, vgg: 0.4953, mask: 0.3542\n",
      "step:    65820, time: 0.782, loss: 1.1025, l1: 0.2217, vgg: 0.4946, mask: 0.3861\n",
      "step:    65840, time: 0.849, loss: 1.0964, l1: 0.2244, vgg: 0.4928, mask: 0.3793\n",
      "step:    65860, time: 0.831, loss: 1.0525, l1: 0.2239, vgg: 0.4697, mask: 0.3589\n",
      "step:    65880, time: 0.827, loss: 1.0545, l1: 0.2066, vgg: 0.4691, mask: 0.3788\n",
      "step:    65900, time: 0.850, loss: 1.3233, l1: 0.3129, vgg: 0.5826, mask: 0.4277\n",
      "step:    65920, time: 0.854, loss: 1.1248, l1: 0.2341, vgg: 0.5149, mask: 0.3758\n",
      "step:    65940, time: 0.766, loss: 1.1592, l1: 0.2807, vgg: 0.4646, mask: 0.4139\n",
      "step:    65960, time: 0.806, loss: 1.1719, l1: 0.2475, vgg: 0.5133, mask: 0.4111\n",
      "step:    65980, time: 0.765, loss: 0.9681, l1: 0.1730, vgg: 0.4634, mask: 0.3316\n",
      "step:    66000, time: 0.784, loss: 1.0919, l1: 0.1696, vgg: 0.5024, mask: 0.4199\n",
      "step:    66020, time: 0.783, loss: 1.0256, l1: 0.2011, vgg: 0.4724, mask: 0.3522\n",
      "step:    66040, time: 0.735, loss: 1.0166, l1: 0.1847, vgg: 0.4875, mask: 0.3444\n",
      "step:    66060, time: 0.757, loss: 1.1125, l1: 0.2295, vgg: 0.4912, mask: 0.3917\n",
      "step:    66080, time: 0.833, loss: 1.2299, l1: 0.2800, vgg: 0.5308, mask: 0.4192\n",
      "step:    66100, time: 0.725, loss: 1.0831, l1: 0.2430, vgg: 0.4358, mask: 0.4042\n",
      "step:    66120, time: 0.776, loss: 1.2086, l1: 0.2704, vgg: 0.5480, mask: 0.3902\n",
      "step:    66140, time: 0.773, loss: 1.1267, l1: 0.2206, vgg: 0.5198, mask: 0.3863\n",
      "step:    66160, time: 0.772, loss: 1.0786, l1: 0.1979, vgg: 0.4975, mask: 0.3832\n",
      "step:    66180, time: 0.761, loss: 1.1389, l1: 0.2472, vgg: 0.5063, mask: 0.3854\n",
      "step:    66200, time: 0.781, loss: 0.9543, l1: 0.1737, vgg: 0.4498, mask: 0.3307\n",
      "step:    66220, time: 0.751, loss: 1.0929, l1: 0.2050, vgg: 0.5294, mask: 0.3584\n",
      "step:    66240, time: 0.753, loss: 1.0439, l1: 0.1753, vgg: 0.4716, mask: 0.3969\n",
      "step:    66260, time: 0.765, loss: 1.1547, l1: 0.2666, vgg: 0.4858, mask: 0.4023\n",
      "step:    66280, time: 0.774, loss: 1.1558, l1: 0.2838, vgg: 0.4624, mask: 0.4097\n",
      "step:    66300, time: 0.769, loss: 1.1108, l1: 0.1908, vgg: 0.5062, mask: 0.4137\n",
      "step:    66320, time: 0.789, loss: 1.1350, l1: 0.2184, vgg: 0.5208, mask: 0.3958\n",
      "step:    66340, time: 0.727, loss: 0.8930, l1: 0.1441, vgg: 0.3885, mask: 0.3604\n",
      "step:    66360, time: 0.752, loss: 0.9935, l1: 0.2003, vgg: 0.4379, mask: 0.3554\n",
      "step:    66380, time: 0.803, loss: 1.1765, l1: 0.2439, vgg: 0.5259, mask: 0.4066\n",
      "step:    66400, time: 0.824, loss: 0.9887, l1: 0.1921, vgg: 0.4243, mask: 0.3722\n",
      "step:    66420, time: 0.793, loss: 1.2022, l1: 0.2504, vgg: 0.5269, mask: 0.4248\n",
      "step:    66440, time: 0.767, loss: 1.0317, l1: 0.1874, vgg: 0.4854, mask: 0.3589\n",
      "step:    66460, time: 0.786, loss: 1.0084, l1: 0.2527, vgg: 0.3831, mask: 0.3726\n",
      "step:    66480, time: 0.757, loss: 1.0920, l1: 0.2477, vgg: 0.4784, mask: 0.3659\n",
      "step:    66500, time: 0.738, loss: 1.0928, l1: 0.2204, vgg: 0.5049, mask: 0.3675\n",
      "step:    66520, time: 0.762, loss: 1.1508, l1: 0.2145, vgg: 0.5725, mask: 0.3638\n",
      "step:    66540, time: 0.780, loss: 1.1108, l1: 0.2482, vgg: 0.4684, mask: 0.3941\n",
      "step:    66560, time: 0.773, loss: 1.1216, l1: 0.2281, vgg: 0.5281, mask: 0.3654\n",
      "step:    66580, time: 0.768, loss: 1.1589, l1: 0.2498, vgg: 0.5383, mask: 0.3708\n",
      "step:    66600, time: 0.740, loss: 1.0093, l1: 0.2192, vgg: 0.4503, mask: 0.3397\n",
      "step:    66620, time: 0.739, loss: 0.9590, l1: 0.1899, vgg: 0.4403, mask: 0.3287\n",
      "step:    66640, time: 0.779, loss: 1.0022, l1: 0.2018, vgg: 0.4341, mask: 0.3664\n",
      "step:    66660, time: 0.769, loss: 1.0711, l1: 0.1794, vgg: 0.5470, mask: 0.3447\n",
      "step:    66680, time: 0.743, loss: 1.0682, l1: 0.1925, vgg: 0.5041, mask: 0.3716\n",
      "step:    66700, time: 0.758, loss: 1.0617, l1: 0.2116, vgg: 0.4830, mask: 0.3670\n",
      "step:    66720, time: 0.735, loss: 1.0441, l1: 0.2172, vgg: 0.4514, mask: 0.3754\n",
      "step:    66740, time: 0.750, loss: 1.2619, l1: 0.2767, vgg: 0.6083, mask: 0.3769\n",
      "step:    66760, time: 0.730, loss: 0.9689, l1: 0.1789, vgg: 0.4541, mask: 0.3358\n",
      "step:    66780, time: 0.752, loss: 1.1338, l1: 0.2537, vgg: 0.5044, mask: 0.3757\n",
      "step:    66800, time: 0.776, loss: 1.1276, l1: 0.2404, vgg: 0.5033, mask: 0.3840\n",
      "step:    66820, time: 0.762, loss: 1.2248, l1: 0.2415, vgg: 0.5613, mask: 0.4220\n",
      "step:    66840, time: 0.739, loss: 1.1573, l1: 0.2252, vgg: 0.5347, mask: 0.3974\n",
      "step:    66860, time: 0.781, loss: 1.0661, l1: 0.2156, vgg: 0.4827, mask: 0.3679\n",
      "step:    66880, time: 0.735, loss: 0.9864, l1: 0.1894, vgg: 0.4491, mask: 0.3478\n",
      "step:    66900, time: 0.769, loss: 0.9765, l1: 0.1883, vgg: 0.4525, mask: 0.3357\n",
      "step:    66920, time: 0.790, loss: 1.1129, l1: 0.2152, vgg: 0.5118, mask: 0.3859\n",
      "step:    66940, time: 0.766, loss: 1.1003, l1: 0.2023, vgg: 0.5020, mask: 0.3961\n",
      "step:    66960, time: 0.766, loss: 1.1062, l1: 0.2024, vgg: 0.5558, mask: 0.3479\n",
      "step:    66980, time: 0.733, loss: 1.0850, l1: 0.2050, vgg: 0.4786, mask: 0.4014\n",
      "step:    67000, time: 0.760, loss: 0.9880, l1: 0.1826, vgg: 0.4409, mask: 0.3645\n",
      "step:    67020, time: 0.760, loss: 1.0091, l1: 0.2072, vgg: 0.4442, mask: 0.3577\n",
      "step:    67040, time: 0.747, loss: 1.1363, l1: 0.2380, vgg: 0.5101, mask: 0.3882\n",
      "step:    67060, time: 0.748, loss: 1.1898, l1: 0.2852, vgg: 0.5147, mask: 0.3899\n",
      "step:    67080, time: 0.745, loss: 0.9814, l1: 0.1894, vgg: 0.4561, mask: 0.3359\n",
      "step:    67100, time: 0.768, loss: 1.1184, l1: 0.2096, vgg: 0.5336, mask: 0.3752\n",
      "step:    67120, time: 0.839, loss: 1.1780, l1: 0.2515, vgg: 0.5092, mask: 0.4174\n",
      "step:    67140, time: 0.744, loss: 1.0091, l1: 0.1831, vgg: 0.4585, mask: 0.3675\n",
      "step:    67160, time: 0.777, loss: 1.0752, l1: 0.2301, vgg: 0.4694, mask: 0.3757\n",
      "step:    67180, time: 0.772, loss: 1.0933, l1: 0.2101, vgg: 0.5125, mask: 0.3707\n",
      "step:    67200, time: 0.741, loss: 1.0528, l1: 0.1955, vgg: 0.4622, mask: 0.3950\n",
      "step:    67220, time: 0.747, loss: 1.1451, l1: 0.2457, vgg: 0.4931, mask: 0.4062\n",
      "step:    67240, time: 0.779, loss: 1.1322, l1: 0.2479, vgg: 0.4858, mask: 0.3985\n",
      "step:    67260, time: 0.754, loss: 1.1132, l1: 0.2430, vgg: 0.4896, mask: 0.3806\n",
      "step:    67280, time: 0.764, loss: 1.1103, l1: 0.1979, vgg: 0.5696, mask: 0.3428\n",
      "step:    67300, time: 0.781, loss: 1.1216, l1: 0.2074, vgg: 0.5296, mask: 0.3846\n",
      "step:    67320, time: 0.765, loss: 1.0308, l1: 0.1765, vgg: 0.5167, mask: 0.3375\n",
      "step:    67340, time: 0.727, loss: 0.9111, l1: 0.1428, vgg: 0.4430, mask: 0.3252\n",
      "step:    67360, time: 0.794, loss: 1.1559, l1: 0.2397, vgg: 0.5134, mask: 0.4028\n",
      "step:    67380, time: 0.793, loss: 1.2247, l1: 0.2527, vgg: 0.5586, mask: 0.4134\n",
      "step:    67400, time: 0.756, loss: 0.9642, l1: 0.2067, vgg: 0.4141, mask: 0.3434\n",
      "step:    67420, time: 0.750, loss: 1.0000, l1: 0.1689, vgg: 0.4706, mask: 0.3606\n",
      "step:    67440, time: 0.769, loss: 1.1214, l1: 0.2282, vgg: 0.5223, mask: 0.3709\n",
      "step:    67460, time: 0.745, loss: 1.0109, l1: 0.2091, vgg: 0.4319, mask: 0.3699\n",
      "step:    67480, time: 0.763, loss: 1.1241, l1: 0.2229, vgg: 0.5191, mask: 0.3822\n",
      "step:    67500, time: 0.771, loss: 1.0419, l1: 0.2105, vgg: 0.4295, mask: 0.4019\n",
      "step:    67520, time: 0.760, loss: 1.0137, l1: 0.2047, vgg: 0.4350, mask: 0.3739\n",
      "step:    67540, time: 0.779, loss: 1.0160, l1: 0.1726, vgg: 0.4742, mask: 0.3692\n",
      "step:    67560, time: 0.751, loss: 1.0964, l1: 0.1757, vgg: 0.5518, mask: 0.3690\n",
      "step:    67580, time: 0.787, loss: 1.1193, l1: 0.2305, vgg: 0.4903, mask: 0.3985\n",
      "step:    67600, time: 0.766, loss: 1.0574, l1: 0.2264, vgg: 0.4685, mask: 0.3624\n",
      "step:    67620, time: 0.792, loss: 1.0869, l1: 0.2252, vgg: 0.4821, mask: 0.3796\n",
      "step:    67640, time: 0.738, loss: 1.0773, l1: 0.2558, vgg: 0.4343, mask: 0.3872\n",
      "step:    67660, time: 0.760, loss: 1.1315, l1: 0.2008, vgg: 0.5671, mask: 0.3636\n",
      "step:    67680, time: 0.767, loss: 1.0989, l1: 0.2171, vgg: 0.5024, mask: 0.3794\n",
      "step:    67700, time: 0.758, loss: 0.9497, l1: 0.1557, vgg: 0.4515, mask: 0.3425\n",
      "step:    67720, time: 0.752, loss: 1.1662, l1: 0.2976, vgg: 0.4463, mask: 0.4224\n",
      "step:    67740, time: 0.771, loss: 1.1778, l1: 0.2319, vgg: 0.5490, mask: 0.3969\n",
      "step:    67760, time: 0.760, loss: 1.0411, l1: 0.1636, vgg: 0.4802, mask: 0.3973\n",
      "step:    67780, time: 0.744, loss: 1.0843, l1: 0.2236, vgg: 0.4647, mask: 0.3960\n",
      "step:    67800, time: 0.795, loss: 1.0499, l1: 0.2051, vgg: 0.4817, mask: 0.3631\n",
      "step:    67820, time: 0.755, loss: 1.0585, l1: 0.2238, vgg: 0.4330, mask: 0.4017\n",
      "step:    67840, time: 0.739, loss: 1.1515, l1: 0.2336, vgg: 0.5146, mask: 0.4032\n",
      "step:    67860, time: 0.781, loss: 1.0853, l1: 0.2321, vgg: 0.4713, mask: 0.3819\n",
      "step:    67880, time: 0.769, loss: 1.1251, l1: 0.2467, vgg: 0.5212, mask: 0.3572\n",
      "step:    67900, time: 0.784, loss: 1.1301, l1: 0.1969, vgg: 0.5330, mask: 0.4003\n",
      "step:    67920, time: 0.768, loss: 1.1090, l1: 0.2382, vgg: 0.4430, mask: 0.4277\n",
      "step:    67940, time: 0.779, loss: 1.2029, l1: 0.2601, vgg: 0.5464, mask: 0.3964\n",
      "step:    67960, time: 0.792, loss: 0.9639, l1: 0.1663, vgg: 0.4343, mask: 0.3632\n",
      "step:    67980, time: 0.758, loss: 1.2070, l1: 0.2696, vgg: 0.5441, mask: 0.3933\n",
      "step:    68000, time: 0.764, loss: 1.0821, l1: 0.2000, vgg: 0.5187, mask: 0.3633\n",
      "step:    68020, time: 0.764, loss: 1.0340, l1: 0.1852, vgg: 0.4981, mask: 0.3508\n",
      "step:    68040, time: 0.746, loss: 1.0438, l1: 0.1889, vgg: 0.4887, mask: 0.3662\n",
      "step:    68060, time: 0.736, loss: 1.0608, l1: 0.2154, vgg: 0.4497, mask: 0.3958\n",
      "step:    68080, time: 0.729, loss: 1.0842, l1: 0.2353, vgg: 0.4625, mask: 0.3864\n",
      "step:    68100, time: 0.751, loss: 0.9392, l1: 0.1625, vgg: 0.4377, mask: 0.3389\n",
      "step:    68120, time: 0.807, loss: 1.0343, l1: 0.2159, vgg: 0.4676, mask: 0.3509\n",
      "step:    68140, time: 0.774, loss: 1.1208, l1: 0.2380, vgg: 0.4734, mask: 0.4094\n",
      "step:    68160, time: 0.759, loss: 1.1745, l1: 0.2598, vgg: 0.5001, mask: 0.4147\n",
      "step:    68180, time: 0.797, loss: 1.1302, l1: 0.2465, vgg: 0.4891, mask: 0.3946\n",
      "step:    68200, time: 0.754, loss: 1.1125, l1: 0.2477, vgg: 0.5028, mask: 0.3619\n",
      "step:    68220, time: 0.775, loss: 1.1671, l1: 0.2627, vgg: 0.4984, mask: 0.4060\n",
      "step:    68240, time: 0.775, loss: 1.1125, l1: 0.1882, vgg: 0.5504, mask: 0.3739\n",
      "step:    68260, time: 0.771, loss: 1.1056, l1: 0.2557, vgg: 0.4555, mask: 0.3943\n",
      "step:    68280, time: 0.773, loss: 1.1760, l1: 0.2872, vgg: 0.4829, mask: 0.4059\n",
      "step:    68300, time: 0.716, loss: 1.0797, l1: 0.2270, vgg: 0.4840, mask: 0.3686\n",
      "step:    68320, time: 0.776, loss: 1.2117, l1: 0.2812, vgg: 0.4942, mask: 0.4363\n",
      "step:    68340, time: 0.743, loss: 1.1160, l1: 0.2708, vgg: 0.4603, mask: 0.3849\n",
      "step:    68360, time: 0.788, loss: 0.9980, l1: 0.1717, vgg: 0.4407, mask: 0.3856\n",
      "step:    68380, time: 0.753, loss: 1.2091, l1: 0.2934, vgg: 0.5014, mask: 0.4143\n",
      "step:    68400, time: 0.751, loss: 1.2079, l1: 0.2593, vgg: 0.5422, mask: 0.4064\n",
      "step:    68420, time: 0.741, loss: 0.9509, l1: 0.1936, vgg: 0.3846, mask: 0.3727\n",
      "step:    68440, time: 0.763, loss: 1.0783, l1: 0.2342, vgg: 0.4673, mask: 0.3769\n",
      "step:    68460, time: 0.757, loss: 1.1091, l1: 0.2229, vgg: 0.4799, mask: 0.4063\n",
      "step:    68480, time: 0.731, loss: 1.0092, l1: 0.1987, vgg: 0.4555, mask: 0.3550\n",
      "step:    68500, time: 0.739, loss: 1.0284, l1: 0.1805, vgg: 0.4751, mask: 0.3729\n",
      "step:    68520, time: 0.783, loss: 1.1389, l1: 0.2260, vgg: 0.5077, mask: 0.4052\n",
      "step:    68540, time: 0.755, loss: 1.0626, l1: 0.2137, vgg: 0.4715, mask: 0.3775\n",
      "step:    68560, time: 0.760, loss: 1.0814, l1: 0.1839, vgg: 0.5253, mask: 0.3722\n",
      "step:    68580, time: 0.759, loss: 1.0469, l1: 0.2177, vgg: 0.4730, mask: 0.3562\n",
      "step:    68600, time: 0.728, loss: 1.0171, l1: 0.1581, vgg: 0.4616, mask: 0.3975\n",
      "step:    68620, time: 0.795, loss: 1.1811, l1: 0.2699, vgg: 0.4880, mask: 0.4232\n",
      "step:    68640, time: 0.753, loss: 0.9599, l1: 0.2096, vgg: 0.3977, mask: 0.3526\n",
      "step:    68660, time: 0.780, loss: 1.0002, l1: 0.1993, vgg: 0.4672, mask: 0.3337\n",
      "step:    68680, time: 0.788, loss: 1.2491, l1: 0.2165, vgg: 0.6574, mask: 0.3751\n",
      "step:    68700, time: 0.769, loss: 1.1197, l1: 0.2726, vgg: 0.4401, mask: 0.4069\n",
      "step:    68720, time: 0.824, loss: 1.0215, l1: 0.1973, vgg: 0.4596, mask: 0.3646\n",
      "step:    68740, time: 0.748, loss: 1.0367, l1: 0.1834, vgg: 0.4955, mask: 0.3578\n",
      "step:    68760, time: 0.755, loss: 1.1123, l1: 0.2329, vgg: 0.4965, mask: 0.3829\n",
      "step:    68780, time: 0.741, loss: 0.9599, l1: 0.1750, vgg: 0.4383, mask: 0.3467\n",
      "step:    68800, time: 0.737, loss: 1.1655, l1: 0.2975, vgg: 0.4757, mask: 0.3923\n",
      "step:    68820, time: 0.783, loss: 1.0475, l1: 0.2059, vgg: 0.5114, mask: 0.3302\n",
      "step:    68840, time: 0.739, loss: 0.9542, l1: 0.2022, vgg: 0.4021, mask: 0.3500\n",
      "step:    68860, time: 0.722, loss: 1.0050, l1: 0.2067, vgg: 0.4127, mask: 0.3855\n",
      "step:    68880, time: 0.736, loss: 1.0085, l1: 0.2149, vgg: 0.4267, mask: 0.3669\n",
      "step:    68900, time: 0.793, loss: 1.1443, l1: 0.2486, vgg: 0.4806, mask: 0.4151\n",
      "step:    68920, time: 0.738, loss: 0.9595, l1: 0.1439, vgg: 0.4343, mask: 0.3813\n",
      "step:    68940, time: 0.776, loss: 1.0812, l1: 0.2055, vgg: 0.4920, mask: 0.3837\n",
      "step:    68960, time: 0.748, loss: 1.1508, l1: 0.2379, vgg: 0.4969, mask: 0.4160\n",
      "step:    68980, time: 0.770, loss: 1.1366, l1: 0.1859, vgg: 0.5399, mask: 0.4108\n",
      "step:    69000, time: 0.745, loss: 1.0834, l1: 0.2251, vgg: 0.4750, mask: 0.3834\n",
      "step:    69020, time: 0.824, loss: 1.1616, l1: 0.2154, vgg: 0.5471, mask: 0.3991\n",
      "step:    69040, time: 0.738, loss: 1.0796, l1: 0.2117, vgg: 0.4917, mask: 0.3762\n",
      "step:    69060, time: 0.737, loss: 1.1860, l1: 0.2765, vgg: 0.4890, mask: 0.4205\n",
      "step:    69080, time: 0.779, loss: 1.1308, l1: 0.2439, vgg: 0.4995, mask: 0.3874\n",
      "step:    69100, time: 0.747, loss: 1.0332, l1: 0.2033, vgg: 0.4813, mask: 0.3486\n",
      "step:    69120, time: 0.772, loss: 0.9760, l1: 0.1596, vgg: 0.4511, mask: 0.3654\n",
      "step:    69140, time: 0.728, loss: 0.9744, l1: 0.1807, vgg: 0.4786, mask: 0.3151\n",
      "step:    69160, time: 0.744, loss: 1.1305, l1: 0.2318, vgg: 0.5020, mask: 0.3966\n",
      "step:    69180, time: 0.775, loss: 1.1377, l1: 0.2273, vgg: 0.5174, mask: 0.3930\n",
      "step:    69200, time: 0.767, loss: 1.1422, l1: 0.2461, vgg: 0.4800, mask: 0.4161\n",
      "step:    69220, time: 0.745, loss: 1.1124, l1: 0.2118, vgg: 0.5114, mask: 0.3891\n",
      "step:    69240, time: 0.728, loss: 1.0413, l1: 0.2249, vgg: 0.4442, mask: 0.3721\n",
      "step:    69260, time: 0.773, loss: 1.1586, l1: 0.2377, vgg: 0.5549, mask: 0.3661\n",
      "step:    69280, time: 0.761, loss: 0.9937, l1: 0.1764, vgg: 0.4421, mask: 0.3752\n",
      "step:    69300, time: 0.782, loss: 1.2810, l1: 0.2660, vgg: 0.6018, mask: 0.4133\n",
      "step:    69320, time: 0.771, loss: 1.1962, l1: 0.2166, vgg: 0.5638, mask: 0.4158\n",
      "step:    69340, time: 0.715, loss: 0.9830, l1: 0.1776, vgg: 0.4506, mask: 0.3548\n",
      "step:    69360, time: 0.755, loss: 1.0386, l1: 0.1927, vgg: 0.4826, mask: 0.3634\n",
      "step:    69380, time: 0.733, loss: 1.0046, l1: 0.1804, vgg: 0.4193, mask: 0.4050\n",
      "step:    69400, time: 0.768, loss: 1.0658, l1: 0.2205, vgg: 0.4844, mask: 0.3609\n",
      "step:    69420, time: 0.794, loss: 0.9882, l1: 0.2174, vgg: 0.4261, mask: 0.3447\n",
      "step:    69440, time: 0.758, loss: 1.1894, l1: 0.2520, vgg: 0.5138, mask: 0.4236\n",
      "step:    69460, time: 0.744, loss: 0.9903, l1: 0.1717, vgg: 0.4402, mask: 0.3784\n",
      "step:    69480, time: 0.759, loss: 1.0264, l1: 0.2188, vgg: 0.4036, mask: 0.4039\n",
      "step:    69500, time: 0.775, loss: 1.0698, l1: 0.2430, vgg: 0.4349, mask: 0.3920\n",
      "step:    69520, time: 0.745, loss: 1.0519, l1: 0.1978, vgg: 0.4711, mask: 0.3830\n",
      "step:    69540, time: 0.777, loss: 0.9721, l1: 0.1810, vgg: 0.4261, mask: 0.3650\n",
      "step:    69560, time: 0.761, loss: 1.1296, l1: 0.2461, vgg: 0.5122, mask: 0.3713\n",
      "step:    69580, time: 0.758, loss: 1.1556, l1: 0.2378, vgg: 0.5227, mask: 0.3952\n",
      "step:    69600, time: 0.778, loss: 1.0185, l1: 0.2091, vgg: 0.4444, mask: 0.3651\n",
      "step:    69620, time: 0.756, loss: 1.0324, l1: 0.1900, vgg: 0.4936, mask: 0.3488\n",
      "step:    69640, time: 0.784, loss: 1.1641, l1: 0.2742, vgg: 0.4724, mask: 0.4175\n",
      "step:    69660, time: 0.746, loss: 1.2182, l1: 0.2911, vgg: 0.5253, mask: 0.4017\n",
      "step:    69680, time: 0.742, loss: 0.9039, l1: 0.1495, vgg: 0.4284, mask: 0.3260\n",
      "step:    69700, time: 0.764, loss: 1.0741, l1: 0.2196, vgg: 0.4811, mask: 0.3734\n",
      "step:    69720, time: 0.759, loss: 1.2751, l1: 0.3311, vgg: 0.4929, mask: 0.4511\n",
      "step:    69740, time: 0.765, loss: 1.1055, l1: 0.2031, vgg: 0.5041, mask: 0.3984\n",
      "step:    69760, time: 0.810, loss: 1.2804, l1: 0.2755, vgg: 0.5824, mask: 0.4225\n",
      "step:    69780, time: 0.738, loss: 1.1364, l1: 0.2226, vgg: 0.4724, mask: 0.4415\n",
      "step:    69800, time: 0.747, loss: 1.0326, l1: 0.2019, vgg: 0.4771, mask: 0.3536\n",
      "step:    69820, time: 0.765, loss: 1.1498, l1: 0.2195, vgg: 0.5191, mask: 0.4113\n",
      "step:    69840, time: 0.771, loss: 1.0953, l1: 0.2408, vgg: 0.4655, mask: 0.3890\n",
      "step:    69860, time: 0.793, loss: 1.1193, l1: 0.2455, vgg: 0.4808, mask: 0.3930\n",
      "step:    69880, time: 0.768, loss: 1.0376, l1: 0.2088, vgg: 0.4641, mask: 0.3648\n",
      "step:    69900, time: 0.741, loss: 1.0636, l1: 0.1904, vgg: 0.5336, mask: 0.3396\n",
      "step:    69920, time: 0.761, loss: 1.1077, l1: 0.2465, vgg: 0.4880, mask: 0.3732\n",
      "step:    69940, time: 0.764, loss: 1.0457, l1: 0.1918, vgg: 0.4744, mask: 0.3795\n",
      "step:    69960, time: 0.741, loss: 1.0920, l1: 0.1960, vgg: 0.5442, mask: 0.3518\n",
      "step:    69980, time: 0.810, loss: 1.0948, l1: 0.1803, vgg: 0.5213, mask: 0.3932\n",
      "step:    70000, time: 0.747, loss: 1.2734, l1: 0.2630, vgg: 0.6078, mask: 0.4026\n",
      "step:    70020, time: 0.767, loss: 1.0148, l1: 0.2234, vgg: 0.4277, mask: 0.3637\n",
      "step:    70040, time: 0.847, loss: 1.0720, l1: 0.2091, vgg: 0.5016, mask: 0.3613\n",
      "step:    70060, time: 0.812, loss: 1.0893, l1: 0.2275, vgg: 0.4364, mask: 0.4254\n",
      "step:    70080, time: 0.810, loss: 1.0990, l1: 0.1997, vgg: 0.5475, mask: 0.3519\n",
      "step:    70100, time: 0.729, loss: 0.9819, l1: 0.2069, vgg: 0.4345, mask: 0.3405\n",
      "step:    70120, time: 0.764, loss: 1.0508, l1: 0.2275, vgg: 0.4253, mask: 0.3980\n",
      "step:    70140, time: 0.741, loss: 1.1616, l1: 0.2886, vgg: 0.4947, mask: 0.3783\n",
      "step:    70160, time: 0.728, loss: 1.1968, l1: 0.2821, vgg: 0.5222, mask: 0.3925\n",
      "step:    70180, time: 0.769, loss: 1.0377, l1: 0.1797, vgg: 0.4561, mask: 0.4018\n",
      "step:    70200, time: 0.822, loss: 1.1560, l1: 0.2407, vgg: 0.5127, mask: 0.4026\n",
      "step:    70220, time: 0.779, loss: 1.1331, l1: 0.2545, vgg: 0.4653, mask: 0.4134\n",
      "step:    70240, time: 0.817, loss: 1.0151, l1: 0.1904, vgg: 0.4724, mask: 0.3523\n",
      "step:    70260, time: 0.749, loss: 0.9931, l1: 0.1944, vgg: 0.4459, mask: 0.3528\n",
      "step:    70280, time: 0.791, loss: 1.1164, l1: 0.1941, vgg: 0.5522, mask: 0.3700\n",
      "step:    70300, time: 0.774, loss: 1.0666, l1: 0.2256, vgg: 0.5053, mask: 0.3357\n",
      "step:    70320, time: 0.756, loss: 1.0830, l1: 0.2020, vgg: 0.4951, mask: 0.3859\n",
      "step:    70340, time: 0.783, loss: 1.1705, l1: 0.2376, vgg: 0.5399, mask: 0.3930\n",
      "step:    70360, time: 0.766, loss: 1.0638, l1: 0.2687, vgg: 0.4235, mask: 0.3716\n",
      "step:    70380, time: 0.776, loss: 1.0321, l1: 0.2131, vgg: 0.4609, mask: 0.3581\n",
      "step:    70400, time: 0.797, loss: 1.0383, l1: 0.2042, vgg: 0.4443, mask: 0.3897\n",
      "step:    70420, time: 0.743, loss: 1.0642, l1: 0.2177, vgg: 0.4833, mask: 0.3631\n",
      "step:    70440, time: 0.769, loss: 1.0504, l1: 0.2163, vgg: 0.4679, mask: 0.3661\n",
      "step:    70460, time: 0.748, loss: 0.9921, l1: 0.1922, vgg: 0.4709, mask: 0.3289\n",
      "step:    70480, time: 0.793, loss: 1.1334, l1: 0.2242, vgg: 0.4797, mask: 0.4294\n",
      "step:    70500, time: 0.764, loss: 1.0964, l1: 0.2472, vgg: 0.4672, mask: 0.3820\n",
      "step:    70520, time: 0.768, loss: 1.1517, l1: 0.2402, vgg: 0.5249, mask: 0.3867\n",
      "step:    70540, time: 0.723, loss: 1.0718, l1: 0.2188, vgg: 0.4957, mask: 0.3572\n",
      "step:    70560, time: 0.774, loss: 1.0580, l1: 0.2194, vgg: 0.4581, mask: 0.3804\n",
      "step:    70580, time: 0.762, loss: 0.9716, l1: 0.1875, vgg: 0.4600, mask: 0.3241\n",
      "step:    70600, time: 0.728, loss: 0.8770, l1: 0.1749, vgg: 0.3899, mask: 0.3122\n",
      "step:    70620, time: 0.744, loss: 1.0148, l1: 0.1783, vgg: 0.4639, mask: 0.3726\n",
      "step:    70640, time: 0.793, loss: 1.1219, l1: 0.1960, vgg: 0.5082, mask: 0.4177\n",
      "step:    70660, time: 0.807, loss: 1.2549, l1: 0.3045, vgg: 0.5179, mask: 0.4325\n",
      "step:    70680, time: 0.766, loss: 1.0869, l1: 0.1985, vgg: 0.5320, mask: 0.3565\n",
      "step:    70700, time: 0.756, loss: 1.0321, l1: 0.1907, vgg: 0.4804, mask: 0.3611\n",
      "step:    70720, time: 0.781, loss: 1.0538, l1: 0.2076, vgg: 0.5009, mask: 0.3454\n",
      "step:    70740, time: 0.783, loss: 1.2516, l1: 0.2805, vgg: 0.5772, mask: 0.3940\n",
      "step:    70760, time: 0.795, loss: 1.0748, l1: 0.2128, vgg: 0.4925, mask: 0.3695\n",
      "step:    70780, time: 0.786, loss: 1.0426, l1: 0.2022, vgg: 0.4717, mask: 0.3687\n",
      "step:    70800, time: 0.762, loss: 1.0436, l1: 0.2109, vgg: 0.4627, mask: 0.3701\n",
      "step:    70820, time: 0.742, loss: 1.0660, l1: 0.1868, vgg: 0.5075, mask: 0.3717\n",
      "step:    70840, time: 0.793, loss: 1.1939, l1: 0.2589, vgg: 0.5195, mask: 0.4155\n",
      "step:    70860, time: 0.745, loss: 1.0228, l1: 0.1869, vgg: 0.4776, mask: 0.3583\n",
      "step:    70880, time: 0.746, loss: 1.1749, l1: 0.2500, vgg: 0.5180, mask: 0.4069\n",
      "step:    70900, time: 0.737, loss: 1.0485, l1: 0.2260, vgg: 0.4292, mask: 0.3934\n",
      "step:    70920, time: 0.823, loss: 1.0490, l1: 0.1957, vgg: 0.4871, mask: 0.3662\n",
      "step:    70940, time: 0.751, loss: 1.1799, l1: 0.2605, vgg: 0.5178, mask: 0.4016\n",
      "step:    70960, time: 0.749, loss: 1.1258, l1: 0.2480, vgg: 0.4684, mask: 0.4094\n",
      "step:    70980, time: 0.759, loss: 1.0056, l1: 0.1965, vgg: 0.4464, mask: 0.3627\n",
      "step:    71000, time: 0.741, loss: 0.9999, l1: 0.2181, vgg: 0.4008, mask: 0.3810\n",
      "step:    71020, time: 0.768, loss: 0.9752, l1: 0.1848, vgg: 0.4420, mask: 0.3484\n",
      "step:    71040, time: 0.744, loss: 1.0051, l1: 0.1779, vgg: 0.4440, mask: 0.3832\n",
      "step:    71060, time: 0.751, loss: 1.0619, l1: 0.2303, vgg: 0.4688, mask: 0.3627\n",
      "step:    71080, time: 0.811, loss: 1.1235, l1: 0.2368, vgg: 0.4488, mask: 0.4380\n",
      "step:    71100, time: 0.770, loss: 1.1267, l1: 0.2322, vgg: 0.5037, mask: 0.3908\n",
      "step:    71120, time: 0.288, loss: 0.8428, l1: 0.0896, vgg: 0.4474, mask: 0.3058\n",
      "step:    71140, time: 0.795, loss: 1.1938, l1: 0.2668, vgg: 0.5341, mask: 0.3929\n",
      "step:    71160, time: 0.762, loss: 1.0598, l1: 0.1825, vgg: 0.5303, mask: 0.3470\n",
      "step:    71180, time: 0.799, loss: 1.1394, l1: 0.1890, vgg: 0.5810, mask: 0.3695\n",
      "step:    71200, time: 0.741, loss: 1.0159, l1: 0.1775, vgg: 0.4776, mask: 0.3607\n",
      "step:    71220, time: 0.788, loss: 1.1069, l1: 0.2107, vgg: 0.5144, mask: 0.3818\n",
      "step:    71240, time: 0.817, loss: 1.0750, l1: 0.2310, vgg: 0.4517, mask: 0.3923\n",
      "step:    71260, time: 0.809, loss: 1.0831, l1: 0.2542, vgg: 0.4432, mask: 0.3857\n",
      "step:    71280, time: 0.792, loss: 1.0845, l1: 0.2120, vgg: 0.5248, mask: 0.3477\n",
      "step:    71300, time: 0.739, loss: 1.0025, l1: 0.1834, vgg: 0.4737, mask: 0.3454\n",
      "step:    71320, time: 0.740, loss: 0.9413, l1: 0.1589, vgg: 0.4520, mask: 0.3304\n",
      "step:    71340, time: 0.755, loss: 1.1095, l1: 0.2608, vgg: 0.4195, mask: 0.4293\n",
      "step:    71360, time: 0.794, loss: 1.1116, l1: 0.2073, vgg: 0.5265, mask: 0.3778\n",
      "step:    71380, time: 0.759, loss: 1.0714, l1: 0.2048, vgg: 0.4838, mask: 0.3827\n",
      "step:    71400, time: 0.781, loss: 1.1172, l1: 0.2432, vgg: 0.4834, mask: 0.3907\n",
      "step:    71420, time: 0.763, loss: 1.0796, l1: 0.2458, vgg: 0.4368, mask: 0.3969\n",
      "step:    71440, time: 0.759, loss: 1.0795, l1: 0.2494, vgg: 0.4524, mask: 0.3777\n",
      "step:    71460, time: 0.779, loss: 1.0378, l1: 0.1955, vgg: 0.4638, mask: 0.3786\n",
      "step:    71480, time: 0.743, loss: 1.1260, l1: 0.2588, vgg: 0.4587, mask: 0.4085\n",
      "step:    71500, time: 0.750, loss: 1.1491, l1: 0.2386, vgg: 0.5043, mask: 0.4062\n",
      "step:    71520, time: 0.709, loss: 0.9516, l1: 0.1864, vgg: 0.4109, mask: 0.3544\n",
      "step:    71540, time: 0.768, loss: 1.1239, l1: 0.1948, vgg: 0.5645, mask: 0.3647\n",
      "step:    71560, time: 0.777, loss: 0.9713, l1: 0.1715, vgg: 0.4428, mask: 0.3569\n",
      "step:    71580, time: 0.784, loss: 1.1529, l1: 0.2572, vgg: 0.4674, mask: 0.4282\n",
      "step:    71600, time: 0.715, loss: 0.9077, l1: 0.1810, vgg: 0.4065, mask: 0.3202\n",
      "step:    71620, time: 0.767, loss: 1.1635, l1: 0.2641, vgg: 0.4830, mask: 0.4164\n",
      "step:    71640, time: 0.784, loss: 1.2018, l1: 0.2822, vgg: 0.5184, mask: 0.4012\n",
      "step:    71660, time: 0.801, loss: 1.0609, l1: 0.2084, vgg: 0.4790, mask: 0.3736\n",
      "step:    71680, time: 0.830, loss: 1.0646, l1: 0.2054, vgg: 0.5043, mask: 0.3549\n",
      "step:    71700, time: 0.767, loss: 1.1257, l1: 0.2408, vgg: 0.4808, mask: 0.4041\n",
      "step:    71720, time: 0.802, loss: 1.2322, l1: 0.2854, vgg: 0.5245, mask: 0.4224\n",
      "step:    71740, time: 0.725, loss: 1.0426, l1: 0.2108, vgg: 0.4226, mask: 0.4092\n",
      "step:    71760, time: 0.774, loss: 1.1175, l1: 0.2367, vgg: 0.5232, mask: 0.3576\n",
      "step:    71780, time: 0.772, loss: 1.0457, l1: 0.1915, vgg: 0.4803, mask: 0.3738\n",
      "step:    71800, time: 0.776, loss: 1.1779, l1: 0.2471, vgg: 0.5407, mask: 0.3901\n",
      "step:    71820, time: 0.764, loss: 0.9919, l1: 0.1760, vgg: 0.4384, mask: 0.3776\n",
      "step:    71840, time: 0.766, loss: 1.1278, l1: 0.2292, vgg: 0.5026, mask: 0.3959\n",
      "step:    71860, time: 0.767, loss: 1.0203, l1: 0.1814, vgg: 0.4993, mask: 0.3397\n",
      "step:    71880, time: 0.781, loss: 0.9864, l1: 0.2035, vgg: 0.4464, mask: 0.3365\n",
      "step:    71900, time: 0.728, loss: 1.0310, l1: 0.2181, vgg: 0.4286, mask: 0.3844\n",
      "step:    71920, time: 0.760, loss: 1.0143, l1: 0.2053, vgg: 0.4573, mask: 0.3516\n",
      "step:    71940, time: 0.803, loss: 1.2413, l1: 0.2374, vgg: 0.6133, mask: 0.3905\n",
      "step:    71960, time: 0.774, loss: 1.1019, l1: 0.1968, vgg: 0.5016, mask: 0.4035\n",
      "step:    71980, time: 0.758, loss: 0.9733, l1: 0.2048, vgg: 0.4099, mask: 0.3585\n",
      "step:    72000, time: 0.761, loss: 0.9161, l1: 0.1690, vgg: 0.4159, mask: 0.3313\n",
      "step:    72020, time: 0.727, loss: 0.9971, l1: 0.1904, vgg: 0.4491, mask: 0.3576\n",
      "step:    72040, time: 0.736, loss: 1.2360, l1: 0.2570, vgg: 0.5561, mask: 0.4229\n",
      "step:    72060, time: 0.748, loss: 1.1034, l1: 0.2464, vgg: 0.4681, mask: 0.3889\n",
      "step:    72080, time: 0.735, loss: 0.9014, l1: 0.1770, vgg: 0.4055, mask: 0.3188\n",
      "step:    72100, time: 0.784, loss: 1.1090, l1: 0.2174, vgg: 0.5150, mask: 0.3767\n",
      "step:    72120, time: 0.816, loss: 1.2909, l1: 0.2959, vgg: 0.5886, mask: 0.4063\n",
      "step:    72140, time: 0.767, loss: 1.1034, l1: 0.2313, vgg: 0.4791, mask: 0.3931\n",
      "step:    72160, time: 0.787, loss: 1.0317, l1: 0.1808, vgg: 0.5034, mask: 0.3476\n",
      "step:    72180, time: 0.774, loss: 1.1821, l1: 0.2446, vgg: 0.5678, mask: 0.3697\n",
      "step:    72200, time: 0.796, loss: 1.3066, l1: 0.2725, vgg: 0.5932, mask: 0.4409\n",
      "step:    72220, time: 0.798, loss: 1.1146, l1: 0.2319, vgg: 0.4784, mask: 0.4043\n",
      "step:    72240, time: 0.770, loss: 1.0498, l1: 0.1857, vgg: 0.4686, mask: 0.3955\n",
      "step:    72260, time: 0.787, loss: 1.1744, l1: 0.2628, vgg: 0.4775, mask: 0.4341\n",
      "step:    72280, time: 0.763, loss: 1.0905, l1: 0.2046, vgg: 0.5001, mask: 0.3858\n",
      "step:    72300, time: 0.793, loss: 1.0722, l1: 0.2032, vgg: 0.4784, mask: 0.3906\n",
      "step:    72320, time: 0.734, loss: 1.0784, l1: 0.2028, vgg: 0.4997, mask: 0.3759\n",
      "step:    72340, time: 0.804, loss: 0.9860, l1: 0.1664, vgg: 0.4673, mask: 0.3523\n",
      "step:    72360, time: 0.778, loss: 1.0315, l1: 0.1753, vgg: 0.5430, mask: 0.3132\n",
      "step:    72380, time: 0.740, loss: 1.1823, l1: 0.2551, vgg: 0.5117, mask: 0.4156\n",
      "step:    72400, time: 0.785, loss: 1.1057, l1: 0.2348, vgg: 0.4894, mask: 0.3815\n",
      "step:    72420, time: 0.748, loss: 1.1050, l1: 0.2283, vgg: 0.4980, mask: 0.3788\n",
      "step:    72440, time: 0.759, loss: 1.3071, l1: 0.3007, vgg: 0.5728, mask: 0.4335\n",
      "step:    72460, time: 0.738, loss: 1.0822, l1: 0.2156, vgg: 0.4660, mask: 0.4006\n",
      "step:    72480, time: 0.748, loss: 1.1126, l1: 0.2314, vgg: 0.5244, mask: 0.3569\n",
      "step:    72500, time: 0.751, loss: 1.0094, l1: 0.1786, vgg: 0.4934, mask: 0.3375\n",
      "step:    72520, time: 0.797, loss: 1.1836, l1: 0.2744, vgg: 0.4947, mask: 0.4145\n",
      "step:    72540, time: 0.772, loss: 1.2263, l1: 0.2701, vgg: 0.5165, mask: 0.4397\n",
      "step:    72560, time: 0.772, loss: 0.9656, l1: 0.1501, vgg: 0.4654, mask: 0.3501\n",
      "step:    72580, time: 0.767, loss: 1.1807, l1: 0.2609, vgg: 0.5185, mask: 0.4014\n",
      "step:    72600, time: 0.765, loss: 1.1315, l1: 0.2212, vgg: 0.5141, mask: 0.3963\n",
      "step:    72620, time: 0.733, loss: 0.9764, l1: 0.1943, vgg: 0.4276, mask: 0.3546\n",
      "step:    72640, time: 0.779, loss: 1.1482, l1: 0.2194, vgg: 0.4980, mask: 0.4308\n",
      "step:    72660, time: 0.804, loss: 1.1325, l1: 0.2500, vgg: 0.4898, mask: 0.3927\n",
      "step:    72680, time: 0.723, loss: 0.9897, l1: 0.1691, vgg: 0.4484, mask: 0.3722\n",
      "step:    72700, time: 0.792, loss: 1.1748, l1: 0.2509, vgg: 0.4981, mask: 0.4259\n",
      "step:    72720, time: 0.781, loss: 1.2014, l1: 0.2986, vgg: 0.4977, mask: 0.4050\n",
      "step:    72740, time: 0.783, loss: 1.0482, l1: 0.1808, vgg: 0.4959, mask: 0.3716\n",
      "step:    72760, time: 0.759, loss: 0.9874, l1: 0.1810, vgg: 0.4678, mask: 0.3386\n",
      "step:    72780, time: 0.757, loss: 1.0831, l1: 0.1905, vgg: 0.5107, mask: 0.3818\n",
      "step:    72800, time: 0.881, loss: 1.0538, l1: 0.2345, vgg: 0.4559, mask: 0.3634\n",
      "step:    72820, time: 0.775, loss: 1.0828, l1: 0.2316, vgg: 0.4861, mask: 0.3650\n",
      "step:    72840, time: 0.777, loss: 1.0205, l1: 0.1999, vgg: 0.4647, mask: 0.3559\n",
      "step:    72860, time: 0.762, loss: 0.9960, l1: 0.1703, vgg: 0.4914, mask: 0.3343\n",
      "step:    72880, time: 0.730, loss: 0.9754, l1: 0.1949, vgg: 0.4356, mask: 0.3448\n",
      "step:    72900, time: 0.836, loss: 1.1471, l1: 0.2410, vgg: 0.5331, mask: 0.3730\n",
      "step:    72920, time: 0.769, loss: 1.2345, l1: 0.2652, vgg: 0.5948, mask: 0.3745\n",
      "step:    72940, time: 0.801, loss: 1.0791, l1: 0.2182, vgg: 0.5009, mask: 0.3599\n",
      "step:    72960, time: 0.756, loss: 1.1123, l1: 0.2253, vgg: 0.4878, mask: 0.3993\n",
      "step:    72980, time: 0.783, loss: 1.1340, l1: 0.2487, vgg: 0.5120, mask: 0.3733\n",
      "step:    73000, time: 0.782, loss: 1.0828, l1: 0.2134, vgg: 0.4634, mask: 0.4060\n",
      "step:    73020, time: 0.780, loss: 1.1262, l1: 0.2283, vgg: 0.5180, mask: 0.3800\n",
      "step:    73040, time: 0.771, loss: 1.1751, l1: 0.2717, vgg: 0.5140, mask: 0.3894\n",
      "step:    73060, time: 0.752, loss: 1.0158, l1: 0.2254, vgg: 0.4318, mask: 0.3587\n",
      "step:    73080, time: 0.735, loss: 0.9423, l1: 0.1763, vgg: 0.4076, mask: 0.3585\n",
      "step:    73100, time: 0.741, loss: 1.1350, l1: 0.2233, vgg: 0.5437, mask: 0.3680\n",
      "step:    73120, time: 0.715, loss: 0.9332, l1: 0.1526, vgg: 0.4021, mask: 0.3785\n",
      "step:    73140, time: 0.755, loss: 1.0678, l1: 0.2411, vgg: 0.4767, mask: 0.3500\n",
      "step:    73160, time: 0.772, loss: 1.0098, l1: 0.1796, vgg: 0.4974, mask: 0.3328\n",
      "step:    73180, time: 0.761, loss: 1.0198, l1: 0.2092, vgg: 0.4596, mask: 0.3509\n",
      "step:    73200, time: 0.804, loss: 1.0476, l1: 0.1854, vgg: 0.4891, mask: 0.3731\n",
      "step:    73220, time: 0.748, loss: 1.0885, l1: 0.2244, vgg: 0.5031, mask: 0.3609\n",
      "step:    73240, time: 0.764, loss: 0.9423, l1: 0.1627, vgg: 0.4321, mask: 0.3475\n",
      "step:    73260, time: 0.733, loss: 1.0890, l1: 0.2485, vgg: 0.4677, mask: 0.3728\n",
      "step:    73280, time: 0.803, loss: 1.1204, l1: 0.2289, vgg: 0.5136, mask: 0.3778\n",
      "step:    73300, time: 0.774, loss: 1.1340, l1: 0.1975, vgg: 0.5840, mask: 0.3524\n",
      "step:    73320, time: 0.770, loss: 1.0756, l1: 0.2291, vgg: 0.4577, mask: 0.3888\n",
      "step:    73340, time: 0.831, loss: 1.0751, l1: 0.1894, vgg: 0.4987, mask: 0.3870\n",
      "step:    73360, time: 0.781, loss: 1.1054, l1: 0.2205, vgg: 0.5076, mask: 0.3773\n",
      "step:    73380, time: 0.813, loss: 1.0619, l1: 0.2082, vgg: 0.4831, mask: 0.3706\n",
      "step:    73400, time: 0.850, loss: 1.0423, l1: 0.1904, vgg: 0.5082, mask: 0.3438\n",
      "step:    73420, time: 0.787, loss: 1.0034, l1: 0.1682, vgg: 0.4655, mask: 0.3697\n",
      "step:    73440, time: 0.856, loss: 1.0298, l1: 0.1738, vgg: 0.4867, mask: 0.3693\n",
      "step:    73460, time: 0.811, loss: 1.0806, l1: 0.2030, vgg: 0.5254, mask: 0.3522\n",
      "step:    73480, time: 0.863, loss: 1.1681, l1: 0.2126, vgg: 0.5679, mask: 0.3876\n",
      "step:    73500, time: 0.839, loss: 1.1390, l1: 0.2320, vgg: 0.5322, mask: 0.3748\n",
      "step:    73520, time: 0.874, loss: 1.1558, l1: 0.2512, vgg: 0.4792, mask: 0.4254\n",
      "step:    73540, time: 0.830, loss: 1.1357, l1: 0.2405, vgg: 0.5035, mask: 0.3917\n",
      "step:    73560, time: 0.821, loss: 1.0813, l1: 0.2124, vgg: 0.4978, mask: 0.3710\n",
      "step:    73580, time: 0.799, loss: 1.0735, l1: 0.1966, vgg: 0.4953, mask: 0.3816\n",
      "step:    73600, time: 0.838, loss: 0.9241, l1: 0.1771, vgg: 0.4082, mask: 0.3387\n",
      "step:    73620, time: 0.812, loss: 1.2238, l1: 0.2832, vgg: 0.5200, mask: 0.4206\n",
      "step:    73640, time: 0.814, loss: 1.0648, l1: 0.1949, vgg: 0.4958, mask: 0.3741\n",
      "step:    73660, time: 0.823, loss: 1.1302, l1: 0.2731, vgg: 0.4701, mask: 0.3870\n",
      "step:    73680, time: 0.837, loss: 1.0766, l1: 0.2243, vgg: 0.4780, mask: 0.3743\n",
      "step:    73700, time: 0.879, loss: 1.1777, l1: 0.2696, vgg: 0.4955, mask: 0.4126\n",
      "step:    73720, time: 0.826, loss: 1.0055, l1: 0.1895, vgg: 0.4737, mask: 0.3423\n",
      "step:    73740, time: 0.799, loss: 1.0919, l1: 0.2157, vgg: 0.4891, mask: 0.3870\n",
      "step:    73760, time: 0.805, loss: 1.0416, l1: 0.2168, vgg: 0.4292, mask: 0.3956\n",
      "step:    73780, time: 0.845, loss: 1.0258, l1: 0.1942, vgg: 0.4831, mask: 0.3485\n",
      "step:    73800, time: 0.791, loss: 1.0135, l1: 0.1836, vgg: 0.4489, mask: 0.3810\n",
      "step:    73820, time: 0.755, loss: 1.0862, l1: 0.2244, vgg: 0.4584, mask: 0.4034\n",
      "step:    73840, time: 0.749, loss: 1.0956, l1: 0.2485, vgg: 0.4896, mask: 0.3575\n",
      "step:    73860, time: 0.766, loss: 1.0856, l1: 0.2392, vgg: 0.4705, mask: 0.3760\n",
      "step:    73880, time: 0.818, loss: 1.1022, l1: 0.2273, vgg: 0.4861, mask: 0.3888\n",
      "step:    73900, time: 0.768, loss: 0.9987, l1: 0.1967, vgg: 0.4157, mask: 0.3863\n",
      "step:    73920, time: 0.759, loss: 1.0990, l1: 0.1966, vgg: 0.5266, mask: 0.3758\n",
      "step:    73940, time: 0.766, loss: 1.1551, l1: 0.2460, vgg: 0.5107, mask: 0.3984\n",
      "step:    73960, time: 0.760, loss: 1.0678, l1: 0.2029, vgg: 0.4686, mask: 0.3964\n",
      "step:    73980, time: 0.737, loss: 1.0201, l1: 0.2074, vgg: 0.4526, mask: 0.3600\n",
      "step:    74000, time: 0.736, loss: 1.2109, l1: 0.2645, vgg: 0.5378, mask: 0.4086\n",
      "step:    74020, time: 0.767, loss: 1.1211, l1: 0.2246, vgg: 0.5075, mask: 0.3890\n",
      "step:    74040, time: 0.813, loss: 1.1076, l1: 0.2100, vgg: 0.5034, mask: 0.3941\n",
      "step:    74060, time: 0.762, loss: 1.0352, l1: 0.1940, vgg: 0.4856, mask: 0.3557\n",
      "step:    74080, time: 0.765, loss: 1.1653, l1: 0.2535, vgg: 0.5077, mask: 0.4041\n",
      "step:    74100, time: 0.756, loss: 1.0375, l1: 0.2153, vgg: 0.4499, mask: 0.3724\n",
      "step:    74120, time: 0.740, loss: 1.0033, l1: 0.1805, vgg: 0.4719, mask: 0.3508\n",
      "step:    74140, time: 0.825, loss: 1.0314, l1: 0.2036, vgg: 0.4804, mask: 0.3474\n",
      "step:    74160, time: 0.764, loss: 1.1772, l1: 0.2677, vgg: 0.5591, mask: 0.3504\n",
      "step:    74180, time: 0.761, loss: 1.0456, l1: 0.2068, vgg: 0.4515, mask: 0.3873\n",
      "step:    74200, time: 0.743, loss: 0.9840, l1: 0.1804, vgg: 0.4387, mask: 0.3648\n",
      "step:    74220, time: 0.796, loss: 1.0439, l1: 0.1927, vgg: 0.4759, mask: 0.3753\n",
      "step:    74240, time: 0.813, loss: 1.0446, l1: 0.1684, vgg: 0.5153, mask: 0.3609\n",
      "step:    74260, time: 0.766, loss: 1.0850, l1: 0.2358, vgg: 0.4770, mask: 0.3723\n",
      "step:    74280, time: 0.748, loss: 1.0071, l1: 0.1908, vgg: 0.4838, mask: 0.3325\n",
      "step:    74300, time: 0.762, loss: 1.1360, l1: 0.2445, vgg: 0.5012, mask: 0.3903\n",
      "step:    74320, time: 0.767, loss: 1.1650, l1: 0.2919, vgg: 0.4696, mask: 0.4036\n",
      "step:    74340, time: 0.744, loss: 1.2315, l1: 0.2383, vgg: 0.6121, mask: 0.3811\n",
      "step:    74360, time: 0.779, loss: 1.1148, l1: 0.2570, vgg: 0.4647, mask: 0.3931\n",
      "step:    74380, time: 0.734, loss: 1.1177, l1: 0.2262, vgg: 0.5091, mask: 0.3824\n",
      "step:    74400, time: 0.763, loss: 1.1358, l1: 0.2388, vgg: 0.5138, mask: 0.3831\n",
      "step:    74420, time: 0.734, loss: 0.9903, l1: 0.1654, vgg: 0.5002, mask: 0.3247\n",
      "step:    74440, time: 0.763, loss: 1.0309, l1: 0.2424, vgg: 0.4274, mask: 0.3611\n",
      "step:    74460, time: 0.736, loss: 1.0121, l1: 0.1641, vgg: 0.4980, mask: 0.3500\n",
      "step:    74480, time: 0.771, loss: 1.1657, l1: 0.2447, vgg: 0.5471, mask: 0.3739\n",
      "step:    74500, time: 0.758, loss: 1.0062, l1: 0.1693, vgg: 0.4885, mask: 0.3484\n",
      "step:    74520, time: 0.716, loss: 0.9465, l1: 0.1985, vgg: 0.4063, mask: 0.3417\n",
      "step:    74540, time: 0.814, loss: 0.9795, l1: 0.1601, vgg: 0.4343, mask: 0.3851\n",
      "step:    74560, time: 0.796, loss: 1.0655, l1: 0.2337, vgg: 0.4553, mask: 0.3765\n",
      "step:    74580, time: 0.776, loss: 1.1624, l1: 0.2666, vgg: 0.4754, mask: 0.4204\n",
      "step:    74600, time: 0.805, loss: 1.0811, l1: 0.2023, vgg: 0.5143, mask: 0.3645\n",
      "step:    74620, time: 0.750, loss: 1.0248, l1: 0.2058, vgg: 0.4541, mask: 0.3649\n",
      "step:    74640, time: 0.776, loss: 1.0490, l1: 0.2098, vgg: 0.4779, mask: 0.3613\n",
      "step:    74660, time: 0.804, loss: 1.1554, l1: 0.2439, vgg: 0.5389, mask: 0.3726\n",
      "step:    74680, time: 0.766, loss: 1.0733, l1: 0.2087, vgg: 0.4499, mask: 0.4146\n",
      "step:    74700, time: 0.735, loss: 1.1274, l1: 0.2740, vgg: 0.4502, mask: 0.4032\n",
      "step:    74720, time: 0.794, loss: 1.0602, l1: 0.2764, vgg: 0.3957, mask: 0.3881\n",
      "step:    74740, time: 0.770, loss: 1.0745, l1: 0.2348, vgg: 0.4612, mask: 0.3784\n",
      "step:    74760, time: 0.794, loss: 1.2003, l1: 0.2453, vgg: 0.5603, mask: 0.3947\n",
      "step:    74780, time: 0.839, loss: 1.1580, l1: 0.2313, vgg: 0.5266, mask: 0.4001\n",
      "step:    74800, time: 0.777, loss: 0.9984, l1: 0.1932, vgg: 0.4502, mask: 0.3550\n",
      "step:    74820, time: 0.813, loss: 1.2405, l1: 0.3280, vgg: 0.5033, mask: 0.4092\n",
      "step:    74840, time: 0.750, loss: 1.1593, l1: 0.2285, vgg: 0.5163, mask: 0.4145\n",
      "step:    74860, time: 0.773, loss: 1.1298, l1: 0.2412, vgg: 0.4967, mask: 0.3919\n",
      "step:    74880, time: 0.795, loss: 1.1298, l1: 0.2281, vgg: 0.5362, mask: 0.3655\n",
      "step:    74900, time: 0.781, loss: 1.1940, l1: 0.2583, vgg: 0.5428, mask: 0.3929\n",
      "step:    74920, time: 0.765, loss: 1.0586, l1: 0.1661, vgg: 0.5172, mask: 0.3754\n",
      "step:    74940, time: 0.744, loss: 1.0316, l1: 0.1754, vgg: 0.5329, mask: 0.3234\n",
      "step:    74960, time: 0.791, loss: 1.1448, l1: 0.2405, vgg: 0.5370, mask: 0.3673\n",
      "step:    74980, time: 0.764, loss: 1.3157, l1: 0.3245, vgg: 0.5607, mask: 0.4304\n",
      "step:    75000, time: 0.766, loss: 1.0635, l1: 0.2409, vgg: 0.4383, mask: 0.3844\n",
      "step:    75020, time: 0.724, loss: 1.0931, l1: 0.2326, vgg: 0.4819, mask: 0.3786\n",
      "step:    75040, time: 0.793, loss: 1.0361, l1: 0.1978, vgg: 0.4662, mask: 0.3721\n",
      "step:    75060, time: 0.731, loss: 1.0077, l1: 0.1799, vgg: 0.4947, mask: 0.3331\n",
      "step:    75080, time: 0.782, loss: 1.1120, l1: 0.2337, vgg: 0.5040, mask: 0.3743\n",
      "step:    75100, time: 0.764, loss: 1.1520, l1: 0.1954, vgg: 0.5788, mask: 0.3778\n",
      "step:    75120, time: 0.772, loss: 1.0854, l1: 0.1985, vgg: 0.4956, mask: 0.3913\n",
      "step:    75140, time: 0.759, loss: 1.0638, l1: 0.2420, vgg: 0.4338, mask: 0.3881\n",
      "step:    75160, time: 0.751, loss: 1.0360, l1: 0.1668, vgg: 0.5153, mask: 0.3540\n",
      "step:    75180, time: 0.754, loss: 1.0449, l1: 0.1955, vgg: 0.5013, mask: 0.3481\n",
      "step:    75200, time: 0.790, loss: 1.0749, l1: 0.2299, vgg: 0.4691, mask: 0.3758\n",
      "step:    75220, time: 0.767, loss: 1.1061, l1: 0.2447, vgg: 0.4834, mask: 0.3780\n",
      "step:    75240, time: 0.774, loss: 1.1192, l1: 0.2247, vgg: 0.5241, mask: 0.3703\n",
      "step:    75260, time: 0.798, loss: 1.1989, l1: 0.2331, vgg: 0.5831, mask: 0.3828\n",
      "step:    75280, time: 0.803, loss: 1.0985, l1: 0.2242, vgg: 0.4497, mask: 0.4245\n",
      "step:    75300, time: 0.798, loss: 1.0557, l1: 0.2145, vgg: 0.4746, mask: 0.3665\n",
      "step:    75320, time: 0.761, loss: 1.0431, l1: 0.2203, vgg: 0.4678, mask: 0.3550\n",
      "step:    75340, time: 0.720, loss: 1.0258, l1: 0.2062, vgg: 0.4700, mask: 0.3497\n",
      "step:    75360, time: 0.777, loss: 1.1001, l1: 0.2083, vgg: 0.5337, mask: 0.3580\n",
      "step:    75380, time: 0.741, loss: 1.1609, l1: 0.2956, vgg: 0.4565, mask: 0.4088\n",
      "step:    75400, time: 0.779, loss: 1.1612, l1: 0.2316, vgg: 0.5821, mask: 0.3475\n",
      "step:    75420, time: 0.748, loss: 1.0527, l1: 0.1918, vgg: 0.4865, mask: 0.3745\n",
      "step:    75440, time: 0.770, loss: 0.9485, l1: 0.1808, vgg: 0.4027, mask: 0.3650\n",
      "step:    75460, time: 0.770, loss: 1.0252, l1: 0.1794, vgg: 0.4878, mask: 0.3580\n",
      "step:    75480, time: 0.753, loss: 1.0959, l1: 0.2327, vgg: 0.4913, mask: 0.3719\n",
      "step:    75500, time: 0.786, loss: 1.1805, l1: 0.2298, vgg: 0.5681, mask: 0.3826\n",
      "step:    75520, time: 0.756, loss: 0.9663, l1: 0.1610, vgg: 0.4611, mask: 0.3442\n",
      "step:    75540, time: 0.773, loss: 1.3486, l1: 0.3103, vgg: 0.6452, mask: 0.3931\n",
      "step:    75560, time: 0.763, loss: 1.1309, l1: 0.1894, vgg: 0.5727, mask: 0.3687\n",
      "step:    75580, time: 0.772, loss: 0.9832, l1: 0.1879, vgg: 0.3988, mask: 0.3965\n",
      "step:    75600, time: 0.727, loss: 1.0264, l1: 0.2257, vgg: 0.4251, mask: 0.3756\n",
      "step:    75620, time: 0.786, loss: 1.1114, l1: 0.1878, vgg: 0.5340, mask: 0.3896\n",
      "step:    75640, time: 0.709, loss: 0.9696, l1: 0.1538, vgg: 0.4419, mask: 0.3739\n",
      "step:    75660, time: 0.740, loss: 0.9405, l1: 0.1670, vgg: 0.4426, mask: 0.3309\n",
      "step:    75680, time: 0.788, loss: 1.1632, l1: 0.2024, vgg: 0.5807, mask: 0.3800\n",
      "step:    75700, time: 0.779, loss: 1.0807, l1: 0.1895, vgg: 0.5237, mask: 0.3675\n",
      "step:    75720, time: 0.745, loss: 1.1881, l1: 0.3110, vgg: 0.4654, mask: 0.4117\n",
      "step:    75740, time: 0.792, loss: 1.0407, l1: 0.1918, vgg: 0.4855, mask: 0.3634\n",
      "step:    75760, time: 0.748, loss: 1.1479, l1: 0.2384, vgg: 0.4961, mask: 0.4135\n",
      "step:    75780, time: 0.795, loss: 1.1148, l1: 0.2176, vgg: 0.5123, mask: 0.3849\n",
      "step:    75800, time: 0.809, loss: 1.2003, l1: 0.2736, vgg: 0.5122, mask: 0.4146\n",
      "step:    75820, time: 0.792, loss: 1.1781, l1: 0.2314, vgg: 0.5411, mask: 0.4056\n",
      "step:    75840, time: 0.778, loss: 1.1506, l1: 0.2263, vgg: 0.5533, mask: 0.3710\n",
      "step:    75860, time: 0.755, loss: 1.0653, l1: 0.2153, vgg: 0.4699, mask: 0.3801\n",
      "step:    75880, time: 0.770, loss: 1.1754, l1: 0.2465, vgg: 0.5487, mask: 0.3801\n",
      "step:    75900, time: 0.785, loss: 1.0814, l1: 0.2363, vgg: 0.4465, mask: 0.3986\n",
      "step:    75920, time: 0.790, loss: 0.9923, l1: 0.1869, vgg: 0.4286, mask: 0.3768\n",
      "step:    75940, time: 0.743, loss: 1.0493, l1: 0.2260, vgg: 0.4426, mask: 0.3807\n",
      "step:    75960, time: 0.740, loss: 1.1070, l1: 0.2273, vgg: 0.4860, mask: 0.3937\n",
      "step:    75980, time: 0.759, loss: 1.0988, l1: 0.2163, vgg: 0.4999, mask: 0.3826\n",
      "step:    76000, time: 0.726, loss: 1.0294, l1: 0.1765, vgg: 0.4868, mask: 0.3661\n",
      "step:    76020, time: 0.758, loss: 1.0559, l1: 0.2109, vgg: 0.4881, mask: 0.3570\n",
      "step:    76040, time: 0.762, loss: 1.1663, l1: 0.2888, vgg: 0.4704, mask: 0.4072\n",
      "step:    76060, time: 0.725, loss: 0.9790, l1: 0.1790, vgg: 0.4386, mask: 0.3615\n",
      "step:    76080, time: 0.734, loss: 0.9203, l1: 0.1499, vgg: 0.4028, mask: 0.3676\n",
      "step:    76100, time: 0.727, loss: 1.0839, l1: 0.2765, vgg: 0.4472, mask: 0.3602\n",
      "step:    76120, time: 0.731, loss: 1.0097, l1: 0.1973, vgg: 0.4248, mask: 0.3876\n",
      "step:    76140, time: 0.747, loss: 1.1483, l1: 0.2202, vgg: 0.5465, mask: 0.3816\n",
      "step:    76160, time: 0.770, loss: 0.9799, l1: 0.2102, vgg: 0.3927, mask: 0.3770\n",
      "step:    76180, time: 0.853, loss: 1.0544, l1: 0.2169, vgg: 0.4785, mask: 0.3590\n",
      "step:    76200, time: 0.784, loss: 1.0230, l1: 0.1973, vgg: 0.4645, mask: 0.3612\n",
      "step:    76220, time: 0.760, loss: 1.1181, l1: 0.2430, vgg: 0.4750, mask: 0.4001\n",
      "step:    76240, time: 0.771, loss: 1.1300, l1: 0.2058, vgg: 0.5327, mask: 0.3915\n",
      "step:    76260, time: 0.760, loss: 1.0010, l1: 0.2011, vgg: 0.4294, mask: 0.3705\n",
      "step:    76280, time: 0.767, loss: 1.0888, l1: 0.2288, vgg: 0.4962, mask: 0.3638\n",
      "step:    76300, time: 0.745, loss: 1.1473, l1: 0.2115, vgg: 0.5858, mask: 0.3499\n",
      "step:    76320, time: 0.762, loss: 1.1486, l1: 0.2444, vgg: 0.5157, mask: 0.3885\n",
      "step:    76340, time: 0.751, loss: 1.1319, l1: 0.2303, vgg: 0.5077, mask: 0.3938\n",
      "step:    76360, time: 0.772, loss: 0.9973, l1: 0.1804, vgg: 0.4639, mask: 0.3530\n",
      "step:    76380, time: 0.767, loss: 1.2326, l1: 0.2928, vgg: 0.5596, mask: 0.3803\n",
      "step:    76400, time: 0.767, loss: 1.1088, l1: 0.2385, vgg: 0.4773, mask: 0.3931\n",
      "step:    76420, time: 0.777, loss: 1.0639, l1: 0.2315, vgg: 0.4673, mask: 0.3650\n",
      "step:    76440, time: 0.761, loss: 1.0649, l1: 0.2356, vgg: 0.4434, mask: 0.3859\n",
      "step:    76460, time: 0.734, loss: 1.0925, l1: 0.2380, vgg: 0.4796, mask: 0.3749\n",
      "step:    76480, time: 0.797, loss: 1.1130, l1: 0.2367, vgg: 0.5024, mask: 0.3739\n",
      "step:    76500, time: 0.795, loss: 1.0956, l1: 0.1744, vgg: 0.5328, mask: 0.3884\n",
      "step:    76520, time: 0.722, loss: 1.0046, l1: 0.1891, vgg: 0.4632, mask: 0.3523\n",
      "step:    76540, time: 0.737, loss: 0.9888, l1: 0.1931, vgg: 0.4369, mask: 0.3588\n",
      "step:    76560, time: 0.767, loss: 1.0584, l1: 0.1983, vgg: 0.4976, mask: 0.3626\n",
      "step:    76580, time: 0.780, loss: 1.0631, l1: 0.1676, vgg: 0.5204, mask: 0.3751\n",
      "step:    76600, time: 0.756, loss: 1.0675, l1: 0.1996, vgg: 0.5211, mask: 0.3469\n",
      "step:    76620, time: 0.789, loss: 0.9797, l1: 0.1685, vgg: 0.4460, mask: 0.3651\n",
      "step:    76640, time: 0.758, loss: 1.0534, l1: 0.1989, vgg: 0.5142, mask: 0.3403\n",
      "step:    76660, time: 0.800, loss: 1.0508, l1: 0.1929, vgg: 0.4947, mask: 0.3632\n",
      "step:    76680, time: 0.793, loss: 1.0009, l1: 0.2106, vgg: 0.3858, mask: 0.4045\n",
      "step:    76700, time: 0.831, loss: 1.0393, l1: 0.2087, vgg: 0.4609, mask: 0.3696\n",
      "step:    76720, time: 0.812, loss: 1.0791, l1: 0.2035, vgg: 0.4600, mask: 0.4155\n",
      "step:    76740, time: 0.851, loss: 1.1538, l1: 0.2279, vgg: 0.5288, mask: 0.3970\n",
      "step:    76760, time: 0.767, loss: 1.0894, l1: 0.2039, vgg: 0.5047, mask: 0.3808\n",
      "step:    76780, time: 0.750, loss: 1.1126, l1: 0.2301, vgg: 0.5120, mask: 0.3705\n",
      "step:    76800, time: 0.766, loss: 1.1227, l1: 0.2593, vgg: 0.4861, mask: 0.3772\n",
      "step:    76820, time: 0.750, loss: 1.1569, l1: 0.2402, vgg: 0.5111, mask: 0.4055\n",
      "step:    76840, time: 0.787, loss: 1.0270, l1: 0.1972, vgg: 0.4417, mask: 0.3882\n",
      "step:    76860, time: 0.756, loss: 1.0980, l1: 0.2496, vgg: 0.4785, mask: 0.3699\n",
      "step:    76880, time: 0.775, loss: 1.1469, l1: 0.1975, vgg: 0.5926, mask: 0.3567\n",
      "step:    76900, time: 0.730, loss: 0.9659, l1: 0.1747, vgg: 0.4159, mask: 0.3753\n",
      "step:    76920, time: 0.776, loss: 1.0999, l1: 0.2288, vgg: 0.4818, mask: 0.3894\n",
      "step:    76940, time: 0.761, loss: 1.0871, l1: 0.2027, vgg: 0.4836, mask: 0.4008\n",
      "step:    76960, time: 0.743, loss: 1.0683, l1: 0.2439, vgg: 0.4279, mask: 0.3964\n",
      "step:    76980, time: 0.768, loss: 0.9772, l1: 0.2054, vgg: 0.4170, mask: 0.3549\n",
      "step:    77000, time: 0.692, loss: 0.9837, l1: 0.2158, vgg: 0.3912, mask: 0.3767\n",
      "step:    77020, time: 0.762, loss: 0.9961, l1: 0.1864, vgg: 0.4577, mask: 0.3520\n",
      "step:    77040, time: 0.746, loss: 1.0200, l1: 0.1656, vgg: 0.4905, mask: 0.3639\n",
      "step:    77060, time: 0.767, loss: 0.9890, l1: 0.1832, vgg: 0.4687, mask: 0.3371\n",
      "step:    77080, time: 0.762, loss: 1.0968, l1: 0.2424, vgg: 0.4442, mask: 0.4101\n",
      "step:    77100, time: 0.757, loss: 1.1465, l1: 0.2619, vgg: 0.4697, mask: 0.4148\n",
      "step:    77120, time: 0.786, loss: 1.1172, l1: 0.2249, vgg: 0.4889, mask: 0.4034\n",
      "step:    77140, time: 0.775, loss: 1.1799, l1: 0.2262, vgg: 0.5687, mask: 0.3850\n",
      "step:    77160, time: 0.758, loss: 0.9844, l1: 0.1738, vgg: 0.4787, mask: 0.3319\n",
      "step:    77180, time: 0.770, loss: 1.0923, l1: 0.1972, vgg: 0.5019, mask: 0.3933\n",
      "step:    77200, time: 0.787, loss: 1.1568, l1: 0.2152, vgg: 0.5447, mask: 0.3969\n",
      "step:    77220, time: 0.751, loss: 1.1837, l1: 0.2265, vgg: 0.5294, mask: 0.4278\n",
      "step:    77240, time: 0.778, loss: 1.0456, l1: 0.1956, vgg: 0.4766, mask: 0.3735\n",
      "step:    77260, time: 0.748, loss: 0.9428, l1: 0.1619, vgg: 0.4368, mask: 0.3441\n",
      "step:    77280, time: 0.747, loss: 1.0307, l1: 0.1727, vgg: 0.4910, mask: 0.3671\n",
      "step:    77300, time: 0.784, loss: 1.0647, l1: 0.2193, vgg: 0.4662, mask: 0.3792\n",
      "step:    77320, time: 0.742, loss: 1.0514, l1: 0.2153, vgg: 0.4495, mask: 0.3865\n",
      "step:    77340, time: 0.741, loss: 1.0284, l1: 0.1976, vgg: 0.4743, mask: 0.3565\n",
      "step:    77360, time: 0.775, loss: 1.1097, l1: 0.2306, vgg: 0.4906, mask: 0.3884\n",
      "step:    77380, time: 0.778, loss: 1.1430, l1: 0.2538, vgg: 0.4730, mask: 0.4161\n",
      "step:    77400, time: 0.766, loss: 1.0929, l1: 0.1711, vgg: 0.4958, mask: 0.4261\n",
      "step:    77420, time: 0.760, loss: 1.0563, l1: 0.2085, vgg: 0.4466, mask: 0.4012\n",
      "step:    77440, time: 0.758, loss: 1.0270, l1: 0.2030, vgg: 0.4784, mask: 0.3456\n",
      "step:    77460, time: 0.741, loss: 1.0809, l1: 0.2634, vgg: 0.4230, mask: 0.3945\n",
      "step:    77480, time: 0.810, loss: 1.0627, l1: 0.2171, vgg: 0.4592, mask: 0.3863\n",
      "step:    77500, time: 0.851, loss: 1.1422, l1: 0.2199, vgg: 0.5537, mask: 0.3687\n",
      "step:    77520, time: 0.832, loss: 1.1449, l1: 0.2572, vgg: 0.4727, mask: 0.4149\n",
      "step:    77540, time: 0.861, loss: 1.1791, l1: 0.2545, vgg: 0.5345, mask: 0.3901\n",
      "step:    77560, time: 0.831, loss: 1.1107, l1: 0.2511, vgg: 0.4667, mask: 0.3929\n",
      "step:    77580, time: 0.809, loss: 1.0125, l1: 0.1942, vgg: 0.4656, mask: 0.3527\n",
      "step:    77600, time: 0.820, loss: 1.2675, l1: 0.3409, vgg: 0.5054, mask: 0.4212\n",
      "step:    77620, time: 0.822, loss: 0.9959, l1: 0.2031, vgg: 0.4282, mask: 0.3645\n",
      "step:    77640, time: 0.811, loss: 1.0839, l1: 0.1920, vgg: 0.5057, mask: 0.3862\n",
      "step:    77660, time: 0.847, loss: 1.0854, l1: 0.2264, vgg: 0.4866, mask: 0.3724\n",
      "step:    77680, time: 0.841, loss: 1.0668, l1: 0.2277, vgg: 0.4436, mask: 0.3955\n",
      "step:    77700, time: 0.850, loss: 1.1564, l1: 0.2319, vgg: 0.5194, mask: 0.4051\n",
      "step:    77720, time: 0.770, loss: 1.0801, l1: 0.2403, vgg: 0.4577, mask: 0.3822\n",
      "step:    77740, time: 0.761, loss: 1.0249, l1: 0.1794, vgg: 0.4661, mask: 0.3794\n",
      "step:    77760, time: 0.794, loss: 1.0816, l1: 0.2270, vgg: 0.4717, mask: 0.3828\n",
      "step:    77780, time: 0.742, loss: 0.9146, l1: 0.1413, vgg: 0.4153, mask: 0.3580\n",
      "step:    77800, time: 0.802, loss: 1.1062, l1: 0.1877, vgg: 0.5298, mask: 0.3887\n",
      "step:    77820, time: 0.751, loss: 1.0218, l1: 0.2151, vgg: 0.4482, mask: 0.3586\n",
      "step:    77840, time: 0.760, loss: 1.0683, l1: 0.2254, vgg: 0.4786, mask: 0.3643\n",
      "step:    77860, time: 0.743, loss: 1.1243, l1: 0.2440, vgg: 0.4747, mask: 0.4056\n",
      "step:    77880, time: 0.825, loss: 0.9486, l1: 0.1833, vgg: 0.4132, mask: 0.3522\n",
      "step:    77900, time: 0.788, loss: 1.1397, l1: 0.2278, vgg: 0.5238, mask: 0.3881\n",
      "step:    77920, time: 0.767, loss: 0.9840, l1: 0.1849, vgg: 0.4238, mask: 0.3753\n",
      "step:    77940, time: 0.746, loss: 1.0194, l1: 0.2154, vgg: 0.4371, mask: 0.3669\n",
      "step:    77960, time: 0.786, loss: 1.0463, l1: 0.2108, vgg: 0.4317, mask: 0.4038\n",
      "step:    77980, time: 0.754, loss: 1.0780, l1: 0.2021, vgg: 0.4946, mask: 0.3812\n",
      "step:    78000, time: 0.734, loss: 1.0020, l1: 0.1828, vgg: 0.4410, mask: 0.3782\n",
      "step:    78020, time: 0.794, loss: 1.1842, l1: 0.2578, vgg: 0.5122, mask: 0.4142\n",
      "step:    78040, time: 0.756, loss: 1.0861, l1: 0.1936, vgg: 0.5077, mask: 0.3849\n",
      "step:    78060, time: 0.763, loss: 1.1721, l1: 0.2257, vgg: 0.5445, mask: 0.4019\n",
      "step:    78080, time: 0.750, loss: 1.0086, l1: 0.1957, vgg: 0.4402, mask: 0.3726\n",
      "step:    78100, time: 0.723, loss: 1.1491, l1: 0.2648, vgg: 0.4926, mask: 0.3917\n",
      "step:    78120, time: 0.753, loss: 1.1130, l1: 0.2308, vgg: 0.5040, mask: 0.3782\n",
      "step:    78140, time: 0.842, loss: 1.0834, l1: 0.1784, vgg: 0.5483, mask: 0.3567\n",
      "step:    78160, time: 0.740, loss: 1.1022, l1: 0.2186, vgg: 0.5185, mask: 0.3651\n",
      "step:    78180, time: 0.744, loss: 1.1127, l1: 0.2444, vgg: 0.4775, mask: 0.3908\n",
      "step:    78200, time: 0.745, loss: 1.2123, l1: 0.3024, vgg: 0.5088, mask: 0.4010\n",
      "step:    78220, time: 0.725, loss: 0.9935, l1: 0.2196, vgg: 0.4118, mask: 0.3622\n",
      "step:    78240, time: 0.730, loss: 1.0396, l1: 0.1790, vgg: 0.5097, mask: 0.3509\n",
      "step:    78260, time: 0.746, loss: 1.0767, l1: 0.2226, vgg: 0.4596, mask: 0.3945\n",
      "step:    78280, time: 0.766, loss: 1.0462, l1: 0.2064, vgg: 0.4681, mask: 0.3718\n",
      "step:    78300, time: 0.743, loss: 1.0397, l1: 0.2016, vgg: 0.4741, mask: 0.3640\n",
      "step:    78320, time: 0.720, loss: 1.0953, l1: 0.2462, vgg: 0.4499, mask: 0.3992\n",
      "step:    78340, time: 0.769, loss: 1.0412, l1: 0.1637, vgg: 0.5404, mask: 0.3370\n",
      "step:    78360, time: 0.763, loss: 1.1159, l1: 0.2196, vgg: 0.5194, mask: 0.3770\n",
      "step:    78380, time: 0.838, loss: 1.0391, l1: 0.1924, vgg: 0.4928, mask: 0.3538\n",
      "step:    78400, time: 0.728, loss: 0.9878, l1: 0.1962, vgg: 0.4462, mask: 0.3454\n",
      "step:    78420, time: 0.773, loss: 1.1959, l1: 0.2766, vgg: 0.5118, mask: 0.4075\n",
      "step:    78440, time: 0.763, loss: 1.1102, l1: 0.2386, vgg: 0.4647, mask: 0.4068\n",
      "step:    78460, time: 0.805, loss: 1.1212, l1: 0.2356, vgg: 0.4990, mask: 0.3866\n",
      "step:    78480, time: 0.761, loss: 1.1036, l1: 0.2334, vgg: 0.4946, mask: 0.3757\n",
      "step:    78500, time: 0.804, loss: 1.0797, l1: 0.2243, vgg: 0.4669, mask: 0.3884\n",
      "step:    78520, time: 0.772, loss: 1.0458, l1: 0.2422, vgg: 0.4078, mask: 0.3957\n",
      "step:    78540, time: 0.793, loss: 1.0988, l1: 0.2553, vgg: 0.4727, mask: 0.3708\n",
      "step:    78560, time: 0.786, loss: 1.0784, l1: 0.2017, vgg: 0.5035, mask: 0.3732\n",
      "step:    78580, time: 0.741, loss: 1.0231, l1: 0.1823, vgg: 0.4662, mask: 0.3746\n",
      "step:    78600, time: 0.757, loss: 1.1433, l1: 0.1791, vgg: 0.5439, mask: 0.4202\n",
      "step:    78620, time: 0.761, loss: 1.0928, l1: 0.2199, vgg: 0.4745, mask: 0.3984\n",
      "step:    78640, time: 0.766, loss: 1.0359, l1: 0.2087, vgg: 0.4366, mask: 0.3905\n",
      "step:    78660, time: 0.800, loss: 1.1618, l1: 0.1974, vgg: 0.5763, mask: 0.3882\n",
      "step:    78680, time: 0.751, loss: 1.0442, l1: 0.1958, vgg: 0.5039, mask: 0.3445\n",
      "step:    78700, time: 0.766, loss: 0.9907, l1: 0.1776, vgg: 0.4497, mask: 0.3634\n",
      "step:    78720, time: 0.774, loss: 1.0288, l1: 0.2037, vgg: 0.4758, mask: 0.3493\n",
      "step:    78740, time: 0.782, loss: 1.1437, l1: 0.2212, vgg: 0.5227, mask: 0.3998\n",
      "step:    78760, time: 0.772, loss: 1.1293, l1: 0.1995, vgg: 0.5712, mask: 0.3586\n",
      "step:    78780, time: 0.757, loss: 0.9912, l1: 0.1940, vgg: 0.4221, mask: 0.3751\n",
      "step:    78800, time: 0.757, loss: 1.0207, l1: 0.2057, vgg: 0.4496, mask: 0.3654\n",
      "step:    78820, time: 0.776, loss: 1.2396, l1: 0.2647, vgg: 0.5990, mask: 0.3759\n",
      "step:    78840, time: 0.730, loss: 1.0488, l1: 0.1855, vgg: 0.5012, mask: 0.3621\n",
      "step:    78860, time: 0.758, loss: 1.0680, l1: 0.1987, vgg: 0.4832, mask: 0.3861\n",
      "step:    78880, time: 0.740, loss: 1.0159, l1: 0.1815, vgg: 0.4260, mask: 0.4084\n",
      "step:    78900, time: 0.765, loss: 1.0414, l1: 0.2192, vgg: 0.4554, mask: 0.3668\n",
      "step:    78920, time: 0.791, loss: 1.1555, l1: 0.2566, vgg: 0.4709, mask: 0.4280\n",
      "step:    78940, time: 0.785, loss: 1.0947, l1: 0.2564, vgg: 0.4568, mask: 0.3815\n",
      "step:    78960, time: 0.793, loss: 1.1947, l1: 0.2506, vgg: 0.5515, mask: 0.3927\n",
      "step:    78980, time: 0.814, loss: 1.0169, l1: 0.2098, vgg: 0.4382, mask: 0.3690\n",
      "step:    79000, time: 0.777, loss: 1.1082, l1: 0.2601, vgg: 0.4364, mask: 0.4117\n",
      "step:    79020, time: 0.802, loss: 1.0307, l1: 0.1669, vgg: 0.5013, mask: 0.3625\n",
      "step:    79040, time: 0.748, loss: 0.9476, l1: 0.1695, vgg: 0.4547, mask: 0.3235\n",
      "step:    79060, time: 0.798, loss: 1.0484, l1: 0.2399, vgg: 0.4276, mask: 0.3808\n",
      "step:    79080, time: 0.776, loss: 1.0786, l1: 0.2167, vgg: 0.5131, mask: 0.3488\n",
      "step:    79100, time: 0.753, loss: 1.1291, l1: 0.2497, vgg: 0.4714, mask: 0.4081\n",
      "step:    79120, time: 0.777, loss: 1.0398, l1: 0.2166, vgg: 0.4506, mask: 0.3727\n",
      "step:    79140, time: 0.726, loss: 0.9721, l1: 0.2003, vgg: 0.4115, mask: 0.3604\n",
      "step:    79160, time: 0.733, loss: 1.1387, l1: 0.2497, vgg: 0.5062, mask: 0.3828\n",
      "step:    79180, time: 0.774, loss: 1.1072, l1: 0.2177, vgg: 0.5218, mask: 0.3677\n",
      "step:    79200, time: 0.775, loss: 1.0595, l1: 0.1933, vgg: 0.4952, mask: 0.3710\n",
      "step:    79220, time: 0.765, loss: 1.1343, l1: 0.2472, vgg: 0.4803, mask: 0.4067\n",
      "step:    79240, time: 0.766, loss: 1.0341, l1: 0.2477, vgg: 0.4114, mask: 0.3750\n",
      "step:    79260, time: 0.809, loss: 1.1568, l1: 0.2403, vgg: 0.5177, mask: 0.3988\n",
      "step:    79280, time: 0.759, loss: 1.0291, l1: 0.1669, vgg: 0.4655, mask: 0.3968\n",
      "step:    79300, time: 0.735, loss: 1.0576, l1: 0.1584, vgg: 0.5373, mask: 0.3619\n",
      "step:    79320, time: 0.774, loss: 1.0362, l1: 0.2193, vgg: 0.4440, mask: 0.3729\n",
      "step:    79340, time: 0.741, loss: 0.9595, l1: 0.2080, vgg: 0.3758, mask: 0.3757\n",
      "step:    79360, time: 0.761, loss: 1.1255, l1: 0.1994, vgg: 0.5110, mask: 0.4152\n",
      "step:    79380, time: 0.734, loss: 1.0549, l1: 0.2283, vgg: 0.4172, mask: 0.4093\n",
      "step:    79400, time: 0.743, loss: 1.1453, l1: 0.2452, vgg: 0.5335, mask: 0.3666\n",
      "step:    79420, time: 0.735, loss: 1.0442, l1: 0.1942, vgg: 0.4791, mask: 0.3709\n",
      "step:    79440, time: 0.795, loss: 1.0015, l1: 0.1914, vgg: 0.4571, mask: 0.3530\n",
      "step:    79460, time: 0.744, loss: 0.9917, l1: 0.1813, vgg: 0.4213, mask: 0.3891\n",
      "step:    79480, time: 0.762, loss: 1.0887, l1: 0.2317, vgg: 0.4666, mask: 0.3905\n",
      "step:    79500, time: 0.825, loss: 1.0263, l1: 0.1739, vgg: 0.4632, mask: 0.3892\n",
      "step:    79520, time: 0.773, loss: 0.9884, l1: 0.1704, vgg: 0.4502, mask: 0.3678\n",
      "step:    79540, time: 0.751, loss: 1.1061, l1: 0.1996, vgg: 0.5228, mask: 0.3837\n",
      "step:    79560, time: 0.741, loss: 0.9739, l1: 0.1752, vgg: 0.4639, mask: 0.3348\n",
      "step:    79580, time: 0.805, loss: 1.0728, l1: 0.2377, vgg: 0.4371, mask: 0.3981\n",
      "step:    79600, time: 0.743, loss: 1.0372, l1: 0.2307, vgg: 0.4389, mask: 0.3677\n",
      "step:    79620, time: 0.766, loss: 1.0622, l1: 0.2146, vgg: 0.4869, mask: 0.3607\n",
      "step:    79640, time: 0.784, loss: 1.0026, l1: 0.1861, vgg: 0.4681, mask: 0.3484\n",
      "step:    79660, time: 0.819, loss: 1.0352, l1: 0.2152, vgg: 0.4184, mask: 0.4016\n",
      "step:    79680, time: 0.797, loss: 1.0219, l1: 0.2093, vgg: 0.4627, mask: 0.3499\n",
      "step:    79700, time: 0.833, loss: 1.0407, l1: 0.2438, vgg: 0.4361, mask: 0.3608\n",
      "step:    79720, time: 0.774, loss: 1.1590, l1: 0.2500, vgg: 0.5196, mask: 0.3894\n",
      "step:    79740, time: 0.736, loss: 1.0073, l1: 0.2071, vgg: 0.4502, mask: 0.3501\n",
      "step:    79760, time: 0.747, loss: 0.9318, l1: 0.1374, vgg: 0.4458, mask: 0.3486\n",
      "step:    79780, time: 0.790, loss: 1.1178, l1: 0.2083, vgg: 0.5161, mask: 0.3934\n",
      "step:    79800, time: 0.759, loss: 1.1045, l1: 0.2193, vgg: 0.4885, mask: 0.3966\n",
      "step:    79820, time: 0.762, loss: 1.0748, l1: 0.2281, vgg: 0.4592, mask: 0.3875\n",
      "step:    79840, time: 0.764, loss: 1.0864, l1: 0.1993, vgg: 0.5240, mask: 0.3631\n",
      "step:    79860, time: 0.742, loss: 1.0216, l1: 0.2052, vgg: 0.4576, mask: 0.3588\n",
      "step:    79880, time: 0.784, loss: 0.9952, l1: 0.1822, vgg: 0.4832, mask: 0.3298\n",
      "step:    79900, time: 0.740, loss: 1.0688, l1: 0.1790, vgg: 0.5154, mask: 0.3744\n",
      "step:    79920, time: 0.718, loss: 1.0459, l1: 0.2058, vgg: 0.4549, mask: 0.3852\n",
      "step:    79940, time: 0.776, loss: 1.0712, l1: 0.2120, vgg: 0.4724, mask: 0.3867\n",
      "step:    79960, time: 0.817, loss: 1.1465, l1: 0.2220, vgg: 0.5025, mask: 0.4221\n",
      "step:    79980, time: 0.752, loss: 0.9980, l1: 0.1865, vgg: 0.4704, mask: 0.3411\n",
      "step:    80000, time: 0.749, loss: 1.1143, l1: 0.2392, vgg: 0.4907, mask: 0.3844\n",
      "step:    80020, time: 0.754, loss: 1.0448, l1: 0.2384, vgg: 0.4386, mask: 0.3677\n",
      "step:    80040, time: 0.794, loss: 1.3004, l1: 0.2958, vgg: 0.5679, mask: 0.4367\n",
      "step:    80060, time: 0.749, loss: 0.9908, l1: 0.1582, vgg: 0.4639, mask: 0.3688\n",
      "step:    80080, time: 0.752, loss: 1.1243, l1: 0.2187, vgg: 0.5305, mask: 0.3751\n",
      "step:    80100, time: 0.783, loss: 1.0619, l1: 0.1783, vgg: 0.5034, mask: 0.3802\n",
      "step:    80120, time: 0.768, loss: 1.1554, l1: 0.2684, vgg: 0.5230, mask: 0.3641\n",
      "step:    80140, time: 0.774, loss: 0.9971, l1: 0.1855, vgg: 0.4524, mask: 0.3592\n",
      "step:    80160, time: 0.795, loss: 1.0240, l1: 0.2211, vgg: 0.4383, mask: 0.3646\n",
      "step:    80180, time: 0.734, loss: 0.9588, l1: 0.2087, vgg: 0.3727, mask: 0.3773\n",
      "step:    80200, time: 0.776, loss: 1.1530, l1: 0.2208, vgg: 0.5571, mask: 0.3752\n",
      "step:    80220, time: 0.761, loss: 1.0035, l1: 0.1767, vgg: 0.4940, mask: 0.3328\n",
      "step:    80240, time: 0.755, loss: 1.2059, l1: 0.2432, vgg: 0.5577, mask: 0.4050\n",
      "step:    80260, time: 0.773, loss: 1.0979, l1: 0.2558, vgg: 0.4728, mask: 0.3693\n",
      "step:    80280, time: 0.783, loss: 1.1479, l1: 0.2384, vgg: 0.5212, mask: 0.3883\n",
      "step:    80300, time: 0.790, loss: 1.1184, l1: 0.2411, vgg: 0.4762, mask: 0.4012\n",
      "step:    80320, time: 0.788, loss: 1.0855, l1: 0.2342, vgg: 0.4559, mask: 0.3954\n",
      "step:    80340, time: 0.774, loss: 1.1298, l1: 0.2201, vgg: 0.4948, mask: 0.4149\n",
      "step:    80360, time: 0.787, loss: 1.0736, l1: 0.2254, vgg: 0.4635, mask: 0.3846\n",
      "step:    80380, time: 0.838, loss: 1.0672, l1: 0.2123, vgg: 0.4855, mask: 0.3695\n",
      "step:    80400, time: 0.752, loss: 1.1281, l1: 0.2449, vgg: 0.4896, mask: 0.3937\n",
      "step:    80420, time: 0.788, loss: 1.1698, l1: 0.2474, vgg: 0.4955, mask: 0.4269\n",
      "step:    80440, time: 0.731, loss: 0.9770, l1: 0.1891, vgg: 0.4318, mask: 0.3561\n",
      "step:    80460, time: 0.745, loss: 1.1289, l1: 0.2543, vgg: 0.4912, mask: 0.3834\n",
      "step:    80480, time: 0.789, loss: 1.1625, l1: 0.2310, vgg: 0.5575, mask: 0.3740\n",
      "step:    80500, time: 0.757, loss: 0.9954, l1: 0.1636, vgg: 0.4868, mask: 0.3449\n",
      "step:    80520, time: 0.768, loss: 1.0289, l1: 0.2003, vgg: 0.4837, mask: 0.3449\n",
      "step:    80540, time: 0.740, loss: 1.0284, l1: 0.2003, vgg: 0.4663, mask: 0.3618\n",
      "step:    80560, time: 0.739, loss: 1.0178, l1: 0.1905, vgg: 0.4829, mask: 0.3444\n",
      "step:    80580, time: 0.764, loss: 1.0891, l1: 0.2167, vgg: 0.4605, mask: 0.4118\n",
      "step:    80600, time: 0.750, loss: 1.0177, l1: 0.2164, vgg: 0.4249, mask: 0.3764\n",
      "step:    80620, time: 0.773, loss: 1.0832, l1: 0.2152, vgg: 0.4896, mask: 0.3784\n",
      "step:    80640, time: 0.771, loss: 1.0081, l1: 0.2209, vgg: 0.4218, mask: 0.3654\n",
      "step:    80660, time: 0.761, loss: 1.1067, l1: 0.2524, vgg: 0.4682, mask: 0.3861\n",
      "step:    80680, time: 0.726, loss: 1.0461, l1: 0.2055, vgg: 0.4271, mask: 0.4136\n",
      "step:    80700, time: 0.804, loss: 1.0886, l1: 0.2773, vgg: 0.4377, mask: 0.3737\n",
      "step:    80720, time: 0.768, loss: 0.9742, l1: 0.2043, vgg: 0.4039, mask: 0.3661\n",
      "step:    80740, time: 0.767, loss: 1.0281, l1: 0.2117, vgg: 0.4462, mask: 0.3703\n",
      "step:    80760, time: 0.743, loss: 1.1479, l1: 0.2672, vgg: 0.4635, mask: 0.4172\n",
      "step:    80780, time: 0.743, loss: 1.1117, l1: 0.2478, vgg: 0.5173, mask: 0.3467\n",
      "step:    80800, time: 0.767, loss: 1.1750, l1: 0.2167, vgg: 0.5787, mask: 0.3796\n",
      "step:    80820, time: 0.807, loss: 1.0103, l1: 0.2083, vgg: 0.4148, mask: 0.3872\n",
      "step:    80840, time: 0.795, loss: 1.0380, l1: 0.1776, vgg: 0.4694, mask: 0.3909\n",
      "step:    80860, time: 0.753, loss: 1.0605, l1: 0.2217, vgg: 0.4749, mask: 0.3639\n",
      "step:    80880, time: 0.787, loss: 1.0710, l1: 0.2106, vgg: 0.4684, mask: 0.3920\n",
      "step:    80900, time: 0.801, loss: 1.0757, l1: 0.2242, vgg: 0.4540, mask: 0.3976\n",
      "step:    80920, time: 0.712, loss: 1.0351, l1: 0.1788, vgg: 0.4959, mask: 0.3604\n",
      "step:    80940, time: 0.766, loss: 1.0640, l1: 0.2237, vgg: 0.4710, mask: 0.3692\n",
      "step:    80960, time: 0.737, loss: 0.9760, l1: 0.1953, vgg: 0.4148, mask: 0.3659\n",
      "step:    80980, time: 0.794, loss: 1.1947, l1: 0.2375, vgg: 0.5521, mask: 0.4050\n",
      "step:    81000, time: 0.750, loss: 1.1609, l1: 0.2422, vgg: 0.5418, mask: 0.3769\n",
      "step:    81020, time: 0.725, loss: 1.0055, l1: 0.1948, vgg: 0.4468, mask: 0.3639\n",
      "step:    81040, time: 0.782, loss: 1.1188, l1: 0.2310, vgg: 0.5044, mask: 0.3834\n",
      "step:    81060, time: 0.755, loss: 1.0956, l1: 0.2482, vgg: 0.4699, mask: 0.3775\n",
      "step:    81080, time: 0.760, loss: 1.1078, l1: 0.2386, vgg: 0.4786, mask: 0.3906\n",
      "step:    81100, time: 0.739, loss: 1.2435, l1: 0.3226, vgg: 0.5176, mask: 0.4033\n",
      "step:    81120, time: 0.751, loss: 1.1233, l1: 0.2107, vgg: 0.5146, mask: 0.3980\n",
      "step:    81140, time: 0.774, loss: 1.0812, l1: 0.2222, vgg: 0.4720, mask: 0.3870\n",
      "step:    81160, time: 0.782, loss: 1.1993, l1: 0.2852, vgg: 0.4954, mask: 0.4187\n",
      "step:    81180, time: 0.763, loss: 1.0868, l1: 0.2482, vgg: 0.4395, mask: 0.3991\n",
      "step:    81200, time: 0.766, loss: 1.0811, l1: 0.2116, vgg: 0.4950, mask: 0.3745\n",
      "step:    81220, time: 0.753, loss: 1.0714, l1: 0.2333, vgg: 0.4733, mask: 0.3648\n",
      "step:    81240, time: 0.776, loss: 1.0372, l1: 0.2083, vgg: 0.4398, mask: 0.3891\n",
      "step:    81260, time: 0.730, loss: 1.0110, l1: 0.2123, vgg: 0.4337, mask: 0.3650\n",
      "step:    81280, time: 0.750, loss: 1.0376, l1: 0.1658, vgg: 0.5131, mask: 0.3587\n",
      "step:    81300, time: 0.740, loss: 1.0749, l1: 0.2228, vgg: 0.4971, mask: 0.3550\n",
      "step:    81320, time: 0.787, loss: 1.1170, l1: 0.2470, vgg: 0.4649, mask: 0.4051\n",
      "step:    81340, time: 0.757, loss: 1.2500, l1: 0.2873, vgg: 0.5336, mask: 0.4290\n",
      "step:    81360, time: 0.774, loss: 1.1132, l1: 0.2290, vgg: 0.4920, mask: 0.3922\n",
      "step:    81380, time: 0.767, loss: 1.1398, l1: 0.2573, vgg: 0.4761, mask: 0.4064\n",
      "step:    81400, time: 0.747, loss: 0.9259, l1: 0.1389, vgg: 0.4039, mask: 0.3832\n",
      "step:    81420, time: 0.764, loss: 1.1390, l1: 0.2229, vgg: 0.4803, mask: 0.4358\n",
      "step:    81440, time: 0.780, loss: 1.0688, l1: 0.1864, vgg: 0.5183, mask: 0.3641\n",
      "step:    81460, time: 0.744, loss: 0.9864, l1: 0.1799, vgg: 0.4645, mask: 0.3420\n",
      "step:    81480, time: 0.766, loss: 1.2208, l1: 0.2914, vgg: 0.5072, mask: 0.4223\n",
      "step:    81500, time: 0.802, loss: 1.0206, l1: 0.1702, vgg: 0.4727, mask: 0.3777\n",
      "step:    81520, time: 0.754, loss: 1.2390, l1: 0.2524, vgg: 0.5875, mask: 0.3992\n",
      "step:    81540, time: 0.781, loss: 1.0838, l1: 0.2133, vgg: 0.5027, mask: 0.3677\n",
      "step:    81560, time: 0.784, loss: 1.1583, l1: 0.2714, vgg: 0.5052, mask: 0.3818\n",
      "step:    81580, time: 0.721, loss: 1.1098, l1: 0.2369, vgg: 0.4808, mask: 0.3921\n",
      "step:    81600, time: 0.760, loss: 1.0535, l1: 0.1973, vgg: 0.4762, mask: 0.3800\n",
      "step:    81620, time: 0.730, loss: 1.0455, l1: 0.1873, vgg: 0.4682, mask: 0.3900\n",
      "step:    81640, time: 0.755, loss: 1.0998, l1: 0.2460, vgg: 0.4474, mask: 0.4063\n",
      "step:    81660, time: 0.741, loss: 1.1460, l1: 0.2449, vgg: 0.5111, mask: 0.3900\n",
      "step:    81680, time: 0.751, loss: 1.0015, l1: 0.1579, vgg: 0.4641, mask: 0.3795\n",
      "step:    81700, time: 0.728, loss: 1.0303, l1: 0.2245, vgg: 0.4369, mask: 0.3689\n",
      "step:    81720, time: 0.745, loss: 1.1687, l1: 0.2739, vgg: 0.4990, mask: 0.3957\n",
      "step:    81740, time: 0.794, loss: 1.0180, l1: 0.1812, vgg: 0.4649, mask: 0.3719\n",
      "step:    81760, time: 0.775, loss: 1.0026, l1: 0.1804, vgg: 0.4577, mask: 0.3645\n",
      "step:    81780, time: 0.811, loss: 1.0508, l1: 0.2095, vgg: 0.4752, mask: 0.3661\n",
      "step:    81800, time: 0.736, loss: 1.1988, l1: 0.2352, vgg: 0.5370, mask: 0.4266\n",
      "step:    81820, time: 0.752, loss: 0.9929, l1: 0.2182, vgg: 0.3839, mask: 0.3908\n",
      "step:    81840, time: 0.778, loss: 1.1145, l1: 0.1965, vgg: 0.5407, mask: 0.3773\n",
      "step:    81860, time: 0.739, loss: 1.0518, l1: 0.2594, vgg: 0.3865, mask: 0.4059\n",
      "step:    81880, time: 0.750, loss: 0.9657, l1: 0.1898, vgg: 0.4412, mask: 0.3347\n",
      "step:    81900, time: 0.762, loss: 1.1564, l1: 0.2349, vgg: 0.5279, mask: 0.3936\n",
      "step:    81920, time: 0.757, loss: 1.1669, l1: 0.2483, vgg: 0.5453, mask: 0.3733\n",
      "step:    81940, time: 0.745, loss: 0.9864, l1: 0.1863, vgg: 0.4032, mask: 0.3970\n",
      "step:    81960, time: 0.740, loss: 0.9997, l1: 0.2040, vgg: 0.4222, mask: 0.3736\n",
      "step:    81980, time: 0.813, loss: 1.0566, l1: 0.1604, vgg: 0.5018, mask: 0.3944\n",
      "step:    82000, time: 0.773, loss: 1.0245, l1: 0.1914, vgg: 0.4443, mask: 0.3888\n",
      "step:    82020, time: 0.749, loss: 0.9549, l1: 0.2074, vgg: 0.4103, mask: 0.3372\n",
      "step:    82040, time: 0.732, loss: 1.1395, l1: 0.2303, vgg: 0.5281, mask: 0.3811\n",
      "step:    82060, time: 0.752, loss: 0.9082, l1: 0.1626, vgg: 0.4107, mask: 0.3349\n",
      "step:    82080, time: 0.760, loss: 1.0550, l1: 0.2219, vgg: 0.4810, mask: 0.3520\n",
      "step:    82100, time: 0.754, loss: 1.0713, l1: 0.2294, vgg: 0.4465, mask: 0.3955\n",
      "step:    82120, time: 0.750, loss: 1.0888, l1: 0.2451, vgg: 0.4284, mask: 0.4153\n",
      "step:    82140, time: 0.742, loss: 0.9318, l1: 0.1321, vgg: 0.4370, mask: 0.3627\n",
      "step:    82160, time: 0.782, loss: 0.9715, l1: 0.1720, vgg: 0.4378, mask: 0.3617\n",
      "step:    82180, time: 0.791, loss: 1.0505, l1: 0.2301, vgg: 0.4396, mask: 0.3807\n",
      "step:    82200, time: 0.752, loss: 0.9554, l1: 0.1703, vgg: 0.4184, mask: 0.3667\n",
      "step:    82220, time: 0.792, loss: 1.0877, l1: 0.2152, vgg: 0.4673, mask: 0.4052\n",
      "step:    82240, time: 0.772, loss: 0.9692, l1: 0.1762, vgg: 0.4512, mask: 0.3419\n",
      "step:    82260, time: 0.788, loss: 0.9919, l1: 0.1840, vgg: 0.4600, mask: 0.3479\n",
      "step:    82280, time: 0.822, loss: 1.0392, l1: 0.2115, vgg: 0.4603, mask: 0.3673\n",
      "step:    82300, time: 0.757, loss: 1.0350, l1: 0.1953, vgg: 0.4820, mask: 0.3577\n",
      "step:    82320, time: 0.771, loss: 1.1337, l1: 0.2115, vgg: 0.4983, mask: 0.4240\n",
      "step:    82340, time: 0.802, loss: 0.9962, l1: 0.1802, vgg: 0.4860, mask: 0.3300\n",
      "step:    82360, time: 0.736, loss: 0.9654, l1: 0.1719, vgg: 0.4593, mask: 0.3342\n",
      "step:    82380, time: 0.776, loss: 1.0769, l1: 0.2289, vgg: 0.4453, mask: 0.4027\n",
      "step:    82400, time: 0.773, loss: 0.9856, l1: 0.1908, vgg: 0.4335, mask: 0.3613\n",
      "step:    82420, time: 0.810, loss: 1.1875, l1: 0.2315, vgg: 0.5337, mask: 0.4223\n",
      "step:    82440, time: 0.753, loss: 1.0048, l1: 0.1958, vgg: 0.4601, mask: 0.3490\n",
      "step:    82460, time: 0.758, loss: 1.0856, l1: 0.2773, vgg: 0.4205, mask: 0.3877\n",
      "step:    82480, time: 0.804, loss: 1.0928, l1: 0.2109, vgg: 0.4962, mask: 0.3857\n",
      "step:    82500, time: 0.775, loss: 1.1024, l1: 0.2317, vgg: 0.4844, mask: 0.3863\n",
      "step:    82520, time: 0.781, loss: 1.0734, l1: 0.2511, vgg: 0.4559, mask: 0.3664\n",
      "step:    82540, time: 0.808, loss: 1.1434, l1: 0.2119, vgg: 0.5267, mask: 0.4049\n",
      "step:    82560, time: 0.772, loss: 1.1300, l1: 0.2431, vgg: 0.4863, mask: 0.4006\n",
      "step:    82580, time: 0.747, loss: 1.0355, l1: 0.1640, vgg: 0.4585, mask: 0.4131\n",
      "step:    82600, time: 0.787, loss: 1.0595, l1: 0.1967, vgg: 0.4891, mask: 0.3736\n",
      "step:    82620, time: 0.747, loss: 1.0139, l1: 0.1850, vgg: 0.4500, mask: 0.3789\n",
      "step:    82640, time: 0.751, loss: 1.1745, l1: 0.2107, vgg: 0.5665, mask: 0.3972\n",
      "step:    82660, time: 0.761, loss: 1.1441, l1: 0.2512, vgg: 0.5020, mask: 0.3909\n",
      "step:    82680, time: 0.769, loss: 1.1087, l1: 0.1893, vgg: 0.5230, mask: 0.3963\n",
      "step:    82700, time: 0.769, loss: 1.0347, l1: 0.1853, vgg: 0.4856, mask: 0.3638\n",
      "step:    82720, time: 0.780, loss: 1.2146, l1: 0.2910, vgg: 0.5320, mask: 0.3915\n",
      "step:    82740, time: 0.744, loss: 1.0687, l1: 0.2250, vgg: 0.4444, mask: 0.3993\n",
      "step:    82760, time: 0.774, loss: 1.1032, l1: 0.2167, vgg: 0.4732, mask: 0.4133\n",
      "step:    82780, time: 0.763, loss: 1.0387, l1: 0.2234, vgg: 0.4561, mask: 0.3592\n",
      "step:    82800, time: 0.735, loss: 1.0426, l1: 0.1975, vgg: 0.4662, mask: 0.3790\n",
      "step:    82820, time: 0.823, loss: 0.9913, l1: 0.2159, vgg: 0.4120, mask: 0.3633\n",
      "step:    82840, time: 0.771, loss: 1.0799, l1: 0.2184, vgg: 0.5032, mask: 0.3582\n",
      "step:    82860, time: 0.799, loss: 1.0948, l1: 0.1616, vgg: 0.5509, mask: 0.3823\n",
      "step:    82880, time: 0.792, loss: 1.0358, l1: 0.2215, vgg: 0.4131, mask: 0.4012\n",
      "step:    82900, time: 0.822, loss: 1.1155, l1: 0.2648, vgg: 0.4553, mask: 0.3954\n",
      "step:    82920, time: 0.740, loss: 1.1050, l1: 0.2488, vgg: 0.4817, mask: 0.3745\n",
      "step:    82940, time: 0.750, loss: 1.0850, l1: 0.1884, vgg: 0.5257, mask: 0.3709\n",
      "step:    82960, time: 0.753, loss: 1.0819, l1: 0.1992, vgg: 0.5206, mask: 0.3621\n",
      "step:    82980, time: 0.751, loss: 0.9783, l1: 0.1800, vgg: 0.4185, mask: 0.3798\n",
      "step:    83000, time: 0.783, loss: 1.1015, l1: 0.2340, vgg: 0.4766, mask: 0.3908\n",
      "step:    83020, time: 0.774, loss: 1.0863, l1: 0.2368, vgg: 0.4526, mask: 0.3969\n",
      "step:    83040, time: 0.752, loss: 1.0487, l1: 0.1946, vgg: 0.4556, mask: 0.3985\n",
      "step:    83060, time: 0.789, loss: 1.1153, l1: 0.2256, vgg: 0.5006, mask: 0.3891\n",
      "step:    83080, time: 0.756, loss: 1.0171, l1: 0.2021, vgg: 0.4192, mask: 0.3958\n",
      "step:    83100, time: 0.757, loss: 0.9451, l1: 0.1756, vgg: 0.4196, mask: 0.3499\n",
      "step:    83120, time: 0.750, loss: 1.0930, l1: 0.2408, vgg: 0.4714, mask: 0.3808\n",
      "step:    83140, time: 0.759, loss: 1.1182, l1: 0.2375, vgg: 0.4859, mask: 0.3949\n",
      "step:    83160, time: 0.757, loss: 1.0077, l1: 0.1954, vgg: 0.4778, mask: 0.3345\n",
      "step:    83180, time: 0.727, loss: 1.1485, l1: 0.2569, vgg: 0.4462, mask: 0.4454\n",
      "step:    83200, time: 0.753, loss: 0.9779, l1: 0.1880, vgg: 0.4421, mask: 0.3477\n",
      "step:    83220, time: 0.753, loss: 1.0590, l1: 0.2105, vgg: 0.4817, mask: 0.3668\n",
      "step:    83240, time: 0.753, loss: 1.0105, l1: 0.1822, vgg: 0.4889, mask: 0.3394\n",
      "step:    83260, time: 0.762, loss: 1.1251, l1: 0.2510, vgg: 0.4403, mask: 0.4339\n",
      "step:    83280, time: 0.746, loss: 1.1671, l1: 0.2736, vgg: 0.4802, mask: 0.4134\n",
      "step:    83300, time: 0.759, loss: 0.9409, l1: 0.1520, vgg: 0.4261, mask: 0.3627\n",
      "step:    83320, time: 0.755, loss: 1.2001, l1: 0.2529, vgg: 0.5613, mask: 0.3860\n",
      "step:    83340, time: 0.791, loss: 0.9868, l1: 0.1996, vgg: 0.4321, mask: 0.3552\n",
      "step:    83360, time: 0.772, loss: 1.1879, l1: 0.2630, vgg: 0.5678, mask: 0.3571\n",
      "step:    83380, time: 0.791, loss: 1.0817, l1: 0.2209, vgg: 0.4726, mask: 0.3882\n",
      "step:    83400, time: 0.772, loss: 1.0304, l1: 0.1881, vgg: 0.4840, mask: 0.3584\n",
      "step:    83420, time: 0.772, loss: 1.0019, l1: 0.1943, vgg: 0.4718, mask: 0.3358\n",
      "step:    83440, time: 0.798, loss: 1.2214, l1: 0.2654, vgg: 0.5547, mask: 0.4013\n",
      "step:    83460, time: 0.740, loss: 1.0780, l1: 0.2604, vgg: 0.4427, mask: 0.3749\n",
      "step:    83480, time: 0.735, loss: 1.2108, l1: 0.2937, vgg: 0.5050, mask: 0.4121\n",
      "step:    83500, time: 0.767, loss: 1.1275, l1: 0.2335, vgg: 0.5065, mask: 0.3875\n",
      "step:    83520, time: 0.737, loss: 0.9534, l1: 0.1836, vgg: 0.4208, mask: 0.3489\n",
      "step:    83540, time: 0.727, loss: 0.9429, l1: 0.1520, vgg: 0.4324, mask: 0.3585\n",
      "step:    83560, time: 0.765, loss: 1.1035, l1: 0.2185, vgg: 0.5098, mask: 0.3752\n",
      "step:    83580, time: 0.751, loss: 1.0822, l1: 0.2473, vgg: 0.4289, mask: 0.4061\n",
      "step:    83600, time: 0.757, loss: 1.0880, l1: 0.2163, vgg: 0.5022, mask: 0.3695\n",
      "step:    83620, time: 0.767, loss: 1.1205, l1: 0.2152, vgg: 0.5130, mask: 0.3923\n",
      "step:    83640, time: 0.754, loss: 1.0718, l1: 0.2491, vgg: 0.4307, mask: 0.3920\n",
      "step:    83660, time: 0.746, loss: 1.0526, l1: 0.2102, vgg: 0.4508, mask: 0.3916\n",
      "step:    83680, time: 0.743, loss: 1.0413, l1: 0.1818, vgg: 0.5000, mask: 0.3595\n",
      "step:    83700, time: 0.756, loss: 1.0097, l1: 0.1893, vgg: 0.4469, mask: 0.3735\n",
      "step:    83720, time: 0.754, loss: 1.0209, l1: 0.1748, vgg: 0.4628, mask: 0.3832\n",
      "step:    83740, time: 0.729, loss: 0.8787, l1: 0.1376, vgg: 0.3886, mask: 0.3526\n",
      "step:    83760, time: 0.760, loss: 1.0344, l1: 0.1891, vgg: 0.4574, mask: 0.3879\n",
      "step:    83780, time: 0.736, loss: 1.0100, l1: 0.1976, vgg: 0.4453, mask: 0.3672\n",
      "step:    83800, time: 0.731, loss: 1.0138, l1: 0.2036, vgg: 0.4064, mask: 0.4038\n",
      "step:    83820, time: 0.753, loss: 1.0249, l1: 0.2056, vgg: 0.4423, mask: 0.3769\n",
      "step:    83840, time: 0.735, loss: 1.0249, l1: 0.2039, vgg: 0.4354, mask: 0.3856\n",
      "step:    83860, time: 0.791, loss: 1.2951, l1: 0.2653, vgg: 0.6280, mask: 0.4017\n",
      "step:    83880, time: 0.767, loss: 1.1754, l1: 0.3197, vgg: 0.4481, mask: 0.4077\n",
      "step:    83900, time: 0.762, loss: 1.0955, l1: 0.2143, vgg: 0.4963, mask: 0.3849\n",
      "step:    83920, time: 0.741, loss: 1.1212, l1: 0.2292, vgg: 0.4999, mask: 0.3921\n",
      "step:    83940, time: 0.720, loss: 0.8617, l1: 0.1524, vgg: 0.3970, mask: 0.3124\n",
      "step:    83960, time: 0.780, loss: 1.2404, l1: 0.2615, vgg: 0.5694, mask: 0.4095\n",
      "step:    83980, time: 0.777, loss: 1.0858, l1: 0.1758, vgg: 0.5403, mask: 0.3697\n",
      "step:    84000, time: 0.772, loss: 1.1017, l1: 0.2177, vgg: 0.4693, mask: 0.4147\n",
      "step:    84020, time: 0.757, loss: 1.0495, l1: 0.2268, vgg: 0.4466, mask: 0.3762\n",
      "step:    84040, time: 0.822, loss: 1.1413, l1: 0.2258, vgg: 0.5200, mask: 0.3954\n",
      "step:    84060, time: 0.802, loss: 1.1352, l1: 0.2438, vgg: 0.4863, mask: 0.4052\n",
      "step:    84080, time: 0.807, loss: 1.1154, l1: 0.2411, vgg: 0.4877, mask: 0.3866\n",
      "step:    84100, time: 0.842, loss: 1.1160, l1: 0.2465, vgg: 0.4818, mask: 0.3878\n",
      "step:    84120, time: 0.786, loss: 1.1008, l1: 0.2243, vgg: 0.4814, mask: 0.3951\n",
      "step:    84140, time: 0.755, loss: 1.0435, l1: 0.2263, vgg: 0.4359, mask: 0.3813\n",
      "step:    84160, time: 0.759, loss: 1.0285, l1: 0.2156, vgg: 0.4397, mask: 0.3733\n",
      "step:    84180, time: 0.782, loss: 1.1849, l1: 0.2276, vgg: 0.5310, mask: 0.4262\n",
      "step:    84200, time: 0.735, loss: 0.9485, l1: 0.1619, vgg: 0.4456, mask: 0.3410\n",
      "step:    84220, time: 0.768, loss: 1.0681, l1: 0.1992, vgg: 0.5151, mask: 0.3538\n",
      "step:    84240, time: 0.782, loss: 1.0613, l1: 0.2356, vgg: 0.4456, mask: 0.3801\n",
      "step:    84260, time: 0.750, loss: 1.1287, l1: 0.2487, vgg: 0.4919, mask: 0.3881\n",
      "step:    84280, time: 0.751, loss: 1.1302, l1: 0.2727, vgg: 0.4745, mask: 0.3830\n",
      "step:    84300, time: 0.785, loss: 1.1049, l1: 0.2170, vgg: 0.4974, mask: 0.3905\n",
      "step:    84320, time: 0.830, loss: 1.0355, l1: 0.2087, vgg: 0.4787, mask: 0.3481\n",
      "step:    84340, time: 0.696, loss: 0.9524, l1: 0.1737, vgg: 0.4312, mask: 0.3475\n",
      "step:    84360, time: 0.754, loss: 1.0845, l1: 0.2030, vgg: 0.5153, mask: 0.3663\n",
      "step:    84380, time: 0.743, loss: 0.8703, l1: 0.1468, vgg: 0.3772, mask: 0.3463\n",
      "step:    84400, time: 0.771, loss: 1.0635, l1: 0.2342, vgg: 0.3964, mask: 0.4329\n",
      "step:    84420, time: 0.746, loss: 1.1043, l1: 0.2144, vgg: 0.4628, mask: 0.4270\n",
      "step:    84440, time: 0.787, loss: 1.0549, l1: 0.2160, vgg: 0.4613, mask: 0.3776\n",
      "step:    84460, time: 0.777, loss: 1.2150, l1: 0.2647, vgg: 0.5251, mask: 0.4252\n",
      "step:    84480, time: 0.864, loss: 1.1727, l1: 0.2488, vgg: 0.5114, mask: 0.4125\n",
      "step:    84500, time: 0.817, loss: 1.0921, l1: 0.1973, vgg: 0.5113, mask: 0.3835\n",
      "step:    84520, time: 0.739, loss: 1.1153, l1: 0.2110, vgg: 0.5418, mask: 0.3625\n",
      "step:    84540, time: 0.773, loss: 1.2076, l1: 0.2743, vgg: 0.5226, mask: 0.4107\n",
      "step:    84560, time: 0.767, loss: 1.0054, l1: 0.1852, vgg: 0.4576, mask: 0.3626\n",
      "step:    84580, time: 0.772, loss: 1.0927, l1: 0.2283, vgg: 0.4725, mask: 0.3920\n",
      "step:    84600, time: 0.756, loss: 1.0803, l1: 0.2042, vgg: 0.5139, mask: 0.3622\n",
      "step:    84620, time: 0.822, loss: 1.1514, l1: 0.2167, vgg: 0.5583, mask: 0.3764\n",
      "step:    84640, time: 0.774, loss: 1.0112, l1: 0.1836, vgg: 0.4635, mask: 0.3641\n",
      "step:    84660, time: 0.747, loss: 1.0080, l1: 0.2079, vgg: 0.4208, mask: 0.3793\n",
      "step:    84680, time: 0.766, loss: 1.2891, l1: 0.2813, vgg: 0.5986, mask: 0.4092\n",
      "step:    84700, time: 0.821, loss: 1.2071, l1: 0.2505, vgg: 0.5649, mask: 0.3916\n",
      "step:    84720, time: 0.755, loss: 1.1722, l1: 0.2538, vgg: 0.5203, mask: 0.3981\n",
      "step:    84740, time: 0.786, loss: 1.0540, l1: 0.2186, vgg: 0.4508, mask: 0.3846\n",
      "step:    84760, time: 0.773, loss: 1.1413, l1: 0.2492, vgg: 0.5109, mask: 0.3812\n",
      "step:    84780, time: 0.733, loss: 1.1361, l1: 0.2745, vgg: 0.4416, mask: 0.4201\n",
      "step:    84800, time: 0.835, loss: 1.0967, l1: 0.2329, vgg: 0.4848, mask: 0.3790\n",
      "step:    84820, time: 0.759, loss: 1.0766, l1: 0.2241, vgg: 0.4739, mask: 0.3786\n",
      "step:    84840, time: 0.762, loss: 1.1472, l1: 0.2206, vgg: 0.5432, mask: 0.3835\n",
      "step:    84860, time: 0.739, loss: 1.0057, l1: 0.2316, vgg: 0.3767, mask: 0.3974\n",
      "step:    84880, time: 0.756, loss: 1.0609, l1: 0.1987, vgg: 0.4733, mask: 0.3889\n",
      "step:    84900, time: 0.806, loss: 1.1001, l1: 0.2281, vgg: 0.4771, mask: 0.3950\n",
      "step:    84920, time: 0.777, loss: 1.1090, l1: 0.2317, vgg: 0.4925, mask: 0.3849\n",
      "step:    84940, time: 0.730, loss: 1.1134, l1: 0.2178, vgg: 0.5040, mask: 0.3916\n",
      "step:    84960, time: 0.743, loss: 0.9734, l1: 0.1725, vgg: 0.4279, mask: 0.3731\n",
      "step:    84980, time: 0.785, loss: 1.2087, l1: 0.2446, vgg: 0.5475, mask: 0.4166\n",
      "step:    85000, time: 0.790, loss: 1.0659, l1: 0.2510, vgg: 0.4779, mask: 0.3370\n",
      "step:    85020, time: 0.794, loss: 1.0248, l1: 0.1756, vgg: 0.4692, mask: 0.3800\n",
      "step:    85040, time: 0.797, loss: 1.0506, l1: 0.2103, vgg: 0.4591, mask: 0.3812\n",
      "step:    85060, time: 0.742, loss: 1.1100, l1: 0.2653, vgg: 0.4543, mask: 0.3904\n",
      "step:    85080, time: 0.807, loss: 1.1322, l1: 0.2415, vgg: 0.4983, mask: 0.3924\n",
      "step:    85100, time: 0.758, loss: 1.0535, l1: 0.2137, vgg: 0.4522, mask: 0.3876\n",
      "step:    85120, time: 0.770, loss: 1.0419, l1: 0.2097, vgg: 0.4667, mask: 0.3656\n",
      "step:    85140, time: 0.719, loss: 0.9391, l1: 0.1800, vgg: 0.4201, mask: 0.3390\n",
      "step:    85160, time: 0.799, loss: 1.0582, l1: 0.2081, vgg: 0.4770, mask: 0.3731\n",
      "step:    85180, time: 0.848, loss: 1.0726, l1: 0.2466, vgg: 0.4426, mask: 0.3835\n",
      "step:    85200, time: 0.769, loss: 1.1196, l1: 0.2150, vgg: 0.5091, mask: 0.3955\n",
      "step:    85220, time: 0.787, loss: 1.0907, l1: 0.2583, vgg: 0.4441, mask: 0.3883\n",
      "step:    85240, time: 0.768, loss: 1.0038, l1: 0.1760, vgg: 0.4774, mask: 0.3503\n",
      "step:    85260, time: 0.760, loss: 1.1144, l1: 0.2893, vgg: 0.4152, mask: 0.4099\n",
      "step:    85280, time: 0.816, loss: 1.1080, l1: 0.2414, vgg: 0.4958, mask: 0.3708\n",
      "step:    85300, time: 0.775, loss: 0.9662, l1: 0.1828, vgg: 0.4447, mask: 0.3388\n",
      "step:    85320, time: 0.754, loss: 1.0200, l1: 0.2112, vgg: 0.4394, mask: 0.3694\n",
      "step:    85340, time: 0.740, loss: 1.0518, l1: 0.2202, vgg: 0.4881, mask: 0.3435\n",
      "step:    85360, time: 0.753, loss: 1.0335, l1: 0.1996, vgg: 0.4685, mask: 0.3655\n",
      "step:    85380, time: 0.758, loss: 0.9938, l1: 0.2038, vgg: 0.4210, mask: 0.3690\n",
      "step:    85400, time: 0.757, loss: 1.0373, l1: 0.2177, vgg: 0.4421, mask: 0.3774\n",
      "step:    85420, time: 0.792, loss: 1.0411, l1: 0.2041, vgg: 0.4590, mask: 0.3780\n",
      "step:    85440, time: 0.758, loss: 1.0926, l1: 0.2589, vgg: 0.4204, mask: 0.4133\n",
      "step:    85460, time: 0.773, loss: 1.1739, l1: 0.2397, vgg: 0.5058, mask: 0.4284\n",
      "step:    85480, time: 0.725, loss: 1.0200, l1: 0.1853, vgg: 0.4614, mask: 0.3733\n",
      "step:    85500, time: 0.761, loss: 1.0057, l1: 0.1898, vgg: 0.4692, mask: 0.3467\n",
      "step:    85520, time: 0.761, loss: 1.1583, l1: 0.2580, vgg: 0.5149, mask: 0.3854\n",
      "step:    85540, time: 0.780, loss: 1.0771, l1: 0.2152, vgg: 0.4775, mask: 0.3844\n",
      "step:    85560, time: 0.779, loss: 1.0475, l1: 0.1890, vgg: 0.4652, mask: 0.3933\n",
      "step:    85580, time: 0.770, loss: 1.0479, l1: 0.2105, vgg: 0.4988, mask: 0.3386\n",
      "step:    85600, time: 0.790, loss: 1.1563, l1: 0.2843, vgg: 0.4637, mask: 0.4082\n",
      "step:    85620, time: 0.800, loss: 1.1815, l1: 0.2852, vgg: 0.4914, mask: 0.4049\n",
      "step:    85640, time: 0.759, loss: 1.0075, l1: 0.1966, vgg: 0.4672, mask: 0.3437\n",
      "step:    85660, time: 0.787, loss: 1.0787, l1: 0.2697, vgg: 0.4088, mask: 0.4002\n",
      "step:    85680, time: 0.776, loss: 1.0027, l1: 0.1810, vgg: 0.4651, mask: 0.3566\n",
      "step:    85700, time: 0.757, loss: 0.9816, l1: 0.2024, vgg: 0.4153, mask: 0.3638\n",
      "step:    85720, time: 0.777, loss: 1.0436, l1: 0.2250, vgg: 0.4192, mask: 0.3993\n",
      "step:    85740, time: 0.769, loss: 1.0918, l1: 0.2501, vgg: 0.4731, mask: 0.3686\n",
      "step:    85760, time: 0.778, loss: 1.0861, l1: 0.2207, vgg: 0.5014, mask: 0.3640\n",
      "step:    85780, time: 0.748, loss: 1.1512, l1: 0.2711, vgg: 0.4621, mask: 0.4179\n",
      "step:    85800, time: 0.779, loss: 1.0907, l1: 0.2265, vgg: 0.4758, mask: 0.3883\n",
      "step:    85820, time: 0.833, loss: 1.0831, l1: 0.2555, vgg: 0.4245, mask: 0.4031\n",
      "step:    85840, time: 0.840, loss: 1.0989, l1: 0.2643, vgg: 0.4349, mask: 0.3997\n",
      "step:    85860, time: 0.755, loss: 1.0688, l1: 0.1972, vgg: 0.5146, mask: 0.3569\n",
      "step:    85880, time: 0.775, loss: 0.9717, l1: 0.1983, vgg: 0.4102, mask: 0.3633\n",
      "step:    85900, time: 0.760, loss: 0.9880, l1: 0.2137, vgg: 0.4164, mask: 0.3579\n",
      "step:    85920, time: 0.770, loss: 1.0652, l1: 0.2349, vgg: 0.4305, mask: 0.3998\n",
      "step:    85940, time: 0.757, loss: 1.0579, l1: 0.2174, vgg: 0.4343, mask: 0.4062\n",
      "step:    85960, time: 0.816, loss: 1.1209, l1: 0.2315, vgg: 0.5036, mask: 0.3858\n",
      "step:    85980, time: 0.764, loss: 1.0349, l1: 0.2292, vgg: 0.4457, mask: 0.3601\n",
      "step:    86000, time: 0.756, loss: 1.0201, l1: 0.2034, vgg: 0.3965, mask: 0.4202\n",
      "step:    86020, time: 0.790, loss: 1.1124, l1: 0.1990, vgg: 0.5339, mask: 0.3795\n",
      "step:    86040, time: 0.770, loss: 1.2060, l1: 0.2860, vgg: 0.5061, mask: 0.4139\n",
      "step:    86060, time: 0.765, loss: 1.1948, l1: 0.2441, vgg: 0.5031, mask: 0.4475\n",
      "step:    86080, time: 0.801, loss: 1.1805, l1: 0.2478, vgg: 0.5579, mask: 0.3747\n",
      "step:    86100, time: 0.772, loss: 1.0314, l1: 0.1834, vgg: 0.4784, mask: 0.3696\n",
      "step:    86120, time: 0.772, loss: 1.0786, l1: 0.1778, vgg: 0.5143, mask: 0.3865\n",
      "step:    86140, time: 0.792, loss: 1.1548, l1: 0.2183, vgg: 0.5532, mask: 0.3834\n",
      "step:    86160, time: 0.754, loss: 1.0138, l1: 0.1738, vgg: 0.4865, mask: 0.3535\n",
      "step:    86180, time: 0.749, loss: 0.9783, l1: 0.1792, vgg: 0.4029, mask: 0.3963\n",
      "step:    86200, time: 0.784, loss: 1.1626, l1: 0.2070, vgg: 0.5843, mask: 0.3713\n",
      "step:    86220, time: 0.764, loss: 1.0190, l1: 0.2058, vgg: 0.4452, mask: 0.3679\n",
      "step:    86240, time: 0.770, loss: 1.0242, l1: 0.2040, vgg: 0.4717, mask: 0.3485\n",
      "step:    86260, time: 0.740, loss: 0.9838, l1: 0.1627, vgg: 0.4407, mask: 0.3804\n",
      "step:    86280, time: 0.775, loss: 1.0146, l1: 0.2251, vgg: 0.4252, mask: 0.3643\n",
      "step:    86300, time: 0.768, loss: 1.0028, l1: 0.1693, vgg: 0.4521, mask: 0.3814\n",
      "step:    86320, time: 0.779, loss: 0.9467, l1: 0.1850, vgg: 0.3920, mask: 0.3697\n",
      "step:    86340, time: 0.725, loss: 1.0597, l1: 0.2172, vgg: 0.4523, mask: 0.3902\n",
      "step:    86360, time: 0.774, loss: 1.0506, l1: 0.2251, vgg: 0.4517, mask: 0.3739\n",
      "step:    86380, time: 0.765, loss: 1.1088, l1: 0.2335, vgg: 0.4784, mask: 0.3969\n",
      "step:    86400, time: 0.763, loss: 1.0860, l1: 0.2006, vgg: 0.5257, mask: 0.3597\n",
      "step:    86420, time: 0.768, loss: 1.1242, l1: 0.2543, vgg: 0.4928, mask: 0.3771\n",
      "step:    86440, time: 0.788, loss: 1.2374, l1: 0.2725, vgg: 0.5606, mask: 0.4043\n",
      "step:    86460, time: 0.879, loss: 1.1881, l1: 0.2348, vgg: 0.5632, mask: 0.3900\n",
      "step:    86480, time: 0.779, loss: 1.0937, l1: 0.2003, vgg: 0.5167, mask: 0.3767\n",
      "step:    86500, time: 0.750, loss: 1.0953, l1: 0.2176, vgg: 0.5300, mask: 0.3477\n",
      "step:    86520, time: 0.770, loss: 1.0680, l1: 0.2077, vgg: 0.4541, mask: 0.4063\n",
      "step:    86540, time: 0.771, loss: 1.0411, l1: 0.2176, vgg: 0.4359, mask: 0.3876\n",
      "step:    86560, time: 0.808, loss: 1.0452, l1: 0.2289, vgg: 0.4351, mask: 0.3812\n",
      "step:    86580, time: 0.778, loss: 1.1197, l1: 0.2549, vgg: 0.4888, mask: 0.3760\n",
      "step:    86600, time: 0.747, loss: 1.0130, l1: 0.1856, vgg: 0.4528, mask: 0.3746\n",
      "step:    86620, time: 0.720, loss: 1.0914, l1: 0.2460, vgg: 0.4494, mask: 0.3960\n",
      "step:    86640, time: 0.769, loss: 1.0207, l1: 0.1746, vgg: 0.4914, mask: 0.3547\n",
      "step:    86660, time: 0.741, loss: 1.0874, l1: 0.2399, vgg: 0.4226, mask: 0.4249\n",
      "step:    86680, time: 0.745, loss: 1.0971, l1: 0.2331, vgg: 0.4578, mask: 0.4062\n",
      "step:    86700, time: 0.742, loss: 1.0935, l1: 0.2448, vgg: 0.4418, mask: 0.4069\n",
      "step:    86720, time: 0.766, loss: 1.1004, l1: 0.2495, vgg: 0.4668, mask: 0.3841\n",
      "step:    86740, time: 0.741, loss: 1.0565, l1: 0.2040, vgg: 0.4814, mask: 0.3712\n",
      "step:    86760, time: 0.840, loss: 1.1358, l1: 0.2389, vgg: 0.5151, mask: 0.3818\n",
      "step:    86780, time: 0.787, loss: 1.1431, l1: 0.2346, vgg: 0.5122, mask: 0.3963\n",
      "step:    86800, time: 0.747, loss: 1.1181, l1: 0.2279, vgg: 0.5028, mask: 0.3874\n",
      "step:    86820, time: 0.807, loss: 0.9544, l1: 0.1734, vgg: 0.4405, mask: 0.3405\n",
      "step:    86840, time: 0.733, loss: 0.9737, l1: 0.1812, vgg: 0.4417, mask: 0.3509\n",
      "step:    86860, time: 0.766, loss: 1.1357, l1: 0.2686, vgg: 0.4360, mask: 0.4310\n",
      "step:    86880, time: 0.762, loss: 1.0642, l1: 0.2278, vgg: 0.4440, mask: 0.3925\n",
      "step:    86900, time: 0.755, loss: 1.1978, l1: 0.2785, vgg: 0.5218, mask: 0.3975\n",
      "step:    86920, time: 0.753, loss: 1.0464, l1: 0.1588, vgg: 0.5408, mask: 0.3467\n",
      "step:    86940, time: 0.752, loss: 1.0437, l1: 0.2544, vgg: 0.4073, mask: 0.3820\n",
      "step:    86960, time: 0.719, loss: 1.0488, l1: 0.2477, vgg: 0.4285, mask: 0.3725\n",
      "step:    86980, time: 0.740, loss: 0.9903, l1: 0.1985, vgg: 0.4388, mask: 0.3531\n",
      "step:    87000, time: 0.733, loss: 0.9977, l1: 0.1984, vgg: 0.3983, mask: 0.4010\n",
      "step:    87020, time: 0.753, loss: 1.1140, l1: 0.2401, vgg: 0.4723, mask: 0.4017\n",
      "step:    87040, time: 0.760, loss: 1.0222, l1: 0.1828, vgg: 0.4811, mask: 0.3584\n",
      "step:    87060, time: 0.755, loss: 1.0496, l1: 0.2187, vgg: 0.4595, mask: 0.3714\n",
      "step:    87080, time: 0.773, loss: 1.0880, l1: 0.2210, vgg: 0.4894, mask: 0.3776\n",
      "step:    87100, time: 0.762, loss: 1.0171, l1: 0.2164, vgg: 0.4190, mask: 0.3817\n",
      "step:    87120, time: 0.746, loss: 1.0258, l1: 0.1766, vgg: 0.5133, mask: 0.3359\n",
      "step:    87140, time: 0.737, loss: 0.9889, l1: 0.2129, vgg: 0.4144, mask: 0.3616\n",
      "step:    87160, time: 0.738, loss: 0.9940, l1: 0.2076, vgg: 0.4177, mask: 0.3687\n",
      "step:    87180, time: 0.794, loss: 1.1088, l1: 0.2218, vgg: 0.5103, mask: 0.3768\n",
      "step:    87200, time: 0.714, loss: 0.9398, l1: 0.1703, vgg: 0.4090, mask: 0.3605\n",
      "step:    87220, time: 0.764, loss: 1.0568, l1: 0.2033, vgg: 0.4876, mask: 0.3659\n",
      "step:    87240, time: 0.710, loss: 0.9758, l1: 0.2009, vgg: 0.4211, mask: 0.3538\n",
      "step:    87260, time: 0.737, loss: 1.0785, l1: 0.2054, vgg: 0.5117, mask: 0.3613\n",
      "step:    87280, time: 0.753, loss: 1.0308, l1: 0.1835, vgg: 0.4637, mask: 0.3835\n",
      "step:    87300, time: 0.758, loss: 1.1645, l1: 0.2587, vgg: 0.5016, mask: 0.4042\n",
      "step:    87320, time: 0.786, loss: 1.1166, l1: 0.2605, vgg: 0.4905, mask: 0.3656\n",
      "step:    87340, time: 0.744, loss: 1.0420, l1: 0.2388, vgg: 0.4322, mask: 0.3709\n",
      "step:    87360, time: 0.743, loss: 1.1404, l1: 0.2545, vgg: 0.4707, mask: 0.4152\n",
      "step:    87380, time: 0.771, loss: 1.0375, l1: 0.2062, vgg: 0.4295, mask: 0.4017\n",
      "step:    87400, time: 0.790, loss: 1.1703, l1: 0.2586, vgg: 0.5142, mask: 0.3976\n",
      "step:    87420, time: 0.745, loss: 1.1402, l1: 0.2815, vgg: 0.4881, mask: 0.3706\n",
      "step:    87440, time: 0.766, loss: 1.1489, l1: 0.2233, vgg: 0.5465, mask: 0.3792\n",
      "step:    87460, time: 0.748, loss: 1.1132, l1: 0.2553, vgg: 0.4464, mask: 0.4116\n",
      "step:    87480, time: 0.764, loss: 1.0813, l1: 0.2144, vgg: 0.4640, mask: 0.4028\n",
      "step:    87500, time: 0.783, loss: 1.0526, l1: 0.2156, vgg: 0.4655, mask: 0.3715\n",
      "step:    87520, time: 0.731, loss: 1.1676, l1: 0.2624, vgg: 0.5024, mask: 0.4028\n",
      "step:    87540, time: 0.766, loss: 1.0175, l1: 0.1822, vgg: 0.4608, mask: 0.3746\n",
      "step:    87560, time: 0.761, loss: 1.0527, l1: 0.2121, vgg: 0.4221, mask: 0.4184\n",
      "step:    87580, time: 0.792, loss: 1.1672, l1: 0.2923, vgg: 0.4735, mask: 0.4014\n",
      "step:    87600, time: 0.746, loss: 1.0073, l1: 0.1891, vgg: 0.4539, mask: 0.3643\n",
      "step:    87620, time: 0.768, loss: 1.0906, l1: 0.2096, vgg: 0.4878, mask: 0.3932\n",
      "step:    87640, time: 0.729, loss: 1.0332, l1: 0.1909, vgg: 0.4821, mask: 0.3602\n",
      "step:    87660, time: 0.755, loss: 1.0776, l1: 0.1937, vgg: 0.4787, mask: 0.4053\n",
      "step:    87680, time: 0.742, loss: 1.0052, l1: 0.1813, vgg: 0.4485, mask: 0.3755\n",
      "step:    87700, time: 0.771, loss: 1.1366, l1: 0.2464, vgg: 0.5124, mask: 0.3779\n",
      "step:    87720, time: 0.717, loss: 0.9524, l1: 0.1705, vgg: 0.4431, mask: 0.3388\n",
      "step:    87740, time: 0.771, loss: 1.0733, l1: 0.2773, vgg: 0.4058, mask: 0.3903\n",
      "step:    87760, time: 0.733, loss: 1.0063, l1: 0.1718, vgg: 0.4638, mask: 0.3707\n",
      "step:    87780, time: 0.808, loss: 1.1105, l1: 0.2578, vgg: 0.4441, mask: 0.4086\n",
      "step:    87800, time: 0.730, loss: 0.9129, l1: 0.1616, vgg: 0.4202, mask: 0.3311\n",
      "step:    87820, time: 0.771, loss: 1.0315, l1: 0.2197, vgg: 0.4406, mask: 0.3712\n",
      "step:    87840, time: 0.741, loss: 0.9974, l1: 0.2214, vgg: 0.4404, mask: 0.3356\n",
      "step:    87860, time: 0.744, loss: 1.0578, l1: 0.2042, vgg: 0.5076, mask: 0.3459\n",
      "step:    87880, time: 0.759, loss: 1.0769, l1: 0.2132, vgg: 0.4834, mask: 0.3803\n",
      "step:    87900, time: 0.794, loss: 1.1381, l1: 0.2246, vgg: 0.5464, mask: 0.3670\n",
      "step:    87920, time: 0.715, loss: 0.9997, l1: 0.1923, vgg: 0.4523, mask: 0.3551\n",
      "step:    87940, time: 0.722, loss: 1.1051, l1: 0.2058, vgg: 0.4842, mask: 0.4150\n",
      "step:    87960, time: 0.759, loss: 1.1912, l1: 0.2153, vgg: 0.5593, mask: 0.4166\n",
      "step:    87980, time: 0.729, loss: 1.0831, l1: 0.2258, vgg: 0.4630, mask: 0.3943\n",
      "step:    88000, time: 0.720, loss: 1.1488, l1: 0.2756, vgg: 0.4844, mask: 0.3889\n",
      "step:    88020, time: 0.789, loss: 1.2926, l1: 0.2743, vgg: 0.6168, mask: 0.4015\n",
      "step:    88040, time: 0.758, loss: 1.0584, l1: 0.2082, vgg: 0.4684, mask: 0.3818\n",
      "step:    88060, time: 0.743, loss: 1.0732, l1: 0.2089, vgg: 0.4912, mask: 0.3731\n",
      "step:    88080, time: 0.772, loss: 1.0259, l1: 0.1798, vgg: 0.4461, mask: 0.4000\n",
      "step:    88100, time: 0.741, loss: 1.0620, l1: 0.1739, vgg: 0.5165, mask: 0.3715\n",
      "step:    88120, time: 0.754, loss: 1.1376, l1: 0.2523, vgg: 0.4940, mask: 0.3912\n",
      "step:    88140, time: 0.727, loss: 1.0913, l1: 0.2382, vgg: 0.4820, mask: 0.3712\n",
      "step:    88160, time: 0.798, loss: 1.2395, l1: 0.2822, vgg: 0.5612, mask: 0.3961\n",
      "step:    88180, time: 0.733, loss: 1.0537, l1: 0.2218, vgg: 0.4460, mask: 0.3859\n",
      "step:    88200, time: 0.763, loss: 1.2052, l1: 0.2352, vgg: 0.5621, mask: 0.4079\n",
      "step:    88220, time: 0.758, loss: 1.0428, l1: 0.2093, vgg: 0.4672, mask: 0.3663\n",
      "step:    88240, time: 0.742, loss: 1.0070, l1: 0.2313, vgg: 0.3945, mask: 0.3813\n",
      "step:    88260, time: 0.743, loss: 1.0905, l1: 0.2452, vgg: 0.4410, mask: 0.4043\n",
      "step:    88280, time: 0.763, loss: 1.1308, l1: 0.2421, vgg: 0.5265, mask: 0.3623\n",
      "step:    88300, time: 0.743, loss: 0.9874, l1: 0.1669, vgg: 0.4419, mask: 0.3786\n",
      "step:    88320, time: 0.768, loss: 1.0651, l1: 0.2309, vgg: 0.4889, mask: 0.3454\n",
      "step:    88340, time: 0.834, loss: 1.0087, l1: 0.1876, vgg: 0.4495, mask: 0.3716\n",
      "step:    88360, time: 0.772, loss: 1.1728, l1: 0.2456, vgg: 0.5351, mask: 0.3921\n",
      "step:    88380, time: 0.757, loss: 1.0565, l1: 0.1935, vgg: 0.4867, mask: 0.3764\n",
      "step:    88400, time: 0.826, loss: 1.1013, l1: 0.1931, vgg: 0.5295, mask: 0.3787\n",
      "step:    88420, time: 0.825, loss: 1.1270, l1: 0.1971, vgg: 0.5524, mask: 0.3775\n",
      "step:    88440, time: 0.790, loss: 1.1325, l1: 0.2955, vgg: 0.4160, mask: 0.4210\n",
      "step:    88460, time: 0.744, loss: 1.0325, l1: 0.2192, vgg: 0.4256, mask: 0.3878\n",
      "step:    88480, time: 0.801, loss: 1.0542, l1: 0.2169, vgg: 0.4371, mask: 0.4002\n",
      "step:    88500, time: 0.765, loss: 1.0351, l1: 0.1878, vgg: 0.4783, mask: 0.3690\n",
      "step:    88520, time: 0.761, loss: 1.0386, l1: 0.2575, vgg: 0.3839, mask: 0.3972\n",
      "step:    88540, time: 0.774, loss: 1.0855, l1: 0.2141, vgg: 0.4942, mask: 0.3773\n",
      "step:    88560, time: 0.736, loss: 1.0085, l1: 0.2030, vgg: 0.4329, mask: 0.3726\n",
      "step:    88580, time: 0.793, loss: 1.0275, l1: 0.1910, vgg: 0.4552, mask: 0.3813\n",
      "step:    88600, time: 0.744, loss: 0.9062, l1: 0.1379, vgg: 0.4089, mask: 0.3594\n",
      "step:    88620, time: 0.731, loss: 1.0609, l1: 0.2269, vgg: 0.4623, mask: 0.3716\n",
      "step:    88640, time: 0.769, loss: 1.0186, l1: 0.1882, vgg: 0.4589, mask: 0.3715\n",
      "step:    88660, time: 0.747, loss: 1.1605, l1: 0.2264, vgg: 0.5300, mask: 0.4041\n",
      "step:    88680, time: 0.795, loss: 0.9885, l1: 0.2078, vgg: 0.3684, mask: 0.4122\n",
      "step:    88700, time: 0.772, loss: 0.9467, l1: 0.1491, vgg: 0.4679, mask: 0.3297\n",
      "step:    88720, time: 0.764, loss: 1.0010, l1: 0.1726, vgg: 0.4802, mask: 0.3482\n",
      "step:    88740, time: 0.739, loss: 1.1810, l1: 0.2858, vgg: 0.4862, mask: 0.4090\n",
      "step:    88760, time: 0.760, loss: 0.9867, l1: 0.1897, vgg: 0.4388, mask: 0.3582\n",
      "step:    88780, time: 0.751, loss: 1.0789, l1: 0.2048, vgg: 0.5111, mask: 0.3630\n",
      "step:    88800, time: 0.736, loss: 1.0374, l1: 0.2091, vgg: 0.4240, mask: 0.4044\n",
      "step:    88820, time: 0.715, loss: 1.0055, l1: 0.2057, vgg: 0.4264, mask: 0.3734\n",
      "step:    88840, time: 0.762, loss: 1.0443, l1: 0.2065, vgg: 0.4459, mask: 0.3920\n",
      "step:    88860, time: 0.751, loss: 0.9786, l1: 0.2033, vgg: 0.3878, mask: 0.3875\n",
      "step:    88880, time: 0.721, loss: 1.0049, l1: 0.1878, vgg: 0.4417, mask: 0.3753\n",
      "step:    88900, time: 0.271, loss: 1.1451, l1: 0.2335, vgg: 0.4079, mask: 0.5037\n",
      "step:    88920, time: 0.749, loss: 1.1071, l1: 0.2429, vgg: 0.5059, mask: 0.3583\n",
      "step:    88940, time: 0.752, loss: 1.0970, l1: 0.2868, vgg: 0.4355, mask: 0.3747\n",
      "step:    88960, time: 0.742, loss: 0.9965, l1: 0.2157, vgg: 0.4333, mask: 0.3475\n",
      "step:    88980, time: 0.753, loss: 0.9969, l1: 0.1775, vgg: 0.4951, mask: 0.3243\n",
      "step:    89000, time: 0.757, loss: 1.0684, l1: 0.1879, vgg: 0.4713, mask: 0.4092\n",
      "step:    89020, time: 0.796, loss: 1.0913, l1: 0.2329, vgg: 0.4632, mask: 0.3952\n",
      "step:    89040, time: 0.731, loss: 1.0628, l1: 0.2274, vgg: 0.4558, mask: 0.3797\n",
      "step:    89060, time: 0.768, loss: 1.0963, l1: 0.2308, vgg: 0.4875, mask: 0.3780\n",
      "step:    89080, time: 0.757, loss: 1.0819, l1: 0.2476, vgg: 0.4413, mask: 0.3930\n",
      "step:    89100, time: 0.806, loss: 1.2494, l1: 0.2633, vgg: 0.5686, mask: 0.4175\n",
      "step:    89120, time: 0.730, loss: 1.1032, l1: 0.2462, vgg: 0.4580, mask: 0.3991\n",
      "step:    89140, time: 0.718, loss: 1.0380, l1: 0.1948, vgg: 0.4667, mask: 0.3765\n",
      "step:    89160, time: 0.785, loss: 1.0398, l1: 0.2301, vgg: 0.4333, mask: 0.3765\n",
      "step:    89180, time: 0.741, loss: 1.0241, l1: 0.1741, vgg: 0.4484, mask: 0.4015\n",
      "step:    89200, time: 0.759, loss: 0.9876, l1: 0.1485, vgg: 0.4567, mask: 0.3824\n",
      "step:    89220, time: 0.704, loss: 1.0007, l1: 0.2415, vgg: 0.3949, mask: 0.3643\n",
      "step:    89240, time: 0.762, loss: 1.1749, l1: 0.2329, vgg: 0.5307, mask: 0.4113\n",
      "step:    89260, time: 0.755, loss: 1.1522, l1: 0.2497, vgg: 0.5277, mask: 0.3748\n",
      "step:    89280, time: 0.780, loss: 1.1663, l1: 0.2880, vgg: 0.4281, mask: 0.4501\n",
      "step:    89300, time: 0.756, loss: 1.0439, l1: 0.1884, vgg: 0.5090, mask: 0.3465\n",
      "step:    89320, time: 0.786, loss: 1.0593, l1: 0.2136, vgg: 0.4570, mask: 0.3887\n",
      "step:    89340, time: 0.729, loss: 0.9058, l1: 0.1644, vgg: 0.4109, mask: 0.3305\n",
      "step:    89360, time: 0.772, loss: 1.1308, l1: 0.2561, vgg: 0.4657, mask: 0.4090\n",
      "step:    89380, time: 0.749, loss: 1.0120, l1: 0.2038, vgg: 0.4458, mask: 0.3624\n",
      "step:    89400, time: 0.757, loss: 1.0412, l1: 0.2512, vgg: 0.4281, mask: 0.3619\n",
      "step:    89420, time: 0.706, loss: 1.0929, l1: 0.2437, vgg: 0.4512, mask: 0.3980\n",
      "step:    89440, time: 0.762, loss: 1.2068, l1: 0.2519, vgg: 0.5563, mask: 0.3987\n",
      "step:    89460, time: 0.746, loss: 1.1461, l1: 0.2826, vgg: 0.4605, mask: 0.4030\n",
      "step:    89480, time: 0.767, loss: 1.2679, l1: 0.2829, vgg: 0.5844, mask: 0.4007\n",
      "step:    89500, time: 0.742, loss: 0.9942, l1: 0.2137, vgg: 0.4089, mask: 0.3715\n",
      "step:    89520, time: 0.770, loss: 1.0693, l1: 0.1682, vgg: 0.5060, mask: 0.3950\n",
      "step:    89540, time: 0.750, loss: 1.1343, l1: 0.2611, vgg: 0.4800, mask: 0.3933\n",
      "step:    89560, time: 0.746, loss: 1.0970, l1: 0.2570, vgg: 0.4445, mask: 0.3955\n",
      "step:    89580, time: 0.787, loss: 1.2449, l1: 0.2578, vgg: 0.6023, mask: 0.3847\n",
      "step:    89600, time: 0.721, loss: 1.0073, l1: 0.1943, vgg: 0.4085, mask: 0.4045\n",
      "step:    89620, time: 0.739, loss: 0.9558, l1: 0.1382, vgg: 0.4534, mask: 0.3642\n",
      "step:    89640, time: 0.724, loss: 1.0532, l1: 0.2368, vgg: 0.4568, mask: 0.3596\n",
      "step:    89660, time: 0.768, loss: 1.0806, l1: 0.1974, vgg: 0.4855, mask: 0.3977\n",
      "step:    89680, time: 0.762, loss: 0.9891, l1: 0.1835, vgg: 0.3802, mask: 0.4254\n",
      "step:    89700, time: 0.758, loss: 1.1404, l1: 0.2636, vgg: 0.5113, mask: 0.3655\n",
      "step:    89720, time: 0.752, loss: 1.0263, l1: 0.1702, vgg: 0.5254, mask: 0.3307\n",
      "step:    89740, time: 0.766, loss: 1.1535, l1: 0.2708, vgg: 0.4821, mask: 0.4007\n",
      "step:    89760, time: 0.738, loss: 1.1188, l1: 0.2784, vgg: 0.4364, mask: 0.4040\n",
      "step:    89780, time: 0.749, loss: 1.1631, l1: 0.2586, vgg: 0.4927, mask: 0.4117\n",
      "step:    89800, time: 0.724, loss: 1.0440, l1: 0.2154, vgg: 0.4708, mask: 0.3578\n",
      "step:    89820, time: 0.778, loss: 1.2361, l1: 0.2421, vgg: 0.5963, mask: 0.3977\n",
      "step:    89840, time: 0.737, loss: 0.9760, l1: 0.1780, vgg: 0.4588, mask: 0.3392\n",
      "step:    89860, time: 0.705, loss: 1.0534, l1: 0.2237, vgg: 0.4540, mask: 0.3757\n",
      "step:    89880, time: 0.721, loss: 0.9302, l1: 0.1426, vgg: 0.4309, mask: 0.3567\n",
      "step:    89900, time: 0.832, loss: 1.0539, l1: 0.2004, vgg: 0.4406, mask: 0.4129\n",
      "step:    89920, time: 0.717, loss: 0.9437, l1: 0.2291, vgg: 0.3884, mask: 0.3262\n",
      "step:    89940, time: 0.746, loss: 0.9907, l1: 0.1997, vgg: 0.4372, mask: 0.3537\n",
      "step:    89960, time: 0.785, loss: 1.0655, l1: 0.1725, vgg: 0.5258, mask: 0.3671\n",
      "step:    89980, time: 0.768, loss: 1.0723, l1: 0.2323, vgg: 0.4682, mask: 0.3719\n",
      "step:    90000, time: 0.770, loss: 1.1360, l1: 0.2207, vgg: 0.5138, mask: 0.4015\n",
      "step:    90020, time: 0.705, loss: 0.9911, l1: 0.1885, vgg: 0.4323, mask: 0.3702\n",
      "step:    90040, time: 0.719, loss: 1.0107, l1: 0.1908, vgg: 0.4251, mask: 0.3948\n",
      "step:    90060, time: 0.731, loss: 1.0584, l1: 0.1953, vgg: 0.4979, mask: 0.3652\n",
      "step:    90080, time: 0.794, loss: 1.1487, l1: 0.2297, vgg: 0.5236, mask: 0.3955\n",
      "step:    90100, time: 0.762, loss: 1.0790, l1: 0.2454, vgg: 0.4425, mask: 0.3912\n",
      "step:    90120, time: 0.743, loss: 1.0624, l1: 0.1892, vgg: 0.5249, mask: 0.3482\n",
      "step:    90140, time: 0.732, loss: 1.0977, l1: 0.2384, vgg: 0.4874, mask: 0.3719\n",
      "step:    90160, time: 0.769, loss: 1.1095, l1: 0.2127, vgg: 0.5273, mask: 0.3695\n",
      "step:    90180, time: 0.742, loss: 1.0057, l1: 0.2429, vgg: 0.3953, mask: 0.3675\n",
      "step:    90200, time: 0.742, loss: 1.0730, l1: 0.2372, vgg: 0.4100, mask: 0.4257\n",
      "step:    90220, time: 0.753, loss: 1.0363, l1: 0.2143, vgg: 0.4576, mask: 0.3643\n",
      "step:    90240, time: 0.761, loss: 0.9397, l1: 0.1689, vgg: 0.3970, mask: 0.3738\n",
      "step:    90260, time: 0.739, loss: 1.0809, l1: 0.2258, vgg: 0.4712, mask: 0.3839\n",
      "step:    90280, time: 0.752, loss: 1.0600, l1: 0.2062, vgg: 0.4652, mask: 0.3886\n",
      "step:    90300, time: 0.745, loss: 0.9127, l1: 0.1526, vgg: 0.4303, mask: 0.3298\n",
      "step:    90320, time: 0.742, loss: 1.0418, l1: 0.1694, vgg: 0.4739, mask: 0.3985\n",
      "step:    90340, time: 0.738, loss: 0.9876, l1: 0.2094, vgg: 0.4148, mask: 0.3634\n",
      "step:    90360, time: 0.752, loss: 1.0420, l1: 0.2557, vgg: 0.4054, mask: 0.3809\n",
      "step:    90380, time: 0.748, loss: 1.0569, l1: 0.2054, vgg: 0.4571, mask: 0.3945\n",
      "step:    90400, time: 0.768, loss: 1.1884, l1: 0.2768, vgg: 0.5176, mask: 0.3940\n",
      "step:    90420, time: 0.733, loss: 1.0974, l1: 0.2371, vgg: 0.4761, mask: 0.3842\n",
      "step:    90440, time: 0.716, loss: 0.9264, l1: 0.1544, vgg: 0.4310, mask: 0.3410\n",
      "step:    90460, time: 0.763, loss: 1.1233, l1: 0.2331, vgg: 0.5006, mask: 0.3896\n",
      "step:    90480, time: 0.754, loss: 1.1032, l1: 0.2097, vgg: 0.5194, mask: 0.3741\n",
      "step:    90500, time: 0.750, loss: 0.9706, l1: 0.1737, vgg: 0.4461, mask: 0.3508\n",
      "step:    90520, time: 0.770, loss: 0.9677, l1: 0.1646, vgg: 0.4372, mask: 0.3658\n",
      "step:    90540, time: 0.736, loss: 0.9780, l1: 0.2111, vgg: 0.4019, mask: 0.3651\n",
      "step:    90560, time: 0.742, loss: 1.0965, l1: 0.2036, vgg: 0.5319, mask: 0.3610\n",
      "step:    90580, time: 0.748, loss: 1.0618, l1: 0.2209, vgg: 0.4649, mask: 0.3760\n",
      "step:    90600, time: 0.733, loss: 0.9547, l1: 0.1522, vgg: 0.4776, mask: 0.3248\n",
      "step:    90620, time: 0.732, loss: 1.0105, l1: 0.2374, vgg: 0.4047, mask: 0.3685\n",
      "step:    90640, time: 0.730, loss: 1.0316, l1: 0.2078, vgg: 0.4569, mask: 0.3670\n",
      "step:    90660, time: 0.740, loss: 1.0138, l1: 0.1550, vgg: 0.4744, mask: 0.3844\n",
      "step:    90680, time: 0.778, loss: 1.0960, l1: 0.2098, vgg: 0.4956, mask: 0.3907\n",
      "step:    90700, time: 0.731, loss: 1.0968, l1: 0.2549, vgg: 0.4507, mask: 0.3912\n",
      "step:    90720, time: 0.835, loss: 1.0707, l1: 0.2094, vgg: 0.4893, mask: 0.3720\n",
      "step:    90740, time: 0.767, loss: 1.0600, l1: 0.1816, vgg: 0.4687, mask: 0.4097\n",
      "step:    90760, time: 0.743, loss: 0.9994, l1: 0.1772, vgg: 0.4717, mask: 0.3506\n",
      "step:    90780, time: 0.776, loss: 1.0030, l1: 0.1924, vgg: 0.4589, mask: 0.3517\n",
      "step:    90800, time: 0.754, loss: 1.0175, l1: 0.2092, vgg: 0.4653, mask: 0.3430\n",
      "step:    90820, time: 0.745, loss: 1.1519, l1: 0.2117, vgg: 0.5494, mask: 0.3908\n",
      "step:    90840, time: 0.735, loss: 1.0019, l1: 0.2000, vgg: 0.4456, mask: 0.3562\n",
      "step:    90860, time: 0.713, loss: 1.0823, l1: 0.2222, vgg: 0.4767, mask: 0.3834\n",
      "step:    90880, time: 0.736, loss: 1.0447, l1: 0.1842, vgg: 0.4836, mask: 0.3769\n",
      "step:    90900, time: 0.755, loss: 1.0680, l1: 0.2666, vgg: 0.4318, mask: 0.3696\n",
      "step:    90920, time: 0.732, loss: 1.1427, l1: 0.2203, vgg: 0.5449, mask: 0.3775\n",
      "step:    90940, time: 0.795, loss: 1.1110, l1: 0.1697, vgg: 0.5459, mask: 0.3954\n",
      "step:    90960, time: 0.754, loss: 0.9786, l1: 0.1828, vgg: 0.4523, mask: 0.3435\n",
      "step:    90980, time: 0.744, loss: 0.9993, l1: 0.1928, vgg: 0.4505, mask: 0.3561\n",
      "step:    91000, time: 0.735, loss: 1.0174, l1: 0.2342, vgg: 0.4369, mask: 0.3463\n",
      "step:    91020, time: 0.736, loss: 1.0793, l1: 0.2394, vgg: 0.4670, mask: 0.3728\n",
      "step:    91040, time: 0.731, loss: 1.0141, l1: 0.2070, vgg: 0.4377, mask: 0.3695\n",
      "step:    91060, time: 0.736, loss: 1.0052, l1: 0.1987, vgg: 0.4523, mask: 0.3542\n",
      "step:    91080, time: 0.781, loss: 1.1002, l1: 0.1943, vgg: 0.5100, mask: 0.3959\n",
      "step:    91100, time: 0.741, loss: 1.1046, l1: 0.2135, vgg: 0.5016, mask: 0.3895\n",
      "step:    91120, time: 0.747, loss: 1.0266, l1: 0.1850, vgg: 0.4564, mask: 0.3852\n",
      "step:    91140, time: 0.744, loss: 1.1979, l1: 0.2577, vgg: 0.5432, mask: 0.3969\n",
      "step:    91160, time: 0.769, loss: 1.0996, l1: 0.2426, vgg: 0.4644, mask: 0.3925\n",
      "step:    91180, time: 0.725, loss: 1.1080, l1: 0.2821, vgg: 0.4418, mask: 0.3840\n",
      "step:    91200, time: 0.740, loss: 1.0778, l1: 0.2178, vgg: 0.5059, mask: 0.3540\n",
      "step:    91220, time: 0.801, loss: 1.1355, l1: 0.2340, vgg: 0.5077, mask: 0.3939\n",
      "step:    91240, time: 0.773, loss: 1.1720, l1: 0.2655, vgg: 0.5018, mask: 0.4047\n",
      "step:    91260, time: 0.729, loss: 1.1426, l1: 0.2425, vgg: 0.4803, mask: 0.4198\n",
      "step:    91280, time: 0.759, loss: 1.2347, l1: 0.2780, vgg: 0.5382, mask: 0.4185\n",
      "step:    91300, time: 0.742, loss: 1.0720, l1: 0.2364, vgg: 0.4406, mask: 0.3949\n",
      "step:    91320, time: 0.749, loss: 1.0313, l1: 0.2183, vgg: 0.4206, mask: 0.3923\n",
      "step:    91340, time: 0.768, loss: 1.0931, l1: 0.1950, vgg: 0.5253, mask: 0.3728\n",
      "step:    91360, time: 0.754, loss: 1.0839, l1: 0.2064, vgg: 0.4518, mask: 0.4257\n",
      "step:    91380, time: 0.733, loss: 1.0825, l1: 0.2456, vgg: 0.4593, mask: 0.3776\n",
      "step:    91400, time: 0.738, loss: 1.0671, l1: 0.2356, vgg: 0.4734, mask: 0.3581\n",
      "step:    91420, time: 0.733, loss: 1.0013, l1: 0.2013, vgg: 0.4363, mask: 0.3638\n",
      "step:    91440, time: 0.733, loss: 1.0562, l1: 0.2485, vgg: 0.4362, mask: 0.3715\n",
      "step:    91460, time: 0.747, loss: 1.0429, l1: 0.1965, vgg: 0.4682, mask: 0.3782\n",
      "step:    91480, time: 0.709, loss: 1.0125, l1: 0.2210, vgg: 0.3871, mask: 0.4044\n",
      "step:    91500, time: 0.753, loss: 1.0556, l1: 0.2485, vgg: 0.4393, mask: 0.3678\n",
      "step:    91520, time: 0.743, loss: 1.0355, l1: 0.1756, vgg: 0.5053, mask: 0.3546\n",
      "step:    91540, time: 0.804, loss: 1.1462, l1: 0.2189, vgg: 0.5434, mask: 0.3838\n",
      "step:    91560, time: 0.769, loss: 0.9486, l1: 0.1667, vgg: 0.4463, mask: 0.3356\n",
      "step:    91580, time: 0.744, loss: 1.2379, l1: 0.2620, vgg: 0.5939, mask: 0.3820\n",
      "step:    91600, time: 0.737, loss: 1.0504, l1: 0.2367, vgg: 0.4155, mask: 0.3981\n",
      "step:    91620, time: 0.735, loss: 1.0467, l1: 0.1924, vgg: 0.4969, mask: 0.3575\n",
      "step:    91640, time: 0.798, loss: 1.0572, l1: 0.1786, vgg: 0.4934, mask: 0.3852\n",
      "step:    91660, time: 0.747, loss: 1.0321, l1: 0.1869, vgg: 0.4878, mask: 0.3575\n",
      "step:    91680, time: 0.752, loss: 1.0685, l1: 0.2283, vgg: 0.4793, mask: 0.3609\n",
      "step:    91700, time: 0.764, loss: 1.0478, l1: 0.2240, vgg: 0.4560, mask: 0.3677\n",
      "step:    91720, time: 0.779, loss: 1.0425, l1: 0.2180, vgg: 0.4199, mask: 0.4045\n",
      "step:    91740, time: 0.747, loss: 1.1524, l1: 0.2800, vgg: 0.4869, mask: 0.3855\n",
      "step:    91760, time: 0.746, loss: 1.0069, l1: 0.2115, vgg: 0.4256, mask: 0.3699\n",
      "step:    91780, time: 0.739, loss: 0.9703, l1: 0.2070, vgg: 0.4102, mask: 0.3531\n",
      "step:    91800, time: 0.773, loss: 0.9874, l1: 0.2168, vgg: 0.4161, mask: 0.3545\n",
      "step:    91820, time: 0.765, loss: 1.0368, l1: 0.1987, vgg: 0.4513, mask: 0.3868\n",
      "step:    91840, time: 0.732, loss: 0.9232, l1: 0.1788, vgg: 0.4141, mask: 0.3303\n",
      "step:    91860, time: 0.749, loss: 0.9148, l1: 0.1647, vgg: 0.4027, mask: 0.3474\n",
      "step:    91880, time: 0.773, loss: 1.0525, l1: 0.2070, vgg: 0.4889, mask: 0.3566\n",
      "step:    91900, time: 0.773, loss: 1.1407, l1: 0.2304, vgg: 0.4770, mask: 0.4333\n",
      "step:    91920, time: 0.758, loss: 0.9888, l1: 0.1921, vgg: 0.4548, mask: 0.3419\n",
      "step:    91940, time: 0.771, loss: 1.1277, l1: 0.2540, vgg: 0.4675, mask: 0.4062\n",
      "step:    91960, time: 0.759, loss: 1.1384, l1: 0.2136, vgg: 0.5398, mask: 0.3850\n",
      "step:    91980, time: 0.748, loss: 1.0294, l1: 0.1812, vgg: 0.5044, mask: 0.3438\n",
      "step:    92000, time: 0.758, loss: 1.0784, l1: 0.2170, vgg: 0.4797, mask: 0.3817\n",
      "step:    92020, time: 0.811, loss: 1.2140, l1: 0.2640, vgg: 0.5437, mask: 0.4063\n",
      "step:    92040, time: 0.770, loss: 1.1258, l1: 0.2250, vgg: 0.4867, mask: 0.4141\n",
      "step:    92060, time: 0.794, loss: 1.1630, l1: 0.2505, vgg: 0.5548, mask: 0.3577\n",
      "step:    92080, time: 0.767, loss: 1.0318, l1: 0.2112, vgg: 0.4263, mask: 0.3943\n",
      "step:    92100, time: 0.783, loss: 1.0478, l1: 0.1999, vgg: 0.4686, mask: 0.3793\n",
      "step:    92120, time: 0.754, loss: 1.0879, l1: 0.2362, vgg: 0.4625, mask: 0.3891\n",
      "step:    92140, time: 0.751, loss: 0.9594, l1: 0.1759, vgg: 0.4197, mask: 0.3638\n",
      "step:    92160, time: 0.761, loss: 1.1791, l1: 0.2197, vgg: 0.5796, mask: 0.3798\n",
      "step:    92180, time: 0.696, loss: 0.8905, l1: 0.1390, vgg: 0.4204, mask: 0.3311\n",
      "step:    92200, time: 0.772, loss: 1.1188, l1: 0.1989, vgg: 0.5348, mask: 0.3851\n",
      "step:    92220, time: 0.759, loss: 1.1363, l1: 0.2045, vgg: 0.5431, mask: 0.3887\n",
      "step:    92240, time: 0.771, loss: 1.1167, l1: 0.2510, vgg: 0.4643, mask: 0.4014\n",
      "step:    92260, time: 0.729, loss: 0.9558, l1: 0.1649, vgg: 0.4500, mask: 0.3409\n",
      "step:    92280, time: 0.741, loss: 1.0728, l1: 0.2213, vgg: 0.4586, mask: 0.3930\n",
      "step:    92300, time: 0.718, loss: 0.9282, l1: 0.1676, vgg: 0.4040, mask: 0.3566\n",
      "step:    92320, time: 0.806, loss: 1.2351, l1: 0.2662, vgg: 0.5597, mask: 0.4091\n",
      "step:    92340, time: 0.730, loss: 1.0839, l1: 0.2332, vgg: 0.4616, mask: 0.3891\n",
      "step:    92360, time: 0.782, loss: 1.1268, l1: 0.2035, vgg: 0.5321, mask: 0.3913\n",
      "step:    92380, time: 0.764, loss: 1.1271, l1: 0.2571, vgg: 0.4687, mask: 0.4013\n",
      "step:    92400, time: 0.781, loss: 1.2700, l1: 0.2394, vgg: 0.6490, mask: 0.3816\n",
      "step:    92420, time: 0.753, loss: 1.0792, l1: 0.2113, vgg: 0.4854, mask: 0.3825\n",
      "step:    92440, time: 0.767, loss: 0.9925, l1: 0.2013, vgg: 0.3883, mask: 0.4029\n",
      "step:    92460, time: 0.732, loss: 1.0214, l1: 0.1732, vgg: 0.4789, mask: 0.3693\n",
      "step:    92480, time: 0.732, loss: 1.0484, l1: 0.2325, vgg: 0.4357, mask: 0.3801\n",
      "step:    92500, time: 0.714, loss: 1.1389, l1: 0.2960, vgg: 0.4284, mask: 0.4145\n",
      "step:    92520, time: 0.754, loss: 1.0517, l1: 0.2043, vgg: 0.4818, mask: 0.3657\n",
      "step:    92540, time: 0.768, loss: 1.0397, l1: 0.2138, vgg: 0.4681, mask: 0.3577\n",
      "step:    92560, time: 0.746, loss: 0.9157, l1: 0.1661, vgg: 0.4131, mask: 0.3366\n",
      "step:    92580, time: 0.727, loss: 1.1203, l1: 0.2221, vgg: 0.5110, mask: 0.3872\n",
      "step:    92600, time: 0.752, loss: 1.0866, l1: 0.2355, vgg: 0.4734, mask: 0.3777\n",
      "step:    92620, time: 0.760, loss: 1.0334, l1: 0.2774, vgg: 0.3939, mask: 0.3622\n",
      "step:    92640, time: 0.754, loss: 0.9902, l1: 0.2249, vgg: 0.4110, mask: 0.3543\n",
      "step:    92660, time: 0.770, loss: 1.0896, l1: 0.2226, vgg: 0.4405, mask: 0.4265\n",
      "step:    92680, time: 0.757, loss: 1.1396, l1: 0.2526, vgg: 0.4685, mask: 0.4185\n",
      "step:    92700, time: 0.756, loss: 1.0752, l1: 0.2294, vgg: 0.4563, mask: 0.3895\n",
      "step:    92720, time: 0.760, loss: 1.1480, l1: 0.2949, vgg: 0.4484, mask: 0.4047\n",
      "step:    92740, time: 0.787, loss: 1.1294, l1: 0.2760, vgg: 0.4419, mask: 0.4115\n",
      "step:    92760, time: 0.739, loss: 0.9927, l1: 0.1721, vgg: 0.4604, mask: 0.3602\n",
      "step:    92780, time: 0.735, loss: 1.0703, l1: 0.2427, vgg: 0.4412, mask: 0.3864\n",
      "step:    92800, time: 0.730, loss: 1.0806, l1: 0.2213, vgg: 0.4704, mask: 0.3889\n",
      "step:    92820, time: 0.780, loss: 1.0305, l1: 0.1917, vgg: 0.4574, mask: 0.3814\n",
      "step:    92840, time: 0.739, loss: 0.9836, l1: 0.2013, vgg: 0.4097, mask: 0.3726\n",
      "step:    92860, time: 0.759, loss: 0.9730, l1: 0.1955, vgg: 0.4159, mask: 0.3616\n",
      "step:    92880, time: 0.787, loss: 1.0558, l1: 0.2427, vgg: 0.4205, mask: 0.3926\n",
      "step:    92900, time: 0.720, loss: 0.9194, l1: 0.1571, vgg: 0.4266, mask: 0.3357\n",
      "step:    92920, time: 0.727, loss: 1.0239, l1: 0.2282, vgg: 0.4354, mask: 0.3603\n",
      "step:    92940, time: 0.770, loss: 1.0645, l1: 0.2061, vgg: 0.4946, mask: 0.3638\n",
      "step:    92960, time: 0.737, loss: 1.1630, l1: 0.2261, vgg: 0.5645, mask: 0.3724\n",
      "step:    92980, time: 0.738, loss: 1.1853, l1: 0.2573, vgg: 0.5107, mask: 0.4172\n",
      "step:    93000, time: 0.736, loss: 1.0149, l1: 0.2008, vgg: 0.4566, mask: 0.3575\n",
      "step:    93020, time: 0.730, loss: 1.0317, l1: 0.2386, vgg: 0.4308, mask: 0.3624\n",
      "step:    93040, time: 0.765, loss: 1.0519, l1: 0.2266, vgg: 0.4264, mask: 0.3990\n",
      "step:    93060, time: 0.743, loss: 1.1870, l1: 0.2336, vgg: 0.5719, mask: 0.3815\n",
      "step:    93080, time: 0.802, loss: 1.1408, l1: 0.2179, vgg: 0.5376, mask: 0.3853\n",
      "step:    93100, time: 0.750, loss: 1.1008, l1: 0.2704, vgg: 0.4724, mask: 0.3580\n",
      "step:    93120, time: 0.758, loss: 1.1209, l1: 0.2647, vgg: 0.4776, mask: 0.3786\n",
      "step:    93140, time: 0.745, loss: 1.0852, l1: 0.2206, vgg: 0.4953, mask: 0.3693\n",
      "step:    93160, time: 0.731, loss: 0.9182, l1: 0.1572, vgg: 0.4269, mask: 0.3340\n",
      "step:    93180, time: 0.757, loss: 1.0972, l1: 0.2178, vgg: 0.4792, mask: 0.4002\n",
      "step:    93200, time: 0.759, loss: 0.9881, l1: 0.1889, vgg: 0.4233, mask: 0.3759\n",
      "step:    93220, time: 0.779, loss: 1.0749, l1: 0.2037, vgg: 0.5104, mask: 0.3607\n",
      "step:    93240, time: 0.752, loss: 1.1686, l1: 0.2576, vgg: 0.5110, mask: 0.3999\n",
      "step:    93260, time: 0.723, loss: 0.9897, l1: 0.1969, vgg: 0.4414, mask: 0.3515\n",
      "step:    93280, time: 0.764, loss: 1.0976, l1: 0.2312, vgg: 0.4635, mask: 0.4030\n",
      "step:    93300, time: 0.735, loss: 1.1582, l1: 0.2722, vgg: 0.4667, mask: 0.4192\n",
      "step:    93320, time: 0.742, loss: 1.0855, l1: 0.2455, vgg: 0.4379, mask: 0.4022\n",
      "step:    93340, time: 0.769, loss: 1.0950, l1: 0.1735, vgg: 0.4792, mask: 0.4423\n",
      "step:    93360, time: 0.729, loss: 1.1560, l1: 0.3007, vgg: 0.4445, mask: 0.4108\n",
      "step:    93380, time: 0.736, loss: 1.1813, l1: 0.2631, vgg: 0.5272, mask: 0.3910\n",
      "step:    93400, time: 0.747, loss: 0.9394, l1: 0.1577, vgg: 0.4426, mask: 0.3391\n",
      "step:    93420, time: 0.743, loss: 1.0101, l1: 0.1434, vgg: 0.4649, mask: 0.4018\n",
      "step:    93440, time: 0.755, loss: 1.0918, l1: 0.1832, vgg: 0.5582, mask: 0.3504\n",
      "step:    93460, time: 0.750, loss: 1.0551, l1: 0.1864, vgg: 0.5041, mask: 0.3646\n",
      "step:    93480, time: 0.735, loss: 1.0704, l1: 0.2364, vgg: 0.4698, mask: 0.3641\n",
      "step:    93500, time: 0.721, loss: 1.0071, l1: 0.2233, vgg: 0.4336, mask: 0.3502\n",
      "step:    93520, time: 0.738, loss: 1.0935, l1: 0.2179, vgg: 0.4855, mask: 0.3902\n",
      "step:    93540, time: 0.751, loss: 1.1251, l1: 0.2248, vgg: 0.5129, mask: 0.3875\n",
      "step:    93560, time: 0.773, loss: 1.1344, l1: 0.2153, vgg: 0.5460, mask: 0.3730\n",
      "step:    93580, time: 0.756, loss: 1.0438, l1: 0.2188, vgg: 0.4294, mask: 0.3956\n",
      "step:    93600, time: 0.752, loss: 1.0796, l1: 0.2402, vgg: 0.4406, mask: 0.3988\n",
      "step:    93620, time: 0.763, loss: 0.9895, l1: 0.1841, vgg: 0.4120, mask: 0.3934\n",
      "step:    93640, time: 0.732, loss: 0.9886, l1: 0.1929, vgg: 0.4491, mask: 0.3466\n",
      "step:    93660, time: 0.744, loss: 1.0769, l1: 0.2263, vgg: 0.4731, mask: 0.3775\n",
      "step:    93680, time: 0.753, loss: 1.0142, l1: 0.1929, vgg: 0.4399, mask: 0.3814\n",
      "step:    93700, time: 0.743, loss: 1.2068, l1: 0.2584, vgg: 0.5609, mask: 0.3875\n",
      "step:    93720, time: 0.750, loss: 1.1162, l1: 0.2744, vgg: 0.4636, mask: 0.3782\n",
      "step:    93740, time: 0.737, loss: 1.0341, l1: 0.2243, vgg: 0.4712, mask: 0.3386\n",
      "step:    93760, time: 0.748, loss: 1.1784, l1: 0.2637, vgg: 0.5106, mask: 0.4041\n",
      "step:    93780, time: 0.723, loss: 1.0535, l1: 0.2379, vgg: 0.4017, mask: 0.4138\n",
      "step:    93800, time: 0.768, loss: 1.2065, l1: 0.2618, vgg: 0.5220, mask: 0.4228\n",
      "step:    93820, time: 0.753, loss: 1.1005, l1: 0.2451, vgg: 0.4224, mask: 0.4330\n",
      "step:    93840, time: 0.761, loss: 1.0084, l1: 0.1971, vgg: 0.4448, mask: 0.3664\n",
      "step:    93860, time: 0.747, loss: 0.9815, l1: 0.1831, vgg: 0.4421, mask: 0.3564\n",
      "step:    93880, time: 0.797, loss: 1.0596, l1: 0.2313, vgg: 0.4508, mask: 0.3776\n",
      "step:    93900, time: 0.777, loss: 1.0852, l1: 0.2534, vgg: 0.4522, mask: 0.3797\n",
      "step:    93920, time: 0.780, loss: 1.1782, l1: 0.2228, vgg: 0.5734, mask: 0.3821\n",
      "step:    93940, time: 0.729, loss: 1.0499, l1: 0.2285, vgg: 0.4266, mask: 0.3949\n",
      "step:    93960, time: 0.757, loss: 1.0638, l1: 0.2213, vgg: 0.4677, mask: 0.3748\n",
      "step:    93980, time: 0.748, loss: 1.1374, l1: 0.2586, vgg: 0.4948, mask: 0.3841\n",
      "step:    94000, time: 0.759, loss: 1.0146, l1: 0.1801, vgg: 0.4782, mask: 0.3563\n",
      "step:    94020, time: 0.780, loss: 1.0967, l1: 0.2327, vgg: 0.4715, mask: 0.3925\n",
      "step:    94040, time: 0.748, loss: 1.0769, l1: 0.2438, vgg: 0.4595, mask: 0.3737\n",
      "step:    94060, time: 0.766, loss: 1.0831, l1: 0.2395, vgg: 0.4453, mask: 0.3983\n",
      "step:    94080, time: 0.707, loss: 0.9277, l1: 0.1551, vgg: 0.4036, mask: 0.3690\n",
      "step:    94100, time: 0.694, loss: 1.0940, l1: 0.2244, vgg: 0.4778, mask: 0.3917\n",
      "step:    94120, time: 0.793, loss: 1.1654, l1: 0.2296, vgg: 0.5311, mask: 0.4047\n",
      "step:    94140, time: 0.741, loss: 1.0864, l1: 0.2185, vgg: 0.4515, mask: 0.4164\n",
      "step:    94160, time: 0.771, loss: 1.1328, l1: 0.2389, vgg: 0.4805, mask: 0.4134\n",
      "step:    94180, time: 0.773, loss: 0.9680, l1: 0.1735, vgg: 0.4348, mask: 0.3597\n",
      "step:    94200, time: 0.752, loss: 1.0724, l1: 0.2266, vgg: 0.4705, mask: 0.3753\n",
      "step:    94220, time: 0.759, loss: 1.0423, l1: 0.2426, vgg: 0.4228, mask: 0.3768\n",
      "step:    94240, time: 0.718, loss: 1.0260, l1: 0.1754, vgg: 0.4474, mask: 0.4033\n",
      "step:    94260, time: 0.732, loss: 0.9429, l1: 0.1781, vgg: 0.4114, mask: 0.3534\n",
      "step:    94280, time: 0.732, loss: 1.1068, l1: 0.2493, vgg: 0.4667, mask: 0.3908\n",
      "step:    94300, time: 0.756, loss: 1.0990, l1: 0.2098, vgg: 0.5084, mask: 0.3807\n",
      "step:    94320, time: 0.743, loss: 1.0260, l1: 0.1822, vgg: 0.4815, mask: 0.3623\n",
      "step:    94340, time: 0.727, loss: 0.9834, l1: 0.2051, vgg: 0.4003, mask: 0.3780\n",
      "step:    94360, time: 0.794, loss: 1.1977, l1: 0.2760, vgg: 0.5221, mask: 0.3996\n",
      "step:    94380, time: 0.753, loss: 1.0186, l1: 0.1763, vgg: 0.4926, mask: 0.3497\n",
      "step:    94400, time: 0.768, loss: 0.9582, l1: 0.1889, vgg: 0.4139, mask: 0.3554\n",
      "step:    94420, time: 0.738, loss: 0.9448, l1: 0.1855, vgg: 0.4051, mask: 0.3542\n",
      "step:    94440, time: 0.773, loss: 1.0961, l1: 0.2171, vgg: 0.4887, mask: 0.3903\n",
      "step:    94460, time: 0.760, loss: 1.0889, l1: 0.1869, vgg: 0.5307, mask: 0.3713\n",
      "step:    94480, time: 0.774, loss: 1.1067, l1: 0.2109, vgg: 0.5102, mask: 0.3856\n",
      "step:    94500, time: 0.786, loss: 0.9454, l1: 0.1565, vgg: 0.4457, mask: 0.3432\n",
      "step:    94520, time: 0.771, loss: 0.9116, l1: 0.1555, vgg: 0.4238, mask: 0.3322\n",
      "step:    94540, time: 0.738, loss: 0.9299, l1: 0.1780, vgg: 0.3981, mask: 0.3539\n",
      "step:    94560, time: 0.772, loss: 1.0470, l1: 0.2519, vgg: 0.4142, mask: 0.3810\n",
      "step:    94580, time: 0.751, loss: 1.1732, l1: 0.2851, vgg: 0.5077, mask: 0.3805\n",
      "step:    94600, time: 0.766, loss: 1.0626, l1: 0.2315, vgg: 0.4370, mask: 0.3941\n",
      "step:    94620, time: 0.698, loss: 0.9494, l1: 0.1674, vgg: 0.4327, mask: 0.3493\n",
      "step:    94640, time: 0.738, loss: 1.1282, l1: 0.2889, vgg: 0.4500, mask: 0.3893\n",
      "step:    94660, time: 0.734, loss: 1.1189, l1: 0.2151, vgg: 0.5043, mask: 0.3995\n",
      "step:    94680, time: 0.760, loss: 1.1055, l1: 0.2356, vgg: 0.4635, mask: 0.4064\n",
      "step:    94700, time: 0.761, loss: 1.0508, l1: 0.2091, vgg: 0.4663, mask: 0.3754\n",
      "step:    94720, time: 0.736, loss: 0.9821, l1: 0.1851, vgg: 0.4531, mask: 0.3439\n",
      "step:    94740, time: 0.777, loss: 1.0741, l1: 0.2294, vgg: 0.4510, mask: 0.3937\n",
      "step:    94760, time: 0.770, loss: 1.0907, l1: 0.2463, vgg: 0.4591, mask: 0.3853\n",
      "step:    94780, time: 0.747, loss: 0.9812, l1: 0.2074, vgg: 0.4079, mask: 0.3659\n",
      "step:    94800, time: 0.763, loss: 0.9640, l1: 0.1798, vgg: 0.4356, mask: 0.3487\n",
      "step:    94820, time: 0.730, loss: 0.9604, l1: 0.1961, vgg: 0.3953, mask: 0.3689\n",
      "step:    94840, time: 0.724, loss: 1.0031, l1: 0.2050, vgg: 0.4002, mask: 0.3979\n",
      "step:    94860, time: 0.758, loss: 0.9830, l1: 0.1976, vgg: 0.4423, mask: 0.3431\n",
      "step:    94880, time: 0.723, loss: 1.1433, l1: 0.2515, vgg: 0.4735, mask: 0.4183\n",
      "step:    94900, time: 0.730, loss: 1.0339, l1: 0.2264, vgg: 0.4306, mask: 0.3770\n",
      "step:    94920, time: 0.724, loss: 0.9718, l1: 0.1769, vgg: 0.4093, mask: 0.3856\n",
      "step:    94940, time: 0.739, loss: 1.0328, l1: 0.1807, vgg: 0.4764, mask: 0.3757\n",
      "step:    94960, time: 0.738, loss: 1.0460, l1: 0.2198, vgg: 0.4487, mask: 0.3775\n",
      "step:    94980, time: 0.747, loss: 1.0547, l1: 0.2153, vgg: 0.4626, mask: 0.3769\n",
      "step:    95000, time: 0.751, loss: 1.0631, l1: 0.2277, vgg: 0.4665, mask: 0.3690\n",
      "step:    95020, time: 0.732, loss: 0.9964, l1: 0.1923, vgg: 0.4424, mask: 0.3618\n",
      "step:    95040, time: 0.784, loss: 1.2469, l1: 0.2745, vgg: 0.5894, mask: 0.3829\n",
      "step:    95060, time: 0.744, loss: 1.1376, l1: 0.2508, vgg: 0.4957, mask: 0.3912\n",
      "step:    95080, time: 0.746, loss: 0.9769, l1: 0.1861, vgg: 0.4339, mask: 0.3568\n",
      "step:    95100, time: 0.733, loss: 1.0231, l1: 0.2059, vgg: 0.4436, mask: 0.3735\n",
      "step:    95120, time: 0.726, loss: 0.9330, l1: 0.1672, vgg: 0.4151, mask: 0.3507\n",
      "step:    95140, time: 0.766, loss: 1.0998, l1: 0.2399, vgg: 0.4467, mask: 0.4133\n",
      "step:    95160, time: 0.744, loss: 1.1412, l1: 0.2600, vgg: 0.4873, mask: 0.3938\n",
      "step:    95180, time: 0.747, loss: 1.1203, l1: 0.2892, vgg: 0.4182, mask: 0.4130\n",
      "step:    95200, time: 0.739, loss: 1.0256, l1: 0.2367, vgg: 0.4030, mask: 0.3860\n",
      "step:    95220, time: 0.757, loss: 1.0450, l1: 0.1791, vgg: 0.5140, mask: 0.3519\n",
      "step:    95240, time: 0.757, loss: 1.0093, l1: 0.2305, vgg: 0.4080, mask: 0.3709\n",
      "step:    95260, time: 0.767, loss: 1.1158, l1: 0.2201, vgg: 0.4861, mask: 0.4096\n",
      "step:    95280, time: 0.738, loss: 0.9951, l1: 0.2424, vgg: 0.3725, mask: 0.3802\n",
      "step:    95300, time: 0.767, loss: 1.1930, l1: 0.2531, vgg: 0.5197, mask: 0.4202\n",
      "step:    95320, time: 0.741, loss: 1.0043, l1: 0.1686, vgg: 0.4597, mask: 0.3760\n",
      "step:    95340, time: 0.774, loss: 0.9427, l1: 0.1648, vgg: 0.4298, mask: 0.3482\n",
      "step:    95360, time: 0.779, loss: 1.0946, l1: 0.2247, vgg: 0.4909, mask: 0.3790\n",
      "step:    95380, time: 0.704, loss: 0.9841, l1: 0.1811, vgg: 0.4414, mask: 0.3617\n",
      "step:    95400, time: 0.726, loss: 0.9137, l1: 0.1683, vgg: 0.3693, mask: 0.3761\n",
      "step:    95420, time: 0.738, loss: 1.0108, l1: 0.1974, vgg: 0.4505, mask: 0.3629\n",
      "step:    95440, time: 0.738, loss: 1.1213, l1: 0.2472, vgg: 0.4499, mask: 0.4243\n",
      "step:    95460, time: 0.744, loss: 0.9807, l1: 0.1854, vgg: 0.4485, mask: 0.3468\n",
      "step:    95480, time: 0.741, loss: 1.0467, l1: 0.2105, vgg: 0.4591, mask: 0.3771\n",
      "step:    95500, time: 0.763, loss: 1.2112, l1: 0.2637, vgg: 0.5210, mask: 0.4265\n",
      "step:    95520, time: 0.743, loss: 1.1393, l1: 0.2698, vgg: 0.4532, mask: 0.4162\n",
      "step:    95540, time: 0.786, loss: 0.9741, l1: 0.1962, vgg: 0.4170, mask: 0.3609\n",
      "step:    95560, time: 0.734, loss: 0.9842, l1: 0.2003, vgg: 0.4109, mask: 0.3730\n",
      "step:    95580, time: 0.745, loss: 1.1036, l1: 0.2193, vgg: 0.5139, mask: 0.3704\n",
      "step:    95600, time: 0.735, loss: 1.0837, l1: 0.2264, vgg: 0.4996, mask: 0.3577\n",
      "step:    95620, time: 0.761, loss: 1.2555, l1: 0.2546, vgg: 0.5666, mask: 0.4343\n",
      "step:    95640, time: 0.750, loss: 1.0416, l1: 0.1905, vgg: 0.5155, mask: 0.3356\n",
      "step:    95660, time: 0.773, loss: 1.1356, l1: 0.2288, vgg: 0.4910, mask: 0.4158\n",
      "step:    95680, time: 0.718, loss: 1.0020, l1: 0.2175, vgg: 0.4497, mask: 0.3349\n",
      "step:    95700, time: 0.771, loss: 1.0909, l1: 0.2182, vgg: 0.4925, mask: 0.3802\n",
      "step:    95720, time: 0.729, loss: 1.0870, l1: 0.1999, vgg: 0.5240, mask: 0.3631\n",
      "step:    95740, time: 0.775, loss: 1.1336, l1: 0.2846, vgg: 0.4321, mask: 0.4169\n",
      "step:    95760, time: 0.729, loss: 1.0180, l1: 0.1895, vgg: 0.4542, mask: 0.3744\n",
      "step:    95780, time: 0.722, loss: 0.9909, l1: 0.1829, vgg: 0.4608, mask: 0.3472\n",
      "step:    95800, time: 0.773, loss: 1.1309, l1: 0.2419, vgg: 0.5022, mask: 0.3867\n",
      "step:    95820, time: 0.763, loss: 1.0651, l1: 0.2104, vgg: 0.4729, mask: 0.3817\n",
      "step:    95840, time: 0.771, loss: 1.2168, l1: 0.2868, vgg: 0.5322, mask: 0.3978\n",
      "step:    95860, time: 0.754, loss: 1.0476, l1: 0.2398, vgg: 0.4244, mask: 0.3834\n",
      "step:    95880, time: 0.770, loss: 1.0869, l1: 0.2041, vgg: 0.4879, mask: 0.3949\n",
      "step:    95900, time: 0.727, loss: 1.0237, l1: 0.2334, vgg: 0.4124, mask: 0.3779\n",
      "step:    95920, time: 0.788, loss: 1.1545, l1: 0.2431, vgg: 0.5029, mask: 0.4086\n",
      "step:    95940, time: 0.765, loss: 1.1627, l1: 0.2724, vgg: 0.4788, mask: 0.4116\n",
      "step:    95960, time: 0.747, loss: 1.0986, l1: 0.2178, vgg: 0.5035, mask: 0.3773\n",
      "step:    95980, time: 0.767, loss: 1.1945, l1: 0.2342, vgg: 0.5676, mask: 0.3927\n",
      "step:    96000, time: 0.739, loss: 1.0218, l1: 0.1797, vgg: 0.4903, mask: 0.3517\n",
      "step:    96020, time: 0.735, loss: 1.1316, l1: 0.2228, vgg: 0.5417, mask: 0.3670\n",
      "step:    96040, time: 0.734, loss: 0.9648, l1: 0.2026, vgg: 0.3928, mask: 0.3695\n",
      "step:    96060, time: 0.774, loss: 1.1730, l1: 0.2554, vgg: 0.4970, mask: 0.4206\n",
      "step:    96080, time: 0.740, loss: 1.0436, l1: 0.2076, vgg: 0.4465, mask: 0.3895\n",
      "step:    96100, time: 0.753, loss: 0.9384, l1: 0.1672, vgg: 0.4319, mask: 0.3392\n",
      "step:    96120, time: 0.725, loss: 0.9227, l1: 0.1618, vgg: 0.4046, mask: 0.3563\n",
      "step:    96140, time: 0.741, loss: 1.0542, l1: 0.2636, vgg: 0.4061, mask: 0.3845\n",
      "step:    96160, time: 0.743, loss: 1.0408, l1: 0.2229, vgg: 0.4332, mask: 0.3847\n",
      "step:    96180, time: 0.738, loss: 0.9890, l1: 0.2161, vgg: 0.4190, mask: 0.3540\n",
      "step:    96200, time: 0.768, loss: 0.9832, l1: 0.1557, vgg: 0.4684, mask: 0.3591\n",
      "step:    96220, time: 0.756, loss: 0.9159, l1: 0.1774, vgg: 0.4095, mask: 0.3290\n",
      "step:    96240, time: 0.712, loss: 1.0557, l1: 0.2358, vgg: 0.3891, mask: 0.4307\n",
      "step:    96260, time: 0.731, loss: 1.0017, l1: 0.1981, vgg: 0.4321, mask: 0.3715\n",
      "step:    96280, time: 0.749, loss: 1.0179, l1: 0.1988, vgg: 0.4179, mask: 0.4012\n",
      "step:    96300, time: 0.717, loss: 1.0109, l1: 0.1851, vgg: 0.4655, mask: 0.3603\n",
      "step:    96320, time: 0.760, loss: 1.1787, l1: 0.2625, vgg: 0.4970, mask: 0.4192\n",
      "step:    96340, time: 0.698, loss: 0.8851, l1: 0.1536, vgg: 0.3994, mask: 0.3321\n",
      "step:    96360, time: 0.783, loss: 1.0236, l1: 0.2066, vgg: 0.4329, mask: 0.3841\n",
      "step:    96380, time: 0.764, loss: 1.0051, l1: 0.1885, vgg: 0.4432, mask: 0.3734\n",
      "step:    96400, time: 0.736, loss: 1.1093, l1: 0.2243, vgg: 0.5000, mask: 0.3850\n",
      "step:    96420, time: 0.755, loss: 1.0047, l1: 0.1813, vgg: 0.4248, mask: 0.3986\n",
      "step:    96440, time: 0.751, loss: 1.0172, l1: 0.1840, vgg: 0.4277, mask: 0.4055\n",
      "step:    96460, time: 0.733, loss: 1.0702, l1: 0.2140, vgg: 0.4831, mask: 0.3731\n",
      "step:    96480, time: 0.757, loss: 1.0450, l1: 0.1885, vgg: 0.4522, mask: 0.4043\n",
      "step:    96500, time: 0.745, loss: 1.0305, l1: 0.2360, vgg: 0.4279, mask: 0.3666\n",
      "step:    96520, time: 0.735, loss: 1.0719, l1: 0.1834, vgg: 0.5026, mask: 0.3859\n",
      "step:    96540, time: 0.791, loss: 1.0180, l1: 0.1944, vgg: 0.4151, mask: 0.4084\n",
      "step:    96560, time: 0.732, loss: 0.9825, l1: 0.1933, vgg: 0.3812, mask: 0.4080\n",
      "step:    96580, time: 0.750, loss: 1.0257, l1: 0.2080, vgg: 0.4480, mask: 0.3697\n",
      "step:    96600, time: 0.772, loss: 1.1230, l1: 0.2631, vgg: 0.4677, mask: 0.3922\n",
      "step:    96620, time: 0.787, loss: 1.1331, l1: 0.2498, vgg: 0.5106, mask: 0.3727\n",
      "step:    96640, time: 0.757, loss: 1.0274, l1: 0.2226, vgg: 0.4352, mask: 0.3695\n",
      "step:    96660, time: 0.730, loss: 1.1163, l1: 0.2452, vgg: 0.4904, mask: 0.3807\n",
      "step:    96680, time: 0.746, loss: 1.2432, l1: 0.2547, vgg: 0.5565, mask: 0.4320\n",
      "step:    96700, time: 0.753, loss: 1.0842, l1: 0.2235, vgg: 0.4933, mask: 0.3674\n",
      "step:    96720, time: 0.771, loss: 1.0966, l1: 0.2597, vgg: 0.4244, mask: 0.4125\n",
      "step:    96740, time: 0.726, loss: 0.9604, l1: 0.1904, vgg: 0.4081, mask: 0.3619\n",
      "step:    96760, time: 0.749, loss: 1.0370, l1: 0.2124, vgg: 0.4570, mask: 0.3676\n",
      "step:    96780, time: 0.755, loss: 1.0918, l1: 0.2582, vgg: 0.4435, mask: 0.3901\n",
      "step:    96800, time: 0.762, loss: 1.0912, l1: 0.2675, vgg: 0.4364, mask: 0.3873\n",
      "step:    96820, time: 0.766, loss: 1.0142, l1: 0.1962, vgg: 0.4371, mask: 0.3808\n",
      "step:    96840, time: 0.744, loss: 1.0540, l1: 0.2366, vgg: 0.4368, mask: 0.3806\n",
      "step:    96860, time: 0.754, loss: 1.0626, l1: 0.2085, vgg: 0.4471, mask: 0.4070\n",
      "step:    96880, time: 0.760, loss: 1.0219, l1: 0.1731, vgg: 0.4985, mask: 0.3502\n",
      "step:    96900, time: 0.781, loss: 1.0637, l1: 0.2288, vgg: 0.4632, mask: 0.3717\n",
      "step:    96920, time: 0.755, loss: 1.0633, l1: 0.2400, vgg: 0.4358, mask: 0.3876\n",
      "step:    96940, time: 0.742, loss: 1.0155, l1: 0.2198, vgg: 0.4447, mask: 0.3509\n",
      "step:    96960, time: 0.769, loss: 1.1754, l1: 0.2794, vgg: 0.4614, mask: 0.4346\n",
      "step:    96980, time: 0.768, loss: 1.0308, l1: 0.1919, vgg: 0.4661, mask: 0.3727\n",
      "step:    97000, time: 0.729, loss: 0.9995, l1: 0.2246, vgg: 0.3933, mask: 0.3816\n",
      "step:    97020, time: 0.760, loss: 1.1071, l1: 0.2530, vgg: 0.4726, mask: 0.3815\n",
      "step:    97040, time: 0.744, loss: 1.1360, l1: 0.2651, vgg: 0.4454, mask: 0.4255\n",
      "step:    97060, time: 0.747, loss: 1.0280, l1: 0.2516, vgg: 0.4072, mask: 0.3692\n",
      "step:    97080, time: 0.752, loss: 1.1120, l1: 0.1833, vgg: 0.5346, mask: 0.3941\n",
      "step:    97100, time: 0.729, loss: 1.1651, l1: 0.2787, vgg: 0.5116, mask: 0.3748\n",
      "step:    97120, time: 0.764, loss: 1.1640, l1: 0.2886, vgg: 0.4955, mask: 0.3799\n",
      "step:    97140, time: 0.770, loss: 1.0909, l1: 0.2371, vgg: 0.4480, mask: 0.4058\n",
      "step:    97160, time: 0.728, loss: 1.0231, l1: 0.1761, vgg: 0.4374, mask: 0.4096\n",
      "step:    97180, time: 0.783, loss: 1.1946, l1: 0.2652, vgg: 0.5302, mask: 0.3992\n",
      "step:    97200, time: 0.745, loss: 1.1772, l1: 0.1992, vgg: 0.5787, mask: 0.3993\n",
      "step:    97220, time: 0.752, loss: 1.1936, l1: 0.2972, vgg: 0.4490, mask: 0.4474\n",
      "step:    97240, time: 0.749, loss: 1.0416, l1: 0.1869, vgg: 0.4381, mask: 0.4167\n",
      "step:    97260, time: 0.764, loss: 0.9520, l1: 0.1761, vgg: 0.4272, mask: 0.3487\n",
      "step:    97280, time: 0.710, loss: 0.9360, l1: 0.1976, vgg: 0.3921, mask: 0.3463\n",
      "step:    97300, time: 0.737, loss: 1.0262, l1: 0.2227, vgg: 0.4484, mask: 0.3551\n",
      "step:    97320, time: 0.769, loss: 1.2221, l1: 0.2643, vgg: 0.5570, mask: 0.4008\n",
      "step:    97340, time: 0.770, loss: 1.1054, l1: 0.2057, vgg: 0.4806, mask: 0.4191\n",
      "step:    97360, time: 0.773, loss: 0.9944, l1: 0.1682, vgg: 0.4645, mask: 0.3617\n",
      "step:    97380, time: 0.717, loss: 1.0454, l1: 0.2042, vgg: 0.4504, mask: 0.3907\n",
      "step:    97400, time: 0.764, loss: 1.0700, l1: 0.2458, vgg: 0.4396, mask: 0.3845\n",
      "step:    97420, time: 0.785, loss: 1.2423, l1: 0.3183, vgg: 0.5192, mask: 0.4048\n",
      "step:    97440, time: 0.753, loss: 1.0406, l1: 0.1956, vgg: 0.4538, mask: 0.3912\n",
      "step:    97460, time: 0.755, loss: 1.1231, l1: 0.2930, vgg: 0.4481, mask: 0.3820\n",
      "step:    97480, time: 0.744, loss: 1.0969, l1: 0.2712, vgg: 0.4405, mask: 0.3852\n",
      "step:    97500, time: 0.737, loss: 1.0246, l1: 0.1816, vgg: 0.4695, mask: 0.3735\n",
      "step:    97520, time: 0.739, loss: 0.9802, l1: 0.1566, vgg: 0.4520, mask: 0.3716\n",
      "step:    97540, time: 0.797, loss: 1.0731, l1: 0.2228, vgg: 0.4442, mask: 0.4060\n",
      "step:    97560, time: 0.743, loss: 1.1466, l1: 0.2645, vgg: 0.4725, mask: 0.4096\n",
      "step:    97580, time: 0.754, loss: 1.1051, l1: 0.1974, vgg: 0.5574, mask: 0.3503\n",
      "step:    97600, time: 0.746, loss: 1.2240, l1: 0.2513, vgg: 0.5628, mask: 0.4100\n",
      "step:    97620, time: 0.788, loss: 1.0113, l1: 0.2095, vgg: 0.3981, mask: 0.4037\n",
      "step:    97640, time: 0.737, loss: 1.0802, l1: 0.2173, vgg: 0.4893, mask: 0.3736\n",
      "step:    97660, time: 0.731, loss: 0.9719, l1: 0.1929, vgg: 0.4185, mask: 0.3605\n",
      "step:    97680, time: 0.768, loss: 1.0615, l1: 0.2121, vgg: 0.5023, mask: 0.3471\n",
      "step:    97700, time: 0.733, loss: 1.1447, l1: 0.2938, vgg: 0.4487, mask: 0.4022\n",
      "step:    97720, time: 0.764, loss: 1.1269, l1: 0.2950, vgg: 0.4305, mask: 0.4014\n",
      "step:    97740, time: 0.763, loss: 1.0409, l1: 0.1980, vgg: 0.4816, mask: 0.3613\n",
      "step:    97760, time: 0.727, loss: 1.1470, l1: 0.2490, vgg: 0.5179, mask: 0.3801\n",
      "step:    97780, time: 0.737, loss: 1.0195, l1: 0.1751, vgg: 0.4923, mask: 0.3520\n",
      "step:    97800, time: 0.796, loss: 1.0665, l1: 0.1951, vgg: 0.4928, mask: 0.3786\n",
      "step:    97820, time: 0.755, loss: 1.1778, l1: 0.2567, vgg: 0.5316, mask: 0.3895\n",
      "step:    97840, time: 0.771, loss: 1.1922, l1: 0.2396, vgg: 0.5608, mask: 0.3918\n",
      "step:    97860, time: 0.758, loss: 1.0379, l1: 0.2193, vgg: 0.4527, mask: 0.3659\n",
      "step:    97880, time: 0.768, loss: 1.1246, l1: 0.3054, vgg: 0.3922, mask: 0.4270\n",
      "step:    97900, time: 0.749, loss: 1.0396, l1: 0.2115, vgg: 0.4513, mask: 0.3768\n",
      "step:    97920, time: 0.792, loss: 1.1039, l1: 0.2322, vgg: 0.4963, mask: 0.3754\n",
      "step:    97940, time: 0.780, loss: 1.0470, l1: 0.1630, vgg: 0.4937, mask: 0.3903\n",
      "step:    97960, time: 0.771, loss: 1.1445, l1: 0.2618, vgg: 0.4984, mask: 0.3843\n",
      "step:    97980, time: 0.725, loss: 1.0822, l1: 0.2097, vgg: 0.4863, mask: 0.3863\n",
      "step:    98000, time: 0.742, loss: 1.0976, l1: 0.2166, vgg: 0.5032, mask: 0.3778\n",
      "step:    98020, time: 0.758, loss: 1.1036, l1: 0.2460, vgg: 0.4686, mask: 0.3889\n",
      "step:    98040, time: 0.748, loss: 0.9929, l1: 0.1861, vgg: 0.4062, mask: 0.4006\n",
      "step:    98060, time: 0.729, loss: 1.1048, l1: 0.1942, vgg: 0.5244, mask: 0.3861\n",
      "step:    98080, time: 0.779, loss: 1.1736, l1: 0.2764, vgg: 0.4964, mask: 0.4008\n",
      "step:    98100, time: 0.747, loss: 1.0680, l1: 0.2404, vgg: 0.4429, mask: 0.3847\n",
      "step:    98120, time: 0.783, loss: 1.0788, l1: 0.2270, vgg: 0.4693, mask: 0.3825\n",
      "step:    98140, time: 0.736, loss: 0.9980, l1: 0.1837, vgg: 0.4401, mask: 0.3742\n",
      "step:    98160, time: 0.748, loss: 1.1228, l1: 0.2630, vgg: 0.4499, mask: 0.4098\n",
      "step:    98180, time: 0.763, loss: 1.0037, l1: 0.2163, vgg: 0.4017, mask: 0.3857\n",
      "step:    98200, time: 0.762, loss: 1.0959, l1: 0.2278, vgg: 0.4919, mask: 0.3762\n",
      "step:    98220, time: 0.728, loss: 1.1656, l1: 0.2820, vgg: 0.4518, mask: 0.4318\n",
      "step:    98240, time: 0.745, loss: 1.1012, l1: 0.2406, vgg: 0.4644, mask: 0.3962\n",
      "step:    98260, time: 0.767, loss: 1.0666, l1: 0.2172, vgg: 0.4964, mask: 0.3530\n",
      "step:    98280, time: 0.756, loss: 1.1968, l1: 0.2515, vgg: 0.5596, mask: 0.3857\n",
      "step:    98300, time: 0.744, loss: 1.1012, l1: 0.2335, vgg: 0.5016, mask: 0.3661\n",
      "step:    98320, time: 0.741, loss: 1.0238, l1: 0.1588, vgg: 0.4755, mask: 0.3895\n",
      "step:    98340, time: 0.752, loss: 1.0946, l1: 0.2115, vgg: 0.5101, mask: 0.3730\n",
      "step:    98360, time: 0.717, loss: 1.0729, l1: 0.2599, vgg: 0.4481, mask: 0.3648\n",
      "step:    98380, time: 0.746, loss: 1.1005, l1: 0.2227, vgg: 0.4920, mask: 0.3857\n",
      "step:    98400, time: 0.720, loss: 0.9788, l1: 0.1816, vgg: 0.4090, mask: 0.3882\n",
      "step:    98420, time: 0.750, loss: 1.0485, l1: 0.2024, vgg: 0.4351, mask: 0.4110\n",
      "step:    98440, time: 0.723, loss: 1.0966, l1: 0.2336, vgg: 0.4902, mask: 0.3728\n",
      "step:    98460, time: 0.772, loss: 1.0857, l1: 0.1870, vgg: 0.5072, mask: 0.3915\n",
      "step:    98480, time: 0.727, loss: 1.1613, l1: 0.2732, vgg: 0.4785, mask: 0.4097\n",
      "step:    98500, time: 0.761, loss: 1.0788, l1: 0.2128, vgg: 0.4628, mask: 0.4032\n",
      "step:    98520, time: 0.784, loss: 1.0480, l1: 0.2200, vgg: 0.4444, mask: 0.3836\n",
      "step:    98540, time: 0.766, loss: 1.0629, l1: 0.2078, vgg: 0.4808, mask: 0.3744\n",
      "step:    98560, time: 0.730, loss: 1.0270, l1: 0.1977, vgg: 0.4035, mask: 0.4258\n",
      "step:    98580, time: 0.755, loss: 1.1364, l1: 0.2524, vgg: 0.4718, mask: 0.4122\n",
      "step:    98600, time: 0.752, loss: 1.0946, l1: 0.2665, vgg: 0.4003, mask: 0.4278\n",
      "step:    98620, time: 0.740, loss: 0.9429, l1: 0.1643, vgg: 0.4398, mask: 0.3389\n",
      "step:    98640, time: 0.736, loss: 0.9444, l1: 0.1998, vgg: 0.3982, mask: 0.3464\n",
      "step:    98660, time: 0.796, loss: 1.2542, l1: 0.2361, vgg: 0.5905, mask: 0.4276\n",
      "step:    98680, time: 0.743, loss: 1.0429, l1: 0.2048, vgg: 0.4648, mask: 0.3732\n",
      "step:    98700, time: 0.739, loss: 1.0489, l1: 0.2058, vgg: 0.4594, mask: 0.3836\n",
      "step:    98720, time: 0.802, loss: 1.0736, l1: 0.2308, vgg: 0.4685, mask: 0.3743\n",
      "step:    98740, time: 0.763, loss: 1.0392, l1: 0.1966, vgg: 0.4646, mask: 0.3780\n",
      "step:    98760, time: 0.727, loss: 1.0783, l1: 0.2126, vgg: 0.4937, mask: 0.3720\n",
      "step:    98780, time: 0.795, loss: 1.2119, l1: 0.2881, vgg: 0.5240, mask: 0.3999\n",
      "step:    98800, time: 0.737, loss: 1.1447, l1: 0.2444, vgg: 0.5005, mask: 0.3998\n",
      "step:    98820, time: 0.737, loss: 1.0184, l1: 0.1975, vgg: 0.4510, mask: 0.3699\n",
      "step:    98840, time: 0.736, loss: 1.0512, l1: 0.2572, vgg: 0.4032, mask: 0.3907\n",
      "step:    98860, time: 0.751, loss: 1.0198, l1: 0.2253, vgg: 0.4210, mask: 0.3735\n",
      "step:    98880, time: 0.755, loss: 1.1346, l1: 0.2967, vgg: 0.3994, mask: 0.4385\n",
      "step:    98900, time: 0.761, loss: 0.9352, l1: 0.1889, vgg: 0.3931, mask: 0.3532\n",
      "step:    98920, time: 0.738, loss: 1.0543, l1: 0.2095, vgg: 0.4307, mask: 0.4141\n",
      "step:    98940, time: 0.733, loss: 1.0661, l1: 0.2202, vgg: 0.4160, mask: 0.4299\n",
      "step:    98960, time: 0.726, loss: 1.0658, l1: 0.2509, vgg: 0.3949, mask: 0.4201\n",
      "step:    98980, time: 0.758, loss: 0.9924, l1: 0.2045, vgg: 0.4335, mask: 0.3544\n",
      "step:    99000, time: 0.808, loss: 1.0433, l1: 0.2231, vgg: 0.4361, mask: 0.3841\n",
      "step:    99020, time: 0.739, loss: 1.0120, l1: 0.1488, vgg: 0.5107, mask: 0.3525\n",
      "step:    99040, time: 0.765, loss: 1.1500, l1: 0.2260, vgg: 0.5404, mask: 0.3837\n",
      "step:    99060, time: 0.725, loss: 1.0151, l1: 0.1829, vgg: 0.4736, mask: 0.3586\n",
      "step:    99080, time: 0.821, loss: 1.0529, l1: 0.1913, vgg: 0.4945, mask: 0.3671\n",
      "step:    99100, time: 0.779, loss: 1.1228, l1: 0.2328, vgg: 0.5274, mask: 0.3625\n",
      "step:    99120, time: 0.778, loss: 0.9575, l1: 0.1811, vgg: 0.4298, mask: 0.3466\n",
      "step:    99140, time: 0.757, loss: 1.0130, l1: 0.2025, vgg: 0.4583, mask: 0.3523\n",
      "step:    99160, time: 0.703, loss: 1.0287, l1: 0.2220, vgg: 0.4228, mask: 0.3839\n",
      "step:    99180, time: 0.744, loss: 1.0939, l1: 0.2422, vgg: 0.4454, mask: 0.4063\n",
      "step:    99200, time: 0.753, loss: 1.0075, l1: 0.2045, vgg: 0.4487, mask: 0.3542\n",
      "step:    99220, time: 0.759, loss: 1.0339, l1: 0.2064, vgg: 0.4412, mask: 0.3864\n",
      "step:    99240, time: 0.778, loss: 1.0706, l1: 0.2080, vgg: 0.4668, mask: 0.3958\n",
      "step:    99260, time: 0.759, loss: 1.0268, l1: 0.2460, vgg: 0.4068, mask: 0.3740\n",
      "step:    99280, time: 0.771, loss: 1.1629, l1: 0.2438, vgg: 0.5205, mask: 0.3986\n",
      "step:    99300, time: 0.743, loss: 1.0172, l1: 0.2114, vgg: 0.4628, mask: 0.3430\n",
      "step:    99320, time: 0.757, loss: 1.1078, l1: 0.2619, vgg: 0.4724, mask: 0.3735\n",
      "step:    99340, time: 0.754, loss: 0.9705, l1: 0.1696, vgg: 0.4563, mask: 0.3446\n",
      "step:    99360, time: 0.740, loss: 1.0239, l1: 0.1812, vgg: 0.4664, mask: 0.3763\n",
      "step:    99380, time: 0.751, loss: 0.9957, l1: 0.1915, vgg: 0.4366, mask: 0.3675\n",
      "step:    99400, time: 0.733, loss: 0.8784, l1: 0.1609, vgg: 0.3727, mask: 0.3448\n",
      "step:    99420, time: 0.741, loss: 1.1654, l1: 0.2744, vgg: 0.4830, mask: 0.4081\n",
      "step:    99440, time: 0.748, loss: 0.9633, l1: 0.2122, vgg: 0.3981, mask: 0.3530\n",
      "step:    99460, time: 0.768, loss: 1.2220, l1: 0.3011, vgg: 0.4697, mask: 0.4512\n",
      "step:    99480, time: 0.770, loss: 0.8976, l1: 0.1432, vgg: 0.4191, mask: 0.3354\n",
      "step:    99500, time: 0.735, loss: 1.0738, l1: 0.2466, vgg: 0.4164, mask: 0.4108\n",
      "step:    99520, time: 0.744, loss: 1.0015, l1: 0.1884, vgg: 0.4497, mask: 0.3635\n",
      "step:    99540, time: 0.747, loss: 1.0835, l1: 0.2276, vgg: 0.4855, mask: 0.3704\n",
      "step:    99560, time: 0.766, loss: 1.1718, l1: 0.2729, vgg: 0.5003, mask: 0.3986\n",
      "step:    99580, time: 0.704, loss: 1.0724, l1: 0.2057, vgg: 0.4596, mask: 0.4071\n",
      "step:    99600, time: 0.734, loss: 0.9480, l1: 0.1622, vgg: 0.4096, mask: 0.3761\n",
      "step:    99620, time: 0.738, loss: 0.9534, l1: 0.2052, vgg: 0.3975, mask: 0.3507\n",
      "step:    99640, time: 0.749, loss: 1.0937, l1: 0.2524, vgg: 0.4662, mask: 0.3751\n",
      "step:    99660, time: 0.743, loss: 1.1338, l1: 0.2826, vgg: 0.4783, mask: 0.3730\n",
      "step:    99680, time: 0.775, loss: 1.1618, l1: 0.2214, vgg: 0.5680, mask: 0.3723\n",
      "step:    99700, time: 0.729, loss: 1.0215, l1: 0.2020, vgg: 0.4350, mask: 0.3844\n",
      "step:    99720, time: 0.770, loss: 1.0056, l1: 0.2051, vgg: 0.4297, mask: 0.3708\n",
      "step:    99740, time: 0.758, loss: 1.0830, l1: 0.2491, vgg: 0.4252, mask: 0.4087\n",
      "step:    99760, time: 0.764, loss: 1.1163, l1: 0.2198, vgg: 0.4959, mask: 0.4006\n",
      "step:    99780, time: 0.736, loss: 0.9730, l1: 0.1900, vgg: 0.4265, mask: 0.3565\n",
      "step:    99800, time: 0.727, loss: 0.9368, l1: 0.1876, vgg: 0.3713, mask: 0.3779\n",
      "step:    99820, time: 0.720, loss: 0.9186, l1: 0.1631, vgg: 0.4098, mask: 0.3457\n",
      "step:    99840, time: 0.752, loss: 1.1357, l1: 0.2613, vgg: 0.4841, mask: 0.3902\n",
      "step:    99860, time: 0.767, loss: 0.8953, l1: 0.1357, vgg: 0.4281, mask: 0.3315\n",
      "step:    99880, time: 0.736, loss: 1.0783, l1: 0.2102, vgg: 0.4599, mask: 0.4082\n",
      "step:    99900, time: 0.733, loss: 1.0631, l1: 0.2632, vgg: 0.4139, mask: 0.3861\n",
      "step:    99920, time: 0.772, loss: 1.0791, l1: 0.2215, vgg: 0.4738, mask: 0.3838\n",
      "step:    99940, time: 0.749, loss: 1.0971, l1: 0.2121, vgg: 0.4663, mask: 0.4187\n",
      "step:    99960, time: 0.754, loss: 0.9183, l1: 0.1736, vgg: 0.3935, mask: 0.3512\n",
      "step:    99980, time: 0.755, loss: 1.0863, l1: 0.2107, vgg: 0.5027, mask: 0.3729\n",
      "step:   100000, time: 0.735, loss: 1.0867, l1: 0.2111, vgg: 0.4589, mask: 0.4167\n",
      "step:   100020, time: 0.725, loss: 1.0604, l1: 0.2490, vgg: 0.3879, mask: 0.4235\n",
      "step:   100040, time: 0.779, loss: 1.2056, l1: 0.3063, vgg: 0.4860, mask: 0.4133\n",
      "step:   100060, time: 0.730, loss: 1.0771, l1: 0.2123, vgg: 0.4756, mask: 0.3892\n",
      "step:   100080, time: 0.741, loss: 1.1105, l1: 0.2558, vgg: 0.4641, mask: 0.3906\n",
      "step:   100100, time: 0.732, loss: 0.9442, l1: 0.1549, vgg: 0.4096, mask: 0.3796\n",
      "step:   100120, time: 0.751, loss: 0.9554, l1: 0.1907, vgg: 0.3781, mask: 0.3865\n",
      "step:   100140, time: 0.738, loss: 0.9628, l1: 0.1883, vgg: 0.4280, mask: 0.3465\n",
      "step:   100160, time: 0.774, loss: 1.1589, l1: 0.2429, vgg: 0.5385, mask: 0.3775\n",
      "step:   100180, time: 0.746, loss: 0.9493, l1: 0.1678, vgg: 0.4164, mask: 0.3651\n",
      "step:   100200, time: 0.735, loss: 1.0268, l1: 0.1977, vgg: 0.4968, mask: 0.3323\n",
      "step:   100220, time: 0.775, loss: 0.9817, l1: 0.1676, vgg: 0.4606, mask: 0.3536\n",
      "step:   100240, time: 0.760, loss: 1.0823, l1: 0.2370, vgg: 0.4804, mask: 0.3649\n",
      "step:   100260, time: 0.745, loss: 1.1276, l1: 0.2025, vgg: 0.4843, mask: 0.4408\n",
      "step:   100280, time: 0.746, loss: 1.0952, l1: 0.2223, vgg: 0.4874, mask: 0.3856\n",
      "step:   100300, time: 0.762, loss: 1.1630, l1: 0.2659, vgg: 0.5216, mask: 0.3756\n",
      "step:   100320, time: 0.772, loss: 1.1523, l1: 0.2723, vgg: 0.4650, mask: 0.4150\n",
      "step:   100340, time: 0.765, loss: 1.0825, l1: 0.2149, vgg: 0.4618, mask: 0.4058\n",
      "step:   100360, time: 0.749, loss: 1.0069, l1: 0.1746, vgg: 0.4877, mask: 0.3445\n",
      "step:   100380, time: 0.742, loss: 1.0291, l1: 0.2100, vgg: 0.4572, mask: 0.3619\n",
      "step:   100400, time: 0.732, loss: 0.9772, l1: 0.2070, vgg: 0.4129, mask: 0.3573\n",
      "step:   100420, time: 0.730, loss: 0.9690, l1: 0.1945, vgg: 0.4172, mask: 0.3574\n",
      "step:   100440, time: 0.733, loss: 1.1229, l1: 0.2435, vgg: 0.5070, mask: 0.3724\n",
      "step:   100460, time: 0.736, loss: 0.9371, l1: 0.1480, vgg: 0.3759, mask: 0.4133\n",
      "step:   100480, time: 0.781, loss: 1.1558, l1: 0.2462, vgg: 0.5167, mask: 0.3929\n",
      "step:   100500, time: 0.764, loss: 1.0406, l1: 0.2238, vgg: 0.4593, mask: 0.3574\n",
      "step:   100520, time: 0.796, loss: 1.0035, l1: 0.2033, vgg: 0.4303, mask: 0.3700\n",
      "step:   100540, time: 0.767, loss: 1.1678, l1: 0.2476, vgg: 0.5131, mask: 0.4071\n",
      "step:   100560, time: 0.760, loss: 1.1815, l1: 0.2634, vgg: 0.5273, mask: 0.3908\n",
      "step:   100580, time: 0.731, loss: 1.0026, l1: 0.2060, vgg: 0.4551, mask: 0.3415\n",
      "step:   100600, time: 0.765, loss: 1.1464, l1: 0.2396, vgg: 0.4869, mask: 0.4199\n",
      "step:   100620, time: 0.728, loss: 1.0781, l1: 0.2235, vgg: 0.4592, mask: 0.3953\n",
      "step:   100640, time: 0.772, loss: 1.0113, l1: 0.2089, vgg: 0.4270, mask: 0.3754\n",
      "step:   100660, time: 0.736, loss: 0.9552, l1: 0.2023, vgg: 0.3996, mask: 0.3532\n",
      "step:   100680, time: 0.739, loss: 1.0880, l1: 0.2072, vgg: 0.4614, mask: 0.4194\n",
      "step:   100700, time: 0.753, loss: 1.0745, l1: 0.2321, vgg: 0.4701, mask: 0.3724\n",
      "step:   100720, time: 0.758, loss: 1.1376, l1: 0.2661, vgg: 0.4663, mask: 0.4052\n",
      "step:   100740, time: 0.750, loss: 1.0689, l1: 0.2261, vgg: 0.4536, mask: 0.3891\n",
      "step:   100760, time: 0.726, loss: 1.0138, l1: 0.2186, vgg: 0.4183, mask: 0.3769\n",
      "step:   100780, time: 0.726, loss: 0.9554, l1: 0.1915, vgg: 0.4139, mask: 0.3500\n",
      "step:   100800, time: 0.752, loss: 0.9653, l1: 0.1878, vgg: 0.4285, mask: 0.3491\n",
      "step:   100820, time: 0.742, loss: 1.1226, l1: 0.2349, vgg: 0.5352, mask: 0.3525\n",
      "step:   100840, time: 0.774, loss: 1.1054, l1: 0.3146, vgg: 0.3889, mask: 0.4019\n",
      "step:   100860, time: 0.773, loss: 0.9835, l1: 0.1987, vgg: 0.4266, mask: 0.3582\n",
      "step:   100880, time: 0.734, loss: 0.9472, l1: 0.1644, vgg: 0.4097, mask: 0.3732\n",
      "step:   100900, time: 0.738, loss: 1.1307, l1: 0.2450, vgg: 0.4553, mask: 0.4305\n",
      "step:   100920, time: 0.747, loss: 1.0355, l1: 0.1854, vgg: 0.4887, mask: 0.3614\n",
      "step:   100940, time: 0.736, loss: 1.1585, l1: 0.3081, vgg: 0.4421, mask: 0.4083\n",
      "step:   100960, time: 0.796, loss: 1.2135, l1: 0.2710, vgg: 0.5205, mask: 0.4221\n",
      "step:   100980, time: 0.757, loss: 1.0323, l1: 0.2120, vgg: 0.4825, mask: 0.3378\n",
      "step:   101000, time: 0.752, loss: 1.0543, l1: 0.2024, vgg: 0.4684, mask: 0.3834\n",
      "step:   101020, time: 0.765, loss: 1.0561, l1: 0.2014, vgg: 0.4802, mask: 0.3744\n",
      "step:   101040, time: 0.748, loss: 1.0109, l1: 0.1761, vgg: 0.4511, mask: 0.3838\n",
      "step:   101060, time: 0.771, loss: 1.1963, l1: 0.2441, vgg: 0.5465, mask: 0.4058\n",
      "step:   101080, time: 0.703, loss: 0.9607, l1: 0.1845, vgg: 0.4210, mask: 0.3552\n",
      "step:   101100, time: 0.754, loss: 1.1203, l1: 0.2705, vgg: 0.4656, mask: 0.3843\n",
      "step:   101120, time: 0.745, loss: 1.0121, l1: 0.2143, vgg: 0.4310, mask: 0.3668\n",
      "step:   101140, time: 0.727, loss: 1.0218, l1: 0.1825, vgg: 0.4528, mask: 0.3865\n",
      "step:   101160, time: 0.756, loss: 1.0653, l1: 0.2464, vgg: 0.4436, mask: 0.3753\n",
      "step:   101180, time: 0.742, loss: 1.0568, l1: 0.2514, vgg: 0.4057, mask: 0.3997\n",
      "step:   101200, time: 0.726, loss: 0.8778, l1: 0.1414, vgg: 0.4006, mask: 0.3359\n",
      "step:   101220, time: 0.757, loss: 0.9987, l1: 0.1931, vgg: 0.4634, mask: 0.3422\n",
      "step:   101240, time: 0.749, loss: 1.1164, l1: 0.2377, vgg: 0.4964, mask: 0.3823\n",
      "step:   101260, time: 0.795, loss: 1.0954, l1: 0.2265, vgg: 0.4711, mask: 0.3979\n",
      "step:   101280, time: 0.772, loss: 1.0753, l1: 0.2033, vgg: 0.5142, mask: 0.3578\n",
      "step:   101300, time: 0.732, loss: 0.9980, l1: 0.1867, vgg: 0.4524, mask: 0.3588\n",
      "step:   101320, time: 0.762, loss: 1.0855, l1: 0.2435, vgg: 0.4506, mask: 0.3915\n",
      "step:   101340, time: 0.740, loss: 0.9611, l1: 0.1957, vgg: 0.4171, mask: 0.3483\n",
      "step:   101360, time: 0.737, loss: 1.0524, l1: 0.2226, vgg: 0.4405, mask: 0.3893\n",
      "step:   101380, time: 0.759, loss: 1.1015, l1: 0.2010, vgg: 0.5239, mask: 0.3766\n",
      "step:   101400, time: 0.750, loss: 1.0055, l1: 0.1998, vgg: 0.4335, mask: 0.3722\n",
      "step:   101420, time: 0.772, loss: 1.0469, l1: 0.1850, vgg: 0.4896, mask: 0.3724\n",
      "step:   101440, time: 0.766, loss: 0.9780, l1: 0.1652, vgg: 0.4556, mask: 0.3572\n",
      "step:   101460, time: 0.793, loss: 1.0697, l1: 0.1850, vgg: 0.5332, mask: 0.3516\n",
      "step:   101480, time: 0.722, loss: 0.9675, l1: 0.1952, vgg: 0.3982, mask: 0.3741\n",
      "step:   101500, time: 0.770, loss: 1.0924, l1: 0.2600, vgg: 0.4447, mask: 0.3877\n",
      "step:   101520, time: 0.803, loss: 1.0297, l1: 0.2206, vgg: 0.4420, mask: 0.3671\n",
      "step:   101540, time: 0.766, loss: 1.0863, l1: 0.2608, vgg: 0.4250, mask: 0.4006\n",
      "step:   101560, time: 0.760, loss: 1.1017, l1: 0.2533, vgg: 0.4404, mask: 0.4081\n",
      "step:   101580, time: 0.732, loss: 1.0303, l1: 0.2248, vgg: 0.4204, mask: 0.3851\n",
      "step:   101600, time: 0.754, loss: 1.0214, l1: 0.1949, vgg: 0.4545, mask: 0.3720\n",
      "step:   101620, time: 0.723, loss: 0.9493, l1: 0.1749, vgg: 0.4322, mask: 0.3422\n",
      "step:   101640, time: 0.764, loss: 1.1785, l1: 0.2734, vgg: 0.4930, mask: 0.4122\n",
      "step:   101660, time: 0.758, loss: 1.0632, l1: 0.2314, vgg: 0.4497, mask: 0.3821\n",
      "step:   101680, time: 0.744, loss: 0.9890, l1: 0.2117, vgg: 0.4170, mask: 0.3603\n",
      "step:   101700, time: 0.769, loss: 1.0013, l1: 0.1910, vgg: 0.4741, mask: 0.3362\n",
      "step:   101720, time: 0.756, loss: 1.0534, l1: 0.2002, vgg: 0.4552, mask: 0.3979\n",
      "step:   101740, time: 0.747, loss: 0.9310, l1: 0.1767, vgg: 0.3930, mask: 0.3613\n",
      "step:   101760, time: 0.751, loss: 1.1368, l1: 0.2388, vgg: 0.4854, mask: 0.4125\n",
      "step:   101780, time: 0.751, loss: 1.1483, l1: 0.2689, vgg: 0.4894, mask: 0.3900\n",
      "step:   101800, time: 0.760, loss: 1.0286, l1: 0.1476, vgg: 0.5193, mask: 0.3617\n",
      "step:   101820, time: 0.749, loss: 1.0440, l1: 0.1969, vgg: 0.4775, mask: 0.3696\n",
      "step:   101840, time: 0.753, loss: 0.9735, l1: 0.2096, vgg: 0.3947, mask: 0.3692\n",
      "step:   101860, time: 0.744, loss: 1.1013, l1: 0.2186, vgg: 0.4738, mask: 0.4090\n",
      "step:   101880, time: 0.746, loss: 1.1430, l1: 0.2914, vgg: 0.4263, mask: 0.4253\n",
      "step:   101900, time: 0.758, loss: 1.0560, l1: 0.1983, vgg: 0.4630, mask: 0.3947\n",
      "step:   101920, time: 0.704, loss: 0.9991, l1: 0.1736, vgg: 0.4451, mask: 0.3804\n",
      "step:   101940, time: 0.755, loss: 0.9244, l1: 0.1891, vgg: 0.3761, mask: 0.3593\n",
      "step:   101960, time: 0.740, loss: 1.1307, l1: 0.2595, vgg: 0.4732, mask: 0.3980\n",
      "step:   101980, time: 0.755, loss: 1.2067, l1: 0.2761, vgg: 0.5058, mask: 0.4249\n",
      "step:   102000, time: 0.729, loss: 1.1105, l1: 0.2583, vgg: 0.4637, mask: 0.3886\n",
      "step:   102020, time: 0.753, loss: 0.9473, l1: 0.1892, vgg: 0.4090, mask: 0.3491\n",
      "step:   102040, time: 0.769, loss: 1.1143, l1: 0.2262, vgg: 0.4975, mask: 0.3907\n",
      "step:   102060, time: 0.755, loss: 1.1210, l1: 0.2804, vgg: 0.4550, mask: 0.3855\n",
      "step:   102080, time: 0.734, loss: 1.0500, l1: 0.1641, vgg: 0.5210, mask: 0.3649\n",
      "step:   102100, time: 0.758, loss: 1.1862, l1: 0.3077, vgg: 0.4759, mask: 0.4027\n",
      "step:   102120, time: 0.735, loss: 1.0615, l1: 0.2154, vgg: 0.4545, mask: 0.3916\n",
      "step:   102140, time: 0.773, loss: 1.1329, l1: 0.2427, vgg: 0.4864, mask: 0.4038\n",
      "step:   102160, time: 0.758, loss: 1.1696, l1: 0.2314, vgg: 0.5042, mask: 0.4340\n",
      "step:   102180, time: 0.724, loss: 1.0952, l1: 0.2439, vgg: 0.4491, mask: 0.4022\n",
      "step:   102200, time: 0.767, loss: 1.0516, l1: 0.1768, vgg: 0.4600, mask: 0.4148\n",
      "step:   102220, time: 0.767, loss: 1.0999, l1: 0.2311, vgg: 0.4888, mask: 0.3800\n",
      "step:   102240, time: 0.754, loss: 1.1032, l1: 0.2255, vgg: 0.4966, mask: 0.3811\n",
      "step:   102260, time: 0.721, loss: 1.0359, l1: 0.1959, vgg: 0.4510, mask: 0.3890\n",
      "step:   102280, time: 0.746, loss: 1.0248, l1: 0.2029, vgg: 0.4195, mask: 0.4024\n",
      "step:   102300, time: 0.737, loss: 1.0670, l1: 0.2276, vgg: 0.4471, mask: 0.3923\n",
      "step:   102320, time: 0.759, loss: 1.0891, l1: 0.2256, vgg: 0.4457, mask: 0.4178\n",
      "step:   102340, time: 0.737, loss: 1.1054, l1: 0.2874, vgg: 0.4302, mask: 0.3878\n",
      "step:   102360, time: 0.760, loss: 0.9951, l1: 0.2031, vgg: 0.4371, mask: 0.3549\n",
      "step:   102380, time: 0.817, loss: 1.1100, l1: 0.2374, vgg: 0.4849, mask: 0.3877\n",
      "step:   102400, time: 0.783, loss: 1.1565, l1: 0.2551, vgg: 0.5076, mask: 0.3939\n",
      "step:   102420, time: 0.772, loss: 1.1071, l1: 0.1889, vgg: 0.5435, mask: 0.3747\n",
      "step:   102440, time: 0.786, loss: 1.1154, l1: 0.2419, vgg: 0.4689, mask: 0.4046\n",
      "step:   102460, time: 0.738, loss: 0.9907, l1: 0.1560, vgg: 0.4707, mask: 0.3640\n",
      "step:   102480, time: 0.751, loss: 1.0528, l1: 0.2232, vgg: 0.4380, mask: 0.3915\n",
      "step:   102500, time: 0.743, loss: 0.9276, l1: 0.1608, vgg: 0.4368, mask: 0.3300\n",
      "step:   102520, time: 0.740, loss: 1.1319, l1: 0.2519, vgg: 0.4702, mask: 0.4098\n",
      "step:   102540, time: 0.765, loss: 1.1406, l1: 0.2358, vgg: 0.4945, mask: 0.4103\n",
      "step:   102560, time: 0.765, loss: 1.1053, l1: 0.2719, vgg: 0.4248, mask: 0.4085\n",
      "step:   102580, time: 0.756, loss: 0.9646, l1: 0.1713, vgg: 0.4429, mask: 0.3504\n",
      "step:   102600, time: 0.756, loss: 1.0533, l1: 0.2190, vgg: 0.4679, mask: 0.3664\n",
      "step:   102620, time: 0.769, loss: 1.0091, l1: 0.1927, vgg: 0.4225, mask: 0.3940\n",
      "step:   102640, time: 0.757, loss: 1.0735, l1: 0.2541, vgg: 0.4372, mask: 0.3823\n",
      "step:   102660, time: 0.765, loss: 1.1179, l1: 0.2543, vgg: 0.4496, mask: 0.4139\n",
      "step:   102680, time: 0.760, loss: 0.9733, l1: 0.1682, vgg: 0.4624, mask: 0.3427\n",
      "step:   102700, time: 0.773, loss: 1.1558, l1: 0.2725, vgg: 0.5096, mask: 0.3737\n",
      "step:   102720, time: 0.797, loss: 1.1364, l1: 0.2284, vgg: 0.5018, mask: 0.4062\n",
      "step:   102740, time: 0.729, loss: 1.0606, l1: 0.2483, vgg: 0.4161, mask: 0.3962\n",
      "step:   102760, time: 0.759, loss: 1.0425, l1: 0.1984, vgg: 0.4435, mask: 0.4005\n",
      "step:   102780, time: 0.743, loss: 0.9578, l1: 0.1688, vgg: 0.4318, mask: 0.3571\n",
      "step:   102800, time: 0.760, loss: 1.0929, l1: 0.2405, vgg: 0.4682, mask: 0.3841\n",
      "step:   102820, time: 0.759, loss: 1.0937, l1: 0.2534, vgg: 0.4679, mask: 0.3725\n",
      "step:   102840, time: 0.768, loss: 1.0739, l1: 0.2289, vgg: 0.4514, mask: 0.3936\n",
      "step:   102860, time: 0.740, loss: 0.9585, l1: 0.2316, vgg: 0.3700, mask: 0.3570\n",
      "step:   102880, time: 0.796, loss: 1.0679, l1: 0.1986, vgg: 0.4684, mask: 0.4010\n",
      "step:   102900, time: 0.746, loss: 1.2527, l1: 0.2556, vgg: 0.5943, mask: 0.4028\n",
      "step:   102920, time: 0.725, loss: 1.0140, l1: 0.2160, vgg: 0.4128, mask: 0.3853\n",
      "step:   102940, time: 0.746, loss: 0.9884, l1: 0.1652, vgg: 0.4657, mask: 0.3574\n",
      "step:   102960, time: 0.736, loss: 0.9006, l1: 0.1610, vgg: 0.3859, mask: 0.3538\n",
      "step:   102980, time: 0.735, loss: 1.1883, l1: 0.2336, vgg: 0.5827, mask: 0.3720\n",
      "step:   103000, time: 0.767, loss: 1.0884, l1: 0.2139, vgg: 0.4948, mask: 0.3797\n",
      "step:   103020, time: 0.751, loss: 0.9925, l1: 0.2055, vgg: 0.4081, mask: 0.3789\n",
      "step:   103040, time: 0.762, loss: 1.0509, l1: 0.2489, vgg: 0.4072, mask: 0.3949\n",
      "step:   103060, time: 0.778, loss: 1.0740, l1: 0.2155, vgg: 0.4694, mask: 0.3891\n",
      "step:   103080, time: 0.754, loss: 0.9624, l1: 0.1823, vgg: 0.4389, mask: 0.3413\n",
      "step:   103100, time: 0.759, loss: 1.0678, l1: 0.2126, vgg: 0.4521, mask: 0.4031\n",
      "step:   103120, time: 0.739, loss: 1.0312, l1: 0.2035, vgg: 0.4720, mask: 0.3556\n",
      "step:   103140, time: 0.736, loss: 0.9453, l1: 0.2061, vgg: 0.3891, mask: 0.3502\n",
      "step:   103160, time: 0.743, loss: 1.0589, l1: 0.2161, vgg: 0.4435, mask: 0.3992\n",
      "step:   103180, time: 0.728, loss: 1.0000, l1: 0.1910, vgg: 0.4458, mask: 0.3631\n",
      "step:   103200, time: 0.784, loss: 1.1567, l1: 0.2351, vgg: 0.5385, mask: 0.3832\n",
      "step:   103220, time: 0.759, loss: 1.1843, l1: 0.2359, vgg: 0.5800, mask: 0.3685\n",
      "step:   103240, time: 0.718, loss: 0.9772, l1: 0.1678, vgg: 0.4649, mask: 0.3445\n",
      "step:   103260, time: 0.734, loss: 0.9374, l1: 0.1963, vgg: 0.3788, mask: 0.3622\n",
      "step:   103280, time: 0.778, loss: 1.0549, l1: 0.2241, vgg: 0.4746, mask: 0.3562\n",
      "step:   103300, time: 0.747, loss: 1.0335, l1: 0.1862, vgg: 0.4260, mask: 0.4213\n",
      "step:   103320, time: 0.726, loss: 0.9725, l1: 0.1518, vgg: 0.4569, mask: 0.3638\n",
      "step:   103340, time: 0.776, loss: 1.1376, l1: 0.2623, vgg: 0.4778, mask: 0.3974\n",
      "step:   103360, time: 0.748, loss: 0.9508, l1: 0.1886, vgg: 0.4136, mask: 0.3486\n",
      "step:   103380, time: 0.791, loss: 1.1150, l1: 0.2362, vgg: 0.5002, mask: 0.3786\n",
      "step:   103400, time: 0.768, loss: 1.0654, l1: 0.2027, vgg: 0.4876, mask: 0.3752\n",
      "step:   103420, time: 0.738, loss: 1.0859, l1: 0.2192, vgg: 0.4746, mask: 0.3921\n",
      "step:   103440, time: 0.750, loss: 1.0190, l1: 0.2081, vgg: 0.4443, mask: 0.3665\n",
      "step:   103460, time: 0.764, loss: 0.9998, l1: 0.1958, vgg: 0.4106, mask: 0.3934\n",
      "step:   103480, time: 0.740, loss: 0.9502, l1: 0.1603, vgg: 0.4299, mask: 0.3600\n",
      "step:   103500, time: 0.763, loss: 1.0847, l1: 0.2327, vgg: 0.4648, mask: 0.3872\n",
      "step:   103520, time: 0.762, loss: 1.2001, l1: 0.2612, vgg: 0.5261, mask: 0.4127\n",
      "step:   103540, time: 0.791, loss: 1.1124, l1: 0.2306, vgg: 0.4871, mask: 0.3947\n",
      "step:   103560, time: 0.758, loss: 1.0501, l1: 0.2158, vgg: 0.4819, mask: 0.3524\n",
      "step:   103580, time: 0.750, loss: 1.0800, l1: 0.2647, vgg: 0.3995, mask: 0.4157\n",
      "step:   103600, time: 0.746, loss: 1.0324, l1: 0.2097, vgg: 0.4556, mask: 0.3671\n",
      "step:   103620, time: 0.762, loss: 0.9826, l1: 0.1802, vgg: 0.4542, mask: 0.3481\n",
      "step:   103640, time: 0.746, loss: 1.1002, l1: 0.2020, vgg: 0.4904, mask: 0.4078\n",
      "step:   103660, time: 0.759, loss: 1.0460, l1: 0.2515, vgg: 0.4085, mask: 0.3860\n",
      "step:   103680, time: 0.745, loss: 1.0116, l1: 0.1701, vgg: 0.4565, mask: 0.3850\n",
      "step:   103700, time: 0.744, loss: 1.0295, l1: 0.2017, vgg: 0.4640, mask: 0.3639\n",
      "step:   103720, time: 0.757, loss: 1.0023, l1: 0.2243, vgg: 0.4206, mask: 0.3574\n",
      "step:   103740, time: 0.764, loss: 0.9934, l1: 0.1881, vgg: 0.4546, mask: 0.3507\n",
      "step:   103760, time: 0.754, loss: 1.0881, l1: 0.2453, vgg: 0.4094, mask: 0.4335\n",
      "step:   103780, time: 0.746, loss: 1.0200, l1: 0.1889, vgg: 0.4705, mask: 0.3605\n",
      "step:   103800, time: 0.751, loss: 1.0654, l1: 0.2412, vgg: 0.4300, mask: 0.3942\n",
      "step:   103820, time: 0.753, loss: 1.0830, l1: 0.2742, vgg: 0.3875, mask: 0.4212\n",
      "step:   103840, time: 0.715, loss: 0.9486, l1: 0.2002, vgg: 0.3770, mask: 0.3715\n",
      "step:   103860, time: 0.784, loss: 1.0987, l1: 0.2454, vgg: 0.4737, mask: 0.3796\n",
      "step:   103880, time: 0.759, loss: 1.1053, l1: 0.2430, vgg: 0.4962, mask: 0.3661\n",
      "step:   103900, time: 0.777, loss: 1.2546, l1: 0.2958, vgg: 0.5810, mask: 0.3778\n",
      "step:   103920, time: 0.770, loss: 1.1566, l1: 0.2270, vgg: 0.5399, mask: 0.3896\n",
      "step:   103940, time: 0.774, loss: 1.0722, l1: 0.2275, vgg: 0.4618, mask: 0.3829\n",
      "step:   103960, time: 0.770, loss: 0.9419, l1: 0.1737, vgg: 0.4248, mask: 0.3434\n",
      "step:   103980, time: 0.762, loss: 1.1396, l1: 0.2233, vgg: 0.5256, mask: 0.3907\n",
      "step:   104000, time: 0.748, loss: 1.1072, l1: 0.2597, vgg: 0.4393, mask: 0.4082\n",
      "step:   104020, time: 0.800, loss: 1.0977, l1: 0.2302, vgg: 0.4823, mask: 0.3851\n",
      "step:   104040, time: 0.754, loss: 0.9906, l1: 0.2153, vgg: 0.3780, mask: 0.3974\n",
      "step:   104060, time: 0.800, loss: 1.0750, l1: 0.2356, vgg: 0.4663, mask: 0.3731\n",
      "step:   104080, time: 0.758, loss: 1.0593, l1: 0.1936, vgg: 0.4800, mask: 0.3858\n",
      "step:   104100, time: 0.697, loss: 1.0328, l1: 0.2379, vgg: 0.4200, mask: 0.3748\n",
      "step:   104120, time: 0.771, loss: 1.1640, l1: 0.2563, vgg: 0.5205, mask: 0.3872\n",
      "step:   104140, time: 0.707, loss: 0.9493, l1: 0.1888, vgg: 0.4249, mask: 0.3356\n",
      "step:   104160, time: 0.752, loss: 0.9958, l1: 0.1908, vgg: 0.4459, mask: 0.3591\n",
      "step:   104180, time: 0.765, loss: 1.0845, l1: 0.2188, vgg: 0.4869, mask: 0.3788\n",
      "step:   104200, time: 0.763, loss: 0.8984, l1: 0.1738, vgg: 0.3876, mask: 0.3370\n",
      "step:   104220, time: 0.764, loss: 1.1578, l1: 0.2434, vgg: 0.5011, mask: 0.4133\n",
      "step:   104240, time: 0.751, loss: 1.0508, l1: 0.2368, vgg: 0.4191, mask: 0.3949\n",
      "step:   104260, time: 0.749, loss: 1.0636, l1: 0.1813, vgg: 0.4974, mask: 0.3849\n",
      "step:   104280, time: 0.777, loss: 1.0718, l1: 0.2331, vgg: 0.4371, mask: 0.4016\n",
      "step:   104300, time: 0.766, loss: 1.2869, l1: 0.2833, vgg: 0.5521, mask: 0.4515\n",
      "step:   104320, time: 0.739, loss: 1.1013, l1: 0.2219, vgg: 0.4944, mask: 0.3849\n",
      "step:   104340, time: 0.783, loss: 1.0624, l1: 0.1900, vgg: 0.4832, mask: 0.3892\n",
      "step:   104360, time: 0.776, loss: 1.1843, l1: 0.2606, vgg: 0.5129, mask: 0.4107\n",
      "step:   104380, time: 0.785, loss: 1.0988, l1: 0.2018, vgg: 0.5245, mask: 0.3725\n",
      "step:   104400, time: 0.770, loss: 1.1389, l1: 0.2156, vgg: 0.5174, mask: 0.4060\n",
      "step:   104420, time: 0.761, loss: 1.1597, l1: 0.2925, vgg: 0.4732, mask: 0.3940\n",
      "step:   104440, time: 0.780, loss: 1.0537, l1: 0.2132, vgg: 0.4665, mask: 0.3740\n",
      "step:   104460, time: 0.739, loss: 0.9772, l1: 0.1978, vgg: 0.3957, mask: 0.3838\n",
      "step:   104480, time: 0.753, loss: 1.0362, l1: 0.2353, vgg: 0.4252, mask: 0.3758\n",
      "step:   104500, time: 0.736, loss: 1.0478, l1: 0.1993, vgg: 0.4662, mask: 0.3823\n",
      "step:   104520, time: 0.756, loss: 0.9660, l1: 0.2061, vgg: 0.3880, mask: 0.3720\n",
      "step:   104540, time: 0.739, loss: 0.9066, l1: 0.1680, vgg: 0.3899, mask: 0.3487\n",
      "step:   104560, time: 0.747, loss: 0.9258, l1: 0.1780, vgg: 0.4029, mask: 0.3449\n",
      "step:   104580, time: 0.753, loss: 0.9825, l1: 0.2223, vgg: 0.4007, mask: 0.3596\n",
      "step:   104600, time: 0.763, loss: 1.2192, l1: 0.2360, vgg: 0.5774, mask: 0.4058\n",
      "step:   104620, time: 0.734, loss: 1.0528, l1: 0.2340, vgg: 0.4235, mask: 0.3952\n",
      "step:   104640, time: 0.733, loss: 1.0627, l1: 0.2160, vgg: 0.4326, mask: 0.4141\n",
      "step:   104660, time: 0.780, loss: 0.9926, l1: 0.2120, vgg: 0.4398, mask: 0.3408\n",
      "step:   104680, time: 0.728, loss: 0.9401, l1: 0.1613, vgg: 0.4263, mask: 0.3524\n",
      "step:   104700, time: 0.765, loss: 1.0130, l1: 0.2157, vgg: 0.4330, mask: 0.3643\n",
      "step:   104720, time: 0.739, loss: 0.8983, l1: 0.1525, vgg: 0.3919, mask: 0.3539\n",
      "step:   104740, time: 0.748, loss: 1.0403, l1: 0.1813, vgg: 0.4890, mask: 0.3700\n",
      "step:   104760, time: 0.738, loss: 1.0013, l1: 0.2028, vgg: 0.4001, mask: 0.3984\n",
      "step:   104780, time: 0.755, loss: 1.0798, l1: 0.2265, vgg: 0.4385, mask: 0.4148\n",
      "step:   104800, time: 0.740, loss: 0.9470, l1: 0.1719, vgg: 0.4123, mask: 0.3628\n",
      "step:   104820, time: 0.732, loss: 1.1060, l1: 0.2570, vgg: 0.4620, mask: 0.3870\n",
      "step:   104840, time: 0.763, loss: 1.0732, l1: 0.2522, vgg: 0.4333, mask: 0.3877\n",
      "step:   104860, time: 0.741, loss: 1.0281, l1: 0.1916, vgg: 0.4786, mask: 0.3579\n",
      "step:   104880, time: 0.768, loss: 1.2086, l1: 0.2017, vgg: 0.6327, mask: 0.3741\n",
      "step:   104900, time: 0.776, loss: 1.2705, l1: 0.3206, vgg: 0.5411, mask: 0.4087\n",
      "step:   104920, time: 0.766, loss: 1.0957, l1: 0.1886, vgg: 0.5154, mask: 0.3917\n",
      "step:   104940, time: 0.747, loss: 1.0853, l1: 0.2284, vgg: 0.4447, mask: 0.4123\n",
      "step:   104960, time: 0.758, loss: 1.0775, l1: 0.2278, vgg: 0.4624, mask: 0.3874\n",
      "step:   104980, time: 0.802, loss: 1.0149, l1: 0.2038, vgg: 0.4626, mask: 0.3485\n",
      "step:   105000, time: 0.754, loss: 1.0801, l1: 0.2328, vgg: 0.4574, mask: 0.3898\n",
      "step:   105020, time: 0.757, loss: 1.1060, l1: 0.1942, vgg: 0.5380, mask: 0.3738\n",
      "step:   105040, time: 0.786, loss: 1.1418, l1: 0.2707, vgg: 0.4684, mask: 0.4027\n",
      "step:   105060, time: 0.739, loss: 1.1045, l1: 0.2448, vgg: 0.4939, mask: 0.3658\n",
      "step:   105080, time: 0.846, loss: 0.9681, l1: 0.1877, vgg: 0.4030, mask: 0.3773\n",
      "step:   105100, time: 0.741, loss: 0.9940, l1: 0.1908, vgg: 0.4390, mask: 0.3642\n",
      "step:   105120, time: 0.741, loss: 0.9974, l1: 0.2026, vgg: 0.4053, mask: 0.3895\n",
      "step:   105140, time: 0.747, loss: 1.0132, l1: 0.2321, vgg: 0.4095, mask: 0.3716\n",
      "step:   105160, time: 0.735, loss: 0.9074, l1: 0.1522, vgg: 0.4103, mask: 0.3449\n",
      "step:   105180, time: 0.760, loss: 1.0835, l1: 0.2415, vgg: 0.4433, mask: 0.3988\n",
      "step:   105200, time: 0.793, loss: 1.2732, l1: 0.2611, vgg: 0.5925, mask: 0.4197\n",
      "step:   105220, time: 0.770, loss: 0.9829, l1: 0.1926, vgg: 0.3978, mask: 0.3925\n",
      "step:   105240, time: 0.723, loss: 1.0333, l1: 0.2053, vgg: 0.4526, mask: 0.3754\n",
      "step:   105260, time: 0.752, loss: 0.9880, l1: 0.2012, vgg: 0.4016, mask: 0.3851\n",
      "step:   105280, time: 0.761, loss: 1.1764, l1: 0.2823, vgg: 0.5019, mask: 0.3921\n",
      "step:   105300, time: 0.738, loss: 0.9652, l1: 0.1684, vgg: 0.4395, mask: 0.3573\n",
      "step:   105320, time: 0.721, loss: 0.9798, l1: 0.1807, vgg: 0.4186, mask: 0.3805\n",
      "step:   105340, time: 0.741, loss: 0.9973, l1: 0.1948, vgg: 0.4606, mask: 0.3419\n",
      "step:   105360, time: 0.754, loss: 1.0458, l1: 0.2110, vgg: 0.4463, mask: 0.3886\n",
      "step:   105380, time: 0.721, loss: 0.9932, l1: 0.1783, vgg: 0.4505, mask: 0.3644\n",
      "step:   105400, time: 0.761, loss: 1.0390, l1: 0.1957, vgg: 0.4613, mask: 0.3820\n",
      "step:   105420, time: 0.719, loss: 0.9473, l1: 0.1902, vgg: 0.4123, mask: 0.3447\n",
      "step:   105440, time: 0.758, loss: 1.0335, l1: 0.2309, vgg: 0.4178, mask: 0.3847\n",
      "step:   105460, time: 0.784, loss: 1.1719, l1: 0.2632, vgg: 0.4899, mask: 0.4188\n",
      "step:   105480, time: 0.771, loss: 1.2036, l1: 0.2691, vgg: 0.4954, mask: 0.4391\n",
      "step:   105500, time: 0.804, loss: 1.1657, l1: 0.2375, vgg: 0.5358, mask: 0.3924\n",
      "step:   105520, time: 0.740, loss: 1.0893, l1: 0.2856, vgg: 0.4104, mask: 0.3933\n",
      "step:   105540, time: 0.735, loss: 1.1150, l1: 0.2635, vgg: 0.4480, mask: 0.4034\n",
      "step:   105560, time: 0.734, loss: 1.0181, l1: 0.1981, vgg: 0.3959, mask: 0.4240\n",
      "step:   105580, time: 0.738, loss: 1.1486, l1: 0.2419, vgg: 0.5389, mask: 0.3679\n",
      "step:   105600, time: 0.765, loss: 1.0243, l1: 0.1926, vgg: 0.4452, mask: 0.3865\n",
      "step:   105620, time: 0.730, loss: 0.9947, l1: 0.1602, vgg: 0.4600, mask: 0.3745\n",
      "step:   105640, time: 0.746, loss: 1.0049, l1: 0.1716, vgg: 0.4098, mask: 0.4234\n",
      "step:   105660, time: 0.790, loss: 1.2525, l1: 0.3097, vgg: 0.5129, mask: 0.4299\n",
      "step:   105680, time: 0.745, loss: 1.0145, l1: 0.1921, vgg: 0.4590, mask: 0.3633\n",
      "step:   105700, time: 0.773, loss: 1.0512, l1: 0.2406, vgg: 0.4258, mask: 0.3848\n",
      "step:   105720, time: 0.758, loss: 0.9959, l1: 0.2337, vgg: 0.3953, mask: 0.3669\n",
      "step:   105740, time: 0.762, loss: 1.0743, l1: 0.2601, vgg: 0.4249, mask: 0.3894\n",
      "step:   105760, time: 0.838, loss: 1.1095, l1: 0.2142, vgg: 0.5031, mask: 0.3921\n",
      "step:   105780, time: 0.744, loss: 1.1667, l1: 0.3136, vgg: 0.4404, mask: 0.4127\n",
      "step:   105800, time: 0.744, loss: 1.1022, l1: 0.2370, vgg: 0.4891, mask: 0.3762\n",
      "step:   105820, time: 0.765, loss: 0.9520, l1: 0.1728, vgg: 0.4140, mask: 0.3651\n",
      "step:   105840, time: 0.772, loss: 1.1324, l1: 0.2647, vgg: 0.4621, mask: 0.4057\n",
      "step:   105860, time: 0.758, loss: 0.9630, l1: 0.1728, vgg: 0.4386, mask: 0.3516\n",
      "step:   105880, time: 0.751, loss: 1.1361, l1: 0.2632, vgg: 0.4892, mask: 0.3837\n",
      "step:   105900, time: 0.770, loss: 0.9914, l1: 0.1386, vgg: 0.4653, mask: 0.3876\n",
      "step:   105920, time: 0.718, loss: 1.0288, l1: 0.2566, vgg: 0.3991, mask: 0.3732\n",
      "step:   105940, time: 0.780, loss: 1.0205, l1: 0.2019, vgg: 0.4308, mask: 0.3878\n",
      "step:   105960, time: 0.765, loss: 0.8823, l1: 0.1597, vgg: 0.3838, mask: 0.3389\n",
      "step:   105980, time: 0.726, loss: 1.0578, l1: 0.2047, vgg: 0.4843, mask: 0.3688\n",
      "step:   106000, time: 0.734, loss: 0.9243, l1: 0.1883, vgg: 0.3776, mask: 0.3583\n",
      "step:   106020, time: 0.759, loss: 0.9914, l1: 0.1895, vgg: 0.4266, mask: 0.3753\n",
      "step:   106040, time: 0.797, loss: 1.0667, l1: 0.2170, vgg: 0.4572, mask: 0.3925\n",
      "step:   106060, time: 0.766, loss: 1.0665, l1: 0.2394, vgg: 0.4311, mask: 0.3960\n",
      "step:   106080, time: 0.717, loss: 0.8994, l1: 0.1826, vgg: 0.3789, mask: 0.3380\n",
      "step:   106100, time: 0.758, loss: 1.0328, l1: 0.2118, vgg: 0.4474, mask: 0.3736\n",
      "step:   106120, time: 0.756, loss: 1.0544, l1: 0.2250, vgg: 0.4026, mask: 0.4268\n",
      "step:   106140, time: 0.734, loss: 1.0830, l1: 0.2116, vgg: 0.5136, mask: 0.3577\n",
      "step:   106160, time: 0.766, loss: 1.0974, l1: 0.1997, vgg: 0.5150, mask: 0.3828\n",
      "step:   106180, time: 0.753, loss: 1.1280, l1: 0.2516, vgg: 0.4606, mask: 0.4158\n",
      "step:   106200, time: 0.743, loss: 1.0784, l1: 0.2161, vgg: 0.4792, mask: 0.3832\n",
      "step:   106220, time: 0.756, loss: 1.1289, l1: 0.2641, vgg: 0.4485, mask: 0.4163\n",
      "step:   106240, time: 0.754, loss: 0.9937, l1: 0.1849, vgg: 0.4184, mask: 0.3904\n",
      "step:   106260, time: 0.766, loss: 0.9956, l1: 0.1768, vgg: 0.4444, mask: 0.3744\n",
      "step:   106280, time: 0.752, loss: 1.0297, l1: 0.2530, vgg: 0.3633, mask: 0.4134\n",
      "step:   106300, time: 0.765, loss: 0.9581, l1: 0.1440, vgg: 0.4616, mask: 0.3525\n",
      "step:   106320, time: 0.735, loss: 1.0649, l1: 0.2181, vgg: 0.4727, mask: 0.3741\n",
      "step:   106340, time: 0.752, loss: 1.0350, l1: 0.2003, vgg: 0.4518, mask: 0.3828\n",
      "step:   106360, time: 0.745, loss: 1.1181, l1: 0.2551, vgg: 0.4323, mask: 0.4306\n",
      "step:   106380, time: 0.737, loss: 0.9083, l1: 0.1614, vgg: 0.4086, mask: 0.3383\n",
      "step:   106400, time: 0.744, loss: 1.0518, l1: 0.2301, vgg: 0.4449, mask: 0.3768\n",
      "step:   106420, time: 0.753, loss: 1.0715, l1: 0.2248, vgg: 0.4759, mask: 0.3708\n",
      "step:   106440, time: 0.777, loss: 1.0096, l1: 0.2142, vgg: 0.4153, mask: 0.3801\n",
      "step:   106460, time: 0.756, loss: 1.0641, l1: 0.2196, vgg: 0.4514, mask: 0.3931\n",
      "step:   106480, time: 0.764, loss: 1.1758, l1: 0.2743, vgg: 0.4958, mask: 0.4056\n",
      "step:   106500, time: 0.726, loss: 0.9913, l1: 0.1930, vgg: 0.4288, mask: 0.3695\n",
      "step:   106520, time: 0.786, loss: 0.9791, l1: 0.1873, vgg: 0.4075, mask: 0.3842\n",
      "step:   106540, time: 0.759, loss: 1.1940, l1: 0.2755, vgg: 0.4963, mask: 0.4222\n",
      "step:   106560, time: 0.733, loss: 1.0314, l1: 0.2542, vgg: 0.3900, mask: 0.3871\n",
      "step:   106580, time: 0.747, loss: 0.9863, l1: 0.1835, vgg: 0.4633, mask: 0.3394\n",
      "step:   106600, time: 0.776, loss: 1.0358, l1: 0.1876, vgg: 0.4584, mask: 0.3899\n",
      "step:   106620, time: 0.793, loss: 1.0328, l1: 0.1924, vgg: 0.4839, mask: 0.3565\n",
      "step:   106640, time: 0.785, loss: 1.0832, l1: 0.2074, vgg: 0.5013, mask: 0.3746\n",
      "step:   106660, time: 0.750, loss: 1.0357, l1: 0.2131, vgg: 0.4723, mask: 0.3503\n",
      "step:   106680, time: 0.299, loss: 1.0450, l1: 0.2469, vgg: 0.4229, mask: 0.3751\n",
      "step:   106700, time: 0.745, loss: 1.0552, l1: 0.2250, vgg: 0.4777, mask: 0.3524\n",
      "step:   106720, time: 0.760, loss: 0.9540, l1: 0.1645, vgg: 0.4353, mask: 0.3541\n",
      "step:   106740, time: 0.750, loss: 1.0741, l1: 0.1981, vgg: 0.4896, mask: 0.3864\n",
      "step:   106760, time: 0.739, loss: 1.0259, l1: 0.1836, vgg: 0.5115, mask: 0.3308\n",
      "step:   106780, time: 0.726, loss: 1.0910, l1: 0.2334, vgg: 0.4690, mask: 0.3886\n",
      "step:   106800, time: 0.734, loss: 1.0170, l1: 0.1689, vgg: 0.4530, mask: 0.3951\n",
      "step:   106820, time: 0.743, loss: 0.9324, l1: 0.1656, vgg: 0.4202, mask: 0.3466\n",
      "step:   106840, time: 0.762, loss: 1.0827, l1: 0.2222, vgg: 0.4866, mask: 0.3739\n",
      "step:   106860, time: 0.739, loss: 0.9667, l1: 0.2078, vgg: 0.3953, mask: 0.3635\n",
      "step:   106880, time: 0.737, loss: 1.1172, l1: 0.2816, vgg: 0.4063, mask: 0.4293\n",
      "step:   106900, time: 0.761, loss: 1.0934, l1: 0.2719, vgg: 0.4156, mask: 0.4059\n",
      "step:   106920, time: 0.768, loss: 1.1324, l1: 0.2378, vgg: 0.4892, mask: 0.4053\n",
      "step:   106940, time: 0.730, loss: 1.0711, l1: 0.2505, vgg: 0.4049, mask: 0.4157\n",
      "step:   106960, time: 0.773, loss: 1.0887, l1: 0.2582, vgg: 0.4610, mask: 0.3696\n",
      "step:   106980, time: 0.775, loss: 1.0960, l1: 0.2301, vgg: 0.4771, mask: 0.3888\n",
      "step:   107000, time: 0.733, loss: 0.9269, l1: 0.1652, vgg: 0.4100, mask: 0.3517\n",
      "step:   107020, time: 0.738, loss: 0.9631, l1: 0.1669, vgg: 0.4256, mask: 0.3706\n",
      "step:   107040, time: 0.792, loss: 1.1233, l1: 0.2265, vgg: 0.5207, mask: 0.3760\n",
      "step:   107060, time: 0.708, loss: 0.9124, l1: 0.1881, vgg: 0.3588, mask: 0.3656\n",
      "step:   107080, time: 0.766, loss: 1.0145, l1: 0.2071, vgg: 0.4405, mask: 0.3669\n",
      "step:   107100, time: 0.762, loss: 1.2389, l1: 0.2944, vgg: 0.5328, mask: 0.4116\n",
      "step:   107120, time: 0.793, loss: 1.0240, l1: 0.1873, vgg: 0.4771, mask: 0.3596\n",
      "step:   107140, time: 0.800, loss: 1.0604, l1: 0.1786, vgg: 0.5216, mask: 0.3601\n",
      "step:   107160, time: 0.729, loss: 1.0064, l1: 0.1702, vgg: 0.4724, mask: 0.3639\n",
      "step:   107180, time: 0.813, loss: 1.0368, l1: 0.2066, vgg: 0.4332, mask: 0.3970\n",
      "step:   107200, time: 0.742, loss: 0.9313, l1: 0.1701, vgg: 0.3962, mask: 0.3650\n",
      "step:   107220, time: 0.768, loss: 0.9914, l1: 0.1860, vgg: 0.4149, mask: 0.3904\n",
      "step:   107240, time: 0.759, loss: 1.0506, l1: 0.1948, vgg: 0.4518, mask: 0.4041\n",
      "step:   107260, time: 0.809, loss: 1.1725, l1: 0.2835, vgg: 0.4681, mask: 0.4209\n",
      "step:   107280, time: 0.806, loss: 1.1473, l1: 0.2284, vgg: 0.5356, mask: 0.3834\n",
      "step:   107300, time: 0.782, loss: 1.2159, l1: 0.2643, vgg: 0.5644, mask: 0.3872\n",
      "step:   107320, time: 0.734, loss: 0.8952, l1: 0.1673, vgg: 0.4171, mask: 0.3108\n",
      "step:   107340, time: 0.756, loss: 0.9981, l1: 0.1780, vgg: 0.4800, mask: 0.3402\n",
      "step:   107360, time: 0.763, loss: 0.9780, l1: 0.2099, vgg: 0.4037, mask: 0.3644\n",
      "step:   107380, time: 0.746, loss: 0.9802, l1: 0.1960, vgg: 0.4155, mask: 0.3688\n",
      "step:   107400, time: 0.765, loss: 1.0690, l1: 0.2153, vgg: 0.4764, mask: 0.3773\n",
      "step:   107420, time: 0.729, loss: 1.0870, l1: 0.2298, vgg: 0.5116, mask: 0.3456\n",
      "step:   107440, time: 0.730, loss: 1.0380, l1: 0.1885, vgg: 0.4817, mask: 0.3678\n",
      "step:   107460, time: 0.738, loss: 1.0568, l1: 0.2157, vgg: 0.4614, mask: 0.3798\n",
      "step:   107480, time: 0.798, loss: 1.0773, l1: 0.2193, vgg: 0.4699, mask: 0.3882\n",
      "step:   107500, time: 0.736, loss: 0.9401, l1: 0.1688, vgg: 0.3878, mask: 0.3834\n",
      "step:   107520, time: 0.774, loss: 1.1438, l1: 0.2130, vgg: 0.5527, mask: 0.3781\n",
      "step:   107540, time: 0.787, loss: 0.9425, l1: 0.1770, vgg: 0.3943, mask: 0.3712\n",
      "step:   107560, time: 0.771, loss: 1.1468, l1: 0.2415, vgg: 0.5266, mask: 0.3787\n",
      "step:   107580, time: 0.806, loss: 1.0501, l1: 0.2232, vgg: 0.4634, mask: 0.3635\n",
      "step:   107600, time: 0.823, loss: 1.0569, l1: 0.1801, vgg: 0.5243, mask: 0.3525\n",
      "step:   107620, time: 0.832, loss: 1.0561, l1: 0.2566, vgg: 0.3882, mask: 0.4113\n",
      "step:   107640, time: 0.769, loss: 0.9251, l1: 0.1530, vgg: 0.3910, mask: 0.3811\n",
      "step:   107660, time: 0.814, loss: 1.0902, l1: 0.2257, vgg: 0.4942, mask: 0.3702\n",
      "step:   107680, time: 0.832, loss: 1.2004, l1: 0.2824, vgg: 0.4994, mask: 0.4186\n",
      "step:   107700, time: 0.740, loss: 1.0411, l1: 0.2013, vgg: 0.4555, mask: 0.3844\n",
      "step:   107720, time: 0.784, loss: 1.0384, l1: 0.1739, vgg: 0.5082, mask: 0.3563\n",
      "step:   107740, time: 0.756, loss: 1.0102, l1: 0.2545, vgg: 0.3707, mask: 0.3849\n",
      "step:   107760, time: 0.747, loss: 0.9894, l1: 0.2440, vgg: 0.3555, mask: 0.3899\n",
      "step:   107780, time: 0.770, loss: 1.1184, l1: 0.2788, vgg: 0.4503, mask: 0.3893\n",
      "step:   107800, time: 0.834, loss: 1.0695, l1: 0.2217, vgg: 0.5002, mask: 0.3476\n",
      "step:   107820, time: 0.767, loss: 1.1130, l1: 0.2142, vgg: 0.5026, mask: 0.3962\n",
      "step:   107840, time: 0.750, loss: 1.0826, l1: 0.1891, vgg: 0.4866, mask: 0.4068\n",
      "step:   107860, time: 0.766, loss: 1.0885, l1: 0.2290, vgg: 0.4748, mask: 0.3847\n",
      "step:   107880, time: 0.745, loss: 1.0512, l1: 0.2527, vgg: 0.4247, mask: 0.3738\n",
      "step:   107900, time: 0.745, loss: 1.0488, l1: 0.1926, vgg: 0.4798, mask: 0.3764\n",
      "step:   107920, time: 0.760, loss: 1.0847, l1: 0.2293, vgg: 0.4485, mask: 0.4069\n",
      "step:   107940, time: 0.764, loss: 1.0769, l1: 0.2137, vgg: 0.4926, mask: 0.3705\n",
      "step:   107960, time: 0.759, loss: 1.0712, l1: 0.2491, vgg: 0.4404, mask: 0.3817\n",
      "step:   107980, time: 0.748, loss: 1.1213, l1: 0.2507, vgg: 0.5084, mask: 0.3621\n",
      "step:   108000, time: 0.746, loss: 1.0513, l1: 0.1827, vgg: 0.4872, mask: 0.3814\n",
      "step:   108020, time: 0.818, loss: 1.1415, l1: 0.1996, vgg: 0.5484, mask: 0.3936\n",
      "step:   108040, time: 0.766, loss: 1.0035, l1: 0.2179, vgg: 0.4160, mask: 0.3696\n",
      "step:   108060, time: 0.730, loss: 1.1360, l1: 0.2527, vgg: 0.4401, mask: 0.4432\n",
      "step:   108080, time: 0.765, loss: 1.1885, l1: 0.2011, vgg: 0.5816, mask: 0.4058\n",
      "step:   108100, time: 0.733, loss: 0.9957, l1: 0.1991, vgg: 0.4424, mask: 0.3542\n",
      "step:   108120, time: 0.742, loss: 1.0486, l1: 0.2083, vgg: 0.4485, mask: 0.3918\n",
      "step:   108140, time: 0.740, loss: 1.0611, l1: 0.2167, vgg: 0.4628, mask: 0.3817\n",
      "step:   108160, time: 0.767, loss: 0.9217, l1: 0.1664, vgg: 0.4112, mask: 0.3441\n",
      "step:   108180, time: 0.779, loss: 1.1017, l1: 0.2233, vgg: 0.5029, mask: 0.3755\n",
      "step:   108200, time: 0.744, loss: 1.0175, l1: 0.1827, vgg: 0.4578, mask: 0.3771\n",
      "step:   108220, time: 0.720, loss: 0.9169, l1: 0.1407, vgg: 0.4079, mask: 0.3683\n",
      "step:   108240, time: 0.762, loss: 1.2463, l1: 0.2562, vgg: 0.5701, mask: 0.4200\n",
      "step:   108260, time: 0.739, loss: 1.1242, l1: 0.2419, vgg: 0.4866, mask: 0.3957\n",
      "step:   108280, time: 0.746, loss: 1.0156, l1: 0.2074, vgg: 0.4524, mask: 0.3558\n",
      "step:   108300, time: 0.740, loss: 1.0873, l1: 0.2365, vgg: 0.4387, mask: 0.4120\n",
      "step:   108320, time: 0.793, loss: 1.0794, l1: 0.2029, vgg: 0.5096, mask: 0.3669\n",
      "step:   108340, time: 0.754, loss: 0.9567, l1: 0.2024, vgg: 0.3871, mask: 0.3672\n",
      "step:   108360, time: 0.748, loss: 1.0850, l1: 0.2389, vgg: 0.4554, mask: 0.3906\n",
      "step:   108380, time: 0.739, loss: 0.9924, l1: 0.1992, vgg: 0.4197, mask: 0.3736\n",
      "step:   108400, time: 0.765, loss: 1.0604, l1: 0.2366, vgg: 0.4383, mask: 0.3855\n",
      "step:   108420, time: 0.762, loss: 1.0405, l1: 0.2320, vgg: 0.4114, mask: 0.3970\n",
      "step:   108440, time: 0.772, loss: 1.1127, l1: 0.2109, vgg: 0.4776, mask: 0.4241\n",
      "step:   108460, time: 0.753, loss: 1.1324, l1: 0.2823, vgg: 0.4170, mask: 0.4331\n",
      "step:   108480, time: 0.764, loss: 1.0264, l1: 0.1720, vgg: 0.4801, mask: 0.3743\n",
      "step:   108500, time: 0.743, loss: 1.0700, l1: 0.1981, vgg: 0.4937, mask: 0.3783\n",
      "step:   108520, time: 0.784, loss: 0.9567, l1: 0.1925, vgg: 0.3969, mask: 0.3672\n",
      "step:   108540, time: 0.819, loss: 1.0611, l1: 0.2313, vgg: 0.4439, mask: 0.3860\n",
      "step:   108560, time: 0.767, loss: 0.9462, l1: 0.2034, vgg: 0.4161, mask: 0.3267\n",
      "step:   108580, time: 0.765, loss: 1.0679, l1: 0.1894, vgg: 0.4854, mask: 0.3931\n",
      "step:   108600, time: 0.777, loss: 1.1550, l1: 0.2313, vgg: 0.5530, mask: 0.3707\n",
      "step:   108620, time: 0.756, loss: 1.0041, l1: 0.2101, vgg: 0.4194, mask: 0.3746\n",
      "step:   108640, time: 0.817, loss: 1.1091, l1: 0.2551, vgg: 0.4629, mask: 0.3910\n",
      "step:   108660, time: 0.796, loss: 1.1911, l1: 0.2964, vgg: 0.4710, mask: 0.4237\n",
      "step:   108680, time: 0.782, loss: 0.9211, l1: 0.1713, vgg: 0.3948, mask: 0.3550\n",
      "step:   108700, time: 0.744, loss: 0.9067, l1: 0.1460, vgg: 0.4383, mask: 0.3225\n",
      "step:   108720, time: 0.761, loss: 1.1813, l1: 0.2481, vgg: 0.5130, mask: 0.4203\n",
      "step:   108740, time: 0.757, loss: 1.0459, l1: 0.2046, vgg: 0.4487, mask: 0.3926\n",
      "step:   108760, time: 0.745, loss: 0.9676, l1: 0.1674, vgg: 0.4350, mask: 0.3651\n",
      "step:   108780, time: 0.818, loss: 1.1139, l1: 0.2143, vgg: 0.5181, mask: 0.3816\n",
      "step:   108800, time: 0.859, loss: 1.0801, l1: 0.2406, vgg: 0.4579, mask: 0.3816\n",
      "step:   108820, time: 0.780, loss: 1.0594, l1: 0.1994, vgg: 0.4754, mask: 0.3845\n",
      "step:   108840, time: 0.782, loss: 1.1366, l1: 0.2652, vgg: 0.4524, mask: 0.4189\n",
      "step:   108860, time: 0.771, loss: 1.0985, l1: 0.2445, vgg: 0.4644, mask: 0.3896\n",
      "step:   108880, time: 0.743, loss: 1.0383, l1: 0.2531, vgg: 0.4077, mask: 0.3775\n",
      "step:   108900, time: 0.754, loss: 1.0643, l1: 0.2345, vgg: 0.4530, mask: 0.3768\n",
      "step:   108920, time: 0.768, loss: 1.0979, l1: 0.2585, vgg: 0.4214, mask: 0.4180\n",
      "step:   108940, time: 0.753, loss: 1.0061, l1: 0.1808, vgg: 0.4479, mask: 0.3774\n",
      "step:   108960, time: 0.799, loss: 0.9022, l1: 0.1366, vgg: 0.4243, mask: 0.3413\n",
      "step:   108980, time: 0.802, loss: 0.9931, l1: 0.1893, vgg: 0.4439, mask: 0.3598\n",
      "step:   109000, time: 0.789, loss: 1.0503, l1: 0.1828, vgg: 0.4811, mask: 0.3864\n",
      "step:   109020, time: 0.770, loss: 1.0890, l1: 0.2137, vgg: 0.4960, mask: 0.3794\n",
      "step:   109040, time: 0.755, loss: 0.9493, l1: 0.1776, vgg: 0.3973, mask: 0.3744\n",
      "step:   109060, time: 0.866, loss: 1.1625, l1: 0.2774, vgg: 0.4897, mask: 0.3954\n",
      "step:   109080, time: 0.765, loss: 1.0494, l1: 0.2302, vgg: 0.4617, mask: 0.3576\n",
      "step:   109100, time: 0.781, loss: 1.1069, l1: 0.2010, vgg: 0.5134, mask: 0.3925\n",
      "step:   109120, time: 0.820, loss: 1.0978, l1: 0.2697, vgg: 0.4194, mask: 0.4088\n",
      "step:   109140, time: 0.755, loss: 1.0798, l1: 0.2154, vgg: 0.4921, mask: 0.3723\n",
      "step:   109160, time: 0.766, loss: 1.0558, l1: 0.2275, vgg: 0.4266, mask: 0.4017\n",
      "step:   109180, time: 0.758, loss: 1.1824, l1: 0.2136, vgg: 0.5477, mask: 0.4210\n",
      "step:   109200, time: 0.805, loss: 1.0611, l1: 0.2439, vgg: 0.4122, mask: 0.4051\n",
      "step:   109220, time: 0.863, loss: 1.1551, l1: 0.2381, vgg: 0.5047, mask: 0.4123\n",
      "step:   109240, time: 0.749, loss: 1.0075, l1: 0.2661, vgg: 0.3828, mask: 0.3586\n",
      "step:   109260, time: 0.819, loss: 1.0597, l1: 0.2523, vgg: 0.4266, mask: 0.3809\n",
      "step:   109280, time: 0.784, loss: 1.0240, l1: 0.2173, vgg: 0.4483, mask: 0.3584\n",
      "step:   109300, time: 0.807, loss: 1.0979, l1: 0.2568, vgg: 0.4391, mask: 0.4019\n",
      "step:   109320, time: 0.753, loss: 1.0096, l1: 0.1851, vgg: 0.4616, mask: 0.3629\n",
      "step:   109340, time: 0.785, loss: 1.1603, l1: 0.2601, vgg: 0.5230, mask: 0.3773\n",
      "step:   109360, time: 0.744, loss: 1.0713, l1: 0.2550, vgg: 0.4245, mask: 0.3917\n",
      "step:   109380, time: 0.765, loss: 1.0906, l1: 0.2207, vgg: 0.4454, mask: 0.4246\n",
      "step:   109400, time: 0.778, loss: 1.0387, l1: 0.2223, vgg: 0.4675, mask: 0.3489\n",
      "step:   109420, time: 0.771, loss: 1.0562, l1: 0.2152, vgg: 0.4675, mask: 0.3735\n",
      "step:   109440, time: 0.773, loss: 1.0754, l1: 0.2244, vgg: 0.4573, mask: 0.3937\n",
      "step:   109460, time: 0.757, loss: 0.9768, l1: 0.1837, vgg: 0.4271, mask: 0.3659\n",
      "step:   109480, time: 0.778, loss: 1.0121, l1: 0.1777, vgg: 0.4786, mask: 0.3558\n",
      "step:   109500, time: 0.821, loss: 0.9978, l1: 0.1914, vgg: 0.4374, mask: 0.3690\n",
      "step:   109520, time: 0.819, loss: 1.0669, l1: 0.2228, vgg: 0.4483, mask: 0.3957\n",
      "step:   109540, time: 0.780, loss: 0.9857, l1: 0.1965, vgg: 0.3954, mask: 0.3938\n",
      "step:   109560, time: 0.725, loss: 0.8855, l1: 0.1777, vgg: 0.3810, mask: 0.3268\n",
      "step:   109580, time: 0.746, loss: 0.9755, l1: 0.2031, vgg: 0.4177, mask: 0.3547\n",
      "step:   109600, time: 0.805, loss: 1.1328, l1: 0.2258, vgg: 0.4919, mask: 0.4150\n",
      "step:   109620, time: 0.838, loss: 1.0255, l1: 0.2068, vgg: 0.4525, mask: 0.3662\n",
      "step:   109640, time: 0.788, loss: 0.9960, l1: 0.2051, vgg: 0.4441, mask: 0.3467\n",
      "step:   109660, time: 0.752, loss: 0.9537, l1: 0.1890, vgg: 0.4015, mask: 0.3632\n",
      "step:   109680, time: 0.750, loss: 1.0806, l1: 0.1913, vgg: 0.5169, mask: 0.3724\n",
      "step:   109700, time: 0.747, loss: 0.9488, l1: 0.1665, vgg: 0.4140, mask: 0.3683\n",
      "step:   109720, time: 0.759, loss: 1.1022, l1: 0.2475, vgg: 0.4495, mask: 0.4053\n",
      "step:   109740, time: 0.754, loss: 1.0966, l1: 0.2496, vgg: 0.4353, mask: 0.4117\n",
      "step:   109760, time: 0.748, loss: 1.2159, l1: 0.2904, vgg: 0.5368, mask: 0.3887\n",
      "step:   109780, time: 0.737, loss: 0.9807, l1: 0.1868, vgg: 0.4361, mask: 0.3579\n",
      "step:   109800, time: 0.761, loss: 1.0128, l1: 0.1788, vgg: 0.4604, mask: 0.3737\n",
      "step:   109820, time: 0.754, loss: 1.1022, l1: 0.2543, vgg: 0.4582, mask: 0.3898\n",
      "step:   109840, time: 0.769, loss: 0.9971, l1: 0.2169, vgg: 0.3809, mask: 0.3994\n",
      "step:   109860, time: 0.744, loss: 0.9851, l1: 0.2148, vgg: 0.3775, mask: 0.3928\n",
      "step:   109880, time: 0.800, loss: 1.0306, l1: 0.1723, vgg: 0.4555, mask: 0.4027\n",
      "step:   109900, time: 0.769, loss: 0.9895, l1: 0.1970, vgg: 0.4540, mask: 0.3385\n",
      "step:   109920, time: 0.721, loss: 1.0499, l1: 0.1823, vgg: 0.4969, mask: 0.3707\n",
      "step:   109940, time: 0.742, loss: 1.0997, l1: 0.2330, vgg: 0.4670, mask: 0.3997\n",
      "step:   109960, time: 0.729, loss: 0.9937, l1: 0.2103, vgg: 0.4119, mask: 0.3716\n",
      "step:   109980, time: 0.751, loss: 1.0282, l1: 0.2202, vgg: 0.4307, mask: 0.3773\n",
      "step:   110000, time: 0.742, loss: 1.0535, l1: 0.1745, vgg: 0.5140, mask: 0.3650\n",
      "step:   110020, time: 0.755, loss: 1.0405, l1: 0.2010, vgg: 0.4688, mask: 0.3707\n",
      "step:   110040, time: 0.734, loss: 0.9842, l1: 0.1581, vgg: 0.4813, mask: 0.3448\n",
      "step:   110060, time: 0.746, loss: 0.9787, l1: 0.1901, vgg: 0.4213, mask: 0.3673\n",
      "step:   110080, time: 0.746, loss: 1.0868, l1: 0.2442, vgg: 0.4467, mask: 0.3959\n",
      "step:   110100, time: 0.754, loss: 1.1076, l1: 0.2164, vgg: 0.4927, mask: 0.3985\n",
      "step:   110120, time: 0.738, loss: 1.0717, l1: 0.2554, vgg: 0.4057, mask: 0.4106\n",
      "step:   110140, time: 0.738, loss: 0.9914, l1: 0.1943, vgg: 0.4442, mask: 0.3529\n",
      "step:   110160, time: 0.760, loss: 1.0179, l1: 0.1887, vgg: 0.4722, mask: 0.3570\n",
      "step:   110180, time: 0.782, loss: 1.0982, l1: 0.2091, vgg: 0.5248, mask: 0.3643\n",
      "step:   110200, time: 0.745, loss: 0.9238, l1: 0.1756, vgg: 0.3943, mask: 0.3539\n",
      "step:   110220, time: 0.774, loss: 1.0143, l1: 0.2012, vgg: 0.4374, mask: 0.3757\n",
      "step:   110240, time: 0.735, loss: 1.0105, l1: 0.2189, vgg: 0.4069, mask: 0.3847\n",
      "step:   110260, time: 0.762, loss: 1.0410, l1: 0.2022, vgg: 0.4644, mask: 0.3744\n",
      "step:   110280, time: 0.778, loss: 1.0871, l1: 0.2315, vgg: 0.4457, mask: 0.4099\n",
      "step:   110300, time: 0.786, loss: 1.0133, l1: 0.2068, vgg: 0.4429, mask: 0.3636\n",
      "step:   110320, time: 0.762, loss: 1.0331, l1: 0.2183, vgg: 0.4311, mask: 0.3838\n",
      "step:   110340, time: 0.794, loss: 1.1565, l1: 0.2557, vgg: 0.5070, mask: 0.3938\n",
      "step:   110360, time: 0.734, loss: 1.1068, l1: 0.2706, vgg: 0.4485, mask: 0.3877\n",
      "step:   110380, time: 0.756, loss: 1.2699, l1: 0.3075, vgg: 0.5368, mask: 0.4256\n",
      "step:   110400, time: 0.729, loss: 0.9507, l1: 0.1866, vgg: 0.3877, mask: 0.3764\n",
      "step:   110420, time: 0.731, loss: 1.0467, l1: 0.2331, vgg: 0.4361, mask: 0.3774\n",
      "step:   110440, time: 0.775, loss: 1.1294, l1: 0.2294, vgg: 0.4752, mask: 0.4248\n",
      "step:   110460, time: 0.788, loss: 1.0844, l1: 0.2425, vgg: 0.4252, mask: 0.4167\n",
      "step:   110480, time: 0.790, loss: 1.1578, l1: 0.2581, vgg: 0.5160, mask: 0.3837\n",
      "step:   110500, time: 0.733, loss: 0.9434, l1: 0.1642, vgg: 0.3902, mask: 0.3891\n",
      "step:   110520, time: 0.754, loss: 0.9698, l1: 0.1876, vgg: 0.3815, mask: 0.4007\n",
      "step:   110540, time: 0.756, loss: 0.9384, l1: 0.1616, vgg: 0.4438, mask: 0.3329\n",
      "step:   110560, time: 0.757, loss: 0.9727, l1: 0.2083, vgg: 0.4276, mask: 0.3368\n",
      "step:   110580, time: 0.765, loss: 1.1163, l1: 0.2458, vgg: 0.4822, mask: 0.3883\n",
      "step:   110600, time: 0.795, loss: 0.9560, l1: 0.1934, vgg: 0.4151, mask: 0.3475\n",
      "step:   110620, time: 0.779, loss: 1.0504, l1: 0.1842, vgg: 0.4815, mask: 0.3847\n",
      "step:   110640, time: 0.751, loss: 0.9926, l1: 0.2014, vgg: 0.4255, mask: 0.3657\n",
      "step:   110660, time: 0.771, loss: 0.9542, l1: 0.1828, vgg: 0.4409, mask: 0.3305\n",
      "step:   110680, time: 0.754, loss: 1.1455, l1: 0.2576, vgg: 0.4454, mask: 0.4426\n",
      "step:   110700, time: 0.814, loss: 1.0342, l1: 0.2194, vgg: 0.4346, mask: 0.3802\n",
      "step:   110720, time: 0.772, loss: 0.9879, l1: 0.1856, vgg: 0.4312, mask: 0.3711\n",
      "step:   110740, time: 0.792, loss: 1.0149, l1: 0.1731, vgg: 0.4538, mask: 0.3879\n",
      "step:   110760, time: 0.830, loss: 0.9708, l1: 0.1958, vgg: 0.4287, mask: 0.3464\n",
      "step:   110780, time: 0.825, loss: 1.1364, l1: 0.2390, vgg: 0.5018, mask: 0.3956\n",
      "step:   110800, time: 0.819, loss: 1.0094, l1: 0.1687, vgg: 0.5015, mask: 0.3391\n",
      "step:   110820, time: 0.783, loss: 0.9347, l1: 0.1811, vgg: 0.3913, mask: 0.3623\n",
      "step:   110840, time: 0.729, loss: 1.1291, l1: 0.2582, vgg: 0.4676, mask: 0.4034\n",
      "step:   110860, time: 0.742, loss: 0.9996, l1: 0.1754, vgg: 0.4430, mask: 0.3812\n",
      "step:   110880, time: 0.771, loss: 1.1336, l1: 0.3021, vgg: 0.3956, mask: 0.4359\n",
      "step:   110900, time: 0.812, loss: 0.8826, l1: 0.1829, vgg: 0.3553, mask: 0.3444\n",
      "step:   110920, time: 0.813, loss: 1.1014, l1: 0.2595, vgg: 0.4619, mask: 0.3799\n",
      "step:   110940, time: 0.745, loss: 1.0649, l1: 0.2427, vgg: 0.4555, mask: 0.3666\n",
      "step:   110960, time: 0.775, loss: 1.0088, l1: 0.2012, vgg: 0.4316, mask: 0.3760\n",
      "step:   110980, time: 0.790, loss: 1.1017, l1: 0.2598, vgg: 0.4110, mask: 0.4310\n",
      "step:   111000, time: 0.758, loss: 1.0077, l1: 0.1904, vgg: 0.4278, mask: 0.3895\n",
      "step:   111020, time: 0.816, loss: 1.1191, l1: 0.2437, vgg: 0.4500, mask: 0.4253\n",
      "step:   111040, time: 0.750, loss: 1.0405, l1: 0.2224, vgg: 0.4348, mask: 0.3834\n",
      "step:   111060, time: 0.765, loss: 1.0175, l1: 0.2238, vgg: 0.4002, mask: 0.3935\n",
      "step:   111080, time: 0.790, loss: 0.9866, l1: 0.1652, vgg: 0.4510, mask: 0.3704\n",
      "step:   111100, time: 0.715, loss: 1.0165, l1: 0.1970, vgg: 0.4422, mask: 0.3772\n",
      "step:   111120, time: 0.762, loss: 0.9811, l1: 0.1926, vgg: 0.4362, mask: 0.3522\n",
      "step:   111140, time: 0.761, loss: 0.9724, l1: 0.1554, vgg: 0.4557, mask: 0.3613\n",
      "step:   111160, time: 0.758, loss: 1.0198, l1: 0.1945, vgg: 0.4662, mask: 0.3591\n",
      "step:   111180, time: 0.770, loss: 0.9528, l1: 0.1888, vgg: 0.3991, mask: 0.3648\n",
      "step:   111200, time: 0.780, loss: 1.0637, l1: 0.2228, vgg: 0.4216, mask: 0.4192\n",
      "step:   111220, time: 0.768, loss: 1.1730, l1: 0.2552, vgg: 0.5023, mask: 0.4155\n",
      "step:   111240, time: 0.742, loss: 0.9246, l1: 0.1558, vgg: 0.4383, mask: 0.3305\n",
      "step:   111260, time: 0.748, loss: 1.1218, l1: 0.2313, vgg: 0.4605, mask: 0.4300\n",
      "step:   111280, time: 0.814, loss: 1.1702, l1: 0.2785, vgg: 0.4710, mask: 0.4206\n",
      "step:   111300, time: 0.781, loss: 1.1645, l1: 0.2594, vgg: 0.4778, mask: 0.4273\n",
      "step:   111320, time: 0.742, loss: 0.8830, l1: 0.1961, vgg: 0.3851, mask: 0.3018\n",
      "step:   111340, time: 0.780, loss: 0.8859, l1: 0.1402, vgg: 0.4035, mask: 0.3421\n",
      "step:   111360, time: 0.747, loss: 1.1207, l1: 0.2680, vgg: 0.4438, mask: 0.4089\n",
      "step:   111380, time: 0.761, loss: 1.0200, l1: 0.1944, vgg: 0.4330, mask: 0.3925\n",
      "step:   111400, time: 0.739, loss: 0.9730, l1: 0.1912, vgg: 0.4163, mask: 0.3655\n",
      "step:   111420, time: 0.784, loss: 1.0727, l1: 0.1848, vgg: 0.5192, mask: 0.3687\n",
      "step:   111440, time: 0.758, loss: 1.1869, l1: 0.2604, vgg: 0.5089, mask: 0.4176\n",
      "step:   111460, time: 0.756, loss: 1.1296, l1: 0.2463, vgg: 0.4795, mask: 0.4039\n",
      "step:   111480, time: 0.745, loss: 1.0549, l1: 0.1806, vgg: 0.5245, mask: 0.3498\n",
      "step:   111500, time: 0.779, loss: 1.1320, l1: 0.2532, vgg: 0.4794, mask: 0.3994\n",
      "step:   111520, time: 0.770, loss: 1.0686, l1: 0.2093, vgg: 0.4416, mask: 0.4176\n",
      "step:   111540, time: 0.776, loss: 1.1038, l1: 0.2193, vgg: 0.4771, mask: 0.4073\n",
      "step:   111560, time: 0.765, loss: 1.1561, l1: 0.2701, vgg: 0.4876, mask: 0.3984\n",
      "step:   111580, time: 0.755, loss: 1.0505, l1: 0.2473, vgg: 0.4463, mask: 0.3569\n",
      "step:   111600, time: 0.752, loss: 1.0726, l1: 0.2405, vgg: 0.4736, mask: 0.3585\n",
      "step:   111620, time: 0.740, loss: 1.1311, l1: 0.2358, vgg: 0.4856, mask: 0.4097\n",
      "step:   111640, time: 0.771, loss: 1.0092, l1: 0.2294, vgg: 0.3883, mask: 0.3914\n",
      "step:   111660, time: 0.740, loss: 1.0211, l1: 0.2058, vgg: 0.4233, mask: 0.3920\n",
      "step:   111680, time: 0.785, loss: 1.0311, l1: 0.2131, vgg: 0.4464, mask: 0.3716\n",
      "step:   111700, time: 0.745, loss: 0.9981, l1: 0.2113, vgg: 0.4434, mask: 0.3433\n",
      "step:   111720, time: 0.732, loss: 0.9171, l1: 0.1961, vgg: 0.3393, mask: 0.3818\n",
      "step:   111740, time: 0.765, loss: 1.1428, l1: 0.2197, vgg: 0.5414, mask: 0.3818\n",
      "step:   111760, time: 0.759, loss: 0.9947, l1: 0.1761, vgg: 0.3934, mask: 0.4251\n",
      "step:   111780, time: 0.736, loss: 1.1057, l1: 0.2770, vgg: 0.4283, mask: 0.4004\n",
      "step:   111800, time: 0.747, loss: 1.0470, l1: 0.1928, vgg: 0.4977, mask: 0.3564\n",
      "step:   111820, time: 0.788, loss: 1.1367, l1: 0.2543, vgg: 0.4809, mask: 0.4015\n",
      "step:   111840, time: 0.782, loss: 0.9920, l1: 0.1763, vgg: 0.4478, mask: 0.3679\n",
      "step:   111860, time: 0.753, loss: 1.0137, l1: 0.1753, vgg: 0.4686, mask: 0.3698\n",
      "step:   111880, time: 0.741, loss: 1.1263, l1: 0.2359, vgg: 0.4998, mask: 0.3905\n",
      "step:   111900, time: 0.733, loss: 0.9262, l1: 0.1729, vgg: 0.4095, mask: 0.3438\n",
      "step:   111920, time: 0.752, loss: 1.0354, l1: 0.1838, vgg: 0.4940, mask: 0.3577\n",
      "step:   111940, time: 0.742, loss: 0.9781, l1: 0.1641, vgg: 0.4373, mask: 0.3767\n",
      "step:   111960, time: 0.729, loss: 0.8857, l1: 0.1377, vgg: 0.4059, mask: 0.3422\n",
      "step:   111980, time: 0.774, loss: 1.0454, l1: 0.2011, vgg: 0.4699, mask: 0.3744\n",
      "step:   112000, time: 0.746, loss: 1.1187, l1: 0.2314, vgg: 0.5041, mask: 0.3833\n",
      "step:   112020, time: 0.743, loss: 1.1590, l1: 0.2984, vgg: 0.4697, mask: 0.3909\n",
      "step:   112040, time: 0.730, loss: 0.8796, l1: 0.1490, vgg: 0.3734, mask: 0.3572\n",
      "step:   112060, time: 0.785, loss: 0.9969, l1: 0.1957, vgg: 0.4392, mask: 0.3620\n",
      "step:   112080, time: 0.730, loss: 0.9224, l1: 0.1793, vgg: 0.4001, mask: 0.3430\n",
      "step:   112100, time: 0.735, loss: 1.0123, l1: 0.1826, vgg: 0.4516, mask: 0.3782\n",
      "step:   112120, time: 0.775, loss: 1.1795, l1: 0.2222, vgg: 0.5822, mask: 0.3750\n",
      "step:   112140, time: 0.754, loss: 0.9969, l1: 0.2193, vgg: 0.4189, mask: 0.3587\n",
      "step:   112160, time: 0.744, loss: 1.0566, l1: 0.2486, vgg: 0.3940, mask: 0.4140\n",
      "step:   112180, time: 0.740, loss: 1.1088, l1: 0.2679, vgg: 0.4232, mask: 0.4176\n",
      "step:   112200, time: 0.731, loss: 1.1013, l1: 0.2221, vgg: 0.5060, mask: 0.3732\n",
      "step:   112220, time: 0.782, loss: 1.1192, l1: 0.1871, vgg: 0.5143, mask: 0.4179\n",
      "step:   112240, time: 0.783, loss: 1.0199, l1: 0.1974, vgg: 0.4539, mask: 0.3686\n",
      "step:   112260, time: 0.767, loss: 0.9857, l1: 0.1888, vgg: 0.4357, mask: 0.3612\n",
      "step:   112280, time: 0.838, loss: 1.1339, l1: 0.2739, vgg: 0.4575, mask: 0.4025\n",
      "step:   112300, time: 0.729, loss: 1.0094, l1: 0.2022, vgg: 0.4461, mask: 0.3611\n",
      "step:   112320, time: 0.709, loss: 1.0620, l1: 0.2092, vgg: 0.4735, mask: 0.3793\n",
      "step:   112340, time: 0.720, loss: 0.9937, l1: 0.1639, vgg: 0.4720, mask: 0.3579\n",
      "step:   112360, time: 0.754, loss: 0.9905, l1: 0.1637, vgg: 0.4665, mask: 0.3603\n",
      "step:   112380, time: 0.778, loss: 1.1134, l1: 0.2118, vgg: 0.5076, mask: 0.3939\n",
      "step:   112400, time: 0.746, loss: 1.0288, l1: 0.2109, vgg: 0.4611, mask: 0.3568\n",
      "step:   112420, time: 0.793, loss: 1.1655, l1: 0.2797, vgg: 0.4624, mask: 0.4234\n",
      "step:   112440, time: 0.743, loss: 1.0536, l1: 0.2336, vgg: 0.4287, mask: 0.3914\n",
      "step:   112460, time: 0.750, loss: 0.9488, l1: 0.1778, vgg: 0.4139, mask: 0.3571\n",
      "step:   112480, time: 0.724, loss: 1.0042, l1: 0.1988, vgg: 0.4122, mask: 0.3933\n",
      "step:   112500, time: 0.765, loss: 1.0314, l1: 0.2038, vgg: 0.4764, mask: 0.3512\n",
      "step:   112520, time: 0.741, loss: 0.9373, l1: 0.2156, vgg: 0.3681, mask: 0.3535\n",
      "step:   112540, time: 0.746, loss: 0.9837, l1: 0.2332, vgg: 0.3693, mask: 0.3812\n",
      "step:   112560, time: 0.807, loss: 1.1642, l1: 0.2524, vgg: 0.5273, mask: 0.3845\n",
      "step:   112580, time: 0.747, loss: 1.0600, l1: 0.1944, vgg: 0.5060, mask: 0.3596\n",
      "step:   112600, time: 0.802, loss: 0.9814, l1: 0.1926, vgg: 0.4540, mask: 0.3349\n",
      "step:   112620, time: 0.738, loss: 1.0589, l1: 0.2042, vgg: 0.4332, mask: 0.4214\n",
      "step:   112640, time: 0.748, loss: 1.0781, l1: 0.2188, vgg: 0.4396, mask: 0.4197\n",
      "step:   112660, time: 0.811, loss: 1.1336, l1: 0.2467, vgg: 0.5063, mask: 0.3805\n",
      "step:   112680, time: 0.776, loss: 1.0735, l1: 0.2604, vgg: 0.4083, mask: 0.4049\n",
      "step:   112700, time: 0.814, loss: 1.1486, l1: 0.2415, vgg: 0.5192, mask: 0.3878\n",
      "step:   112720, time: 0.807, loss: 1.2514, l1: 0.2691, vgg: 0.5954, mask: 0.3870\n",
      "step:   112740, time: 0.822, loss: 1.1210, l1: 0.2498, vgg: 0.4809, mask: 0.3903\n",
      "step:   112760, time: 0.778, loss: 1.0414, l1: 0.2127, vgg: 0.4600, mask: 0.3687\n",
      "step:   112780, time: 0.793, loss: 0.9829, l1: 0.1982, vgg: 0.4229, mask: 0.3618\n",
      "step:   112800, time: 0.753, loss: 1.1854, l1: 0.2942, vgg: 0.4792, mask: 0.4120\n",
      "step:   112820, time: 0.765, loss: 1.0451, l1: 0.1963, vgg: 0.4669, mask: 0.3819\n",
      "step:   112840, time: 0.763, loss: 1.0102, l1: 0.1937, vgg: 0.4451, mask: 0.3714\n",
      "step:   112860, time: 0.739, loss: 0.9606, l1: 0.1801, vgg: 0.4010, mask: 0.3794\n",
      "step:   112880, time: 0.741, loss: 1.1334, l1: 0.2081, vgg: 0.5252, mask: 0.4001\n",
      "step:   112900, time: 0.751, loss: 1.0889, l1: 0.2562, vgg: 0.4521, mask: 0.3806\n",
      "step:   112920, time: 0.756, loss: 0.9974, l1: 0.2087, vgg: 0.4533, mask: 0.3354\n",
      "step:   112940, time: 0.744, loss: 1.0233, l1: 0.2117, vgg: 0.4463, mask: 0.3653\n",
      "step:   112960, time: 0.759, loss: 1.0740, l1: 0.2230, vgg: 0.4764, mask: 0.3745\n",
      "step:   112980, time: 0.750, loss: 1.0269, l1: 0.1796, vgg: 0.4613, mask: 0.3861\n",
      "step:   113000, time: 0.736, loss: 0.8888, l1: 0.1739, vgg: 0.3660, mask: 0.3488\n",
      "step:   113020, time: 0.758, loss: 1.0213, l1: 0.2006, vgg: 0.4251, mask: 0.3956\n",
      "step:   113040, time: 0.748, loss: 1.0542, l1: 0.1783, vgg: 0.4675, mask: 0.4084\n",
      "step:   113060, time: 0.776, loss: 0.9731, l1: 0.1927, vgg: 0.4321, mask: 0.3483\n",
      "step:   113080, time: 0.751, loss: 1.0599, l1: 0.2319, vgg: 0.4617, mask: 0.3663\n",
      "step:   113100, time: 0.745, loss: 1.0682, l1: 0.2180, vgg: 0.4838, mask: 0.3664\n",
      "step:   113120, time: 0.732, loss: 0.9039, l1: 0.2081, vgg: 0.3448, mask: 0.3511\n",
      "step:   113140, time: 0.744, loss: 1.0499, l1: 0.2070, vgg: 0.4793, mask: 0.3637\n",
      "step:   113160, time: 0.774, loss: 1.1257, l1: 0.1997, vgg: 0.5557, mask: 0.3703\n",
      "step:   113180, time: 0.768, loss: 1.0367, l1: 0.2116, vgg: 0.4714, mask: 0.3537\n",
      "step:   113200, time: 0.740, loss: 1.0062, l1: 0.2179, vgg: 0.4395, mask: 0.3488\n",
      "step:   113220, time: 0.753, loss: 0.9260, l1: 0.1858, vgg: 0.4005, mask: 0.3397\n",
      "step:   113240, time: 0.741, loss: 0.9952, l1: 0.2117, vgg: 0.3962, mask: 0.3873\n",
      "step:   113260, time: 0.774, loss: 1.1641, l1: 0.2459, vgg: 0.5267, mask: 0.3915\n",
      "step:   113280, time: 0.793, loss: 1.1258, l1: 0.2587, vgg: 0.4829, mask: 0.3843\n",
      "step:   113300, time: 0.734, loss: 0.9717, l1: 0.1801, vgg: 0.4463, mask: 0.3453\n",
      "step:   113320, time: 0.753, loss: 1.0460, l1: 0.2489, vgg: 0.4085, mask: 0.3887\n",
      "step:   113340, time: 0.772, loss: 1.1159, l1: 0.2294, vgg: 0.4937, mask: 0.3929\n",
      "step:   113360, time: 0.760, loss: 1.0625, l1: 0.2033, vgg: 0.4959, mask: 0.3632\n",
      "step:   113380, time: 0.745, loss: 0.9989, l1: 0.1722, vgg: 0.4600, mask: 0.3667\n",
      "step:   113400, time: 0.714, loss: 1.0554, l1: 0.2246, vgg: 0.4053, mask: 0.4255\n",
      "step:   113420, time: 0.780, loss: 1.0865, l1: 0.2310, vgg: 0.4720, mask: 0.3835\n",
      "step:   113440, time: 0.749, loss: 1.0565, l1: 0.2302, vgg: 0.4522, mask: 0.3741\n",
      "step:   113460, time: 0.749, loss: 0.9724, l1: 0.1542, vgg: 0.4373, mask: 0.3808\n",
      "step:   113480, time: 0.779, loss: 1.0284, l1: 0.2043, vgg: 0.4560, mask: 0.3680\n",
      "step:   113500, time: 0.749, loss: 0.9784, l1: 0.1894, vgg: 0.4595, mask: 0.3295\n",
      "step:   113520, time: 0.725, loss: 0.9886, l1: 0.1849, vgg: 0.4445, mask: 0.3592\n",
      "step:   113540, time: 0.812, loss: 1.0045, l1: 0.1850, vgg: 0.4507, mask: 0.3688\n",
      "step:   113560, time: 0.787, loss: 1.0817, l1: 0.2106, vgg: 0.5047, mask: 0.3664\n",
      "step:   113580, time: 0.769, loss: 1.1502, l1: 0.2455, vgg: 0.4507, mask: 0.4540\n",
      "step:   113600, time: 0.817, loss: 1.1538, l1: 0.2882, vgg: 0.4799, mask: 0.3857\n",
      "step:   113620, time: 0.737, loss: 0.8537, l1: 0.1329, vgg: 0.3895, mask: 0.3314\n",
      "step:   113640, time: 0.800, loss: 1.0285, l1: 0.2137, vgg: 0.4217, mask: 0.3930\n",
      "step:   113660, time: 0.743, loss: 1.0977, l1: 0.2299, vgg: 0.4925, mask: 0.3754\n",
      "step:   113680, time: 0.719, loss: 0.8608, l1: 0.1349, vgg: 0.3786, mask: 0.3473\n",
      "step:   113700, time: 0.749, loss: 1.0550, l1: 0.2093, vgg: 0.4617, mask: 0.3840\n",
      "step:   113720, time: 0.744, loss: 0.9456, l1: 0.1748, vgg: 0.4127, mask: 0.3581\n",
      "step:   113740, time: 0.754, loss: 1.1449, l1: 0.2471, vgg: 0.4870, mask: 0.4108\n",
      "step:   113760, time: 0.751, loss: 1.0657, l1: 0.2385, vgg: 0.4323, mask: 0.3950\n",
      "step:   113780, time: 0.828, loss: 1.0304, l1: 0.1925, vgg: 0.4699, mask: 0.3680\n",
      "step:   113800, time: 0.708, loss: 0.9269, l1: 0.1645, vgg: 0.4370, mask: 0.3255\n",
      "step:   113820, time: 0.745, loss: 1.0380, l1: 0.2092, vgg: 0.4362, mask: 0.3926\n",
      "step:   113840, time: 0.756, loss: 1.1236, l1: 0.2288, vgg: 0.5370, mask: 0.3578\n",
      "step:   113860, time: 0.773, loss: 1.0385, l1: 0.2268, vgg: 0.4602, mask: 0.3515\n",
      "step:   113880, time: 0.714, loss: 0.9372, l1: 0.1716, vgg: 0.4034, mask: 0.3622\n",
      "step:   113900, time: 0.746, loss: 0.9916, l1: 0.1854, vgg: 0.4570, mask: 0.3492\n",
      "step:   113920, time: 0.812, loss: 1.0413, l1: 0.2253, vgg: 0.4411, mask: 0.3749\n",
      "step:   113940, time: 0.741, loss: 1.0866, l1: 0.2313, vgg: 0.4933, mask: 0.3620\n",
      "step:   113960, time: 0.748, loss: 1.1153, l1: 0.2275, vgg: 0.5199, mask: 0.3678\n",
      "step:   113980, time: 0.758, loss: 1.1485, l1: 0.2743, vgg: 0.4641, mask: 0.4101\n",
      "step:   114000, time: 0.772, loss: 1.0969, l1: 0.2257, vgg: 0.4876, mask: 0.3835\n",
      "step:   114020, time: 0.749, loss: 0.9754, l1: 0.1890, vgg: 0.4425, mask: 0.3440\n",
      "step:   114040, time: 0.735, loss: 1.0672, l1: 0.2153, vgg: 0.4413, mask: 0.4105\n",
      "step:   114060, time: 0.796, loss: 1.1326, l1: 0.2763, vgg: 0.4361, mask: 0.4202\n",
      "step:   114080, time: 0.784, loss: 1.0763, l1: 0.2179, vgg: 0.4795, mask: 0.3789\n",
      "step:   114100, time: 0.811, loss: 1.0351, l1: 0.1893, vgg: 0.4606, mask: 0.3852\n",
      "step:   114120, time: 0.757, loss: 1.0916, l1: 0.2215, vgg: 0.4589, mask: 0.4113\n",
      "step:   114140, time: 0.742, loss: 1.2416, l1: 0.2700, vgg: 0.5737, mask: 0.3979\n",
      "step:   114160, time: 0.772, loss: 1.0501, l1: 0.2155, vgg: 0.4370, mask: 0.3977\n",
      "step:   114180, time: 0.775, loss: 1.0886, l1: 0.2039, vgg: 0.5059, mask: 0.3788\n",
      "step:   114200, time: 0.783, loss: 1.2114, l1: 0.2700, vgg: 0.5188, mask: 0.4226\n",
      "step:   114220, time: 0.767, loss: 1.0185, l1: 0.1852, vgg: 0.4824, mask: 0.3509\n",
      "step:   114240, time: 0.733, loss: 1.1039, l1: 0.2754, vgg: 0.4311, mask: 0.3973\n",
      "step:   114260, time: 0.782, loss: 1.0124, l1: 0.1933, vgg: 0.4600, mask: 0.3591\n",
      "step:   114280, time: 0.763, loss: 0.9864, l1: 0.2046, vgg: 0.3995, mask: 0.3823\n",
      "step:   114300, time: 0.759, loss: 0.9744, l1: 0.1583, vgg: 0.4896, mask: 0.3266\n",
      "step:   114320, time: 0.751, loss: 1.1721, l1: 0.2726, vgg: 0.4800, mask: 0.4195\n",
      "step:   114340, time: 0.737, loss: 1.0747, l1: 0.2437, vgg: 0.4543, mask: 0.3767\n",
      "step:   114360, time: 0.771, loss: 1.1408, l1: 0.2518, vgg: 0.4845, mask: 0.4045\n",
      "step:   114380, time: 0.782, loss: 0.9799, l1: 0.1740, vgg: 0.4323, mask: 0.3736\n",
      "step:   114400, time: 0.725, loss: 1.0013, l1: 0.2149, vgg: 0.4009, mask: 0.3856\n",
      "step:   114420, time: 0.735, loss: 0.9951, l1: 0.1806, vgg: 0.4467, mask: 0.3678\n",
      "step:   114440, time: 0.720, loss: 1.1519, l1: 0.3106, vgg: 0.3970, mask: 0.4443\n",
      "step:   114460, time: 0.787, loss: 1.0508, l1: 0.2066, vgg: 0.4781, mask: 0.3662\n",
      "step:   114480, time: 0.749, loss: 1.0004, l1: 0.2149, vgg: 0.4230, mask: 0.3625\n",
      "step:   114500, time: 0.778, loss: 1.1477, l1: 0.2129, vgg: 0.5521, mask: 0.3827\n",
      "step:   114520, time: 0.811, loss: 1.0105, l1: 0.2077, vgg: 0.4340, mask: 0.3688\n",
      "step:   114540, time: 0.768, loss: 1.0975, l1: 0.2441, vgg: 0.4669, mask: 0.3865\n",
      "step:   114560, time: 0.732, loss: 1.0179, l1: 0.1951, vgg: 0.4492, mask: 0.3735\n",
      "step:   114580, time: 0.755, loss: 1.0551, l1: 0.2342, vgg: 0.4022, mask: 0.4187\n",
      "step:   114600, time: 0.753, loss: 1.0299, l1: 0.2407, vgg: 0.4050, mask: 0.3841\n",
      "step:   114620, time: 0.730, loss: 0.9906, l1: 0.2202, vgg: 0.3742, mask: 0.3962\n",
      "step:   114640, time: 0.792, loss: 1.0957, l1: 0.2360, vgg: 0.4642, mask: 0.3955\n",
      "step:   114660, time: 0.812, loss: 1.0319, l1: 0.2248, vgg: 0.4174, mask: 0.3897\n",
      "step:   114680, time: 0.780, loss: 1.0566, l1: 0.2310, vgg: 0.4319, mask: 0.3937\n",
      "step:   114700, time: 0.742, loss: 1.1012, l1: 0.2563, vgg: 0.4660, mask: 0.3790\n",
      "step:   114720, time: 0.781, loss: 0.9923, l1: 0.1917, vgg: 0.3886, mask: 0.4120\n",
      "step:   114740, time: 0.778, loss: 1.2048, l1: 0.3264, vgg: 0.4578, mask: 0.4207\n",
      "step:   114760, time: 0.833, loss: 1.1041, l1: 0.2873, vgg: 0.4336, mask: 0.3832\n",
      "step:   114780, time: 0.809, loss: 0.9908, l1: 0.1947, vgg: 0.4174, mask: 0.3787\n",
      "step:   114800, time: 0.746, loss: 1.1478, l1: 0.2644, vgg: 0.4555, mask: 0.4280\n",
      "step:   114820, time: 0.800, loss: 1.1095, l1: 0.2948, vgg: 0.4117, mask: 0.4030\n",
      "step:   114840, time: 0.793, loss: 1.0549, l1: 0.2128, vgg: 0.4171, mask: 0.4250\n",
      "step:   114860, time: 0.813, loss: 1.0254, l1: 0.2587, vgg: 0.3615, mask: 0.4053\n",
      "step:   114880, time: 0.793, loss: 1.1068, l1: 0.2152, vgg: 0.4931, mask: 0.3985\n",
      "step:   114900, time: 0.790, loss: 1.0811, l1: 0.2092, vgg: 0.5094, mask: 0.3625\n",
      "step:   114920, time: 0.803, loss: 1.1060, l1: 0.2055, vgg: 0.5175, mask: 0.3830\n",
      "step:   114940, time: 0.789, loss: 1.1203, l1: 0.2631, vgg: 0.4786, mask: 0.3785\n",
      "step:   114960, time: 0.822, loss: 1.1936, l1: 0.2805, vgg: 0.5123, mask: 0.4008\n",
      "step:   114980, time: 0.736, loss: 0.9950, l1: 0.2019, vgg: 0.4222, mask: 0.3709\n",
      "step:   115000, time: 0.758, loss: 1.0308, l1: 0.2318, vgg: 0.4055, mask: 0.3935\n",
      "step:   115020, time: 0.736, loss: 0.9190, l1: 0.1502, vgg: 0.4187, mask: 0.3502\n",
      "step:   115040, time: 0.773, loss: 1.0278, l1: 0.1948, vgg: 0.4716, mask: 0.3615\n",
      "step:   115060, time: 0.753, loss: 1.1497, l1: 0.2697, vgg: 0.4826, mask: 0.3974\n",
      "step:   115080, time: 0.774, loss: 1.0437, l1: 0.1780, vgg: 0.4828, mask: 0.3829\n",
      "step:   115100, time: 0.724, loss: 0.9284, l1: 0.1551, vgg: 0.4232, mask: 0.3500\n",
      "step:   115120, time: 0.790, loss: 1.1216, l1: 0.2458, vgg: 0.4852, mask: 0.3906\n",
      "step:   115140, time: 0.775, loss: 1.0632, l1: 0.2024, vgg: 0.4721, mask: 0.3887\n",
      "step:   115160, time: 0.788, loss: 1.1026, l1: 0.2382, vgg: 0.4758, mask: 0.3886\n",
      "step:   115180, time: 0.825, loss: 1.0372, l1: 0.2102, vgg: 0.4676, mask: 0.3595\n",
      "step:   115200, time: 0.790, loss: 1.0300, l1: 0.2127, vgg: 0.4649, mask: 0.3523\n",
      "step:   115220, time: 0.741, loss: 0.9312, l1: 0.1572, vgg: 0.4265, mask: 0.3476\n",
      "step:   115240, time: 0.741, loss: 1.0046, l1: 0.2068, vgg: 0.4379, mask: 0.3600\n",
      "step:   115260, time: 0.766, loss: 0.9990, l1: 0.1988, vgg: 0.4187, mask: 0.3815\n",
      "step:   115280, time: 0.747, loss: 1.0294, l1: 0.2071, vgg: 0.4602, mask: 0.3621\n",
      "step:   115300, time: 0.748, loss: 1.0941, l1: 0.2309, vgg: 0.4730, mask: 0.3902\n",
      "step:   115320, time: 0.747, loss: 1.0265, l1: 0.2109, vgg: 0.3984, mask: 0.4173\n",
      "step:   115340, time: 0.763, loss: 1.0588, l1: 0.1744, vgg: 0.5168, mask: 0.3676\n",
      "step:   115360, time: 0.793, loss: 1.0714, l1: 0.2328, vgg: 0.4594, mask: 0.3793\n",
      "step:   115380, time: 0.753, loss: 0.9793, l1: 0.1693, vgg: 0.4208, mask: 0.3892\n",
      "step:   115400, time: 0.773, loss: 0.9504, l1: 0.2026, vgg: 0.3762, mask: 0.3717\n",
      "step:   115420, time: 0.709, loss: 0.8794, l1: 0.1515, vgg: 0.3702, mask: 0.3577\n",
      "step:   115440, time: 0.808, loss: 1.1855, l1: 0.2900, vgg: 0.4881, mask: 0.4074\n",
      "step:   115460, time: 0.743, loss: 0.9615, l1: 0.1839, vgg: 0.4049, mask: 0.3727\n",
      "step:   115480, time: 0.757, loss: 0.9434, l1: 0.1901, vgg: 0.3984, mask: 0.3548\n",
      "step:   115500, time: 0.712, loss: 1.0446, l1: 0.2152, vgg: 0.4399, mask: 0.3896\n",
      "step:   115520, time: 0.764, loss: 1.0943, l1: 0.2511, vgg: 0.4527, mask: 0.3906\n",
      "step:   115540, time: 0.774, loss: 0.9746, l1: 0.1865, vgg: 0.4243, mask: 0.3638\n",
      "step:   115560, time: 0.741, loss: 0.9749, l1: 0.1745, vgg: 0.4343, mask: 0.3662\n",
      "step:   115580, time: 0.814, loss: 1.0315, l1: 0.1905, vgg: 0.4722, mask: 0.3688\n",
      "step:   115600, time: 0.769, loss: 1.0198, l1: 0.1619, vgg: 0.4969, mask: 0.3609\n",
      "step:   115620, time: 0.811, loss: 0.9762, l1: 0.1807, vgg: 0.4364, mask: 0.3591\n",
      "step:   115640, time: 0.719, loss: 1.0504, l1: 0.2133, vgg: 0.4432, mask: 0.3939\n",
      "step:   115660, time: 0.722, loss: 0.9605, l1: 0.1656, vgg: 0.4506, mask: 0.3444\n",
      "step:   115680, time: 0.759, loss: 1.1093, l1: 0.2276, vgg: 0.4886, mask: 0.3931\n",
      "step:   115700, time: 0.755, loss: 1.1319, l1: 0.2071, vgg: 0.5659, mask: 0.3589\n",
      "step:   115720, time: 0.759, loss: 0.9959, l1: 0.2025, vgg: 0.4403, mask: 0.3531\n",
      "step:   115740, time: 0.886, loss: 1.0092, l1: 0.2143, vgg: 0.4212, mask: 0.3737\n",
      "step:   115760, time: 0.747, loss: 1.0484, l1: 0.2504, vgg: 0.4091, mask: 0.3889\n",
      "step:   115780, time: 0.771, loss: 1.0767, l1: 0.2413, vgg: 0.4275, mask: 0.4078\n",
      "step:   115800, time: 0.753, loss: 0.9933, l1: 0.1701, vgg: 0.4565, mask: 0.3667\n",
      "step:   115820, time: 0.757, loss: 0.9220, l1: 0.1665, vgg: 0.4019, mask: 0.3537\n",
      "step:   115840, time: 0.734, loss: 0.9669, l1: 0.2048, vgg: 0.3913, mask: 0.3709\n",
      "step:   115860, time: 0.772, loss: 1.0549, l1: 0.2344, vgg: 0.4276, mask: 0.3930\n",
      "step:   115880, time: 0.789, loss: 1.0713, l1: 0.2638, vgg: 0.4380, mask: 0.3696\n",
      "step:   115900, time: 0.776, loss: 1.0325, l1: 0.2093, vgg: 0.4175, mask: 0.4056\n",
      "step:   115920, time: 0.787, loss: 1.0331, l1: 0.1859, vgg: 0.4759, mask: 0.3714\n",
      "step:   115940, time: 0.807, loss: 1.0804, l1: 0.2440, vgg: 0.4571, mask: 0.3794\n",
      "step:   115960, time: 0.753, loss: 1.0582, l1: 0.2218, vgg: 0.4262, mask: 0.4102\n",
      "step:   115980, time: 0.773, loss: 1.0845, l1: 0.2402, vgg: 0.4687, mask: 0.3756\n",
      "step:   116000, time: 0.769, loss: 1.0291, l1: 0.2342, vgg: 0.4235, mask: 0.3713\n",
      "step:   116020, time: 0.759, loss: 0.9720, l1: 0.1809, vgg: 0.4312, mask: 0.3598\n",
      "step:   116040, time: 0.757, loss: 1.0574, l1: 0.2129, vgg: 0.4650, mask: 0.3795\n",
      "step:   116060, time: 0.797, loss: 1.0776, l1: 0.2213, vgg: 0.4616, mask: 0.3947\n",
      "step:   116080, time: 0.745, loss: 1.0895, l1: 0.2562, vgg: 0.4152, mask: 0.4181\n",
      "step:   116100, time: 0.836, loss: 1.1012, l1: 0.1766, vgg: 0.5359, mask: 0.3888\n",
      "step:   116120, time: 0.779, loss: 1.0308, l1: 0.2292, vgg: 0.4331, mask: 0.3685\n",
      "step:   116140, time: 0.748, loss: 0.9934, l1: 0.1922, vgg: 0.4479, mask: 0.3533\n",
      "step:   116160, time: 0.789, loss: 1.0856, l1: 0.2767, vgg: 0.4027, mask: 0.4061\n",
      "step:   116180, time: 0.765, loss: 1.0595, l1: 0.2080, vgg: 0.4876, mask: 0.3639\n",
      "step:   116200, time: 0.783, loss: 1.1347, l1: 0.2843, vgg: 0.4484, mask: 0.4020\n",
      "step:   116220, time: 0.778, loss: 1.0473, l1: 0.2141, vgg: 0.4570, mask: 0.3761\n",
      "step:   116240, time: 0.757, loss: 0.9806, l1: 0.2150, vgg: 0.3823, mask: 0.3833\n",
      "step:   116260, time: 0.819, loss: 1.0684, l1: 0.2049, vgg: 0.4853, mask: 0.3782\n",
      "step:   116280, time: 0.800, loss: 0.9914, l1: 0.2046, vgg: 0.4123, mask: 0.3745\n",
      "step:   116300, time: 0.763, loss: 1.1520, l1: 0.2934, vgg: 0.4585, mask: 0.4001\n",
      "step:   116320, time: 0.802, loss: 1.0063, l1: 0.1754, vgg: 0.4833, mask: 0.3476\n",
      "step:   116340, time: 0.758, loss: 1.0084, l1: 0.2012, vgg: 0.4431, mask: 0.3641\n",
      "step:   116360, time: 0.783, loss: 1.1640, l1: 0.2377, vgg: 0.5543, mask: 0.3720\n",
      "step:   116380, time: 0.751, loss: 0.9531, l1: 0.1909, vgg: 0.4220, mask: 0.3402\n",
      "step:   116400, time: 0.795, loss: 1.0219, l1: 0.1718, vgg: 0.4435, mask: 0.4066\n",
      "step:   116420, time: 0.750, loss: 0.9905, l1: 0.1741, vgg: 0.4819, mask: 0.3345\n",
      "step:   116440, time: 0.754, loss: 1.1041, l1: 0.2276, vgg: 0.4947, mask: 0.3819\n",
      "step:   116460, time: 0.739, loss: 1.1027, l1: 0.2289, vgg: 0.4322, mask: 0.4417\n",
      "step:   116480, time: 0.762, loss: 1.0508, l1: 0.2167, vgg: 0.4808, mask: 0.3532\n",
      "step:   116500, time: 0.768, loss: 1.0182, l1: 0.2305, vgg: 0.3839, mask: 0.4039\n",
      "step:   116520, time: 0.759, loss: 1.1299, l1: 0.2691, vgg: 0.4624, mask: 0.3984\n",
      "step:   116540, time: 0.757, loss: 1.1194, l1: 0.2442, vgg: 0.5119, mask: 0.3633\n",
      "step:   116560, time: 0.815, loss: 1.1442, l1: 0.2612, vgg: 0.4742, mask: 0.4088\n",
      "step:   116580, time: 0.754, loss: 0.9932, l1: 0.2081, vgg: 0.4146, mask: 0.3705\n",
      "step:   116600, time: 0.782, loss: 0.9740, l1: 0.1817, vgg: 0.4002, mask: 0.3921\n",
      "step:   116620, time: 0.733, loss: 0.9721, l1: 0.1966, vgg: 0.4344, mask: 0.3411\n",
      "step:   116640, time: 0.763, loss: 1.0021, l1: 0.2198, vgg: 0.3973, mask: 0.3850\n",
      "step:   116660, time: 0.773, loss: 1.0211, l1: 0.2187, vgg: 0.4208, mask: 0.3816\n",
      "step:   116680, time: 0.764, loss: 1.0447, l1: 0.1513, vgg: 0.4465, mask: 0.4469\n",
      "step:   116700, time: 0.864, loss: 1.0450, l1: 0.2396, vgg: 0.4225, mask: 0.3829\n",
      "step:   116720, time: 0.741, loss: 1.0618, l1: 0.1893, vgg: 0.5198, mask: 0.3527\n",
      "step:   116740, time: 0.779, loss: 1.0655, l1: 0.2312, vgg: 0.4597, mask: 0.3746\n",
      "step:   116760, time: 0.789, loss: 1.2660, l1: 0.2617, vgg: 0.6172, mask: 0.3871\n",
      "step:   116780, time: 0.711, loss: 0.9960, l1: 0.2446, vgg: 0.3392, mask: 0.4121\n",
      "step:   116800, time: 0.772, loss: 1.0244, l1: 0.2180, vgg: 0.4300, mask: 0.3764\n",
      "step:   116820, time: 0.763, loss: 1.0708, l1: 0.2082, vgg: 0.5109, mask: 0.3517\n",
      "step:   116840, time: 0.740, loss: 1.0454, l1: 0.2342, vgg: 0.4480, mask: 0.3633\n",
      "step:   116860, time: 0.760, loss: 1.0606, l1: 0.2134, vgg: 0.4961, mask: 0.3511\n",
      "step:   116880, time: 0.747, loss: 1.0340, l1: 0.2333, vgg: 0.4126, mask: 0.3881\n",
      "step:   116900, time: 0.769, loss: 1.0284, l1: 0.1932, vgg: 0.4735, mask: 0.3618\n",
      "step:   116920, time: 0.747, loss: 1.0987, l1: 0.2461, vgg: 0.4490, mask: 0.4037\n",
      "step:   116940, time: 0.715, loss: 0.9909, l1: 0.1984, vgg: 0.3998, mask: 0.3926\n",
      "step:   116960, time: 0.739, loss: 0.9803, l1: 0.1899, vgg: 0.4326, mask: 0.3579\n",
      "step:   116980, time: 0.770, loss: 1.0580, l1: 0.2409, vgg: 0.4512, mask: 0.3659\n",
      "step:   117000, time: 0.744, loss: 1.1500, l1: 0.2790, vgg: 0.4700, mask: 0.4010\n",
      "step:   117020, time: 0.738, loss: 1.0759, l1: 0.2387, vgg: 0.4393, mask: 0.3979\n",
      "step:   117040, time: 0.825, loss: 1.1295, l1: 0.2329, vgg: 0.4902, mask: 0.4064\n",
      "step:   117060, time: 0.781, loss: 1.1528, l1: 0.2552, vgg: 0.4985, mask: 0.3991\n",
      "step:   117080, time: 0.754, loss: 1.0292, l1: 0.2226, vgg: 0.4246, mask: 0.3820\n",
      "step:   117100, time: 0.775, loss: 1.1548, l1: 0.2544, vgg: 0.4788, mask: 0.4216\n",
      "step:   117120, time: 0.749, loss: 1.0193, l1: 0.1883, vgg: 0.4762, mask: 0.3548\n",
      "step:   117140, time: 0.749, loss: 0.9945, l1: 0.2071, vgg: 0.4413, mask: 0.3462\n",
      "step:   117160, time: 0.766, loss: 1.1110, l1: 0.2439, vgg: 0.4564, mask: 0.4106\n",
      "step:   117180, time: 0.762, loss: 1.0150, l1: 0.1841, vgg: 0.4626, mask: 0.3683\n",
      "step:   117200, time: 0.791, loss: 0.9780, l1: 0.2057, vgg: 0.4102, mask: 0.3620\n",
      "step:   117220, time: 0.766, loss: 1.0981, l1: 0.2042, vgg: 0.5324, mask: 0.3615\n",
      "step:   117240, time: 0.738, loss: 1.0825, l1: 0.2613, vgg: 0.4277, mask: 0.3936\n",
      "step:   117260, time: 0.779, loss: 1.1039, l1: 0.2232, vgg: 0.4756, mask: 0.4051\n",
      "step:   117280, time: 0.744, loss: 1.0831, l1: 0.2270, vgg: 0.4200, mask: 0.4361\n",
      "step:   117300, time: 0.735, loss: 1.0930, l1: 0.2735, vgg: 0.4041, mask: 0.4153\n",
      "step:   117320, time: 0.722, loss: 0.9379, l1: 0.1739, vgg: 0.3840, mask: 0.3800\n",
      "step:   117340, time: 0.746, loss: 1.0622, l1: 0.2384, vgg: 0.4262, mask: 0.3975\n",
      "step:   117360, time: 0.778, loss: 1.0427, l1: 0.1992, vgg: 0.4884, mask: 0.3550\n",
      "step:   117380, time: 0.763, loss: 1.1241, l1: 0.2847, vgg: 0.4326, mask: 0.4068\n",
      "step:   117400, time: 0.794, loss: 1.0579, l1: 0.2110, vgg: 0.4793, mask: 0.3676\n",
      "step:   117420, time: 0.750, loss: 0.9304, l1: 0.1589, vgg: 0.3977, mask: 0.3738\n",
      "step:   117440, time: 0.780, loss: 1.0980, l1: 0.2489, vgg: 0.4481, mask: 0.4010\n",
      "step:   117460, time: 0.787, loss: 1.1076, l1: 0.2546, vgg: 0.4590, mask: 0.3940\n",
      "step:   117480, time: 0.761, loss: 1.0624, l1: 0.1994, vgg: 0.4976, mask: 0.3654\n",
      "step:   117500, time: 0.748, loss: 1.1187, l1: 0.2298, vgg: 0.4763, mask: 0.4127\n",
      "step:   117520, time: 0.743, loss: 1.0321, l1: 0.2056, vgg: 0.4554, mask: 0.3710\n",
      "step:   117540, time: 0.744, loss: 0.9580, l1: 0.1841, vgg: 0.4246, mask: 0.3493\n",
      "step:   117560, time: 0.748, loss: 1.0443, l1: 0.2194, vgg: 0.4553, mask: 0.3696\n",
      "step:   117580, time: 0.742, loss: 1.0060, l1: 0.2088, vgg: 0.4235, mask: 0.3738\n",
      "step:   117600, time: 0.772, loss: 1.0870, l1: 0.2265, vgg: 0.4741, mask: 0.3864\n",
      "step:   117620, time: 0.751, loss: 1.0631, l1: 0.1957, vgg: 0.5020, mask: 0.3654\n",
      "step:   117640, time: 0.766, loss: 1.0853, l1: 0.2216, vgg: 0.4920, mask: 0.3717\n",
      "step:   117660, time: 0.760, loss: 1.1217, l1: 0.2713, vgg: 0.4489, mask: 0.4015\n",
      "step:   117680, time: 0.797, loss: 1.1118, l1: 0.2469, vgg: 0.4485, mask: 0.4164\n",
      "step:   117700, time: 0.758, loss: 1.1262, l1: 0.2609, vgg: 0.4773, mask: 0.3881\n",
      "step:   117720, time: 0.776, loss: 1.1835, l1: 0.2457, vgg: 0.5367, mask: 0.4012\n",
      "step:   117740, time: 0.744, loss: 1.0045, l1: 0.1977, vgg: 0.4388, mask: 0.3680\n",
      "step:   117760, time: 0.827, loss: 1.1996, l1: 0.2227, vgg: 0.5742, mask: 0.4027\n",
      "step:   117780, time: 0.742, loss: 1.0725, l1: 0.2138, vgg: 0.4851, mask: 0.3737\n",
      "step:   117800, time: 0.771, loss: 1.1432, l1: 0.2656, vgg: 0.4745, mask: 0.4032\n",
      "step:   117820, time: 0.726, loss: 0.9708, l1: 0.2158, vgg: 0.3720, mask: 0.3829\n",
      "step:   117840, time: 0.734, loss: 0.9829, l1: 0.2102, vgg: 0.4261, mask: 0.3466\n",
      "step:   117860, time: 0.751, loss: 1.0297, l1: 0.2519, vgg: 0.4053, mask: 0.3726\n",
      "step:   117880, time: 0.739, loss: 1.1015, l1: 0.2445, vgg: 0.4448, mask: 0.4122\n",
      "step:   117900, time: 0.767, loss: 1.1494, l1: 0.2609, vgg: 0.4851, mask: 0.4034\n",
      "step:   117920, time: 0.745, loss: 0.9658, l1: 0.1749, vgg: 0.4401, mask: 0.3508\n",
      "step:   117940, time: 0.756, loss: 1.0218, l1: 0.2215, vgg: 0.4157, mask: 0.3846\n",
      "step:   117960, time: 0.740, loss: 1.0268, l1: 0.2464, vgg: 0.4007, mask: 0.3797\n",
      "step:   117980, time: 0.753, loss: 1.0755, l1: 0.1999, vgg: 0.5066, mask: 0.3690\n",
      "step:   118000, time: 0.765, loss: 1.1764, l1: 0.2853, vgg: 0.4823, mask: 0.4088\n",
      "step:   118020, time: 0.751, loss: 1.1331, l1: 0.2291, vgg: 0.5077, mask: 0.3963\n",
      "step:   118040, time: 0.737, loss: 1.0664, l1: 0.2156, vgg: 0.4077, mask: 0.4431\n",
      "step:   118060, time: 0.759, loss: 1.0160, l1: 0.1763, vgg: 0.4543, mask: 0.3853\n",
      "step:   118080, time: 0.733, loss: 0.9648, l1: 0.1842, vgg: 0.4001, mask: 0.3805\n",
      "step:   118100, time: 0.715, loss: 0.9199, l1: 0.1555, vgg: 0.4162, mask: 0.3481\n",
      "step:   118120, time: 0.762, loss: 1.1102, l1: 0.2580, vgg: 0.4817, mask: 0.3705\n",
      "step:   118140, time: 0.757, loss: 1.1196, l1: 0.2846, vgg: 0.4506, mask: 0.3844\n",
      "step:   118160, time: 0.724, loss: 0.9435, l1: 0.1960, vgg: 0.3729, mask: 0.3746\n",
      "step:   118180, time: 0.734, loss: 1.0413, l1: 0.2498, vgg: 0.3806, mask: 0.4110\n",
      "step:   118200, time: 0.772, loss: 1.0469, l1: 0.2204, vgg: 0.4376, mask: 0.3889\n",
      "step:   118220, time: 0.774, loss: 1.1785, l1: 0.2538, vgg: 0.5232, mask: 0.4015\n",
      "step:   118240, time: 0.734, loss: 1.0063, l1: 0.2201, vgg: 0.4081, mask: 0.3781\n",
      "step:   118260, time: 0.737, loss: 0.9613, l1: 0.2108, vgg: 0.4018, mask: 0.3487\n",
      "step:   118280, time: 0.750, loss: 1.0788, l1: 0.2392, vgg: 0.4504, mask: 0.3891\n",
      "step:   118300, time: 0.756, loss: 0.9980, l1: 0.1724, vgg: 0.4706, mask: 0.3550\n",
      "step:   118320, time: 0.749, loss: 1.0059, l1: 0.2196, vgg: 0.4233, mask: 0.3631\n",
      "step:   118340, time: 0.754, loss: 1.0872, l1: 0.2368, vgg: 0.4573, mask: 0.3931\n",
      "step:   118360, time: 0.744, loss: 0.9271, l1: 0.1484, vgg: 0.4210, mask: 0.3576\n",
      "step:   118380, time: 0.721, loss: 0.9849, l1: 0.1722, vgg: 0.4459, mask: 0.3668\n",
      "step:   118400, time: 0.791, loss: 1.1212, l1: 0.2485, vgg: 0.4472, mask: 0.4255\n",
      "step:   118420, time: 0.801, loss: 1.1759, l1: 0.2645, vgg: 0.5124, mask: 0.3991\n",
      "step:   118440, time: 0.821, loss: 1.0701, l1: 0.2222, vgg: 0.4454, mask: 0.4024\n",
      "step:   118460, time: 0.765, loss: 1.0960, l1: 0.2526, vgg: 0.4443, mask: 0.3991\n",
      "step:   118480, time: 0.766, loss: 1.1765, l1: 0.2885, vgg: 0.4672, mask: 0.4208\n",
      "step:   118500, time: 0.798, loss: 1.0802, l1: 0.2522, vgg: 0.4307, mask: 0.3972\n",
      "step:   118520, time: 0.767, loss: 1.0467, l1: 0.2152, vgg: 0.4333, mask: 0.3983\n",
      "step:   118540, time: 0.757, loss: 1.0492, l1: 0.2341, vgg: 0.4376, mask: 0.3775\n",
      "step:   118560, time: 0.755, loss: 1.2651, l1: 0.3743, vgg: 0.4501, mask: 0.4408\n",
      "step:   118580, time: 0.805, loss: 1.1072, l1: 0.2278, vgg: 0.5019, mask: 0.3775\n",
      "step:   118600, time: 0.786, loss: 1.1073, l1: 0.2352, vgg: 0.4705, mask: 0.4017\n",
      "step:   118620, time: 0.786, loss: 1.0773, l1: 0.2264, vgg: 0.4404, mask: 0.4104\n",
      "step:   118640, time: 0.757, loss: 1.1688, l1: 0.2344, vgg: 0.5224, mask: 0.4120\n",
      "step:   118660, time: 0.751, loss: 1.0066, l1: 0.1922, vgg: 0.4291, mask: 0.3853\n",
      "step:   118680, time: 0.726, loss: 0.8788, l1: 0.1636, vgg: 0.3638, mask: 0.3514\n",
      "step:   118700, time: 0.794, loss: 1.1134, l1: 0.2646, vgg: 0.4346, mask: 0.4142\n",
      "step:   118720, time: 0.754, loss: 1.0946, l1: 0.2691, vgg: 0.4314, mask: 0.3941\n",
      "step:   118740, time: 0.744, loss: 0.9719, l1: 0.1914, vgg: 0.4244, mask: 0.3562\n",
      "step:   118760, time: 0.840, loss: 1.0893, l1: 0.1998, vgg: 0.5134, mask: 0.3761\n",
      "step:   118780, time: 0.759, loss: 1.1290, l1: 0.2236, vgg: 0.5033, mask: 0.4021\n",
      "step:   118800, time: 0.762, loss: 1.1104, l1: 0.2389, vgg: 0.4893, mask: 0.3822\n",
      "step:   118820, time: 0.789, loss: 1.0598, l1: 0.2319, vgg: 0.4541, mask: 0.3738\n",
      "step:   118840, time: 0.746, loss: 0.9581, l1: 0.1674, vgg: 0.4290, mask: 0.3617\n",
      "step:   118860, time: 0.762, loss: 1.0651, l1: 0.2095, vgg: 0.4516, mask: 0.4039\n",
      "step:   118880, time: 0.739, loss: 1.0136, l1: 0.2107, vgg: 0.4139, mask: 0.3889\n",
      "step:   118900, time: 0.773, loss: 1.1161, l1: 0.2418, vgg: 0.4880, mask: 0.3863\n",
      "step:   118920, time: 0.802, loss: 0.9810, l1: 0.1881, vgg: 0.4434, mask: 0.3495\n",
      "step:   118940, time: 0.766, loss: 0.9101, l1: 0.1854, vgg: 0.3694, mask: 0.3553\n",
      "step:   118960, time: 0.762, loss: 0.9971, l1: 0.2372, vgg: 0.3754, mask: 0.3845\n",
      "step:   118980, time: 0.768, loss: 1.1824, l1: 0.2557, vgg: 0.5148, mask: 0.4118\n",
      "step:   119000, time: 0.733, loss: 0.9604, l1: 0.1931, vgg: 0.4092, mask: 0.3581\n",
      "step:   119020, time: 0.772, loss: 0.9653, l1: 0.1853, vgg: 0.3852, mask: 0.3948\n",
      "step:   119040, time: 0.750, loss: 0.9994, l1: 0.2100, vgg: 0.4115, mask: 0.3779\n",
      "step:   119060, time: 0.748, loss: 0.9757, l1: 0.1885, vgg: 0.4206, mask: 0.3667\n",
      "step:   119080, time: 0.775, loss: 1.0089, l1: 0.1872, vgg: 0.4532, mask: 0.3685\n",
      "step:   119100, time: 0.756, loss: 0.9488, l1: 0.1680, vgg: 0.4391, mask: 0.3417\n",
      "step:   119120, time: 0.773, loss: 0.9365, l1: 0.1595, vgg: 0.4092, mask: 0.3678\n",
      "step:   119140, time: 0.806, loss: 1.0029, l1: 0.2435, vgg: 0.3970, mask: 0.3624\n",
      "step:   119160, time: 0.769, loss: 1.0184, l1: 0.1824, vgg: 0.4269, mask: 0.4091\n",
      "step:   119180, time: 0.741, loss: 1.0209, l1: 0.2256, vgg: 0.3987, mask: 0.3966\n",
      "step:   119200, time: 0.727, loss: 0.9648, l1: 0.1750, vgg: 0.4219, mask: 0.3679\n",
      "step:   119220, time: 0.744, loss: 1.0371, l1: 0.1787, vgg: 0.4948, mask: 0.3636\n",
      "step:   119240, time: 0.773, loss: 1.2305, l1: 0.2965, vgg: 0.5217, mask: 0.4124\n",
      "step:   119260, time: 0.739, loss: 0.9856, l1: 0.1752, vgg: 0.4359, mask: 0.3744\n",
      "step:   119280, time: 0.812, loss: 1.1276, l1: 0.2103, vgg: 0.5275, mask: 0.3898\n",
      "step:   119300, time: 0.772, loss: 0.9959, l1: 0.1853, vgg: 0.4387, mask: 0.3719\n",
      "step:   119320, time: 0.778, loss: 1.0421, l1: 0.2095, vgg: 0.4525, mask: 0.3801\n",
      "step:   119340, time: 0.851, loss: 1.0573, l1: 0.2113, vgg: 0.4537, mask: 0.3923\n",
      "step:   119360, time: 0.794, loss: 1.0789, l1: 0.2184, vgg: 0.4447, mask: 0.4157\n",
      "step:   119380, time: 0.806, loss: 1.0997, l1: 0.2380, vgg: 0.4635, mask: 0.3983\n",
      "step:   119400, time: 0.802, loss: 1.0773, l1: 0.2372, vgg: 0.4741, mask: 0.3660\n",
      "step:   119420, time: 0.785, loss: 1.0085, l1: 0.1854, vgg: 0.4647, mask: 0.3584\n",
      "step:   119440, time: 0.744, loss: 1.1061, l1: 0.2313, vgg: 0.4815, mask: 0.3932\n",
      "step:   119460, time: 0.770, loss: 1.0889, l1: 0.2332, vgg: 0.4664, mask: 0.3893\n",
      "step:   119480, time: 0.764, loss: 0.9824, l1: 0.2057, vgg: 0.3972, mask: 0.3795\n",
      "step:   119500, time: 0.743, loss: 0.9873, l1: 0.1827, vgg: 0.4253, mask: 0.3794\n",
      "step:   119520, time: 0.800, loss: 1.1136, l1: 0.2281, vgg: 0.4781, mask: 0.4074\n",
      "step:   119540, time: 0.782, loss: 1.0401, l1: 0.2378, vgg: 0.4602, mask: 0.3420\n",
      "step:   119560, time: 0.734, loss: 1.0124, l1: 0.1879, vgg: 0.4350, mask: 0.3895\n",
      "step:   119580, time: 0.764, loss: 1.0392, l1: 0.1755, vgg: 0.4554, mask: 0.4082\n",
      "step:   119600, time: 0.750, loss: 1.0342, l1: 0.2135, vgg: 0.4737, mask: 0.3471\n",
      "step:   119620, time: 0.754, loss: 1.1052, l1: 0.2019, vgg: 0.5254, mask: 0.3779\n",
      "step:   119640, time: 0.743, loss: 0.9087, l1: 0.1569, vgg: 0.4081, mask: 0.3437\n",
      "step:   119660, time: 0.756, loss: 1.0212, l1: 0.1898, vgg: 0.4542, mask: 0.3772\n",
      "step:   119680, time: 0.753, loss: 1.1467, l1: 0.2564, vgg: 0.4805, mask: 0.4098\n",
      "step:   119700, time: 0.739, loss: 0.9715, l1: 0.1787, vgg: 0.4202, mask: 0.3726\n",
      "step:   119720, time: 0.757, loss: 1.0318, l1: 0.2414, vgg: 0.4051, mask: 0.3854\n",
      "step:   119740, time: 0.752, loss: 1.0728, l1: 0.2186, vgg: 0.4736, mask: 0.3806\n",
      "step:   119760, time: 0.816, loss: 1.1643, l1: 0.2512, vgg: 0.4945, mask: 0.4186\n",
      "step:   119780, time: 0.762, loss: 1.1524, l1: 0.2507, vgg: 0.5086, mask: 0.3931\n",
      "step:   119800, time: 0.759, loss: 1.0549, l1: 0.2562, vgg: 0.4162, mask: 0.3825\n",
      "step:   119820, time: 0.759, loss: 0.9588, l1: 0.1782, vgg: 0.4194, mask: 0.3612\n",
      "step:   119840, time: 0.786, loss: 1.0134, l1: 0.2053, vgg: 0.4333, mask: 0.3748\n",
      "step:   119860, time: 0.786, loss: 1.0846, l1: 0.1937, vgg: 0.4995, mask: 0.3914\n",
      "step:   119880, time: 0.778, loss: 1.0048, l1: 0.2077, vgg: 0.3992, mask: 0.3979\n",
      "step:   119900, time: 0.755, loss: 1.0769, l1: 0.2351, vgg: 0.4579, mask: 0.3839\n",
      "step:   119920, time: 0.744, loss: 0.9799, l1: 0.1796, vgg: 0.4382, mask: 0.3622\n",
      "step:   119940, time: 0.739, loss: 1.0254, l1: 0.2561, vgg: 0.3608, mask: 0.4085\n",
      "step:   119960, time: 0.789, loss: 1.0211, l1: 0.1841, vgg: 0.4692, mask: 0.3677\n",
      "step:   119980, time: 0.747, loss: 0.9763, l1: 0.1980, vgg: 0.3844, mask: 0.3938\n",
      "step:   120000, time: 0.810, loss: 1.0195, l1: 0.2003, vgg: 0.4643, mask: 0.3549\n",
      "step:   120020, time: 0.769, loss: 1.0696, l1: 0.2084, vgg: 0.4520, mask: 0.4091\n",
      "step:   120040, time: 0.751, loss: 1.0643, l1: 0.2494, vgg: 0.4352, mask: 0.3797\n",
      "step:   120060, time: 0.774, loss: 1.0161, l1: 0.2118, vgg: 0.4264, mask: 0.3780\n",
      "step:   120080, time: 0.748, loss: 0.8771, l1: 0.1502, vgg: 0.3878, mask: 0.3391\n",
      "step:   120100, time: 0.769, loss: 1.0405, l1: 0.2024, vgg: 0.4583, mask: 0.3798\n",
      "step:   120120, time: 0.746, loss: 0.9672, l1: 0.2122, vgg: 0.3614, mask: 0.3936\n",
      "step:   120140, time: 0.795, loss: 1.0829, l1: 0.2630, vgg: 0.3901, mask: 0.4298\n",
      "step:   120160, time: 0.748, loss: 1.1162, l1: 0.2428, vgg: 0.4589, mask: 0.4145\n",
      "step:   120180, time: 0.767, loss: 1.0073, l1: 0.1959, vgg: 0.4483, mask: 0.3631\n",
      "step:   120200, time: 0.792, loss: 1.0110, l1: 0.2259, vgg: 0.3935, mask: 0.3916\n",
      "step:   120220, time: 0.793, loss: 1.1140, l1: 0.2073, vgg: 0.5219, mask: 0.3848\n",
      "step:   120240, time: 0.745, loss: 0.9644, l1: 0.2128, vgg: 0.4010, mask: 0.3506\n",
      "step:   120260, time: 0.745, loss: 0.9749, l1: 0.1871, vgg: 0.4374, mask: 0.3504\n",
      "step:   120280, time: 0.747, loss: 1.1928, l1: 0.2884, vgg: 0.4838, mask: 0.4206\n",
      "step:   120300, time: 0.720, loss: 0.9573, l1: 0.1648, vgg: 0.4117, mask: 0.3807\n",
      "step:   120320, time: 0.768, loss: 1.0904, l1: 0.2564, vgg: 0.4599, mask: 0.3742\n",
      "step:   120340, time: 0.756, loss: 1.0307, l1: 0.1739, vgg: 0.5033, mask: 0.3535\n",
      "step:   120360, time: 0.800, loss: 1.1080, l1: 0.2385, vgg: 0.4931, mask: 0.3763\n",
      "step:   120380, time: 0.790, loss: 1.1611, l1: 0.2563, vgg: 0.4977, mask: 0.4071\n",
      "step:   120400, time: 0.732, loss: 0.8931, l1: 0.1973, vgg: 0.3438, mask: 0.3519\n",
      "step:   120420, time: 0.767, loss: 1.0441, l1: 0.2160, vgg: 0.4612, mask: 0.3669\n",
      "step:   120440, time: 0.717, loss: 1.0410, l1: 0.1868, vgg: 0.4878, mask: 0.3664\n",
      "step:   120460, time: 0.735, loss: 1.0400, l1: 0.2110, vgg: 0.4607, mask: 0.3682\n",
      "step:   120480, time: 0.741, loss: 1.1394, l1: 0.2728, vgg: 0.4521, mask: 0.4145\n",
      "step:   120500, time: 0.730, loss: 0.9984, l1: 0.1930, vgg: 0.4015, mask: 0.4039\n",
      "step:   120520, time: 0.757, loss: 1.1050, l1: 0.2240, vgg: 0.5231, mask: 0.3580\n",
      "step:   120540, time: 0.766, loss: 1.0638, l1: 0.1898, vgg: 0.4748, mask: 0.3992\n",
      "step:   120560, time: 0.778, loss: 1.0754, l1: 0.1838, vgg: 0.5155, mask: 0.3761\n",
      "step:   120580, time: 0.747, loss: 1.0788, l1: 0.2408, vgg: 0.4131, mask: 0.4248\n",
      "step:   120600, time: 0.756, loss: 1.0412, l1: 0.2166, vgg: 0.4500, mask: 0.3746\n",
      "step:   120620, time: 0.753, loss: 1.1810, l1: 0.2715, vgg: 0.5291, mask: 0.3805\n",
      "step:   120640, time: 0.759, loss: 1.1787, l1: 0.2386, vgg: 0.5156, mask: 0.4244\n",
      "step:   120660, time: 0.773, loss: 1.1694, l1: 0.2531, vgg: 0.5315, mask: 0.3847\n",
      "step:   120680, time: 0.784, loss: 1.1457, l1: 0.2533, vgg: 0.4852, mask: 0.4072\n",
      "step:   120700, time: 0.766, loss: 0.9700, l1: 0.1963, vgg: 0.4201, mask: 0.3535\n",
      "step:   120720, time: 0.762, loss: 1.0078, l1: 0.1931, vgg: 0.4209, mask: 0.3938\n",
      "step:   120740, time: 0.729, loss: 1.0678, l1: 0.2503, vgg: 0.4189, mask: 0.3986\n",
      "step:   120760, time: 0.726, loss: 0.9632, l1: 0.1751, vgg: 0.4434, mask: 0.3447\n",
      "step:   120780, time: 0.763, loss: 1.1308, l1: 0.2530, vgg: 0.4837, mask: 0.3940\n",
      "step:   120800, time: 0.746, loss: 0.9889, l1: 0.1868, vgg: 0.4262, mask: 0.3759\n",
      "step:   120820, time: 0.750, loss: 0.9774, l1: 0.2166, vgg: 0.3910, mask: 0.3699\n",
      "step:   120840, time: 0.737, loss: 1.0752, l1: 0.2501, vgg: 0.4124, mask: 0.4127\n",
      "step:   120860, time: 0.730, loss: 1.0190, l1: 0.1891, vgg: 0.4362, mask: 0.3938\n",
      "step:   120880, time: 0.774, loss: 0.9950, l1: 0.2094, vgg: 0.3816, mask: 0.4039\n",
      "step:   120900, time: 0.739, loss: 0.9705, l1: 0.1704, vgg: 0.4279, mask: 0.3722\n",
      "step:   120920, time: 0.734, loss: 0.9014, l1: 0.1522, vgg: 0.3905, mask: 0.3587\n",
      "step:   120940, time: 0.773, loss: 1.0017, l1: 0.2013, vgg: 0.4267, mask: 0.3737\n",
      "step:   120960, time: 0.785, loss: 1.0557, l1: 0.2210, vgg: 0.4571, mask: 0.3776\n",
      "step:   120980, time: 0.775, loss: 1.0096, l1: 0.2047, vgg: 0.4303, mask: 0.3745\n",
      "step:   121000, time: 0.780, loss: 1.0935, l1: 0.2112, vgg: 0.4933, mask: 0.3891\n",
      "step:   121020, time: 0.751, loss: 0.9836, l1: 0.2093, vgg: 0.4193, mask: 0.3550\n",
      "step:   121040, time: 0.780, loss: 0.9899, l1: 0.1603, vgg: 0.4476, mask: 0.3820\n",
      "step:   121060, time: 0.762, loss: 1.1045, l1: 0.2758, vgg: 0.4622, mask: 0.3665\n",
      "step:   121080, time: 0.761, loss: 1.0181, l1: 0.2060, vgg: 0.4021, mask: 0.4099\n",
      "step:   121100, time: 0.776, loss: 1.0061, l1: 0.2144, vgg: 0.4202, mask: 0.3714\n",
      "step:   121120, time: 0.731, loss: 1.0374, l1: 0.2194, vgg: 0.4420, mask: 0.3760\n",
      "step:   121140, time: 0.769, loss: 1.0646, l1: 0.2463, vgg: 0.4381, mask: 0.3802\n",
      "step:   121160, time: 0.761, loss: 0.9586, l1: 0.1434, vgg: 0.4200, mask: 0.3953\n",
      "step:   121180, time: 0.726, loss: 1.0663, l1: 0.2426, vgg: 0.4387, mask: 0.3850\n",
      "step:   121200, time: 0.753, loss: 1.0602, l1: 0.2426, vgg: 0.4215, mask: 0.3960\n",
      "step:   121220, time: 0.767, loss: 1.0697, l1: 0.2163, vgg: 0.4829, mask: 0.3705\n",
      "step:   121240, time: 0.811, loss: 1.0892, l1: 0.2609, vgg: 0.4583, mask: 0.3700\n",
      "step:   121260, time: 0.775, loss: 1.0588, l1: 0.2164, vgg: 0.4701, mask: 0.3723\n",
      "step:   121280, time: 0.729, loss: 1.0201, l1: 0.2382, vgg: 0.4062, mask: 0.3757\n",
      "step:   121300, time: 0.739, loss: 0.9212, l1: 0.1733, vgg: 0.4036, mask: 0.3443\n",
      "step:   121320, time: 0.742, loss: 0.9948, l1: 0.2153, vgg: 0.4061, mask: 0.3735\n",
      "step:   121340, time: 0.787, loss: 1.0915, l1: 0.2249, vgg: 0.4847, mask: 0.3820\n",
      "step:   121360, time: 0.742, loss: 1.0642, l1: 0.2269, vgg: 0.4690, mask: 0.3683\n",
      "step:   121380, time: 0.762, loss: 1.1742, l1: 0.2591, vgg: 0.5230, mask: 0.3920\n",
      "step:   121400, time: 0.749, loss: 0.9487, l1: 0.1781, vgg: 0.4181, mask: 0.3524\n",
      "step:   121420, time: 0.706, loss: 0.9218, l1: 0.1469, vgg: 0.4475, mask: 0.3274\n",
      "step:   121440, time: 0.743, loss: 1.1187, l1: 0.2365, vgg: 0.4966, mask: 0.3855\n",
      "step:   121460, time: 0.732, loss: 1.0245, l1: 0.1879, vgg: 0.4572, mask: 0.3793\n",
      "step:   121480, time: 0.766, loss: 1.0791, l1: 0.2247, vgg: 0.4802, mask: 0.3742\n",
      "step:   121500, time: 0.748, loss: 1.0256, l1: 0.2247, vgg: 0.4085, mask: 0.3924\n",
      "step:   121520, time: 0.784, loss: 1.0903, l1: 0.2207, vgg: 0.4942, mask: 0.3754\n",
      "step:   121540, time: 0.734, loss: 1.0171, l1: 0.1880, vgg: 0.4588, mask: 0.3703\n",
      "step:   121560, time: 0.788, loss: 1.0458, l1: 0.2457, vgg: 0.4197, mask: 0.3804\n",
      "step:   121580, time: 0.729, loss: 1.0463, l1: 0.1835, vgg: 0.5159, mask: 0.3469\n",
      "step:   121600, time: 0.751, loss: 1.0688, l1: 0.2609, vgg: 0.4347, mask: 0.3732\n",
      "step:   121620, time: 0.739, loss: 0.9832, l1: 0.1816, vgg: 0.4616, mask: 0.3400\n",
      "step:   121640, time: 0.727, loss: 1.0850, l1: 0.2358, vgg: 0.4394, mask: 0.4098\n",
      "step:   121660, time: 0.758, loss: 0.9887, l1: 0.2258, vgg: 0.4068, mask: 0.3562\n",
      "step:   121680, time: 0.729, loss: 1.1120, l1: 0.2535, vgg: 0.4724, mask: 0.3861\n",
      "step:   121700, time: 0.758, loss: 0.9976, l1: 0.1959, vgg: 0.4260, mask: 0.3757\n",
      "step:   121720, time: 0.743, loss: 1.0097, l1: 0.1954, vgg: 0.4520, mask: 0.3623\n",
      "step:   121740, time: 0.743, loss: 0.9530, l1: 0.1849, vgg: 0.4076, mask: 0.3604\n",
      "step:   121760, time: 0.753, loss: 1.0081, l1: 0.1654, vgg: 0.4821, mask: 0.3606\n",
      "step:   121780, time: 0.734, loss: 0.9077, l1: 0.1790, vgg: 0.3934, mask: 0.3354\n",
      "step:   121800, time: 0.729, loss: 0.9799, l1: 0.2060, vgg: 0.3990, mask: 0.3749\n",
      "step:   121820, time: 0.744, loss: 1.1440, l1: 0.2397, vgg: 0.5086, mask: 0.3957\n",
      "step:   121840, time: 0.728, loss: 0.9892, l1: 0.2099, vgg: 0.4263, mask: 0.3530\n",
      "step:   121860, time: 0.764, loss: 1.1037, l1: 0.2446, vgg: 0.4559, mask: 0.4032\n",
      "step:   121880, time: 0.715, loss: 0.9001, l1: 0.1977, vgg: 0.3581, mask: 0.3443\n",
      "step:   121900, time: 0.765, loss: 1.1442, l1: 0.2348, vgg: 0.4994, mask: 0.4101\n",
      "step:   121920, time: 0.739, loss: 0.8899, l1: 0.1485, vgg: 0.4100, mask: 0.3314\n",
      "step:   121940, time: 0.728, loss: 0.9718, l1: 0.1503, vgg: 0.4617, mask: 0.3598\n",
      "step:   121960, time: 0.748, loss: 1.0712, l1: 0.2290, vgg: 0.4769, mask: 0.3653\n",
      "step:   121980, time: 0.749, loss: 0.9579, l1: 0.1861, vgg: 0.4160, mask: 0.3559\n",
      "step:   122000, time: 0.733, loss: 0.8933, l1: 0.1654, vgg: 0.3835, mask: 0.3444\n",
      "step:   122020, time: 0.760, loss: 0.9807, l1: 0.1899, vgg: 0.4406, mask: 0.3503\n",
      "step:   122040, time: 0.728, loss: 0.8880, l1: 0.1371, vgg: 0.3904, mask: 0.3606\n",
      "step:   122060, time: 0.740, loss: 1.0425, l1: 0.2048, vgg: 0.4558, mask: 0.3819\n",
      "step:   122080, time: 0.724, loss: 1.1155, l1: 0.2974, vgg: 0.4229, mask: 0.3953\n",
      "step:   122100, time: 0.758, loss: 1.0263, l1: 0.2047, vgg: 0.4569, mask: 0.3647\n",
      "step:   122120, time: 0.749, loss: 1.0265, l1: 0.2098, vgg: 0.4544, mask: 0.3623\n",
      "step:   122140, time: 0.776, loss: 0.9809, l1: 0.1772, vgg: 0.4162, mask: 0.3875\n",
      "step:   122160, time: 0.768, loss: 1.1286, l1: 0.2697, vgg: 0.4561, mask: 0.4028\n",
      "step:   122180, time: 0.752, loss: 1.0304, l1: 0.1952, vgg: 0.4779, mask: 0.3573\n",
      "step:   122200, time: 0.758, loss: 0.8982, l1: 0.1576, vgg: 0.4086, mask: 0.3319\n",
      "step:   122220, time: 0.775, loss: 1.0540, l1: 0.2038, vgg: 0.4400, mask: 0.4101\n",
      "step:   122240, time: 0.761, loss: 1.0659, l1: 0.2251, vgg: 0.4584, mask: 0.3824\n",
      "step:   122260, time: 0.766, loss: 1.0046, l1: 0.2237, vgg: 0.4112, mask: 0.3696\n",
      "step:   122280, time: 0.755, loss: 1.1336, l1: 0.2577, vgg: 0.4781, mask: 0.3979\n",
      "step:   122300, time: 0.737, loss: 1.1341, l1: 0.2849, vgg: 0.4394, mask: 0.4099\n",
      "step:   122320, time: 0.755, loss: 1.0306, l1: 0.1950, vgg: 0.4728, mask: 0.3628\n",
      "step:   122340, time: 0.769, loss: 1.0374, l1: 0.2344, vgg: 0.4360, mask: 0.3670\n",
      "step:   122360, time: 0.788, loss: 1.0690, l1: 0.1891, vgg: 0.5016, mask: 0.3782\n",
      "step:   122380, time: 0.773, loss: 1.0107, l1: 0.1838, vgg: 0.4634, mask: 0.3635\n",
      "step:   122400, time: 0.758, loss: 0.9891, l1: 0.1970, vgg: 0.4321, mask: 0.3600\n",
      "step:   122420, time: 0.781, loss: 1.1672, l1: 0.2840, vgg: 0.4929, mask: 0.3902\n",
      "step:   122440, time: 0.744, loss: 1.0627, l1: 0.2065, vgg: 0.4841, mask: 0.3721\n",
      "step:   122460, time: 0.744, loss: 0.9839, l1: 0.1824, vgg: 0.4192, mask: 0.3823\n",
      "step:   122480, time: 0.754, loss: 1.0427, l1: 0.2168, vgg: 0.4488, mask: 0.3770\n",
      "step:   122500, time: 0.765, loss: 1.0690, l1: 0.2336, vgg: 0.4393, mask: 0.3961\n",
      "step:   122520, time: 0.771, loss: 1.0455, l1: 0.2188, vgg: 0.4126, mask: 0.4142\n",
      "step:   122540, time: 0.711, loss: 0.9459, l1: 0.1954, vgg: 0.4023, mask: 0.3483\n",
      "step:   122560, time: 0.737, loss: 0.9573, l1: 0.1696, vgg: 0.4347, mask: 0.3530\n",
      "step:   122580, time: 0.753, loss: 0.8847, l1: 0.1479, vgg: 0.4088, mask: 0.3280\n",
      "step:   122600, time: 0.721, loss: 0.8256, l1: 0.1481, vgg: 0.3526, mask: 0.3249\n",
      "step:   122620, time: 0.738, loss: 0.9399, l1: 0.1865, vgg: 0.3618, mask: 0.3915\n",
      "step:   122640, time: 0.740, loss: 1.0399, l1: 0.1987, vgg: 0.4920, mask: 0.3492\n",
      "step:   122660, time: 0.794, loss: 1.2569, l1: 0.2884, vgg: 0.5647, mask: 0.4039\n",
      "step:   122680, time: 0.762, loss: 1.0318, l1: 0.1747, vgg: 0.4703, mask: 0.3868\n",
      "step:   122700, time: 0.752, loss: 0.9507, l1: 0.2036, vgg: 0.3951, mask: 0.3520\n",
      "step:   122720, time: 0.740, loss: 1.0482, l1: 0.1856, vgg: 0.4479, mask: 0.4148\n",
      "step:   122740, time: 0.756, loss: 1.0976, l1: 0.2340, vgg: 0.4614, mask: 0.4022\n",
      "step:   122760, time: 0.781, loss: 1.1205, l1: 0.2845, vgg: 0.4102, mask: 0.4258\n",
      "step:   122780, time: 0.734, loss: 1.0260, l1: 0.1993, vgg: 0.4236, mask: 0.4032\n",
      "step:   122800, time: 0.764, loss: 1.0648, l1: 0.2094, vgg: 0.4777, mask: 0.3777\n",
      "step:   122820, time: 0.777, loss: 1.0792, l1: 0.2288, vgg: 0.4759, mask: 0.3745\n",
      "step:   122840, time: 0.773, loss: 1.0818, l1: 0.2159, vgg: 0.4552, mask: 0.4107\n",
      "step:   122860, time: 0.730, loss: 0.9535, l1: 0.1891, vgg: 0.3944, mask: 0.3701\n",
      "step:   122880, time: 0.793, loss: 1.0952, l1: 0.2239, vgg: 0.4736, mask: 0.3977\n",
      "step:   122900, time: 0.750, loss: 1.0270, l1: 0.2127, vgg: 0.4372, mask: 0.3771\n",
      "step:   122920, time: 0.758, loss: 1.0814, l1: 0.2617, vgg: 0.4227, mask: 0.3970\n",
      "step:   122940, time: 0.744, loss: 0.9822, l1: 0.2207, vgg: 0.3700, mask: 0.3916\n",
      "step:   122960, time: 0.742, loss: 1.0332, l1: 0.1968, vgg: 0.4785, mask: 0.3579\n",
      "step:   122980, time: 0.756, loss: 1.0526, l1: 0.1774, vgg: 0.4616, mask: 0.4136\n",
      "step:   123000, time: 0.758, loss: 0.9789, l1: 0.1580, vgg: 0.4446, mask: 0.3763\n",
      "step:   123020, time: 0.764, loss: 1.1409, l1: 0.2298, vgg: 0.4695, mask: 0.4416\n",
      "step:   123040, time: 0.777, loss: 1.0327, l1: 0.2148, vgg: 0.4106, mask: 0.4073\n",
      "step:   123060, time: 0.772, loss: 1.0924, l1: 0.2204, vgg: 0.5054, mask: 0.3666\n",
      "step:   123080, time: 0.760, loss: 1.1319, l1: 0.2195, vgg: 0.5152, mask: 0.3972\n",
      "step:   123100, time: 0.785, loss: 1.1123, l1: 0.2379, vgg: 0.4724, mask: 0.4019\n",
      "step:   123120, time: 0.737, loss: 0.8879, l1: 0.1464, vgg: 0.4047, mask: 0.3367\n",
      "step:   123140, time: 0.791, loss: 1.0372, l1: 0.2408, vgg: 0.4450, mask: 0.3514\n",
      "step:   123160, time: 0.731, loss: 0.9811, l1: 0.2018, vgg: 0.4241, mask: 0.3553\n",
      "step:   123180, time: 0.803, loss: 1.1374, l1: 0.2748, vgg: 0.4925, mask: 0.3700\n",
      "step:   123200, time: 0.750, loss: 0.9064, l1: 0.1516, vgg: 0.4218, mask: 0.3330\n",
      "step:   123220, time: 0.771, loss: 1.1127, l1: 0.2125, vgg: 0.5229, mask: 0.3773\n",
      "step:   123240, time: 0.726, loss: 0.9105, l1: 0.1841, vgg: 0.3896, mask: 0.3367\n",
      "step:   123260, time: 0.742, loss: 1.0196, l1: 0.2155, vgg: 0.4211, mask: 0.3830\n",
      "step:   123280, time: 0.737, loss: 0.9489, l1: 0.1591, vgg: 0.4313, mask: 0.3585\n",
      "step:   123300, time: 0.718, loss: 1.0048, l1: 0.2227, vgg: 0.4041, mask: 0.3780\n",
      "step:   123320, time: 0.734, loss: 1.0436, l1: 0.2399, vgg: 0.3916, mask: 0.4121\n",
      "step:   123340, time: 0.779, loss: 1.0396, l1: 0.2228, vgg: 0.4293, mask: 0.3875\n",
      "step:   123360, time: 0.724, loss: 0.9467, l1: 0.1628, vgg: 0.4502, mask: 0.3338\n",
      "step:   123380, time: 0.759, loss: 1.0733, l1: 0.2141, vgg: 0.4796, mask: 0.3797\n",
      "step:   123400, time: 0.748, loss: 1.0461, l1: 0.1931, vgg: 0.4645, mask: 0.3886\n",
      "step:   123420, time: 0.759, loss: 1.1388, l1: 0.2613, vgg: 0.4588, mask: 0.4186\n",
      "step:   123440, time: 0.769, loss: 1.1635, l1: 0.2751, vgg: 0.4678, mask: 0.4205\n",
      "step:   123460, time: 0.749, loss: 1.0028, l1: 0.1734, vgg: 0.4355, mask: 0.3939\n",
      "step:   123480, time: 0.777, loss: 1.1867, l1: 0.2457, vgg: 0.5372, mask: 0.4038\n",
      "step:   123500, time: 0.751, loss: 1.0652, l1: 0.1925, vgg: 0.4408, mask: 0.4319\n",
      "step:   123520, time: 0.758, loss: 1.0083, l1: 0.1866, vgg: 0.4595, mask: 0.3623\n",
      "step:   123540, time: 0.739, loss: 1.0582, l1: 0.2172, vgg: 0.4595, mask: 0.3815\n",
      "step:   123560, time: 0.779, loss: 1.0343, l1: 0.1972, vgg: 0.4668, mask: 0.3703\n",
      "step:   123580, time: 0.723, loss: 1.0940, l1: 0.2111, vgg: 0.4741, mask: 0.4088\n",
      "step:   123600, time: 0.737, loss: 0.9513, l1: 0.1962, vgg: 0.4050, mask: 0.3501\n",
      "step:   123620, time: 0.758, loss: 0.9595, l1: 0.1621, vgg: 0.4355, mask: 0.3619\n",
      "step:   123640, time: 0.761, loss: 1.0909, l1: 0.2370, vgg: 0.4722, mask: 0.3817\n",
      "step:   123660, time: 0.793, loss: 1.0853, l1: 0.2363, vgg: 0.4702, mask: 0.3788\n",
      "step:   123680, time: 0.754, loss: 1.1198, l1: 0.2888, vgg: 0.4132, mask: 0.4177\n",
      "step:   123700, time: 0.818, loss: 1.1320, l1: 0.2545, vgg: 0.4764, mask: 0.4010\n",
      "step:   123720, time: 0.749, loss: 1.0805, l1: 0.2323, vgg: 0.4446, mask: 0.4036\n",
      "step:   123740, time: 0.763, loss: 0.9977, l1: 0.1712, vgg: 0.4606, mask: 0.3659\n",
      "step:   123760, time: 0.785, loss: 1.1487, l1: 0.2864, vgg: 0.4577, mask: 0.4046\n",
      "step:   123780, time: 0.736, loss: 1.1054, l1: 0.2329, vgg: 0.4691, mask: 0.4033\n",
      "step:   123800, time: 0.745, loss: 0.9181, l1: 0.1650, vgg: 0.4151, mask: 0.3381\n",
      "step:   123820, time: 0.725, loss: 0.9613, l1: 0.1936, vgg: 0.3863, mask: 0.3814\n",
      "step:   123840, time: 0.748, loss: 1.0868, l1: 0.2132, vgg: 0.4541, mask: 0.4195\n",
      "step:   123860, time: 0.768, loss: 0.9581, l1: 0.1720, vgg: 0.4534, mask: 0.3327\n",
      "step:   123880, time: 0.774, loss: 1.0213, l1: 0.2062, vgg: 0.4413, mask: 0.3738\n",
      "step:   123900, time: 0.738, loss: 1.0931, l1: 0.2277, vgg: 0.4886, mask: 0.3768\n",
      "step:   123920, time: 0.745, loss: 0.9999, l1: 0.2231, vgg: 0.3568, mask: 0.4200\n",
      "step:   123940, time: 0.719, loss: 1.0178, l1: 0.2197, vgg: 0.4068, mask: 0.3914\n",
      "step:   123960, time: 0.740, loss: 0.9377, l1: 0.1451, vgg: 0.4465, mask: 0.3461\n",
      "step:   123980, time: 0.762, loss: 1.0542, l1: 0.2136, vgg: 0.4724, mask: 0.3682\n",
      "step:   124000, time: 0.755, loss: 1.0460, l1: 0.2015, vgg: 0.4613, mask: 0.3832\n",
      "step:   124020, time: 0.749, loss: 1.0048, l1: 0.1809, vgg: 0.4522, mask: 0.3718\n",
      "step:   124040, time: 0.759, loss: 0.9497, l1: 0.1709, vgg: 0.3999, mask: 0.3789\n",
      "step:   124060, time: 0.742, loss: 1.1403, l1: 0.2196, vgg: 0.5432, mask: 0.3774\n",
      "step:   124080, time: 0.748, loss: 1.1340, l1: 0.2582, vgg: 0.4796, mask: 0.3962\n",
      "step:   124100, time: 0.779, loss: 1.2080, l1: 0.2534, vgg: 0.5203, mask: 0.4344\n",
      "step:   124120, time: 0.746, loss: 1.0921, l1: 0.2238, vgg: 0.5110, mask: 0.3573\n",
      "step:   124140, time: 0.736, loss: 1.1288, l1: 0.2529, vgg: 0.4919, mask: 0.3840\n",
      "step:   124160, time: 0.734, loss: 0.9900, l1: 0.1736, vgg: 0.4406, mask: 0.3759\n",
      "step:   124180, time: 0.749, loss: 1.0385, l1: 0.1596, vgg: 0.5377, mask: 0.3412\n",
      "step:   124200, time: 0.730, loss: 1.0576, l1: 0.2299, vgg: 0.4324, mask: 0.3954\n",
      "step:   124220, time: 0.741, loss: 1.0287, l1: 0.1879, vgg: 0.4787, mask: 0.3621\n",
      "step:   124240, time: 0.748, loss: 0.8817, l1: 0.1839, vgg: 0.3497, mask: 0.3482\n",
      "step:   124260, time: 0.752, loss: 1.0940, l1: 0.1761, vgg: 0.5193, mask: 0.3985\n",
      "step:   124280, time: 0.747, loss: 0.9419, l1: 0.1848, vgg: 0.3615, mask: 0.3956\n",
      "step:   124300, time: 0.763, loss: 1.0315, l1: 0.2093, vgg: 0.4188, mask: 0.4034\n",
      "step:   124320, time: 0.763, loss: 1.0058, l1: 0.2025, vgg: 0.4368, mask: 0.3665\n",
      "step:   124340, time: 0.744, loss: 1.0753, l1: 0.2353, vgg: 0.4229, mask: 0.4171\n",
      "step:   124360, time: 0.793, loss: 0.9707, l1: 0.1891, vgg: 0.4018, mask: 0.3798\n",
      "step:   124380, time: 0.764, loss: 1.0901, l1: 0.2165, vgg: 0.4780, mask: 0.3956\n",
      "step:   124400, time: 0.774, loss: 1.0151, l1: 0.2013, vgg: 0.4067, mask: 0.4072\n",
      "step:   124420, time: 0.757, loss: 1.1263, l1: 0.2491, vgg: 0.4652, mask: 0.4120\n",
      "step:   124440, time: 0.739, loss: 1.0105, l1: 0.2133, vgg: 0.4279, mask: 0.3694\n",
      "step:   124460, time: 0.289, loss: 1.0319, l1: 0.2591, vgg: 0.4703, mask: 0.3025\n",
      "step:   124480, time: 0.758, loss: 1.0290, l1: 0.1930, vgg: 0.4424, mask: 0.3936\n",
      "step:   124500, time: 0.745, loss: 1.0334, l1: 0.2067, vgg: 0.4549, mask: 0.3719\n",
      "step:   124520, time: 0.754, loss: 0.9729, l1: 0.1586, vgg: 0.4537, mask: 0.3606\n",
      "step:   124540, time: 0.756, loss: 1.1059, l1: 0.2380, vgg: 0.4878, mask: 0.3801\n",
      "step:   124560, time: 0.777, loss: 1.1034, l1: 0.2485, vgg: 0.4578, mask: 0.3970\n",
      "step:   124580, time: 0.746, loss: 0.9797, l1: 0.1851, vgg: 0.4191, mask: 0.3755\n",
      "step:   124600, time: 0.771, loss: 1.0504, l1: 0.2180, vgg: 0.4599, mask: 0.3725\n",
      "step:   124620, time: 0.776, loss: 1.0600, l1: 0.1992, vgg: 0.4747, mask: 0.3861\n",
      "step:   124640, time: 0.788, loss: 1.0743, l1: 0.2329, vgg: 0.4586, mask: 0.3828\n",
      "step:   124660, time: 0.791, loss: 1.0557, l1: 0.2200, vgg: 0.4025, mask: 0.4332\n",
      "step:   124680, time: 0.750, loss: 1.0864, l1: 0.2354, vgg: 0.4505, mask: 0.4006\n",
      "step:   124700, time: 0.763, loss: 1.1586, l1: 0.2266, vgg: 0.5252, mask: 0.4068\n",
      "step:   124720, time: 0.742, loss: 0.9953, l1: 0.2036, vgg: 0.4270, mask: 0.3647\n",
      "step:   124740, time: 0.749, loss: 1.1817, l1: 0.2516, vgg: 0.5419, mask: 0.3883\n",
      "step:   124760, time: 0.752, loss: 0.9147, l1: 0.1866, vgg: 0.3582, mask: 0.3699\n",
      "step:   124780, time: 0.735, loss: 1.1143, l1: 0.2355, vgg: 0.4916, mask: 0.3872\n",
      "step:   124800, time: 0.747, loss: 1.0644, l1: 0.2399, vgg: 0.4471, mask: 0.3774\n",
      "step:   124820, time: 0.764, loss: 1.0473, l1: 0.2487, vgg: 0.3872, mask: 0.4114\n",
      "step:   124840, time: 0.748, loss: 1.0419, l1: 0.2506, vgg: 0.4037, mask: 0.3876\n",
      "step:   124860, time: 0.737, loss: 0.9993, l1: 0.1980, vgg: 0.4195, mask: 0.3818\n",
      "step:   124880, time: 0.730, loss: 0.9896, l1: 0.1923, vgg: 0.4222, mask: 0.3751\n",
      "step:   124900, time: 0.755, loss: 1.0170, l1: 0.2031, vgg: 0.4586, mask: 0.3552\n",
      "step:   124920, time: 0.803, loss: 1.1455, l1: 0.2913, vgg: 0.4395, mask: 0.4147\n",
      "step:   124940, time: 0.741, loss: 1.0405, l1: 0.2131, vgg: 0.4686, mask: 0.3588\n",
      "step:   124960, time: 0.726, loss: 0.9663, l1: 0.1740, vgg: 0.4359, mask: 0.3564\n",
      "step:   124980, time: 0.745, loss: 1.1554, l1: 0.2626, vgg: 0.5048, mask: 0.3879\n",
      "step:   125000, time: 0.794, loss: 1.1179, l1: 0.2532, vgg: 0.4602, mask: 0.4046\n",
      "step:   125020, time: 0.749, loss: 1.0352, l1: 0.2204, vgg: 0.4557, mask: 0.3591\n",
      "step:   125040, time: 0.742, loss: 0.9392, l1: 0.1899, vgg: 0.3912, mask: 0.3580\n",
      "step:   125060, time: 0.751, loss: 0.9644, l1: 0.1666, vgg: 0.4272, mask: 0.3707\n",
      "step:   125080, time: 0.738, loss: 0.9019, l1: 0.1454, vgg: 0.4327, mask: 0.3237\n",
      "step:   125100, time: 0.733, loss: 1.1115, l1: 0.2685, vgg: 0.4439, mask: 0.3991\n",
      "step:   125120, time: 0.761, loss: 1.0726, l1: 0.2222, vgg: 0.4530, mask: 0.3973\n",
      "step:   125140, time: 0.742, loss: 1.0383, l1: 0.2145, vgg: 0.4023, mask: 0.4214\n",
      "step:   125160, time: 0.746, loss: 1.0838, l1: 0.2548, vgg: 0.4292, mask: 0.3999\n",
      "step:   125180, time: 0.753, loss: 0.9474, l1: 0.1626, vgg: 0.4404, mask: 0.3444\n",
      "step:   125200, time: 0.729, loss: 0.9618, l1: 0.1676, vgg: 0.4267, mask: 0.3676\n",
      "step:   125220, time: 0.759, loss: 0.9545, l1: 0.1724, vgg: 0.4167, mask: 0.3654\n",
      "step:   125240, time: 0.745, loss: 0.9959, l1: 0.1906, vgg: 0.4481, mask: 0.3572\n",
      "step:   125260, time: 0.760, loss: 0.9672, l1: 0.1673, vgg: 0.4596, mask: 0.3402\n",
      "step:   125280, time: 0.749, loss: 1.0196, l1: 0.2149, vgg: 0.4504, mask: 0.3543\n",
      "step:   125300, time: 0.762, loss: 1.0954, l1: 0.2364, vgg: 0.4992, mask: 0.3598\n",
      "step:   125320, time: 0.763, loss: 1.0571, l1: 0.2188, vgg: 0.4836, mask: 0.3546\n",
      "step:   125340, time: 0.755, loss: 1.0970, l1: 0.2004, vgg: 0.5094, mask: 0.3872\n",
      "step:   125360, time: 0.722, loss: 0.9795, l1: 0.2200, vgg: 0.4016, mask: 0.3579\n",
      "step:   125380, time: 0.773, loss: 0.9502, l1: 0.1795, vgg: 0.3688, mask: 0.4019\n",
      "step:   125400, time: 0.823, loss: 1.1499, l1: 0.2450, vgg: 0.4818, mask: 0.4230\n",
      "step:   125420, time: 0.750, loss: 1.0493, l1: 0.1892, vgg: 0.4777, mask: 0.3823\n",
      "step:   125440, time: 0.753, loss: 1.0287, l1: 0.2218, vgg: 0.4132, mask: 0.3937\n",
      "step:   125460, time: 0.739, loss: 1.0983, l1: 0.2766, vgg: 0.3882, mask: 0.4335\n",
      "step:   125480, time: 0.758, loss: 1.1180, l1: 0.2319, vgg: 0.4746, mask: 0.4115\n",
      "step:   125500, time: 0.739, loss: 1.0682, l1: 0.1987, vgg: 0.4652, mask: 0.4043\n",
      "step:   125520, time: 0.755, loss: 1.0354, l1: 0.2137, vgg: 0.4370, mask: 0.3847\n",
      "step:   125540, time: 0.776, loss: 1.0650, l1: 0.2489, vgg: 0.4246, mask: 0.3916\n",
      "step:   125560, time: 0.746, loss: 1.1400, l1: 0.2234, vgg: 0.5034, mask: 0.4132\n",
      "step:   125580, time: 0.747, loss: 1.0018, l1: 0.1927, vgg: 0.4261, mask: 0.3829\n",
      "step:   125600, time: 0.722, loss: 0.9656, l1: 0.2243, vgg: 0.3535, mask: 0.3879\n",
      "step:   125620, time: 0.751, loss: 1.1189, l1: 0.2390, vgg: 0.4692, mask: 0.4107\n",
      "step:   125640, time: 0.727, loss: 0.9741, l1: 0.1866, vgg: 0.4365, mask: 0.3510\n",
      "step:   125660, time: 0.791, loss: 1.1547, l1: 0.2509, vgg: 0.5163, mask: 0.3875\n",
      "step:   125680, time: 0.732, loss: 0.9506, l1: 0.1811, vgg: 0.3984, mask: 0.3711\n",
      "step:   125700, time: 0.721, loss: 0.9620, l1: 0.1907, vgg: 0.3349, mask: 0.4364\n",
      "step:   125720, time: 0.755, loss: 0.9870, l1: 0.1724, vgg: 0.4532, mask: 0.3613\n",
      "step:   125740, time: 0.766, loss: 1.1372, l1: 0.2404, vgg: 0.4960, mask: 0.4008\n",
      "step:   125760, time: 0.766, loss: 1.0654, l1: 0.2288, vgg: 0.4480, mask: 0.3886\n",
      "step:   125780, time: 0.752, loss: 1.1018, l1: 0.2409, vgg: 0.4809, mask: 0.3800\n",
      "step:   125800, time: 0.763, loss: 1.0924, l1: 0.2148, vgg: 0.4847, mask: 0.3930\n",
      "step:   125820, time: 0.740, loss: 0.9559, l1: 0.2306, vgg: 0.3588, mask: 0.3664\n",
      "step:   125840, time: 0.778, loss: 1.0036, l1: 0.1835, vgg: 0.4466, mask: 0.3735\n",
      "step:   125860, time: 0.747, loss: 0.9476, l1: 0.1910, vgg: 0.4004, mask: 0.3562\n",
      "step:   125880, time: 0.772, loss: 1.0518, l1: 0.2462, vgg: 0.4250, mask: 0.3806\n",
      "step:   125900, time: 0.757, loss: 1.0748, l1: 0.2222, vgg: 0.4423, mask: 0.4103\n",
      "step:   125920, time: 0.784, loss: 1.0162, l1: 0.2173, vgg: 0.4339, mask: 0.3651\n",
      "step:   125940, time: 0.756, loss: 0.9156, l1: 0.1535, vgg: 0.3863, mask: 0.3759\n",
      "step:   125960, time: 0.748, loss: 0.9989, l1: 0.2180, vgg: 0.4096, mask: 0.3713\n",
      "step:   125980, time: 0.791, loss: 0.9725, l1: 0.1636, vgg: 0.4137, mask: 0.3952\n",
      "step:   126000, time: 0.819, loss: 1.0316, l1: 0.2131, vgg: 0.4490, mask: 0.3695\n",
      "step:   126020, time: 0.786, loss: 1.0375, l1: 0.2444, vgg: 0.4160, mask: 0.3771\n",
      "step:   126040, time: 0.753, loss: 0.9815, l1: 0.1926, vgg: 0.4094, mask: 0.3794\n",
      "step:   126060, time: 0.813, loss: 1.0783, l1: 0.2350, vgg: 0.4509, mask: 0.3925\n",
      "step:   126080, time: 0.750, loss: 1.0401, l1: 0.2313, vgg: 0.4541, mask: 0.3546\n",
      "step:   126100, time: 0.749, loss: 1.0531, l1: 0.2543, vgg: 0.4251, mask: 0.3737\n",
      "step:   126120, time: 0.766, loss: 1.2173, l1: 0.2826, vgg: 0.5082, mask: 0.4265\n",
      "step:   126140, time: 0.764, loss: 1.0649, l1: 0.2225, vgg: 0.4510, mask: 0.3915\n",
      "step:   126160, time: 0.748, loss: 1.0339, l1: 0.1953, vgg: 0.4811, mask: 0.3576\n",
      "step:   126180, time: 0.752, loss: 0.9671, l1: 0.1786, vgg: 0.4050, mask: 0.3836\n",
      "step:   126200, time: 0.761, loss: 1.1017, l1: 0.2412, vgg: 0.4970, mask: 0.3635\n",
      "step:   126220, time: 0.808, loss: 0.9679, l1: 0.1765, vgg: 0.4377, mask: 0.3537\n",
      "step:   126240, time: 0.775, loss: 0.9924, l1: 0.2094, vgg: 0.3952, mask: 0.3878\n",
      "step:   126260, time: 0.852, loss: 0.9493, l1: 0.1810, vgg: 0.4164, mask: 0.3519\n",
      "step:   126280, time: 0.786, loss: 1.0691, l1: 0.2176, vgg: 0.4639, mask: 0.3876\n",
      "step:   126300, time: 0.730, loss: 0.9696, l1: 0.2086, vgg: 0.3858, mask: 0.3753\n",
      "step:   126320, time: 0.772, loss: 1.0024, l1: 0.2014, vgg: 0.4006, mask: 0.4004\n",
      "step:   126340, time: 0.748, loss: 0.9575, l1: 0.1930, vgg: 0.4058, mask: 0.3587\n",
      "step:   126360, time: 0.753, loss: 1.0447, l1: 0.2070, vgg: 0.4609, mask: 0.3768\n",
      "step:   126380, time: 0.740, loss: 1.0165, l1: 0.2022, vgg: 0.4307, mask: 0.3836\n",
      "step:   126400, time: 0.754, loss: 0.9711, l1: 0.1920, vgg: 0.4061, mask: 0.3730\n",
      "step:   126420, time: 0.715, loss: 0.9181, l1: 0.1821, vgg: 0.3865, mask: 0.3495\n",
      "step:   126440, time: 0.803, loss: 1.0316, l1: 0.2171, vgg: 0.4600, mask: 0.3545\n",
      "step:   126460, time: 0.751, loss: 1.0564, l1: 0.2392, vgg: 0.4181, mask: 0.3991\n",
      "step:   126480, time: 0.793, loss: 1.0709, l1: 0.2162, vgg: 0.4683, mask: 0.3864\n",
      "step:   126500, time: 0.756, loss: 1.0340, l1: 0.1895, vgg: 0.4498, mask: 0.3947\n",
      "step:   126520, time: 0.745, loss: 1.0302, l1: 0.2289, vgg: 0.4221, mask: 0.3793\n",
      "step:   126540, time: 0.741, loss: 0.9529, l1: 0.1695, vgg: 0.4109, mask: 0.3725\n",
      "step:   126560, time: 0.726, loss: 0.8891, l1: 0.1727, vgg: 0.3973, mask: 0.3191\n",
      "step:   126580, time: 0.752, loss: 0.9755, l1: 0.1857, vgg: 0.4173, mask: 0.3725\n",
      "step:   126600, time: 0.733, loss: 1.0636, l1: 0.2329, vgg: 0.4285, mask: 0.4022\n",
      "step:   126620, time: 0.709, loss: 0.9923, l1: 0.2086, vgg: 0.4089, mask: 0.3747\n",
      "step:   126640, time: 0.752, loss: 1.1535, l1: 0.3073, vgg: 0.4177, mask: 0.4285\n",
      "step:   126660, time: 0.760, loss: 1.0611, l1: 0.1678, vgg: 0.5060, mask: 0.3873\n",
      "step:   126680, time: 0.732, loss: 1.1031, l1: 0.2418, vgg: 0.4942, mask: 0.3670\n",
      "step:   126700, time: 0.738, loss: 0.9238, l1: 0.1676, vgg: 0.4114, mask: 0.3447\n",
      "step:   126720, time: 0.738, loss: 0.9890, l1: 0.1912, vgg: 0.4302, mask: 0.3676\n",
      "step:   126740, time: 0.758, loss: 1.1212, l1: 0.2228, vgg: 0.5001, mask: 0.3983\n",
      "step:   126760, time: 0.746, loss: 1.1070, l1: 0.2295, vgg: 0.4711, mask: 0.4064\n",
      "step:   126780, time: 0.766, loss: 1.0407, l1: 0.1869, vgg: 0.4961, mask: 0.3577\n",
      "step:   126800, time: 0.785, loss: 0.9654, l1: 0.2022, vgg: 0.4265, mask: 0.3367\n",
      "step:   126820, time: 0.734, loss: 0.9895, l1: 0.2247, vgg: 0.3924, mask: 0.3724\n",
      "step:   126840, time: 0.779, loss: 1.0610, l1: 0.2315, vgg: 0.4392, mask: 0.3902\n",
      "step:   126860, time: 0.772, loss: 1.1520, l1: 0.2351, vgg: 0.5282, mask: 0.3887\n",
      "step:   126880, time: 0.766, loss: 1.0681, l1: 0.2279, vgg: 0.4555, mask: 0.3847\n",
      "step:   126900, time: 0.760, loss: 1.0071, l1: 0.1929, vgg: 0.4453, mask: 0.3689\n",
      "step:   126920, time: 0.739, loss: 1.1481, l1: 0.3102, vgg: 0.3907, mask: 0.4472\n",
      "step:   126940, time: 0.754, loss: 1.1137, l1: 0.2538, vgg: 0.4525, mask: 0.4074\n",
      "step:   126960, time: 0.762, loss: 1.0524, l1: 0.2366, vgg: 0.4500, mask: 0.3658\n",
      "step:   126980, time: 0.742, loss: 1.1338, l1: 0.2601, vgg: 0.4317, mask: 0.4421\n",
      "step:   127000, time: 0.790, loss: 1.0236, l1: 0.1766, vgg: 0.4515, mask: 0.3955\n",
      "step:   127020, time: 0.774, loss: 1.0750, l1: 0.1959, vgg: 0.5161, mask: 0.3630\n",
      "step:   127040, time: 0.800, loss: 1.2163, l1: 0.2950, vgg: 0.5186, mask: 0.4027\n",
      "step:   127060, time: 0.750, loss: 1.1204, l1: 0.2651, vgg: 0.4274, mask: 0.4280\n",
      "step:   127080, time: 0.776, loss: 1.0720, l1: 0.1711, vgg: 0.5282, mask: 0.3727\n",
      "step:   127100, time: 0.748, loss: 1.0236, l1: 0.2172, vgg: 0.4023, mask: 0.4041\n",
      "step:   127120, time: 0.730, loss: 0.8735, l1: 0.1408, vgg: 0.3985, mask: 0.3342\n",
      "step:   127140, time: 0.719, loss: 1.0031, l1: 0.2179, vgg: 0.4017, mask: 0.3835\n",
      "step:   127160, time: 0.783, loss: 1.0882, l1: 0.2135, vgg: 0.4828, mask: 0.3919\n",
      "step:   127180, time: 0.771, loss: 1.2039, l1: 0.2513, vgg: 0.5168, mask: 0.4358\n",
      "step:   127200, time: 0.747, loss: 1.0085, l1: 0.2011, vgg: 0.4102, mask: 0.3972\n",
      "step:   127220, time: 0.747, loss: 1.2025, l1: 0.2523, vgg: 0.5484, mask: 0.4018\n",
      "step:   127240, time: 0.767, loss: 1.0211, l1: 0.2336, vgg: 0.4213, mask: 0.3662\n",
      "step:   127260, time: 0.821, loss: 1.1867, l1: 0.2866, vgg: 0.4705, mask: 0.4296\n",
      "step:   127280, time: 0.821, loss: 1.0421, l1: 0.1979, vgg: 0.4457, mask: 0.3985\n",
      "step:   127300, time: 0.751, loss: 0.9523, l1: 0.1529, vgg: 0.4443, mask: 0.3551\n",
      "step:   127320, time: 0.762, loss: 1.0313, l1: 0.1849, vgg: 0.4885, mask: 0.3579\n",
      "step:   127340, time: 0.756, loss: 0.9544, l1: 0.1819, vgg: 0.4097, mask: 0.3627\n",
      "step:   127360, time: 0.752, loss: 0.9874, l1: 0.1765, vgg: 0.4808, mask: 0.3301\n",
      "step:   127380, time: 0.795, loss: 1.0503, l1: 0.2295, vgg: 0.4265, mask: 0.3942\n",
      "step:   127400, time: 0.746, loss: 0.9504, l1: 0.1845, vgg: 0.3671, mask: 0.3988\n",
      "step:   127420, time: 0.748, loss: 0.9269, l1: 0.1652, vgg: 0.4019, mask: 0.3599\n",
      "step:   127440, time: 0.724, loss: 0.9948, l1: 0.2130, vgg: 0.3834, mask: 0.3984\n",
      "step:   127460, time: 0.771, loss: 1.0209, l1: 0.1821, vgg: 0.4525, mask: 0.3862\n",
      "step:   127480, time: 0.743, loss: 0.9430, l1: 0.1747, vgg: 0.3922, mask: 0.3761\n",
      "step:   127500, time: 0.771, loss: 1.0563, l1: 0.2426, vgg: 0.4437, mask: 0.3699\n",
      "step:   127520, time: 0.759, loss: 1.1824, l1: 0.2675, vgg: 0.5031, mask: 0.4118\n",
      "step:   127540, time: 0.740, loss: 0.9677, l1: 0.2004, vgg: 0.4211, mask: 0.3463\n",
      "step:   127560, time: 0.735, loss: 1.0041, l1: 0.2033, vgg: 0.4113, mask: 0.3896\n",
      "step:   127580, time: 0.748, loss: 0.9351, l1: 0.1781, vgg: 0.3508, mask: 0.4062\n",
      "step:   127600, time: 0.779, loss: 1.0252, l1: 0.1953, vgg: 0.4468, mask: 0.3832\n",
      "step:   127620, time: 0.751, loss: 1.0018, l1: 0.2224, vgg: 0.4065, mask: 0.3729\n",
      "step:   127640, time: 0.745, loss: 1.0574, l1: 0.2286, vgg: 0.4359, mask: 0.3929\n",
      "step:   127660, time: 0.766, loss: 0.9929, l1: 0.2477, vgg: 0.3537, mask: 0.3915\n",
      "step:   127680, time: 0.754, loss: 0.9707, l1: 0.1715, vgg: 0.4150, mask: 0.3842\n",
      "step:   127700, time: 0.751, loss: 1.0460, l1: 0.2307, vgg: 0.4707, mask: 0.3445\n",
      "step:   127720, time: 0.739, loss: 0.8915, l1: 0.1791, vgg: 0.3837, mask: 0.3287\n",
      "step:   127740, time: 0.763, loss: 1.0862, l1: 0.2094, vgg: 0.4744, mask: 0.4023\n",
      "step:   127760, time: 0.753, loss: 1.1258, l1: 0.2313, vgg: 0.5098, mask: 0.3847\n",
      "step:   127780, time: 0.761, loss: 1.0333, l1: 0.2102, vgg: 0.4222, mask: 0.4009\n",
      "step:   127800, time: 0.721, loss: 1.0049, l1: 0.1919, vgg: 0.4379, mask: 0.3751\n",
      "step:   127820, time: 0.734, loss: 1.0833, l1: 0.2580, vgg: 0.4292, mask: 0.3961\n",
      "step:   127840, time: 0.750, loss: 0.9825, l1: 0.1889, vgg: 0.4281, mask: 0.3655\n",
      "step:   127860, time: 0.764, loss: 1.0367, l1: 0.2107, vgg: 0.4397, mask: 0.3863\n",
      "step:   127880, time: 0.725, loss: 0.9169, l1: 0.1728, vgg: 0.3911, mask: 0.3530\n",
      "step:   127900, time: 0.749, loss: 0.9896, l1: 0.1914, vgg: 0.4340, mask: 0.3642\n",
      "step:   127920, time: 0.732, loss: 0.8794, l1: 0.1770, vgg: 0.3618, mask: 0.3406\n",
      "step:   127940, time: 0.749, loss: 0.9520, l1: 0.1821, vgg: 0.4088, mask: 0.3611\n",
      "step:   127960, time: 0.768, loss: 1.0177, l1: 0.2230, vgg: 0.4157, mask: 0.3791\n",
      "step:   127980, time: 0.778, loss: 1.1200, l1: 0.2364, vgg: 0.5059, mask: 0.3777\n",
      "step:   128000, time: 0.752, loss: 1.1083, l1: 0.2118, vgg: 0.5050, mask: 0.3915\n",
      "step:   128020, time: 0.743, loss: 0.9681, l1: 0.1861, vgg: 0.4072, mask: 0.3748\n",
      "step:   128040, time: 0.748, loss: 1.0459, l1: 0.2020, vgg: 0.4658, mask: 0.3781\n",
      "step:   128060, time: 0.784, loss: 1.0736, l1: 0.2295, vgg: 0.4562, mask: 0.3880\n",
      "step:   128080, time: 0.775, loss: 1.0434, l1: 0.2126, vgg: 0.4602, mask: 0.3705\n",
      "step:   128100, time: 0.734, loss: 1.0469, l1: 0.2325, vgg: 0.4461, mask: 0.3683\n",
      "step:   128120, time: 0.733, loss: 0.9988, l1: 0.2116, vgg: 0.3995, mask: 0.3876\n",
      "step:   128140, time: 0.750, loss: 1.0863, l1: 0.2510, vgg: 0.4552, mask: 0.3801\n",
      "step:   128160, time: 0.747, loss: 0.9879, l1: 0.2240, vgg: 0.3628, mask: 0.4011\n",
      "step:   128180, time: 0.756, loss: 0.9589, l1: 0.2163, vgg: 0.3663, mask: 0.3763\n",
      "step:   128200, time: 0.759, loss: 0.9918, l1: 0.1971, vgg: 0.4138, mask: 0.3808\n",
      "step:   128220, time: 0.762, loss: 0.9463, l1: 0.2207, vgg: 0.3308, mask: 0.3949\n",
      "step:   128240, time: 0.727, loss: 0.9963, l1: 0.2016, vgg: 0.4607, mask: 0.3341\n",
      "step:   128260, time: 0.763, loss: 1.0366, l1: 0.2070, vgg: 0.4657, mask: 0.3640\n",
      "step:   128280, time: 0.761, loss: 1.0794, l1: 0.2065, vgg: 0.4853, mask: 0.3876\n",
      "step:   128300, time: 0.749, loss: 1.0268, l1: 0.2140, vgg: 0.3846, mask: 0.4282\n",
      "step:   128320, time: 0.756, loss: 1.0013, l1: 0.2029, vgg: 0.4140, mask: 0.3844\n",
      "step:   128340, time: 0.772, loss: 1.0498, l1: 0.2138, vgg: 0.4109, mask: 0.4251\n",
      "step:   128360, time: 0.736, loss: 1.0051, l1: 0.1749, vgg: 0.4535, mask: 0.3767\n",
      "step:   128380, time: 0.763, loss: 1.0411, l1: 0.2390, vgg: 0.4143, mask: 0.3878\n",
      "step:   128400, time: 0.768, loss: 1.0352, l1: 0.1869, vgg: 0.5044, mask: 0.3439\n",
      "step:   128420, time: 0.752, loss: 1.1021, l1: 0.2286, vgg: 0.5007, mask: 0.3727\n",
      "step:   128440, time: 0.734, loss: 0.9545, l1: 0.1817, vgg: 0.3660, mask: 0.4069\n",
      "step:   128460, time: 0.749, loss: 0.9367, l1: 0.1659, vgg: 0.4296, mask: 0.3412\n",
      "step:   128480, time: 0.791, loss: 1.1993, l1: 0.2192, vgg: 0.5587, mask: 0.4214\n",
      "step:   128500, time: 0.764, loss: 1.1852, l1: 0.2443, vgg: 0.5442, mask: 0.3966\n",
      "step:   128520, time: 0.774, loss: 0.9488, l1: 0.1938, vgg: 0.3917, mask: 0.3633\n",
      "step:   128540, time: 0.759, loss: 1.0770, l1: 0.2438, vgg: 0.4349, mask: 0.3983\n",
      "step:   128560, time: 0.740, loss: 0.9518, l1: 0.1832, vgg: 0.4046, mask: 0.3640\n",
      "step:   128580, time: 0.764, loss: 1.2777, l1: 0.2960, vgg: 0.5372, mask: 0.4444\n",
      "step:   128600, time: 0.757, loss: 1.0334, l1: 0.1942, vgg: 0.4561, mask: 0.3832\n",
      "step:   128620, time: 0.735, loss: 1.0347, l1: 0.1771, vgg: 0.4888, mask: 0.3688\n",
      "step:   128640, time: 0.758, loss: 1.0103, l1: 0.2123, vgg: 0.4190, mask: 0.3790\n",
      "step:   128660, time: 0.795, loss: 0.9914, l1: 0.2075, vgg: 0.3981, mask: 0.3858\n",
      "step:   128680, time: 0.756, loss: 1.0290, l1: 0.1956, vgg: 0.4519, mask: 0.3814\n",
      "step:   128700, time: 0.756, loss: 1.0246, l1: 0.2025, vgg: 0.4525, mask: 0.3695\n",
      "step:   128720, time: 0.767, loss: 1.1040, l1: 0.2520, vgg: 0.4731, mask: 0.3789\n",
      "step:   128740, time: 0.760, loss: 1.1401, l1: 0.2663, vgg: 0.4776, mask: 0.3962\n",
      "step:   128760, time: 0.785, loss: 1.0730, l1: 0.2530, vgg: 0.4104, mask: 0.4095\n",
      "step:   128780, time: 0.753, loss: 1.1185, l1: 0.2291, vgg: 0.4730, mask: 0.4164\n",
      "step:   128800, time: 0.723, loss: 0.9158, l1: 0.1669, vgg: 0.4087, mask: 0.3402\n",
      "step:   128820, time: 0.748, loss: 0.9261, l1: 0.1866, vgg: 0.3924, mask: 0.3471\n",
      "step:   128840, time: 0.759, loss: 0.9362, l1: 0.1458, vgg: 0.4516, mask: 0.3388\n",
      "step:   128860, time: 0.750, loss: 1.0517, l1: 0.2010, vgg: 0.4504, mask: 0.4003\n",
      "step:   128880, time: 0.728, loss: 0.9014, l1: 0.1861, vgg: 0.3825, mask: 0.3328\n",
      "step:   128900, time: 0.791, loss: 1.0967, l1: 0.1935, vgg: 0.5044, mask: 0.3987\n",
      "step:   128920, time: 0.735, loss: 0.9304, l1: 0.1581, vgg: 0.4136, mask: 0.3588\n",
      "step:   128940, time: 0.748, loss: 1.0472, l1: 0.2557, vgg: 0.4163, mask: 0.3752\n",
      "step:   128960, time: 0.756, loss: 1.0831, l1: 0.2389, vgg: 0.4206, mask: 0.4237\n",
      "step:   128980, time: 0.739, loss: 1.0566, l1: 0.2393, vgg: 0.4387, mask: 0.3786\n",
      "step:   129000, time: 0.780, loss: 0.9518, l1: 0.1890, vgg: 0.4031, mask: 0.3598\n",
      "step:   129020, time: 0.729, loss: 0.9408, l1: 0.1862, vgg: 0.4266, mask: 0.3280\n",
      "step:   129040, time: 0.756, loss: 1.2437, l1: 0.2549, vgg: 0.5972, mask: 0.3917\n",
      "step:   129060, time: 0.730, loss: 0.9563, l1: 0.2046, vgg: 0.3953, mask: 0.3564\n",
      "step:   129080, time: 0.734, loss: 1.0416, l1: 0.1912, vgg: 0.4782, mask: 0.3721\n",
      "step:   129100, time: 0.743, loss: 1.0168, l1: 0.1792, vgg: 0.4673, mask: 0.3702\n",
      "step:   129120, time: 0.835, loss: 1.0816, l1: 0.2281, vgg: 0.4717, mask: 0.3818\n",
      "step:   129140, time: 0.737, loss: 1.0449, l1: 0.2249, vgg: 0.4273, mask: 0.3928\n",
      "step:   129160, time: 0.733, loss: 0.9543, l1: 0.2003, vgg: 0.3755, mask: 0.3785\n",
      "step:   129180, time: 0.715, loss: 0.9260, l1: 0.1934, vgg: 0.3657, mask: 0.3668\n",
      "step:   129200, time: 0.766, loss: 1.0759, l1: 0.2658, vgg: 0.4191, mask: 0.3910\n",
      "step:   129220, time: 0.754, loss: 1.0773, l1: 0.2030, vgg: 0.5067, mask: 0.3676\n",
      "step:   129240, time: 0.750, loss: 1.2127, l1: 0.2553, vgg: 0.5393, mask: 0.4181\n",
      "step:   129260, time: 0.742, loss: 0.9779, l1: 0.1849, vgg: 0.4110, mask: 0.3819\n",
      "step:   129280, time: 0.741, loss: 1.1262, l1: 0.2595, vgg: 0.4599, mask: 0.4068\n",
      "step:   129300, time: 0.770, loss: 0.9846, l1: 0.2225, vgg: 0.3923, mask: 0.3697\n",
      "step:   129320, time: 0.763, loss: 0.9406, l1: 0.1948, vgg: 0.3769, mask: 0.3689\n",
      "step:   129340, time: 0.773, loss: 1.1011, l1: 0.2378, vgg: 0.4694, mask: 0.3939\n",
      "step:   129360, time: 0.772, loss: 0.9861, l1: 0.2143, vgg: 0.3864, mask: 0.3854\n",
      "step:   129380, time: 0.774, loss: 0.9430, l1: 0.1853, vgg: 0.4083, mask: 0.3495\n",
      "step:   129400, time: 0.742, loss: 1.0243, l1: 0.2476, vgg: 0.4213, mask: 0.3554\n",
      "step:   129420, time: 0.760, loss: 1.1250, l1: 0.2546, vgg: 0.4873, mask: 0.3831\n",
      "step:   129440, time: 0.781, loss: 1.2379, l1: 0.2993, vgg: 0.5195, mask: 0.4191\n",
      "step:   129460, time: 0.743, loss: 1.0046, l1: 0.2274, vgg: 0.3312, mask: 0.4460\n",
      "step:   129480, time: 0.758, loss: 1.1453, l1: 0.2558, vgg: 0.4536, mask: 0.4359\n",
      "step:   129500, time: 0.774, loss: 1.0344, l1: 0.2388, vgg: 0.4096, mask: 0.3860\n",
      "step:   129520, time: 0.745, loss: 0.9756, l1: 0.2145, vgg: 0.3776, mask: 0.3835\n",
      "step:   129540, time: 0.737, loss: 0.9504, l1: 0.1819, vgg: 0.3923, mask: 0.3761\n",
      "step:   129560, time: 0.777, loss: 1.0463, l1: 0.2298, vgg: 0.4344, mask: 0.3821\n",
      "step:   129580, time: 0.749, loss: 1.0304, l1: 0.2208, vgg: 0.4461, mask: 0.3634\n",
      "step:   129600, time: 0.771, loss: 1.0497, l1: 0.2176, vgg: 0.4590, mask: 0.3731\n",
      "step:   129620, time: 0.759, loss: 1.0776, l1: 0.2597, vgg: 0.4238, mask: 0.3941\n",
      "step:   129640, time: 0.750, loss: 1.0150, l1: 0.1882, vgg: 0.4895, mask: 0.3373\n",
      "step:   129660, time: 0.766, loss: 0.9859, l1: 0.1893, vgg: 0.4232, mask: 0.3735\n",
      "step:   129680, time: 0.760, loss: 1.0492, l1: 0.2211, vgg: 0.4461, mask: 0.3821\n",
      "step:   129700, time: 0.812, loss: 0.9962, l1: 0.2074, vgg: 0.4162, mask: 0.3725\n",
      "step:   129720, time: 0.778, loss: 1.0473, l1: 0.2176, vgg: 0.4442, mask: 0.3855\n",
      "step:   129740, time: 0.735, loss: 1.2320, l1: 0.3272, vgg: 0.4703, mask: 0.4345\n",
      "step:   129760, time: 0.747, loss: 0.8863, l1: 0.1686, vgg: 0.3647, mask: 0.3530\n",
      "step:   129780, time: 0.747, loss: 0.9426, l1: 0.1718, vgg: 0.4025, mask: 0.3684\n",
      "step:   129800, time: 0.738, loss: 0.8530, l1: 0.1424, vgg: 0.3604, mask: 0.3502\n",
      "step:   129820, time: 0.757, loss: 1.0282, l1: 0.2104, vgg: 0.4318, mask: 0.3860\n",
      "step:   129840, time: 0.734, loss: 0.9679, l1: 0.1796, vgg: 0.4190, mask: 0.3693\n",
      "step:   129860, time: 0.786, loss: 1.1169, l1: 0.2279, vgg: 0.4705, mask: 0.4185\n",
      "step:   129880, time: 0.770, loss: 0.9363, l1: 0.1884, vgg: 0.3924, mask: 0.3555\n",
      "step:   129900, time: 0.746, loss: 1.0603, l1: 0.2315, vgg: 0.4258, mask: 0.4030\n",
      "step:   129920, time: 0.768, loss: 1.0900, l1: 0.2020, vgg: 0.4824, mask: 0.4056\n",
      "step:   129940, time: 0.769, loss: 0.9547, l1: 0.1748, vgg: 0.4315, mask: 0.3484\n",
      "step:   129960, time: 0.759, loss: 1.1022, l1: 0.1982, vgg: 0.4900, mask: 0.4140\n",
      "step:   129980, time: 0.773, loss: 1.0435, l1: 0.2091, vgg: 0.4631, mask: 0.3713\n",
      "step:   130000, time: 0.761, loss: 1.0243, l1: 0.2092, vgg: 0.4433, mask: 0.3717\n",
      "step:   130020, time: 0.753, loss: 0.9933, l1: 0.2136, vgg: 0.4148, mask: 0.3649\n",
      "step:   130040, time: 0.816, loss: 1.0230, l1: 0.2382, vgg: 0.4048, mask: 0.3800\n",
      "step:   130060, time: 0.829, loss: 1.0010, l1: 0.1873, vgg: 0.4501, mask: 0.3636\n",
      "step:   130080, time: 0.791, loss: 0.9271, l1: 0.1591, vgg: 0.4115, mask: 0.3566\n",
      "step:   130100, time: 0.766, loss: 1.0592, l1: 0.2480, vgg: 0.3968, mask: 0.4144\n",
      "step:   130120, time: 0.797, loss: 1.0141, l1: 0.1924, vgg: 0.4756, mask: 0.3462\n",
      "step:   130140, time: 0.764, loss: 0.9905, l1: 0.1627, vgg: 0.4731, mask: 0.3547\n",
      "step:   130160, time: 0.781, loss: 1.0285, l1: 0.2488, vgg: 0.4058, mask: 0.3738\n",
      "step:   130180, time: 0.831, loss: 1.1967, l1: 0.2521, vgg: 0.5452, mask: 0.3994\n",
      "step:   130200, time: 0.753, loss: 1.0721, l1: 0.1991, vgg: 0.4944, mask: 0.3787\n",
      "step:   130220, time: 0.751, loss: 0.9558, l1: 0.1920, vgg: 0.4320, mask: 0.3318\n",
      "step:   130240, time: 0.767, loss: 1.0553, l1: 0.2334, vgg: 0.4410, mask: 0.3808\n",
      "step:   130260, time: 0.754, loss: 1.0803, l1: 0.2247, vgg: 0.4399, mask: 0.4157\n",
      "step:   130280, time: 0.780, loss: 1.0572, l1: 0.2349, vgg: 0.4378, mask: 0.3845\n",
      "step:   130300, time: 0.728, loss: 1.1226, l1: 0.2423, vgg: 0.4858, mask: 0.3946\n",
      "step:   130320, time: 0.733, loss: 1.0549, l1: 0.2745, vgg: 0.4137, mask: 0.3666\n",
      "step:   130340, time: 0.792, loss: 1.0673, l1: 0.2132, vgg: 0.4304, mask: 0.4237\n",
      "step:   130360, time: 0.758, loss: 0.9183, l1: 0.1929, vgg: 0.3837, mask: 0.3417\n",
      "step:   130380, time: 0.764, loss: 1.0407, l1: 0.2154, vgg: 0.4201, mask: 0.4052\n",
      "step:   130400, time: 0.831, loss: 1.1347, l1: 0.2535, vgg: 0.4516, mask: 0.4296\n",
      "step:   130420, time: 0.753, loss: 1.1384, l1: 0.2361, vgg: 0.4915, mask: 0.4108\n",
      "step:   130440, time: 0.756, loss: 0.9539, l1: 0.1711, vgg: 0.4109, mask: 0.3719\n",
      "step:   130460, time: 0.765, loss: 0.9828, l1: 0.1906, vgg: 0.4177, mask: 0.3746\n",
      "step:   130480, time: 0.743, loss: 0.9864, l1: 0.2191, vgg: 0.4138, mask: 0.3536\n",
      "step:   130500, time: 0.729, loss: 0.9091, l1: 0.1668, vgg: 0.4026, mask: 0.3396\n",
      "step:   130520, time: 0.764, loss: 0.9614, l1: 0.1969, vgg: 0.3853, mask: 0.3792\n",
      "step:   130540, time: 0.756, loss: 1.0646, l1: 0.2906, vgg: 0.4121, mask: 0.3619\n",
      "step:   130560, time: 0.776, loss: 0.8981, l1: 0.1282, vgg: 0.4097, mask: 0.3601\n",
      "step:   130580, time: 0.772, loss: 1.0642, l1: 0.2179, vgg: 0.4573, mask: 0.3891\n",
      "step:   130600, time: 0.744, loss: 1.0402, l1: 0.1989, vgg: 0.4423, mask: 0.3990\n",
      "step:   130620, time: 0.747, loss: 1.0189, l1: 0.2112, vgg: 0.4310, mask: 0.3768\n",
      "step:   130640, time: 0.769, loss: 1.0239, l1: 0.2129, vgg: 0.3971, mask: 0.4139\n",
      "step:   130660, time: 0.829, loss: 1.0243, l1: 0.2130, vgg: 0.4574, mask: 0.3540\n",
      "step:   130680, time: 0.815, loss: 1.0390, l1: 0.2068, vgg: 0.4267, mask: 0.4055\n",
      "step:   130700, time: 0.788, loss: 1.0909, l1: 0.2730, vgg: 0.4313, mask: 0.3866\n",
      "step:   130720, time: 0.753, loss: 0.9558, l1: 0.1845, vgg: 0.3863, mask: 0.3849\n",
      "step:   130740, time: 0.711, loss: 0.9118, l1: 0.1881, vgg: 0.3642, mask: 0.3595\n",
      "step:   130760, time: 0.775, loss: 1.0303, l1: 0.2032, vgg: 0.4585, mask: 0.3687\n",
      "step:   130780, time: 0.734, loss: 1.0544, l1: 0.2105, vgg: 0.3908, mask: 0.4531\n",
      "step:   130800, time: 0.743, loss: 1.0237, l1: 0.2196, vgg: 0.4041, mask: 0.4000\n",
      "step:   130820, time: 0.764, loss: 1.0486, l1: 0.2109, vgg: 0.4346, mask: 0.4032\n",
      "step:   130840, time: 0.725, loss: 1.0302, l1: 0.1964, vgg: 0.4079, mask: 0.4258\n",
      "step:   130860, time: 0.744, loss: 0.9598, l1: 0.1995, vgg: 0.3930, mask: 0.3673\n",
      "step:   130880, time: 0.783, loss: 1.0819, l1: 0.2206, vgg: 0.4617, mask: 0.3996\n",
      "step:   130900, time: 0.745, loss: 1.0513, l1: 0.2178, vgg: 0.4467, mask: 0.3868\n",
      "step:   130920, time: 0.762, loss: 0.9872, l1: 0.1957, vgg: 0.4278, mask: 0.3637\n",
      "step:   130940, time: 0.740, loss: 1.0799, l1: 0.2815, vgg: 0.4235, mask: 0.3749\n",
      "step:   130960, time: 0.776, loss: 1.0281, l1: 0.2434, vgg: 0.4169, mask: 0.3678\n",
      "step:   130980, time: 0.769, loss: 1.1062, l1: 0.2242, vgg: 0.4820, mask: 0.4001\n",
      "step:   131000, time: 0.748, loss: 1.0220, l1: 0.2136, vgg: 0.4537, mask: 0.3547\n",
      "step:   131020, time: 0.731, loss: 1.0354, l1: 0.2086, vgg: 0.4232, mask: 0.4036\n",
      "step:   131040, time: 0.748, loss: 1.0108, l1: 0.2198, vgg: 0.4458, mask: 0.3451\n",
      "step:   131060, time: 0.779, loss: 0.9724, l1: 0.2075, vgg: 0.4087, mask: 0.3562\n",
      "step:   131080, time: 0.786, loss: 0.9957, l1: 0.1815, vgg: 0.4519, mask: 0.3623\n",
      "step:   131100, time: 0.769, loss: 1.0072, l1: 0.2033, vgg: 0.4234, mask: 0.3805\n",
      "step:   131120, time: 0.769, loss: 0.9828, l1: 0.2178, vgg: 0.4161, mask: 0.3489\n",
      "step:   131140, time: 0.774, loss: 1.0810, l1: 0.2344, vgg: 0.4487, mask: 0.3979\n",
      "step:   131160, time: 0.730, loss: 1.0908, l1: 0.2168, vgg: 0.4838, mask: 0.3902\n",
      "step:   131180, time: 0.739, loss: 0.9953, l1: 0.1606, vgg: 0.4271, mask: 0.4075\n",
      "step:   131200, time: 0.769, loss: 1.0567, l1: 0.1919, vgg: 0.4981, mask: 0.3668\n",
      "step:   131220, time: 0.720, loss: 0.9092, l1: 0.1616, vgg: 0.4008, mask: 0.3468\n",
      "step:   131240, time: 0.777, loss: 1.0532, l1: 0.2154, vgg: 0.4425, mask: 0.3954\n",
      "step:   131260, time: 0.799, loss: 0.9908, l1: 0.1970, vgg: 0.4117, mask: 0.3821\n",
      "step:   131280, time: 0.751, loss: 1.0437, l1: 0.2116, vgg: 0.4279, mask: 0.4042\n",
      "step:   131300, time: 0.743, loss: 0.9784, l1: 0.1707, vgg: 0.4273, mask: 0.3804\n",
      "step:   131320, time: 0.788, loss: 1.0094, l1: 0.2121, vgg: 0.4233, mask: 0.3741\n",
      "step:   131340, time: 0.737, loss: 0.9870, l1: 0.1926, vgg: 0.4647, mask: 0.3297\n",
      "step:   131360, time: 0.735, loss: 1.0714, l1: 0.1889, vgg: 0.4630, mask: 0.4195\n",
      "step:   131380, time: 0.698, loss: 1.0454, l1: 0.2398, vgg: 0.3935, mask: 0.4120\n",
      "step:   131400, time: 0.741, loss: 1.0951, l1: 0.2402, vgg: 0.4766, mask: 0.3783\n",
      "step:   131420, time: 0.784, loss: 1.1889, l1: 0.2493, vgg: 0.5561, mask: 0.3836\n",
      "step:   131440, time: 0.801, loss: 1.0867, l1: 0.2235, vgg: 0.4867, mask: 0.3765\n",
      "step:   131460, time: 0.718, loss: 1.0443, l1: 0.2253, vgg: 0.4298, mask: 0.3893\n",
      "step:   131480, time: 0.738, loss: 0.8945, l1: 0.1422, vgg: 0.3992, mask: 0.3531\n",
      "step:   131500, time: 0.744, loss: 1.0942, l1: 0.2015, vgg: 0.4897, mask: 0.4030\n",
      "step:   131520, time: 0.734, loss: 1.0770, l1: 0.2600, vgg: 0.4060, mask: 0.4110\n",
      "step:   131540, time: 0.769, loss: 1.0489, l1: 0.2304, vgg: 0.4437, mask: 0.3748\n",
      "step:   131560, time: 0.737, loss: 1.1114, l1: 0.2509, vgg: 0.4607, mask: 0.3997\n",
      "step:   131580, time: 0.779, loss: 0.9852, l1: 0.1819, vgg: 0.4433, mask: 0.3599\n",
      "step:   131600, time: 0.773, loss: 1.0600, l1: 0.2208, vgg: 0.4684, mask: 0.3708\n",
      "step:   131620, time: 0.766, loss: 1.0918, l1: 0.2409, vgg: 0.4804, mask: 0.3705\n",
      "step:   131640, time: 0.723, loss: 1.0378, l1: 0.2249, vgg: 0.4313, mask: 0.3816\n",
      "step:   131660, time: 0.769, loss: 1.1510, l1: 0.2723, vgg: 0.4611, mask: 0.4176\n",
      "step:   131680, time: 0.743, loss: 0.9802, l1: 0.1736, vgg: 0.4146, mask: 0.3920\n",
      "step:   131700, time: 0.746, loss: 0.9335, l1: 0.1807, vgg: 0.3878, mask: 0.3650\n",
      "step:   131720, time: 0.764, loss: 1.0416, l1: 0.2514, vgg: 0.3997, mask: 0.3905\n",
      "step:   131740, time: 0.731, loss: 0.9824, l1: 0.2032, vgg: 0.4070, mask: 0.3722\n",
      "step:   131760, time: 0.759, loss: 1.1508, l1: 0.2660, vgg: 0.4618, mask: 0.4231\n",
      "step:   131780, time: 0.754, loss: 1.1590, l1: 0.2965, vgg: 0.4315, mask: 0.4310\n",
      "step:   131800, time: 0.768, loss: 1.0148, l1: 0.2106, vgg: 0.4578, mask: 0.3465\n",
      "step:   131820, time: 0.761, loss: 1.0176, l1: 0.1894, vgg: 0.4213, mask: 0.4069\n",
      "step:   131840, time: 0.752, loss: 0.9545, l1: 0.2157, vgg: 0.3498, mask: 0.3891\n",
      "step:   131860, time: 0.731, loss: 1.2486, l1: 0.2610, vgg: 0.6041, mask: 0.3834\n",
      "step:   131880, time: 0.764, loss: 1.0210, l1: 0.1960, vgg: 0.4331, mask: 0.3919\n",
      "step:   131900, time: 0.737, loss: 1.0520, l1: 0.2489, vgg: 0.4043, mask: 0.3989\n",
      "step:   131920, time: 0.734, loss: 1.0708, l1: 0.2420, vgg: 0.4043, mask: 0.4245\n",
      "step:   131940, time: 0.744, loss: 1.1047, l1: 0.2862, vgg: 0.3989, mask: 0.4196\n",
      "step:   131960, time: 0.721, loss: 1.0028, l1: 0.2225, vgg: 0.4024, mask: 0.3779\n",
      "step:   131980, time: 0.760, loss: 1.1167, l1: 0.2377, vgg: 0.4754, mask: 0.4036\n",
      "step:   132000, time: 0.778, loss: 1.0198, l1: 0.1987, vgg: 0.4482, mask: 0.3729\n",
      "step:   132020, time: 0.759, loss: 1.0145, l1: 0.2106, vgg: 0.4013, mask: 0.4026\n",
      "step:   132040, time: 0.742, loss: 0.9624, l1: 0.1866, vgg: 0.4159, mask: 0.3599\n",
      "step:   132060, time: 0.745, loss: 0.9835, l1: 0.2323, vgg: 0.3876, mask: 0.3636\n",
      "step:   132080, time: 0.747, loss: 0.9727, l1: 0.1947, vgg: 0.4111, mask: 0.3670\n",
      "step:   132100, time: 0.733, loss: 0.9819, l1: 0.2186, vgg: 0.3839, mask: 0.3795\n",
      "step:   132120, time: 0.720, loss: 0.9143, l1: 0.1765, vgg: 0.3990, mask: 0.3388\n",
      "step:   132140, time: 0.752, loss: 1.0326, l1: 0.2161, vgg: 0.4618, mask: 0.3546\n",
      "step:   132160, time: 0.764, loss: 1.0815, l1: 0.2232, vgg: 0.4440, mask: 0.4143\n",
      "step:   132180, time: 0.774, loss: 0.9733, l1: 0.1692, vgg: 0.4017, mask: 0.4024\n",
      "step:   132200, time: 0.747, loss: 1.1073, l1: 0.2759, vgg: 0.4483, mask: 0.3831\n",
      "step:   132220, time: 0.743, loss: 1.0744, l1: 0.2327, vgg: 0.4687, mask: 0.3729\n",
      "step:   132240, time: 0.729, loss: 0.8963, l1: 0.1762, vgg: 0.3649, mask: 0.3553\n",
      "step:   132260, time: 0.779, loss: 1.0539, l1: 0.2127, vgg: 0.4372, mask: 0.4040\n",
      "step:   132280, time: 0.762, loss: 0.9973, l1: 0.1963, vgg: 0.4178, mask: 0.3832\n",
      "step:   132300, time: 0.717, loss: 0.9487, l1: 0.1709, vgg: 0.4141, mask: 0.3638\n",
      "step:   132320, time: 0.742, loss: 0.9293, l1: 0.1869, vgg: 0.3793, mask: 0.3631\n",
      "step:   132340, time: 0.775, loss: 1.0549, l1: 0.2388, vgg: 0.4188, mask: 0.3973\n",
      "step:   132360, time: 0.787, loss: 1.0659, l1: 0.2297, vgg: 0.4619, mask: 0.3743\n",
      "step:   132380, time: 0.777, loss: 0.9816, l1: 0.2074, vgg: 0.4240, mask: 0.3502\n",
      "step:   132400, time: 0.795, loss: 0.9969, l1: 0.2097, vgg: 0.4295, mask: 0.3578\n",
      "step:   132420, time: 0.737, loss: 1.0311, l1: 0.2180, vgg: 0.4390, mask: 0.3740\n",
      "step:   132440, time: 0.733, loss: 1.0566, l1: 0.2630, vgg: 0.4202, mask: 0.3734\n",
      "step:   132460, time: 0.752, loss: 0.9289, l1: 0.1957, vgg: 0.3969, mask: 0.3363\n",
      "step:   132480, time: 0.746, loss: 1.0799, l1: 0.2191, vgg: 0.4713, mask: 0.3896\n",
      "step:   132500, time: 0.732, loss: 1.1126, l1: 0.2754, vgg: 0.4135, mask: 0.4236\n",
      "step:   132520, time: 0.789, loss: 1.1848, l1: 0.2999, vgg: 0.4907, mask: 0.3942\n",
      "step:   132540, time: 0.723, loss: 0.9257, l1: 0.1929, vgg: 0.4128, mask: 0.3200\n",
      "step:   132560, time: 0.776, loss: 1.0980, l1: 0.2421, vgg: 0.4839, mask: 0.3719\n",
      "step:   132580, time: 0.754, loss: 1.0491, l1: 0.2330, vgg: 0.4363, mask: 0.3797\n",
      "step:   132600, time: 0.746, loss: 1.0792, l1: 0.2524, vgg: 0.4526, mask: 0.3742\n",
      "step:   132620, time: 0.744, loss: 1.0116, l1: 0.1842, vgg: 0.4921, mask: 0.3352\n",
      "step:   132640, time: 0.739, loss: 0.9717, l1: 0.1819, vgg: 0.4234, mask: 0.3664\n",
      "step:   132660, time: 0.740, loss: 1.0107, l1: 0.2421, vgg: 0.3808, mask: 0.3878\n",
      "step:   132680, time: 0.743, loss: 1.0391, l1: 0.2120, vgg: 0.4437, mask: 0.3834\n",
      "step:   132700, time: 0.745, loss: 1.0081, l1: 0.2386, vgg: 0.3594, mask: 0.4101\n",
      "step:   132720, time: 0.764, loss: 0.9362, l1: 0.1793, vgg: 0.4047, mask: 0.3521\n",
      "step:   132740, time: 0.718, loss: 0.9035, l1: 0.2091, vgg: 0.3585, mask: 0.3359\n",
      "step:   132760, time: 0.755, loss: 1.0069, l1: 0.1948, vgg: 0.4409, mask: 0.3711\n",
      "step:   132780, time: 0.718, loss: 0.9474, l1: 0.1703, vgg: 0.4333, mask: 0.3439\n",
      "step:   132800, time: 0.748, loss: 0.9950, l1: 0.1891, vgg: 0.4732, mask: 0.3327\n",
      "step:   132820, time: 0.738, loss: 0.9978, l1: 0.1861, vgg: 0.4306, mask: 0.3810\n",
      "step:   132840, time: 0.761, loss: 1.0533, l1: 0.2093, vgg: 0.4785, mask: 0.3655\n",
      "step:   132860, time: 0.743, loss: 1.0344, l1: 0.2497, vgg: 0.3813, mask: 0.4033\n",
      "step:   132880, time: 0.782, loss: 1.0409, l1: 0.2233, vgg: 0.4283, mask: 0.3894\n",
      "step:   132900, time: 0.779, loss: 0.9856, l1: 0.1874, vgg: 0.4399, mask: 0.3584\n",
      "step:   132920, time: 0.765, loss: 1.0275, l1: 0.1731, vgg: 0.4771, mask: 0.3774\n",
      "step:   132940, time: 0.769, loss: 1.0330, l1: 0.2074, vgg: 0.4429, mask: 0.3826\n",
      "step:   132960, time: 0.749, loss: 1.0874, l1: 0.2036, vgg: 0.4863, mask: 0.3975\n",
      "step:   132980, time: 0.751, loss: 1.0253, l1: 0.2128, vgg: 0.4410, mask: 0.3714\n",
      "step:   133000, time: 0.804, loss: 1.0558, l1: 0.2116, vgg: 0.4795, mask: 0.3646\n",
      "step:   133020, time: 0.749, loss: 0.9482, l1: 0.1671, vgg: 0.4045, mask: 0.3766\n",
      "step:   133040, time: 0.727, loss: 0.9565, l1: 0.1949, vgg: 0.3941, mask: 0.3675\n",
      "step:   133060, time: 0.749, loss: 1.0553, l1: 0.2246, vgg: 0.4310, mask: 0.3997\n",
      "step:   133080, time: 0.747, loss: 1.2250, l1: 0.3454, vgg: 0.4847, mask: 0.3949\n",
      "step:   133100, time: 0.753, loss: 0.8989, l1: 0.1634, vgg: 0.3866, mask: 0.3490\n",
      "step:   133120, time: 0.770, loss: 0.9899, l1: 0.2209, vgg: 0.3997, mask: 0.3694\n",
      "step:   133140, time: 0.771, loss: 1.1414, l1: 0.2470, vgg: 0.4877, mask: 0.4068\n",
      "step:   133160, time: 0.743, loss: 0.9777, l1: 0.1682, vgg: 0.4360, mask: 0.3735\n",
      "step:   133180, time: 0.748, loss: 1.0134, l1: 0.1935, vgg: 0.4405, mask: 0.3793\n",
      "step:   133200, time: 0.775, loss: 0.9869, l1: 0.1883, vgg: 0.4189, mask: 0.3797\n",
      "step:   133220, time: 0.757, loss: 1.0376, l1: 0.1864, vgg: 0.4628, mask: 0.3884\n",
      "step:   133240, time: 0.775, loss: 1.1213, l1: 0.2304, vgg: 0.5003, mask: 0.3906\n",
      "step:   133260, time: 0.765, loss: 1.1022, l1: 0.2388, vgg: 0.5044, mask: 0.3591\n",
      "step:   133280, time: 0.763, loss: 1.0794, l1: 0.2200, vgg: 0.4682, mask: 0.3913\n",
      "step:   133300, time: 0.765, loss: 1.1778, l1: 0.3204, vgg: 0.4514, mask: 0.4060\n",
      "step:   133320, time: 0.776, loss: 1.1197, l1: 0.2246, vgg: 0.4949, mask: 0.4001\n",
      "step:   133340, time: 0.736, loss: 0.8884, l1: 0.1498, vgg: 0.4044, mask: 0.3342\n",
      "step:   133360, time: 0.742, loss: 0.9972, l1: 0.1907, vgg: 0.4172, mask: 0.3893\n",
      "step:   133380, time: 0.807, loss: 1.0117, l1: 0.2361, vgg: 0.4021, mask: 0.3735\n",
      "step:   133400, time: 0.764, loss: 1.0894, l1: 0.2619, vgg: 0.4308, mask: 0.3967\n",
      "step:   133420, time: 0.766, loss: 1.0344, l1: 0.2169, vgg: 0.4368, mask: 0.3807\n",
      "step:   133440, time: 0.768, loss: 1.0048, l1: 0.1858, vgg: 0.4504, mask: 0.3686\n",
      "step:   133460, time: 0.764, loss: 1.1615, l1: 0.2600, vgg: 0.4933, mask: 0.4083\n",
      "step:   133480, time: 0.767, loss: 1.0835, l1: 0.2281, vgg: 0.4581, mask: 0.3972\n",
      "step:   133500, time: 0.740, loss: 0.8850, l1: 0.1425, vgg: 0.3477, mask: 0.3948\n",
      "step:   133520, time: 0.746, loss: 1.0028, l1: 0.2035, vgg: 0.4452, mask: 0.3541\n",
      "step:   133540, time: 0.757, loss: 1.0020, l1: 0.1957, vgg: 0.4296, mask: 0.3767\n",
      "step:   133560, time: 0.741, loss: 0.9670, l1: 0.2023, vgg: 0.3947, mask: 0.3700\n",
      "step:   133580, time: 0.735, loss: 1.0887, l1: 0.2250, vgg: 0.4804, mask: 0.3833\n",
      "step:   133600, time: 0.721, loss: 0.9599, l1: 0.1800, vgg: 0.4284, mask: 0.3515\n",
      "step:   133620, time: 0.779, loss: 1.0185, l1: 0.1881, vgg: 0.4392, mask: 0.3912\n",
      "step:   133640, time: 0.722, loss: 0.9244, l1: 0.1829, vgg: 0.3725, mask: 0.3690\n",
      "step:   133660, time: 0.766, loss: 1.0452, l1: 0.1970, vgg: 0.4695, mask: 0.3787\n",
      "step:   133680, time: 0.759, loss: 1.1213, l1: 0.2206, vgg: 0.4583, mask: 0.4424\n",
      "step:   133700, time: 0.753, loss: 1.0307, l1: 0.1971, vgg: 0.4888, mask: 0.3448\n",
      "step:   133720, time: 0.770, loss: 1.0091, l1: 0.1637, vgg: 0.4894, mask: 0.3560\n",
      "step:   133740, time: 0.736, loss: 1.0039, l1: 0.1902, vgg: 0.3970, mask: 0.4167\n",
      "step:   133760, time: 0.716, loss: 0.9570, l1: 0.1823, vgg: 0.4139, mask: 0.3608\n",
      "step:   133780, time: 0.736, loss: 0.9126, l1: 0.1931, vgg: 0.3782, mask: 0.3413\n",
      "step:   133800, time: 0.746, loss: 0.9766, l1: 0.2082, vgg: 0.4022, mask: 0.3662\n",
      "step:   133820, time: 0.806, loss: 0.9949, l1: 0.2096, vgg: 0.4236, mask: 0.3617\n",
      "step:   133840, time: 0.861, loss: 1.0513, l1: 0.2057, vgg: 0.4947, mask: 0.3509\n",
      "step:   133860, time: 0.806, loss: 1.0396, l1: 0.1994, vgg: 0.4555, mask: 0.3847\n",
      "step:   133880, time: 0.778, loss: 1.1365, l1: 0.2839, vgg: 0.4753, mask: 0.3772\n",
      "step:   133900, time: 0.812, loss: 1.0675, l1: 0.2169, vgg: 0.4786, mask: 0.3721\n",
      "step:   133920, time: 0.843, loss: 1.0070, l1: 0.1866, vgg: 0.4017, mask: 0.4186\n",
      "step:   133940, time: 0.775, loss: 1.1105, l1: 0.2502, vgg: 0.4574, mask: 0.4029\n",
      "step:   133960, time: 0.737, loss: 1.0668, l1: 0.2426, vgg: 0.4301, mask: 0.3940\n",
      "step:   133980, time: 0.733, loss: 0.9929, l1: 0.1721, vgg: 0.4162, mask: 0.4046\n",
      "step:   134000, time: 0.770, loss: 1.0791, l1: 0.1953, vgg: 0.5344, mask: 0.3494\n",
      "step:   134020, time: 0.743, loss: 0.9469, l1: 0.1787, vgg: 0.4116, mask: 0.3565\n",
      "step:   134040, time: 0.749, loss: 1.0621, l1: 0.2625, vgg: 0.4051, mask: 0.3945\n",
      "step:   134060, time: 0.750, loss: 1.1240, l1: 0.2602, vgg: 0.4850, mask: 0.3787\n",
      "step:   134080, time: 0.767, loss: 1.0096, l1: 0.2012, vgg: 0.4580, mask: 0.3504\n",
      "step:   134100, time: 0.746, loss: 1.0890, l1: 0.2449, vgg: 0.4472, mask: 0.3970\n",
      "step:   134120, time: 0.749, loss: 1.0665, l1: 0.2373, vgg: 0.4381, mask: 0.3912\n",
      "step:   134140, time: 0.763, loss: 1.0912, l1: 0.2657, vgg: 0.4457, mask: 0.3798\n",
      "step:   134160, time: 0.780, loss: 1.1258, l1: 0.2123, vgg: 0.5251, mask: 0.3884\n",
      "step:   134180, time: 0.752, loss: 1.0243, l1: 0.2292, vgg: 0.3994, mask: 0.3957\n",
      "step:   134200, time: 0.748, loss: 1.0348, l1: 0.2209, vgg: 0.4448, mask: 0.3690\n",
      "step:   134220, time: 0.741, loss: 1.0407, l1: 0.2083, vgg: 0.4474, mask: 0.3850\n",
      "step:   134240, time: 0.712, loss: 0.8864, l1: 0.1557, vgg: 0.3951, mask: 0.3356\n",
      "step:   134260, time: 0.755, loss: 1.1055, l1: 0.2727, vgg: 0.4477, mask: 0.3852\n",
      "step:   134280, time: 0.768, loss: 1.1353, l1: 0.2717, vgg: 0.4767, mask: 0.3869\n",
      "step:   134300, time: 0.760, loss: 0.9564, l1: 0.1766, vgg: 0.4386, mask: 0.3411\n",
      "step:   134320, time: 0.736, loss: 0.9486, l1: 0.1783, vgg: 0.3791, mask: 0.3912\n",
      "step:   134340, time: 0.773, loss: 1.1079, l1: 0.2356, vgg: 0.4664, mask: 0.4060\n",
      "step:   134360, time: 0.753, loss: 1.0000, l1: 0.2026, vgg: 0.4098, mask: 0.3877\n",
      "step:   134380, time: 0.765, loss: 1.0421, l1: 0.2241, vgg: 0.4256, mask: 0.3925\n",
      "step:   134400, time: 0.788, loss: 1.0562, l1: 0.2195, vgg: 0.4597, mask: 0.3769\n",
      "step:   134420, time: 0.793, loss: 1.0239, l1: 0.1938, vgg: 0.4160, mask: 0.4140\n",
      "step:   134440, time: 0.772, loss: 0.9879, l1: 0.1556, vgg: 0.4464, mask: 0.3858\n",
      "step:   134460, time: 0.771, loss: 1.0154, l1: 0.1830, vgg: 0.4585, mask: 0.3739\n",
      "step:   134480, time: 0.775, loss: 1.0373, l1: 0.2402, vgg: 0.4213, mask: 0.3758\n",
      "step:   134500, time: 0.751, loss: 0.9528, l1: 0.1983, vgg: 0.3934, mask: 0.3611\n",
      "step:   134520, time: 0.758, loss: 1.0305, l1: 0.1918, vgg: 0.4732, mask: 0.3655\n",
      "step:   134540, time: 0.794, loss: 1.0564, l1: 0.2290, vgg: 0.4492, mask: 0.3782\n",
      "step:   134560, time: 0.760, loss: 0.9693, l1: 0.1783, vgg: 0.4363, mask: 0.3546\n",
      "step:   134580, time: 0.758, loss: 1.0091, l1: 0.2231, vgg: 0.4089, mask: 0.3772\n",
      "step:   134600, time: 0.774, loss: 1.0893, l1: 0.2509, vgg: 0.4237, mask: 0.4147\n",
      "step:   134620, time: 0.757, loss: 1.0740, l1: 0.2239, vgg: 0.4585, mask: 0.3916\n",
      "step:   134640, time: 0.752, loss: 0.9938, l1: 0.1628, vgg: 0.4308, mask: 0.4002\n",
      "step:   134660, time: 0.757, loss: 0.9396, l1: 0.1587, vgg: 0.4159, mask: 0.3650\n",
      "step:   134680, time: 0.781, loss: 1.0314, l1: 0.2410, vgg: 0.4313, mask: 0.3591\n",
      "step:   134700, time: 0.724, loss: 0.9905, l1: 0.2034, vgg: 0.3876, mask: 0.3994\n",
      "step:   134720, time: 0.816, loss: 1.0240, l1: 0.2115, vgg: 0.4338, mask: 0.3787\n",
      "step:   134740, time: 0.754, loss: 1.1878, l1: 0.2806, vgg: 0.5009, mask: 0.4063\n",
      "step:   134760, time: 0.770, loss: 0.9492, l1: 0.2006, vgg: 0.3617, mask: 0.3870\n",
      "step:   134780, time: 0.756, loss: 1.0622, l1: 0.2544, vgg: 0.3962, mask: 0.4116\n",
      "step:   134800, time: 0.754, loss: 0.9576, l1: 0.1455, vgg: 0.4297, mask: 0.3824\n",
      "step:   134820, time: 0.726, loss: 0.8843, l1: 0.1450, vgg: 0.4002, mask: 0.3392\n",
      "step:   134840, time: 0.761, loss: 0.9552, l1: 0.1962, vgg: 0.4230, mask: 0.3360\n",
      "step:   134860, time: 0.795, loss: 0.9379, l1: 0.1941, vgg: 0.4027, mask: 0.3411\n",
      "step:   134880, time: 0.739, loss: 1.0431, l1: 0.1878, vgg: 0.4902, mask: 0.3650\n",
      "step:   134900, time: 0.745, loss: 1.1001, l1: 0.2260, vgg: 0.4844, mask: 0.3897\n",
      "step:   134920, time: 0.787, loss: 0.9886, l1: 0.1929, vgg: 0.4100, mask: 0.3857\n",
      "step:   134940, time: 0.752, loss: 1.1133, l1: 0.2167, vgg: 0.5044, mask: 0.3922\n",
      "step:   134960, time: 0.762, loss: 0.9462, l1: 0.1915, vgg: 0.3890, mask: 0.3658\n",
      "step:   134980, time: 0.757, loss: 1.0828, l1: 0.2285, vgg: 0.4565, mask: 0.3978\n",
      "step:   135000, time: 0.766, loss: 1.1194, l1: 0.2511, vgg: 0.4569, mask: 0.4115\n",
      "step:   135020, time: 0.776, loss: 1.0809, l1: 0.2133, vgg: 0.4624, mask: 0.4051\n",
      "step:   135040, time: 0.729, loss: 1.0046, l1: 0.2132, vgg: 0.4038, mask: 0.3875\n",
      "step:   135060, time: 0.757, loss: 1.1569, l1: 0.2585, vgg: 0.4918, mask: 0.4066\n",
      "step:   135080, time: 0.771, loss: 1.0653, l1: 0.2257, vgg: 0.4462, mask: 0.3934\n",
      "step:   135100, time: 0.807, loss: 1.0578, l1: 0.2130, vgg: 0.4622, mask: 0.3826\n",
      "step:   135120, time: 0.750, loss: 1.0139, l1: 0.1878, vgg: 0.4358, mask: 0.3903\n",
      "step:   135140, time: 0.726, loss: 0.9089, l1: 0.1831, vgg: 0.3570, mask: 0.3687\n",
      "step:   135160, time: 0.789, loss: 1.1336, l1: 0.2428, vgg: 0.4727, mask: 0.4181\n",
      "step:   135180, time: 0.749, loss: 0.9303, l1: 0.1708, vgg: 0.4028, mask: 0.3568\n",
      "step:   135200, time: 0.768, loss: 1.0824, l1: 0.2465, vgg: 0.4388, mask: 0.3971\n",
      "step:   135220, time: 0.753, loss: 1.0295, l1: 0.2289, vgg: 0.3965, mask: 0.4041\n",
      "step:   135240, time: 0.786, loss: 1.0854, l1: 0.2490, vgg: 0.4474, mask: 0.3890\n",
      "step:   135260, time: 0.748, loss: 0.9855, l1: 0.1953, vgg: 0.4079, mask: 0.3823\n",
      "step:   135280, time: 0.760, loss: 1.1424, l1: 0.2627, vgg: 0.4641, mask: 0.4156\n",
      "step:   135300, time: 0.781, loss: 1.1917, l1: 0.2705, vgg: 0.5167, mask: 0.4045\n",
      "step:   135320, time: 0.728, loss: 1.0589, l1: 0.2671, vgg: 0.4036, mask: 0.3883\n",
      "step:   135340, time: 0.743, loss: 1.0170, l1: 0.2187, vgg: 0.4154, mask: 0.3830\n",
      "step:   135360, time: 0.814, loss: 1.1620, l1: 0.2298, vgg: 0.5335, mask: 0.3987\n",
      "step:   135380, time: 0.778, loss: 1.2193, l1: 0.2602, vgg: 0.5566, mask: 0.4025\n",
      "step:   135400, time: 0.716, loss: 0.8751, l1: 0.1521, vgg: 0.3697, mask: 0.3534\n",
      "step:   135420, time: 0.763, loss: 0.9816, l1: 0.1957, vgg: 0.4132, mask: 0.3728\n",
      "step:   135440, time: 0.749, loss: 1.1076, l1: 0.2351, vgg: 0.4889, mask: 0.3836\n",
      "step:   135460, time: 0.718, loss: 0.9153, l1: 0.1532, vgg: 0.3744, mask: 0.3876\n",
      "step:   135480, time: 0.795, loss: 1.1925, l1: 0.2585, vgg: 0.5023, mask: 0.4317\n",
      "step:   135500, time: 0.754, loss: 1.0197, l1: 0.2080, vgg: 0.4435, mask: 0.3682\n",
      "step:   135520, time: 0.759, loss: 1.0825, l1: 0.2353, vgg: 0.4613, mask: 0.3859\n",
      "step:   135540, time: 0.791, loss: 1.1550, l1: 0.2293, vgg: 0.5126, mask: 0.4131\n",
      "step:   135560, time: 0.746, loss: 1.0754, l1: 0.2379, vgg: 0.4721, mask: 0.3655\n",
      "step:   135580, time: 0.784, loss: 0.9286, l1: 0.1864, vgg: 0.3889, mask: 0.3533\n",
      "step:   135600, time: 0.765, loss: 1.0663, l1: 0.2391, vgg: 0.4156, mask: 0.4117\n",
      "step:   135620, time: 0.726, loss: 0.9403, l1: 0.1489, vgg: 0.4399, mask: 0.3515\n",
      "step:   135640, time: 0.763, loss: 0.9804, l1: 0.1955, vgg: 0.4274, mask: 0.3576\n",
      "step:   135660, time: 0.768, loss: 1.0459, l1: 0.2794, vgg: 0.3629, mask: 0.4037\n",
      "step:   135680, time: 0.767, loss: 1.0094, l1: 0.1710, vgg: 0.4667, mask: 0.3717\n",
      "step:   135700, time: 0.726, loss: 0.8937, l1: 0.1534, vgg: 0.3740, mask: 0.3663\n",
      "step:   135720, time: 0.748, loss: 0.9955, l1: 0.2246, vgg: 0.4121, mask: 0.3587\n",
      "step:   135740, time: 0.770, loss: 0.9932, l1: 0.2270, vgg: 0.3813, mask: 0.3849\n",
      "step:   135760, time: 0.770, loss: 1.0550, l1: 0.2398, vgg: 0.4182, mask: 0.3969\n",
      "step:   135780, time: 0.749, loss: 1.0186, l1: 0.1961, vgg: 0.4367, mask: 0.3859\n",
      "step:   135800, time: 0.739, loss: 1.0545, l1: 0.2435, vgg: 0.3997, mask: 0.4114\n",
      "step:   135820, time: 0.764, loss: 1.0915, l1: 0.2247, vgg: 0.4801, mask: 0.3867\n",
      "step:   135840, time: 0.789, loss: 1.0789, l1: 0.2291, vgg: 0.4525, mask: 0.3974\n",
      "step:   135860, time: 0.754, loss: 0.9611, l1: 0.1953, vgg: 0.4393, mask: 0.3265\n",
      "step:   135880, time: 0.732, loss: 0.9768, l1: 0.2196, vgg: 0.3808, mask: 0.3763\n",
      "step:   135900, time: 0.792, loss: 0.9040, l1: 0.1610, vgg: 0.3779, mask: 0.3651\n",
      "step:   135920, time: 0.767, loss: 0.9968, l1: 0.1796, vgg: 0.4438, mask: 0.3734\n",
      "step:   135940, time: 0.805, loss: 1.1569, l1: 0.2606, vgg: 0.4991, mask: 0.3972\n",
      "step:   135960, time: 0.766, loss: 1.0313, l1: 0.1937, vgg: 0.4705, mask: 0.3671\n",
      "step:   135980, time: 0.797, loss: 0.9712, l1: 0.2059, vgg: 0.4222, mask: 0.3430\n",
      "step:   136000, time: 0.743, loss: 0.9845, l1: 0.2104, vgg: 0.3763, mask: 0.3978\n",
      "step:   136020, time: 0.787, loss: 1.1755, l1: 0.2867, vgg: 0.4753, mask: 0.4135\n",
      "step:   136040, time: 0.741, loss: 1.1182, l1: 0.2466, vgg: 0.4478, mask: 0.4238\n",
      "step:   136060, time: 0.732, loss: 0.9140, l1: 0.1472, vgg: 0.4100, mask: 0.3568\n",
      "step:   136080, time: 0.741, loss: 1.0320, l1: 0.2329, vgg: 0.4174, mask: 0.3817\n",
      "step:   136100, time: 0.764, loss: 1.0312, l1: 0.2172, vgg: 0.4591, mask: 0.3549\n",
      "step:   136120, time: 0.768, loss: 1.0348, l1: 0.2593, vgg: 0.3848, mask: 0.3907\n",
      "step:   136140, time: 0.809, loss: 0.9235, l1: 0.1609, vgg: 0.4254, mask: 0.3372\n",
      "step:   136160, time: 0.798, loss: 1.0435, l1: 0.1996, vgg: 0.4641, mask: 0.3798\n",
      "step:   136180, time: 0.728, loss: 1.0515, l1: 0.2256, vgg: 0.4206, mask: 0.4053\n",
      "step:   136200, time: 0.771, loss: 1.0889, l1: 0.2182, vgg: 0.4753, mask: 0.3954\n",
      "step:   136220, time: 0.723, loss: 0.9814, l1: 0.1533, vgg: 0.4448, mask: 0.3834\n",
      "step:   136240, time: 0.751, loss: 1.0438, l1: 0.2218, vgg: 0.4562, mask: 0.3658\n",
      "step:   136260, time: 0.762, loss: 1.0649, l1: 0.2106, vgg: 0.4639, mask: 0.3904\n",
      "step:   136280, time: 0.753, loss: 1.0166, l1: 0.2079, vgg: 0.4421, mask: 0.3666\n",
      "step:   136300, time: 0.729, loss: 0.9478, l1: 0.2050, vgg: 0.3885, mask: 0.3543\n",
      "step:   136320, time: 0.762, loss: 0.9149, l1: 0.1671, vgg: 0.3738, mask: 0.3740\n",
      "step:   136340, time: 0.815, loss: 1.0214, l1: 0.2027, vgg: 0.4544, mask: 0.3644\n",
      "step:   136360, time: 0.713, loss: 0.9244, l1: 0.1807, vgg: 0.3772, mask: 0.3665\n",
      "step:   136380, time: 0.757, loss: 0.9269, l1: 0.1518, vgg: 0.4400, mask: 0.3351\n",
      "step:   136400, time: 0.762, loss: 0.9282, l1: 0.1978, vgg: 0.3639, mask: 0.3666\n",
      "step:   136420, time: 0.740, loss: 1.0479, l1: 0.2575, vgg: 0.3996, mask: 0.3908\n",
      "step:   136440, time: 0.744, loss: 1.0028, l1: 0.1904, vgg: 0.4596, mask: 0.3529\n",
      "step:   136460, time: 0.765, loss: 1.1402, l1: 0.2403, vgg: 0.4958, mask: 0.4041\n",
      "step:   136480, time: 0.749, loss: 0.9694, l1: 0.1638, vgg: 0.4059, mask: 0.3997\n",
      "step:   136500, time: 0.790, loss: 1.1346, l1: 0.2400, vgg: 0.4940, mask: 0.4006\n",
      "step:   136520, time: 0.792, loss: 0.9095, l1: 0.1781, vgg: 0.3735, mask: 0.3579\n",
      "step:   136540, time: 0.747, loss: 1.0107, l1: 0.2145, vgg: 0.4311, mask: 0.3651\n",
      "step:   136560, time: 0.762, loss: 1.0543, l1: 0.2571, vgg: 0.3981, mask: 0.3991\n",
      "step:   136580, time: 0.745, loss: 0.9488, l1: 0.1744, vgg: 0.3907, mask: 0.3837\n",
      "step:   136600, time: 0.779, loss: 1.1604, l1: 0.2570, vgg: 0.5215, mask: 0.3819\n",
      "step:   136620, time: 0.731, loss: 1.0795, l1: 0.2553, vgg: 0.4423, mask: 0.3819\n",
      "step:   136640, time: 0.769, loss: 1.0503, l1: 0.1963, vgg: 0.4608, mask: 0.3933\n",
      "step:   136660, time: 0.760, loss: 1.0280, l1: 0.2199, vgg: 0.3922, mask: 0.4159\n",
      "step:   136680, time: 0.757, loss: 0.9893, l1: 0.2049, vgg: 0.4008, mask: 0.3836\n",
      "step:   136700, time: 0.741, loss: 1.0985, l1: 0.2540, vgg: 0.4185, mask: 0.4260\n",
      "step:   136720, time: 0.783, loss: 1.0513, l1: 0.2064, vgg: 0.4628, mask: 0.3821\n",
      "step:   136740, time: 0.740, loss: 1.0689, l1: 0.2395, vgg: 0.4451, mask: 0.3843\n",
      "step:   136760, time: 0.788, loss: 1.1211, l1: 0.2393, vgg: 0.4798, mask: 0.4020\n",
      "step:   136780, time: 0.783, loss: 0.9931, l1: 0.2143, vgg: 0.3987, mask: 0.3801\n",
      "step:   136800, time: 0.767, loss: 0.9536, l1: 0.1901, vgg: 0.3934, mask: 0.3701\n",
      "step:   136820, time: 0.741, loss: 0.9292, l1: 0.1872, vgg: 0.3501, mask: 0.3919\n",
      "step:   136840, time: 0.787, loss: 0.9636, l1: 0.1731, vgg: 0.4465, mask: 0.3440\n",
      "step:   136860, time: 0.759, loss: 1.0318, l1: 0.2127, vgg: 0.4351, mask: 0.3839\n",
      "step:   136880, time: 0.767, loss: 1.0286, l1: 0.2229, vgg: 0.4213, mask: 0.3845\n",
      "step:   136900, time: 0.870, loss: 0.9971, l1: 0.1436, vgg: 0.4350, mask: 0.4184\n",
      "step:   136920, time: 0.808, loss: 1.0689, l1: 0.2195, vgg: 0.4631, mask: 0.3863\n",
      "step:   136940, time: 0.766, loss: 1.0475, l1: 0.2178, vgg: 0.4607, mask: 0.3690\n",
      "step:   136960, time: 0.781, loss: 1.0133, l1: 0.2113, vgg: 0.4413, mask: 0.3607\n",
      "step:   136980, time: 0.753, loss: 0.9165, l1: 0.1755, vgg: 0.3544, mask: 0.3865\n",
      "step:   137000, time: 0.783, loss: 1.1074, l1: 0.2221, vgg: 0.5083, mask: 0.3770\n",
      "step:   137020, time: 0.759, loss: 1.1690, l1: 0.2248, vgg: 0.5573, mask: 0.3868\n",
      "step:   137040, time: 0.732, loss: 1.2011, l1: 0.2282, vgg: 0.5553, mask: 0.4176\n",
      "step:   137060, time: 0.725, loss: 1.0246, l1: 0.1851, vgg: 0.4912, mask: 0.3483\n",
      "step:   137080, time: 0.729, loss: 0.8986, l1: 0.1349, vgg: 0.4195, mask: 0.3441\n",
      "step:   137100, time: 0.772, loss: 0.9537, l1: 0.1688, vgg: 0.4421, mask: 0.3428\n",
      "step:   137120, time: 0.750, loss: 0.9971, l1: 0.2012, vgg: 0.4204, mask: 0.3755\n",
      "step:   137140, time: 0.780, loss: 1.1076, l1: 0.2284, vgg: 0.4725, mask: 0.4068\n",
      "step:   137160, time: 0.751, loss: 1.0938, l1: 0.2717, vgg: 0.4226, mask: 0.3995\n",
      "step:   137180, time: 0.735, loss: 0.9581, l1: 0.1914, vgg: 0.4034, mask: 0.3633\n",
      "step:   137200, time: 0.749, loss: 1.0308, l1: 0.2192, vgg: 0.4370, mask: 0.3746\n",
      "step:   137220, time: 0.740, loss: 0.9569, l1: 0.1792, vgg: 0.4275, mask: 0.3502\n",
      "step:   137240, time: 0.800, loss: 1.0755, l1: 0.2258, vgg: 0.4365, mask: 0.4132\n",
      "step:   137260, time: 0.751, loss: 1.0404, l1: 0.2296, vgg: 0.4335, mask: 0.3773\n",
      "step:   137280, time: 0.758, loss: 0.9983, l1: 0.2216, vgg: 0.3813, mask: 0.3955\n",
      "step:   137300, time: 0.741, loss: 0.9069, l1: 0.1352, vgg: 0.4396, mask: 0.3321\n",
      "step:   137320, time: 0.752, loss: 1.0221, l1: 0.1788, vgg: 0.4406, mask: 0.4027\n",
      "step:   137340, time: 0.752, loss: 0.9875, l1: 0.2053, vgg: 0.4279, mask: 0.3543\n",
      "step:   137360, time: 0.762, loss: 1.0725, l1: 0.1976, vgg: 0.4594, mask: 0.4154\n",
      "step:   137380, time: 0.760, loss: 1.0518, l1: 0.2179, vgg: 0.4193, mask: 0.4147\n",
      "step:   137400, time: 0.727, loss: 0.9471, l1: 0.1790, vgg: 0.4055, mask: 0.3626\n",
      "step:   137420, time: 0.760, loss: 1.0149, l1: 0.1569, vgg: 0.5234, mask: 0.3346\n",
      "step:   137440, time: 0.751, loss: 1.0067, l1: 0.2051, vgg: 0.4196, mask: 0.3819\n",
      "step:   137460, time: 0.762, loss: 1.0086, l1: 0.2019, vgg: 0.4307, mask: 0.3760\n",
      "step:   137480, time: 0.748, loss: 1.0453, l1: 0.2248, vgg: 0.4272, mask: 0.3933\n",
      "step:   137500, time: 0.748, loss: 1.0623, l1: 0.2080, vgg: 0.4809, mask: 0.3734\n",
      "step:   137520, time: 0.748, loss: 1.0181, l1: 0.1855, vgg: 0.4748, mask: 0.3579\n",
      "step:   137540, time: 0.767, loss: 0.9976, l1: 0.2286, vgg: 0.3878, mask: 0.3812\n",
      "step:   137560, time: 0.741, loss: 0.9988, l1: 0.1783, vgg: 0.4603, mask: 0.3602\n",
      "step:   137580, time: 0.730, loss: 1.1154, l1: 0.2406, vgg: 0.4860, mask: 0.3887\n",
      "step:   137600, time: 0.739, loss: 0.9941, l1: 0.1687, vgg: 0.4623, mask: 0.3632\n",
      "step:   137620, time: 0.763, loss: 0.9994, l1: 0.1845, vgg: 0.4728, mask: 0.3422\n",
      "step:   137640, time: 0.774, loss: 1.1014, l1: 0.2602, vgg: 0.4502, mask: 0.3909\n",
      "step:   137660, time: 0.803, loss: 1.0074, l1: 0.2082, vgg: 0.4280, mask: 0.3713\n",
      "step:   137680, time: 0.755, loss: 0.9720, l1: 0.1825, vgg: 0.4289, mask: 0.3606\n",
      "step:   137700, time: 0.758, loss: 1.0435, l1: 0.2308, vgg: 0.4455, mask: 0.3671\n",
      "step:   137720, time: 0.745, loss: 0.9461, l1: 0.1905, vgg: 0.3997, mask: 0.3558\n",
      "step:   137740, time: 0.706, loss: 0.8807, l1: 0.1374, vgg: 0.3620, mask: 0.3813\n",
      "step:   137760, time: 0.728, loss: 0.9534, l1: 0.2070, vgg: 0.3887, mask: 0.3576\n",
      "step:   137780, time: 0.745, loss: 1.0386, l1: 0.2053, vgg: 0.4582, mask: 0.3751\n",
      "step:   137800, time: 0.778, loss: 1.0069, l1: 0.1950, vgg: 0.4104, mask: 0.4015\n",
      "step:   137820, time: 0.757, loss: 1.0027, l1: 0.2179, vgg: 0.4325, mask: 0.3523\n",
      "step:   137840, time: 0.794, loss: 0.9742, l1: 0.2208, vgg: 0.4175, mask: 0.3359\n",
      "step:   137860, time: 0.767, loss: 1.0240, l1: 0.2406, vgg: 0.3880, mask: 0.3954\n",
      "step:   137880, time: 0.739, loss: 1.0514, l1: 0.2497, vgg: 0.4277, mask: 0.3740\n",
      "step:   137900, time: 0.771, loss: 1.0545, l1: 0.2110, vgg: 0.4663, mask: 0.3772\n",
      "step:   137920, time: 0.747, loss: 1.0224, l1: 0.2053, vgg: 0.4477, mask: 0.3693\n",
      "step:   137940, time: 0.752, loss: 1.0973, l1: 0.2432, vgg: 0.4549, mask: 0.3992\n",
      "step:   137960, time: 0.743, loss: 1.1083, l1: 0.2835, vgg: 0.4173, mask: 0.4075\n",
      "step:   137980, time: 0.749, loss: 0.9484, l1: 0.1601, vgg: 0.4046, mask: 0.3837\n",
      "step:   138000, time: 0.760, loss: 1.1710, l1: 0.2569, vgg: 0.5089, mask: 0.4053\n",
      "step:   138020, time: 0.720, loss: 0.9523, l1: 0.1876, vgg: 0.4173, mask: 0.3475\n",
      "step:   138040, time: 0.754, loss: 1.0942, l1: 0.2543, vgg: 0.4286, mask: 0.4113\n",
      "step:   138060, time: 0.790, loss: 1.0198, l1: 0.2210, vgg: 0.4266, mask: 0.3722\n",
      "step:   138080, time: 0.805, loss: 1.0310, l1: 0.2085, vgg: 0.4375, mask: 0.3851\n",
      "step:   138100, time: 0.742, loss: 1.1004, l1: 0.2777, vgg: 0.4141, mask: 0.4086\n",
      "step:   138120, time: 0.750, loss: 0.9930, l1: 0.1936, vgg: 0.4315, mask: 0.3678\n",
      "step:   138140, time: 0.771, loss: 0.9781, l1: 0.2023, vgg: 0.4061, mask: 0.3697\n",
      "step:   138160, time: 0.766, loss: 1.1583, l1: 0.2659, vgg: 0.4744, mask: 0.4181\n",
      "step:   138180, time: 0.706, loss: 0.9860, l1: 0.1885, vgg: 0.4246, mask: 0.3729\n",
      "step:   138200, time: 0.738, loss: 1.0953, l1: 0.2892, vgg: 0.4091, mask: 0.3970\n",
      "step:   138220, time: 0.727, loss: 1.0758, l1: 0.2290, vgg: 0.4432, mask: 0.4036\n",
      "step:   138240, time: 0.772, loss: 1.0653, l1: 0.2255, vgg: 0.4682, mask: 0.3716\n",
      "step:   138260, time: 0.751, loss: 0.9852, l1: 0.1913, vgg: 0.4239, mask: 0.3701\n",
      "step:   138280, time: 0.747, loss: 0.9353, l1: 0.1632, vgg: 0.3850, mask: 0.3871\n",
      "step:   138300, time: 0.794, loss: 1.1279, l1: 0.2458, vgg: 0.4227, mask: 0.4594\n",
      "step:   138320, time: 0.783, loss: 0.9769, l1: 0.1990, vgg: 0.3922, mask: 0.3858\n",
      "step:   138340, time: 0.751, loss: 1.0826, l1: 0.2485, vgg: 0.4473, mask: 0.3867\n",
      "step:   138360, time: 0.783, loss: 1.0078, l1: 0.2348, vgg: 0.3930, mask: 0.3799\n",
      "step:   138380, time: 0.751, loss: 1.0076, l1: 0.2003, vgg: 0.4138, mask: 0.3934\n",
      "step:   138400, time: 0.733, loss: 1.0333, l1: 0.2358, vgg: 0.4214, mask: 0.3760\n",
      "step:   138420, time: 0.737, loss: 1.0404, l1: 0.2083, vgg: 0.4596, mask: 0.3725\n",
      "step:   138440, time: 0.756, loss: 1.1191, l1: 0.2586, vgg: 0.4665, mask: 0.3940\n",
      "step:   138460, time: 0.781, loss: 1.0124, l1: 0.2327, vgg: 0.3954, mask: 0.3843\n",
      "step:   138480, time: 0.751, loss: 1.0140, l1: 0.1921, vgg: 0.4546, mask: 0.3674\n",
      "step:   138500, time: 0.747, loss: 1.1537, l1: 0.2419, vgg: 0.5012, mask: 0.4106\n",
      "step:   138520, time: 0.764, loss: 1.0893, l1: 0.2121, vgg: 0.5090, mask: 0.3682\n",
      "step:   138540, time: 0.765, loss: 1.1657, l1: 0.2648, vgg: 0.4618, mask: 0.4392\n",
      "step:   138560, time: 0.749, loss: 0.9439, l1: 0.1733, vgg: 0.4254, mask: 0.3452\n",
      "step:   138580, time: 0.763, loss: 1.0541, l1: 0.2145, vgg: 0.4707, mask: 0.3689\n",
      "step:   138600, time: 0.750, loss: 1.1228, l1: 0.2237, vgg: 0.4722, mask: 0.4270\n",
      "step:   138620, time: 0.750, loss: 1.1448, l1: 0.2592, vgg: 0.4807, mask: 0.4049\n",
      "step:   138640, time: 0.799, loss: 1.1085, l1: 0.2260, vgg: 0.4913, mask: 0.3912\n",
      "step:   138660, time: 0.757, loss: 0.9956, l1: 0.1863, vgg: 0.4365, mask: 0.3728\n",
      "step:   138680, time: 0.736, loss: 0.9300, l1: 0.1938, vgg: 0.3778, mask: 0.3584\n",
      "step:   138700, time: 0.782, loss: 1.1218, l1: 0.2536, vgg: 0.4917, mask: 0.3765\n",
      "step:   138720, time: 0.742, loss: 1.1777, l1: 0.2771, vgg: 0.4970, mask: 0.4036\n",
      "step:   138740, time: 0.751, loss: 0.9935, l1: 0.2308, vgg: 0.3758, mask: 0.3869\n",
      "step:   138760, time: 0.762, loss: 1.1140, l1: 0.2337, vgg: 0.4965, mask: 0.3838\n",
      "step:   138780, time: 0.753, loss: 0.9110, l1: 0.1448, vgg: 0.3822, mask: 0.3840\n",
      "step:   138800, time: 0.717, loss: 1.0101, l1: 0.2131, vgg: 0.4081, mask: 0.3889\n",
      "step:   138820, time: 0.751, loss: 0.9725, l1: 0.1607, vgg: 0.4299, mask: 0.3820\n",
      "step:   138840, time: 0.713, loss: 0.9193, l1: 0.1774, vgg: 0.3907, mask: 0.3511\n",
      "step:   138860, time: 0.757, loss: 1.0176, l1: 0.2268, vgg: 0.4072, mask: 0.3836\n",
      "step:   138880, time: 0.727, loss: 0.9860, l1: 0.1685, vgg: 0.4480, mask: 0.3696\n",
      "step:   138900, time: 0.763, loss: 1.0427, l1: 0.2351, vgg: 0.4009, mask: 0.4066\n",
      "step:   138920, time: 0.742, loss: 0.9026, l1: 0.1751, vgg: 0.3600, mask: 0.3675\n",
      "step:   138940, time: 0.752, loss: 0.9650, l1: 0.2182, vgg: 0.3782, mask: 0.3687\n",
      "step:   138960, time: 0.775, loss: 1.1391, l1: 0.2558, vgg: 0.4837, mask: 0.3996\n",
      "step:   138980, time: 0.724, loss: 0.9350, l1: 0.1762, vgg: 0.3969, mask: 0.3619\n",
      "step:   139000, time: 0.720, loss: 0.8797, l1: 0.1533, vgg: 0.3762, mask: 0.3503\n",
      "step:   139020, time: 0.742, loss: 1.0124, l1: 0.1999, vgg: 0.4248, mask: 0.3877\n",
      "step:   139040, time: 0.705, loss: 0.8786, l1: 0.1636, vgg: 0.3651, mask: 0.3499\n",
      "step:   139060, time: 0.753, loss: 0.8899, l1: 0.1208, vgg: 0.4299, mask: 0.3392\n",
      "step:   139080, time: 0.748, loss: 0.9654, l1: 0.1995, vgg: 0.3954, mask: 0.3705\n",
      "step:   139100, time: 0.765, loss: 1.0824, l1: 0.2161, vgg: 0.4650, mask: 0.4013\n",
      "step:   139120, time: 0.787, loss: 1.0890, l1: 0.2519, vgg: 0.4341, mask: 0.4030\n",
      "step:   139140, time: 0.762, loss: 1.0598, l1: 0.2178, vgg: 0.4795, mask: 0.3624\n",
      "step:   139160, time: 0.734, loss: 0.9792, l1: 0.2050, vgg: 0.4039, mask: 0.3704\n",
      "step:   139180, time: 0.719, loss: 0.9748, l1: 0.1902, vgg: 0.3930, mask: 0.3916\n",
      "step:   139200, time: 0.766, loss: 1.0608, l1: 0.2121, vgg: 0.4374, mask: 0.4113\n",
      "step:   139220, time: 0.743, loss: 1.0093, l1: 0.2202, vgg: 0.3924, mask: 0.3967\n",
      "step:   139240, time: 0.758, loss: 1.0757, l1: 0.2478, vgg: 0.4358, mask: 0.3922\n",
      "step:   139260, time: 0.754, loss: 1.2287, l1: 0.3147, vgg: 0.5065, mask: 0.4075\n",
      "step:   139280, time: 0.757, loss: 1.0005, l1: 0.1805, vgg: 0.4285, mask: 0.3916\n",
      "step:   139300, time: 0.727, loss: 0.9992, l1: 0.1898, vgg: 0.4245, mask: 0.3850\n",
      "step:   139320, time: 0.709, loss: 0.8942, l1: 0.1830, vgg: 0.3593, mask: 0.3519\n",
      "step:   139340, time: 0.747, loss: 0.9088, l1: 0.1673, vgg: 0.4019, mask: 0.3396\n",
      "step:   139360, time: 0.764, loss: 0.9561, l1: 0.1785, vgg: 0.4200, mask: 0.3577\n",
      "step:   139380, time: 0.740, loss: 0.9617, l1: 0.1908, vgg: 0.4132, mask: 0.3578\n",
      "step:   139400, time: 0.740, loss: 1.0518, l1: 0.2317, vgg: 0.4457, mask: 0.3744\n",
      "step:   139420, time: 0.747, loss: 0.9761, l1: 0.1719, vgg: 0.3990, mask: 0.4051\n",
      "step:   139440, time: 0.764, loss: 1.0918, l1: 0.2334, vgg: 0.4943, mask: 0.3640\n",
      "step:   139460, time: 0.779, loss: 1.0712, l1: 0.2444, vgg: 0.4434, mask: 0.3833\n",
      "step:   139480, time: 0.766, loss: 0.9914, l1: 0.1597, vgg: 0.4931, mask: 0.3386\n",
      "step:   139500, time: 0.776, loss: 1.0186, l1: 0.1998, vgg: 0.4767, mask: 0.3421\n",
      "step:   139520, time: 0.726, loss: 1.0036, l1: 0.2002, vgg: 0.4127, mask: 0.3907\n",
      "step:   139540, time: 0.738, loss: 1.0214, l1: 0.2595, vgg: 0.3932, mask: 0.3686\n",
      "step:   139560, time: 0.729, loss: 0.9888, l1: 0.2175, vgg: 0.4048, mask: 0.3665\n",
      "step:   139580, time: 0.751, loss: 1.1111, l1: 0.2275, vgg: 0.5004, mask: 0.3832\n",
      "step:   139600, time: 0.746, loss: 1.0188, l1: 0.2488, vgg: 0.3768, mask: 0.3932\n",
      "step:   139620, time: 0.751, loss: 1.1187, l1: 0.2298, vgg: 0.4939, mask: 0.3950\n",
      "step:   139640, time: 0.730, loss: 0.9239, l1: 0.1862, vgg: 0.3508, mask: 0.3868\n",
      "step:   139660, time: 0.735, loss: 0.9209, l1: 0.1749, vgg: 0.4050, mask: 0.3410\n",
      "step:   139680, time: 0.755, loss: 1.0146, l1: 0.2325, vgg: 0.3909, mask: 0.3912\n",
      "step:   139700, time: 0.762, loss: 1.1005, l1: 0.1964, vgg: 0.4970, mask: 0.4071\n",
      "step:   139720, time: 0.734, loss: 1.0488, l1: 0.2089, vgg: 0.4633, mask: 0.3766\n",
      "step:   139740, time: 0.751, loss: 0.9786, l1: 0.2168, vgg: 0.3893, mask: 0.3725\n",
      "step:   139760, time: 0.757, loss: 1.0786, l1: 0.2271, vgg: 0.4432, mask: 0.4084\n",
      "step:   139780, time: 0.747, loss: 0.9479, l1: 0.1802, vgg: 0.4080, mask: 0.3597\n",
      "step:   139800, time: 0.729, loss: 0.9677, l1: 0.1839, vgg: 0.4149, mask: 0.3689\n",
      "step:   139820, time: 0.730, loss: 1.0670, l1: 0.1791, vgg: 0.4900, mask: 0.3979\n",
      "step:   139840, time: 0.725, loss: 0.9660, l1: 0.1902, vgg: 0.4161, mask: 0.3597\n",
      "step:   139860, time: 0.739, loss: 1.1080, l1: 0.1841, vgg: 0.5134, mask: 0.4104\n",
      "step:   139880, time: 0.787, loss: 1.1139, l1: 0.2408, vgg: 0.4769, mask: 0.3962\n",
      "step:   139900, time: 0.712, loss: 0.8627, l1: 0.1382, vgg: 0.3752, mask: 0.3494\n",
      "step:   139920, time: 0.766, loss: 1.0452, l1: 0.1845, vgg: 0.4831, mask: 0.3775\n",
      "step:   139940, time: 0.757, loss: 1.1249, l1: 0.1991, vgg: 0.5086, mask: 0.4172\n",
      "step:   139960, time: 0.762, loss: 1.0728, l1: 0.2128, vgg: 0.4667, mask: 0.3934\n",
      "step:   139980, time: 0.761, loss: 1.0538, l1: 0.1999, vgg: 0.4600, mask: 0.3939\n",
      "step:   140000, time: 0.816, loss: 1.1146, l1: 0.2411, vgg: 0.4910, mask: 0.3825\n",
      "step:   140020, time: 0.747, loss: 1.1330, l1: 0.2612, vgg: 0.4875, mask: 0.3844\n",
      "step:   140040, time: 0.750, loss: 1.1085, l1: 0.2485, vgg: 0.4429, mask: 0.4171\n",
      "step:   140060, time: 0.751, loss: 0.9823, l1: 0.2190, vgg: 0.4055, mask: 0.3579\n",
      "step:   140080, time: 0.752, loss: 0.9713, l1: 0.1715, vgg: 0.4214, mask: 0.3785\n",
      "step:   140100, time: 0.773, loss: 1.1834, l1: 0.2805, vgg: 0.5281, mask: 0.3747\n",
      "step:   140120, time: 0.749, loss: 1.0411, l1: 0.2376, vgg: 0.4339, mask: 0.3697\n",
      "step:   140140, time: 0.762, loss: 0.9740, l1: 0.2008, vgg: 0.4068, mask: 0.3664\n",
      "step:   140160, time: 0.749, loss: 0.9452, l1: 0.1713, vgg: 0.4343, mask: 0.3396\n",
      "step:   140180, time: 0.756, loss: 1.0483, l1: 0.2123, vgg: 0.4909, mask: 0.3451\n",
      "step:   140200, time: 0.749, loss: 0.9976, l1: 0.2036, vgg: 0.4519, mask: 0.3421\n",
      "step:   140220, time: 0.767, loss: 0.9946, l1: 0.1898, vgg: 0.4469, mask: 0.3578\n",
      "step:   140240, time: 0.788, loss: 1.0653, l1: 0.1919, vgg: 0.4755, mask: 0.3979\n",
      "step:   140260, time: 0.756, loss: 1.1994, l1: 0.3087, vgg: 0.4834, mask: 0.4073\n",
      "step:   140280, time: 0.789, loss: 0.9868, l1: 0.1965, vgg: 0.4191, mask: 0.3712\n",
      "step:   140300, time: 0.770, loss: 1.0673, l1: 0.2576, vgg: 0.4021, mask: 0.4077\n",
      "step:   140320, time: 0.719, loss: 0.9892, l1: 0.1799, vgg: 0.4134, mask: 0.3958\n",
      "step:   140340, time: 0.760, loss: 1.0056, l1: 0.2129, vgg: 0.4101, mask: 0.3826\n",
      "step:   140360, time: 0.720, loss: 0.9524, l1: 0.1807, vgg: 0.4211, mask: 0.3507\n",
      "step:   140380, time: 0.752, loss: 1.0208, l1: 0.1804, vgg: 0.4793, mask: 0.3611\n",
      "step:   140400, time: 0.724, loss: 0.9770, l1: 0.2278, vgg: 0.3804, mask: 0.3688\n",
      "step:   140420, time: 0.779, loss: 0.9898, l1: 0.1946, vgg: 0.4315, mask: 0.3638\n",
      "step:   140440, time: 0.735, loss: 1.0237, l1: 0.2104, vgg: 0.4267, mask: 0.3867\n",
      "step:   140460, time: 0.787, loss: 1.0357, l1: 0.2108, vgg: 0.4247, mask: 0.4002\n",
      "step:   140480, time: 0.761, loss: 1.1527, l1: 0.2580, vgg: 0.4881, mask: 0.4065\n",
      "step:   140500, time: 0.740, loss: 1.0033, l1: 0.1727, vgg: 0.4537, mask: 0.3768\n",
      "step:   140520, time: 0.752, loss: 0.9625, l1: 0.1676, vgg: 0.4551, mask: 0.3398\n",
      "step:   140540, time: 0.732, loss: 1.0035, l1: 0.1936, vgg: 0.4436, mask: 0.3663\n",
      "step:   140560, time: 0.738, loss: 1.0451, l1: 0.2370, vgg: 0.4089, mask: 0.3992\n",
      "step:   140580, time: 0.733, loss: 1.0570, l1: 0.2056, vgg: 0.5018, mask: 0.3497\n",
      "step:   140600, time: 0.766, loss: 1.0737, l1: 0.2247, vgg: 0.4605, mask: 0.3885\n",
      "step:   140620, time: 0.760, loss: 1.0965, l1: 0.2230, vgg: 0.4659, mask: 0.4075\n",
      "step:   140640, time: 0.754, loss: 1.1539, l1: 0.2851, vgg: 0.4330, mask: 0.4358\n",
      "step:   140660, time: 0.782, loss: 0.9447, l1: 0.1850, vgg: 0.4271, mask: 0.3326\n",
      "step:   140680, time: 0.753, loss: 1.1613, l1: 0.2664, vgg: 0.4844, mask: 0.4104\n",
      "step:   140700, time: 0.744, loss: 1.0576, l1: 0.2005, vgg: 0.4696, mask: 0.3875\n",
      "step:   140720, time: 0.714, loss: 0.9419, l1: 0.1939, vgg: 0.3879, mask: 0.3601\n",
      "step:   140740, time: 0.760, loss: 1.0236, l1: 0.2127, vgg: 0.4612, mask: 0.3496\n",
      "step:   140760, time: 0.784, loss: 0.9936, l1: 0.2109, vgg: 0.4323, mask: 0.3504\n",
      "step:   140780, time: 0.753, loss: 0.9715, l1: 0.1963, vgg: 0.3912, mask: 0.3840\n",
      "step:   140800, time: 0.747, loss: 0.9249, l1: 0.1810, vgg: 0.3777, mask: 0.3662\n",
      "step:   140820, time: 0.781, loss: 1.1796, l1: 0.3170, vgg: 0.4316, mask: 0.4310\n",
      "step:   140840, time: 0.726, loss: 0.9590, l1: 0.1807, vgg: 0.4248, mask: 0.3536\n",
      "step:   140860, time: 0.737, loss: 1.0156, l1: 0.1971, vgg: 0.4486, mask: 0.3699\n",
      "step:   140880, time: 0.740, loss: 1.0292, l1: 0.2335, vgg: 0.4086, mask: 0.3872\n",
      "step:   140900, time: 0.806, loss: 1.0372, l1: 0.1973, vgg: 0.4545, mask: 0.3854\n",
      "step:   140920, time: 0.734, loss: 0.8940, l1: 0.1757, vgg: 0.3384, mask: 0.3800\n",
      "step:   140940, time: 0.760, loss: 1.1927, l1: 0.3042, vgg: 0.4744, mask: 0.4141\n",
      "step:   140960, time: 0.732, loss: 0.9745, l1: 0.1676, vgg: 0.3936, mask: 0.4133\n",
      "step:   140980, time: 0.758, loss: 1.1270, l1: 0.2320, vgg: 0.5003, mask: 0.3947\n",
      "step:   141000, time: 0.713, loss: 0.9246, l1: 0.1572, vgg: 0.3768, mask: 0.3907\n",
      "step:   141020, time: 0.711, loss: 1.0852, l1: 0.2421, vgg: 0.4335, mask: 0.4097\n",
      "step:   141040, time: 0.777, loss: 1.1185, l1: 0.2275, vgg: 0.4952, mask: 0.3958\n",
      "step:   141060, time: 0.770, loss: 0.9926, l1: 0.1782, vgg: 0.4224, mask: 0.3920\n",
      "step:   141080, time: 0.762, loss: 0.9470, l1: 0.1905, vgg: 0.4038, mask: 0.3527\n",
      "step:   141100, time: 0.776, loss: 1.0420, l1: 0.2110, vgg: 0.4516, mask: 0.3794\n",
      "step:   141120, time: 0.746, loss: 0.9777, l1: 0.2090, vgg: 0.3906, mask: 0.3780\n",
      "step:   141140, time: 0.770, loss: 1.0068, l1: 0.1568, vgg: 0.4855, mask: 0.3644\n",
      "step:   141160, time: 0.752, loss: 1.0296, l1: 0.2440, vgg: 0.3935, mask: 0.3921\n",
      "step:   141180, time: 0.775, loss: 1.0911, l1: 0.2349, vgg: 0.4736, mask: 0.3826\n",
      "step:   141200, time: 0.760, loss: 1.0492, l1: 0.2371, vgg: 0.4272, mask: 0.3850\n",
      "step:   141220, time: 0.762, loss: 0.9601, l1: 0.2202, vgg: 0.3348, mask: 0.4051\n",
      "step:   141240, time: 0.745, loss: 1.0967, l1: 0.2619, vgg: 0.4159, mask: 0.4189\n",
      "step:   141260, time: 0.739, loss: 0.9305, l1: 0.1637, vgg: 0.4037, mask: 0.3631\n",
      "step:   141280, time: 0.754, loss: 0.8942, l1: 0.1899, vgg: 0.3761, mask: 0.3281\n",
      "step:   141300, time: 0.725, loss: 0.9139, l1: 0.1659, vgg: 0.4060, mask: 0.3420\n",
      "step:   141320, time: 0.768, loss: 0.9697, l1: 0.1956, vgg: 0.4065, mask: 0.3676\n",
      "step:   141340, time: 0.765, loss: 1.0780, l1: 0.2341, vgg: 0.4350, mask: 0.4088\n",
      "step:   141360, time: 0.794, loss: 1.1036, l1: 0.2203, vgg: 0.4963, mask: 0.3870\n",
      "step:   141380, time: 0.744, loss: 1.0053, l1: 0.1962, vgg: 0.3797, mask: 0.4293\n",
      "step:   141400, time: 0.730, loss: 0.8839, l1: 0.1375, vgg: 0.3957, mask: 0.3507\n",
      "step:   141420, time: 0.750, loss: 1.0426, l1: 0.2610, vgg: 0.3975, mask: 0.3841\n",
      "step:   141440, time: 0.749, loss: 1.0542, l1: 0.2214, vgg: 0.4646, mask: 0.3682\n",
      "step:   141460, time: 0.757, loss: 0.9895, l1: 0.2139, vgg: 0.3863, mask: 0.3894\n",
      "step:   141480, time: 0.740, loss: 1.0926, l1: 0.2381, vgg: 0.4413, mask: 0.4133\n",
      "step:   141500, time: 0.774, loss: 1.1244, l1: 0.2138, vgg: 0.4958, mask: 0.4148\n",
      "step:   141520, time: 0.741, loss: 1.1129, l1: 0.2771, vgg: 0.4323, mask: 0.4035\n",
      "step:   141540, time: 0.750, loss: 1.0082, l1: 0.2277, vgg: 0.3927, mask: 0.3878\n",
      "step:   141560, time: 0.727, loss: 0.9810, l1: 0.1985, vgg: 0.4058, mask: 0.3767\n",
      "step:   141580, time: 0.737, loss: 1.0205, l1: 0.2209, vgg: 0.3915, mask: 0.4081\n",
      "step:   141600, time: 0.737, loss: 0.9686, l1: 0.2137, vgg: 0.4074, mask: 0.3475\n",
      "step:   141620, time: 0.744, loss: 1.0069, l1: 0.2069, vgg: 0.4081, mask: 0.3919\n",
      "step:   141640, time: 0.765, loss: 1.1084, l1: 0.2158, vgg: 0.5131, mask: 0.3795\n",
      "step:   141660, time: 0.725, loss: 0.9749, l1: 0.1981, vgg: 0.4202, mask: 0.3566\n",
      "step:   141680, time: 0.735, loss: 1.0282, l1: 0.1713, vgg: 0.4814, mask: 0.3755\n",
      "step:   141700, time: 0.749, loss: 1.0236, l1: 0.2293, vgg: 0.3991, mask: 0.3953\n",
      "step:   141720, time: 0.747, loss: 1.0353, l1: 0.2462, vgg: 0.3755, mask: 0.4136\n",
      "step:   141740, time: 0.741, loss: 1.1151, l1: 0.2361, vgg: 0.4691, mask: 0.4099\n",
      "step:   141760, time: 0.724, loss: 0.9524, l1: 0.1931, vgg: 0.3895, mask: 0.3698\n",
      "step:   141780, time: 0.760, loss: 1.0397, l1: 0.2401, vgg: 0.3822, mask: 0.4174\n",
      "step:   141800, time: 0.749, loss: 1.0972, l1: 0.2120, vgg: 0.4949, mask: 0.3903\n",
      "step:   141820, time: 0.760, loss: 0.9033, l1: 0.1838, vgg: 0.3606, mask: 0.3588\n",
      "step:   141840, time: 0.774, loss: 1.1316, l1: 0.2596, vgg: 0.4685, mask: 0.4035\n",
      "step:   141860, time: 0.751, loss: 1.0898, l1: 0.2564, vgg: 0.4596, mask: 0.3738\n",
      "step:   141880, time: 0.749, loss: 1.1034, l1: 0.2632, vgg: 0.4377, mask: 0.4025\n",
      "step:   141900, time: 0.732, loss: 1.1482, l1: 0.2951, vgg: 0.4501, mask: 0.4030\n",
      "step:   141920, time: 0.787, loss: 1.0742, l1: 0.2467, vgg: 0.4145, mask: 0.4131\n",
      "step:   141940, time: 0.749, loss: 0.9267, l1: 0.1825, vgg: 0.3997, mask: 0.3445\n",
      "step:   141960, time: 0.751, loss: 0.9660, l1: 0.2113, vgg: 0.3993, mask: 0.3554\n",
      "step:   141980, time: 0.773, loss: 1.0525, l1: 0.2030, vgg: 0.4705, mask: 0.3790\n",
      "step:   142000, time: 0.808, loss: 1.0313, l1: 0.2217, vgg: 0.4596, mask: 0.3501\n",
      "step:   142020, time: 0.748, loss: 1.0945, l1: 0.2531, vgg: 0.4025, mask: 0.4389\n",
      "step:   142040, time: 0.766, loss: 1.0950, l1: 0.2283, vgg: 0.4714, mask: 0.3953\n",
      "step:   142060, time: 0.748, loss: 1.0532, l1: 0.2216, vgg: 0.4301, mask: 0.4014\n",
      "step:   142080, time: 0.744, loss: 1.0545, l1: 0.2197, vgg: 0.4588, mask: 0.3760\n",
      "step:   142100, time: 0.765, loss: 1.0240, l1: 0.2269, vgg: 0.4553, mask: 0.3418\n",
      "step:   142120, time: 0.731, loss: 1.0476, l1: 0.2113, vgg: 0.4601, mask: 0.3762\n",
      "step:   142140, time: 0.723, loss: 1.1221, l1: 0.2761, vgg: 0.4292, mask: 0.4169\n",
      "step:   142160, time: 0.748, loss: 1.0324, l1: 0.2031, vgg: 0.4541, mask: 0.3751\n",
      "step:   142180, time: 0.779, loss: 1.1686, l1: 0.2853, vgg: 0.4673, mask: 0.4160\n",
      "step:   142200, time: 0.750, loss: 1.1675, l1: 0.1951, vgg: 0.5931, mask: 0.3792\n",
      "step:   142220, time: 0.757, loss: 1.0351, l1: 0.2141, vgg: 0.4479, mask: 0.3731\n",
      "step:   142240, time: 0.291, loss: 0.9148, l1: 0.1704, vgg: 0.3863, mask: 0.3581\n",
      "step:   142260, time: 0.773, loss: 1.0091, l1: 0.2013, vgg: 0.4453, mask: 0.3625\n",
      "step:   142280, time: 0.757, loss: 1.0849, l1: 0.2127, vgg: 0.5040, mask: 0.3682\n",
      "step:   142300, time: 0.728, loss: 0.9292, l1: 0.1915, vgg: 0.3905, mask: 0.3472\n",
      "step:   142320, time: 0.751, loss: 0.9260, l1: 0.1894, vgg: 0.3738, mask: 0.3628\n",
      "step:   142340, time: 0.754, loss: 1.0362, l1: 0.2093, vgg: 0.4307, mask: 0.3962\n",
      "step:   142360, time: 0.748, loss: 1.1414, l1: 0.2796, vgg: 0.4520, mask: 0.4099\n",
      "step:   142380, time: 0.726, loss: 1.0108, l1: 0.1917, vgg: 0.4328, mask: 0.3864\n",
      "step:   142400, time: 0.731, loss: 1.2054, l1: 0.2887, vgg: 0.4930, mask: 0.4237\n",
      "step:   142420, time: 0.748, loss: 0.9975, l1: 0.1611, vgg: 0.4543, mask: 0.3822\n",
      "step:   142440, time: 0.753, loss: 1.0060, l1: 0.1911, vgg: 0.3967, mask: 0.4183\n",
      "step:   142460, time: 0.787, loss: 1.1112, l1: 0.2507, vgg: 0.4927, mask: 0.3679\n",
      "step:   142480, time: 0.744, loss: 0.9882, l1: 0.2103, vgg: 0.4180, mask: 0.3600\n",
      "step:   142500, time: 0.726, loss: 0.8789, l1: 0.1653, vgg: 0.3681, mask: 0.3455\n",
      "step:   142520, time: 0.763, loss: 0.9587, l1: 0.1865, vgg: 0.3998, mask: 0.3724\n",
      "step:   142540, time: 0.760, loss: 1.0428, l1: 0.2200, vgg: 0.4431, mask: 0.3797\n",
      "step:   142560, time: 0.761, loss: 1.1269, l1: 0.1933, vgg: 0.5276, mask: 0.4060\n",
      "step:   142580, time: 0.746, loss: 0.9513, l1: 0.1952, vgg: 0.4149, mask: 0.3411\n",
      "step:   142600, time: 0.719, loss: 1.0521, l1: 0.1878, vgg: 0.4780, mask: 0.3862\n",
      "step:   142620, time: 0.772, loss: 1.0886, l1: 0.2534, vgg: 0.4395, mask: 0.3957\n",
      "step:   142640, time: 0.756, loss: 1.0494, l1: 0.2260, vgg: 0.4193, mask: 0.4041\n",
      "step:   142660, time: 0.754, loss: 0.9369, l1: 0.1852, vgg: 0.3978, mask: 0.3539\n",
      "step:   142680, time: 0.734, loss: 1.0139, l1: 0.2267, vgg: 0.4251, mask: 0.3621\n",
      "step:   142700, time: 0.754, loss: 1.1009, l1: 0.2380, vgg: 0.4403, mask: 0.4226\n",
      "step:   142720, time: 0.743, loss: 0.9825, l1: 0.1855, vgg: 0.4324, mask: 0.3646\n",
      "step:   142740, time: 0.729, loss: 1.0171, l1: 0.2113, vgg: 0.3964, mask: 0.4094\n",
      "step:   142760, time: 0.744, loss: 1.1372, l1: 0.2385, vgg: 0.4952, mask: 0.4034\n",
      "step:   142780, time: 0.754, loss: 1.0054, l1: 0.1843, vgg: 0.4313, mask: 0.3898\n",
      "step:   142800, time: 0.739, loss: 1.0510, l1: 0.2062, vgg: 0.4378, mask: 0.4070\n",
      "step:   142820, time: 0.769, loss: 1.0812, l1: 0.2254, vgg: 0.4448, mask: 0.4110\n",
      "step:   142840, time: 0.725, loss: 0.9903, l1: 0.1948, vgg: 0.4134, mask: 0.3821\n",
      "step:   142860, time: 0.740, loss: 1.0333, l1: 0.2372, vgg: 0.4298, mask: 0.3663\n",
      "step:   142880, time: 0.770, loss: 1.1673, l1: 0.2505, vgg: 0.5017, mask: 0.4152\n",
      "step:   142900, time: 0.767, loss: 0.9761, l1: 0.1930, vgg: 0.4447, mask: 0.3384\n",
      "step:   142920, time: 0.763, loss: 0.9825, l1: 0.1985, vgg: 0.4336, mask: 0.3504\n",
      "step:   142940, time: 0.748, loss: 0.9526, l1: 0.1699, vgg: 0.4342, mask: 0.3485\n",
      "step:   142960, time: 0.723, loss: 0.9643, l1: 0.2024, vgg: 0.3516, mask: 0.4104\n",
      "step:   142980, time: 0.745, loss: 0.9720, l1: 0.2124, vgg: 0.3941, mask: 0.3655\n",
      "step:   143000, time: 0.734, loss: 0.9232, l1: 0.1765, vgg: 0.3630, mask: 0.3837\n",
      "step:   143020, time: 0.736, loss: 1.1187, l1: 0.2198, vgg: 0.5088, mask: 0.3902\n",
      "step:   143040, time: 0.760, loss: 1.0861, l1: 0.2648, vgg: 0.4069, mask: 0.4144\n",
      "step:   143060, time: 0.758, loss: 1.1080, l1: 0.2881, vgg: 0.4352, mask: 0.3847\n",
      "step:   143080, time: 0.748, loss: 1.0952, l1: 0.2658, vgg: 0.4311, mask: 0.3983\n",
      "step:   143100, time: 0.728, loss: 0.9796, l1: 0.2207, vgg: 0.3904, mask: 0.3684\n",
      "step:   143120, time: 0.767, loss: 1.1228, l1: 0.2479, vgg: 0.4755, mask: 0.3994\n",
      "step:   143140, time: 0.761, loss: 1.1041, l1: 0.2614, vgg: 0.4451, mask: 0.3977\n",
      "step:   143160, time: 0.751, loss: 1.0477, l1: 0.2354, vgg: 0.4135, mask: 0.3988\n",
      "step:   143180, time: 0.744, loss: 1.1066, l1: 0.2192, vgg: 0.4709, mask: 0.4165\n",
      "step:   143200, time: 0.760, loss: 1.0746, l1: 0.2128, vgg: 0.4769, mask: 0.3849\n",
      "step:   143220, time: 0.776, loss: 0.9346, l1: 0.1832, vgg: 0.3852, mask: 0.3662\n",
      "step:   143240, time: 0.787, loss: 1.0511, l1: 0.1968, vgg: 0.4867, mask: 0.3676\n",
      "step:   143260, time: 0.768, loss: 1.0145, l1: 0.2139, vgg: 0.4105, mask: 0.3901\n",
      "step:   143280, time: 0.736, loss: 1.0045, l1: 0.1930, vgg: 0.4623, mask: 0.3492\n",
      "step:   143300, time: 0.789, loss: 1.0211, l1: 0.2132, vgg: 0.4232, mask: 0.3846\n",
      "step:   143320, time: 0.767, loss: 0.9636, l1: 0.1760, vgg: 0.4140, mask: 0.3736\n",
      "step:   143340, time: 0.757, loss: 1.0657, l1: 0.2183, vgg: 0.4199, mask: 0.4276\n",
      "step:   143360, time: 0.732, loss: 1.0825, l1: 0.2315, vgg: 0.4622, mask: 0.3888\n",
      "step:   143380, time: 0.742, loss: 0.9943, l1: 0.1841, vgg: 0.4682, mask: 0.3420\n",
      "step:   143400, time: 0.733, loss: 1.0535, l1: 0.2281, vgg: 0.4332, mask: 0.3922\n",
      "step:   143420, time: 0.771, loss: 1.2076, l1: 0.2621, vgg: 0.5398, mask: 0.4057\n",
      "step:   143440, time: 0.720, loss: 0.9839, l1: 0.2150, vgg: 0.4160, mask: 0.3529\n",
      "step:   143460, time: 0.772, loss: 1.0875, l1: 0.2466, vgg: 0.4541, mask: 0.3868\n",
      "step:   143480, time: 0.754, loss: 0.9453, l1: 0.1696, vgg: 0.4395, mask: 0.3362\n",
      "step:   143500, time: 0.751, loss: 0.9968, l1: 0.2009, vgg: 0.4548, mask: 0.3411\n",
      "step:   143520, time: 0.741, loss: 0.9899, l1: 0.2376, vgg: 0.3802, mask: 0.3721\n",
      "step:   143540, time: 0.737, loss: 1.0098, l1: 0.1911, vgg: 0.4379, mask: 0.3808\n",
      "step:   143560, time: 0.787, loss: 1.1378, l1: 0.3127, vgg: 0.3898, mask: 0.4353\n",
      "step:   143580, time: 0.755, loss: 1.0456, l1: 0.2154, vgg: 0.4212, mask: 0.4091\n",
      "step:   143600, time: 0.769, loss: 1.0115, l1: 0.2109, vgg: 0.4011, mask: 0.3995\n",
      "step:   143620, time: 0.743, loss: 1.0647, l1: 0.2100, vgg: 0.4689, mask: 0.3858\n",
      "step:   143640, time: 0.733, loss: 1.0590, l1: 0.2205, vgg: 0.4526, mask: 0.3859\n",
      "step:   143660, time: 0.737, loss: 0.8848, l1: 0.1471, vgg: 0.4110, mask: 0.3268\n",
      "step:   143680, time: 0.754, loss: 1.0027, l1: 0.1824, vgg: 0.4385, mask: 0.3818\n",
      "step:   143700, time: 0.723, loss: 1.0050, l1: 0.2294, vgg: 0.3959, mask: 0.3797\n",
      "step:   143720, time: 0.733, loss: 0.9840, l1: 0.2336, vgg: 0.3601, mask: 0.3902\n",
      "step:   143740, time: 0.753, loss: 1.0923, l1: 0.2088, vgg: 0.4929, mask: 0.3905\n",
      "step:   143760, time: 0.775, loss: 1.1291, l1: 0.2535, vgg: 0.4717, mask: 0.4039\n",
      "step:   143780, time: 0.798, loss: 1.0639, l1: 0.2422, vgg: 0.4218, mask: 0.3999\n",
      "step:   143800, time: 0.760, loss: 1.2125, l1: 0.2443, vgg: 0.5556, mask: 0.4126\n",
      "step:   143820, time: 0.775, loss: 1.1315, l1: 0.2765, vgg: 0.4697, mask: 0.3853\n",
      "step:   143840, time: 0.750, loss: 1.0906, l1: 0.1957, vgg: 0.4789, mask: 0.4161\n",
      "step:   143860, time: 0.736, loss: 1.0791, l1: 0.2498, vgg: 0.4157, mask: 0.4137\n",
      "step:   143880, time: 0.767, loss: 0.9862, l1: 0.2081, vgg: 0.3843, mask: 0.3939\n",
      "step:   143900, time: 0.773, loss: 1.0725, l1: 0.2485, vgg: 0.4042, mask: 0.4198\n",
      "step:   143920, time: 0.743, loss: 1.0390, l1: 0.2079, vgg: 0.4452, mask: 0.3859\n",
      "step:   143940, time: 0.716, loss: 0.9780, l1: 0.1929, vgg: 0.3903, mask: 0.3949\n",
      "step:   143960, time: 0.740, loss: 1.0057, l1: 0.2134, vgg: 0.3837, mask: 0.4086\n",
      "step:   143980, time: 0.772, loss: 0.9671, l1: 0.2190, vgg: 0.3829, mask: 0.3652\n",
      "step:   144000, time: 0.738, loss: 1.2225, l1: 0.2801, vgg: 0.5334, mask: 0.4090\n",
      "step:   144020, time: 0.740, loss: 1.0100, l1: 0.1608, vgg: 0.4617, mask: 0.3876\n",
      "step:   144040, time: 0.724, loss: 0.9008, l1: 0.2062, vgg: 0.3214, mask: 0.3732\n",
      "step:   144060, time: 0.732, loss: 0.9825, l1: 0.1952, vgg: 0.3924, mask: 0.3949\n",
      "step:   144080, time: 0.760, loss: 0.9813, l1: 0.2127, vgg: 0.3903, mask: 0.3783\n",
      "step:   144100, time: 0.752, loss: 0.9776, l1: 0.2141, vgg: 0.3792, mask: 0.3843\n",
      "step:   144120, time: 0.740, loss: 0.9639, l1: 0.1998, vgg: 0.4023, mask: 0.3617\n",
      "step:   144140, time: 0.726, loss: 0.9223, l1: 0.1748, vgg: 0.3785, mask: 0.3691\n",
      "step:   144160, time: 0.755, loss: 0.9866, l1: 0.1708, vgg: 0.4304, mask: 0.3854\n",
      "step:   144180, time: 0.749, loss: 1.0599, l1: 0.1859, vgg: 0.5062, mask: 0.3678\n",
      "step:   144200, time: 0.734, loss: 1.0302, l1: 0.2292, vgg: 0.4463, mask: 0.3547\n",
      "step:   144220, time: 0.729, loss: 1.1071, l1: 0.2327, vgg: 0.5003, mask: 0.3742\n",
      "step:   144240, time: 0.774, loss: 0.9324, l1: 0.1677, vgg: 0.3627, mask: 0.4020\n",
      "step:   144260, time: 0.764, loss: 1.1379, l1: 0.2574, vgg: 0.4538, mask: 0.4268\n",
      "step:   144280, time: 0.763, loss: 1.0592, l1: 0.2134, vgg: 0.4392, mask: 0.4066\n",
      "step:   144300, time: 0.762, loss: 1.0987, l1: 0.2037, vgg: 0.5020, mask: 0.3930\n",
      "step:   144320, time: 0.789, loss: 1.0428, l1: 0.2150, vgg: 0.4289, mask: 0.3989\n",
      "step:   144340, time: 0.741, loss: 1.0562, l1: 0.2221, vgg: 0.4210, mask: 0.4131\n",
      "step:   144360, time: 0.775, loss: 0.9546, l1: 0.1694, vgg: 0.4127, mask: 0.3725\n",
      "step:   144380, time: 0.715, loss: 0.9800, l1: 0.1924, vgg: 0.4297, mask: 0.3579\n",
      "step:   144400, time: 0.791, loss: 1.1492, l1: 0.2486, vgg: 0.4598, mask: 0.4408\n",
      "step:   144420, time: 0.736, loss: 1.0433, l1: 0.2417, vgg: 0.4102, mask: 0.3915\n",
      "step:   144440, time: 0.763, loss: 1.0519, l1: 0.1849, vgg: 0.4994, mask: 0.3676\n",
      "step:   144460, time: 0.774, loss: 1.0840, l1: 0.2448, vgg: 0.4371, mask: 0.4022\n",
      "step:   144480, time: 0.768, loss: 1.0489, l1: 0.2144, vgg: 0.4534, mask: 0.3810\n",
      "step:   144500, time: 0.737, loss: 0.9678, l1: 0.1865, vgg: 0.4072, mask: 0.3741\n",
      "step:   144520, time: 0.762, loss: 1.0027, l1: 0.2020, vgg: 0.4087, mask: 0.3920\n",
      "step:   144540, time: 0.779, loss: 1.1478, l1: 0.2140, vgg: 0.5638, mask: 0.3700\n",
      "step:   144560, time: 0.768, loss: 0.9840, l1: 0.1866, vgg: 0.4403, mask: 0.3570\n",
      "step:   144580, time: 0.814, loss: 1.1596, l1: 0.2796, vgg: 0.4496, mask: 0.4303\n",
      "step:   144600, time: 0.721, loss: 0.9684, l1: 0.2226, vgg: 0.3499, mask: 0.3959\n",
      "step:   144620, time: 0.755, loss: 1.0786, l1: 0.2308, vgg: 0.4726, mask: 0.3752\n",
      "step:   144640, time: 0.754, loss: 1.0801, l1: 0.2089, vgg: 0.4880, mask: 0.3832\n",
      "step:   144660, time: 0.744, loss: 0.9478, l1: 0.1396, vgg: 0.4693, mask: 0.3389\n",
      "step:   144680, time: 0.737, loss: 0.9210, l1: 0.1656, vgg: 0.4133, mask: 0.3422\n",
      "step:   144700, time: 0.739, loss: 1.0035, l1: 0.2039, vgg: 0.4395, mask: 0.3601\n",
      "step:   144720, time: 0.773, loss: 1.0272, l1: 0.2180, vgg: 0.4307, mask: 0.3785\n",
      "step:   144740, time: 0.757, loss: 1.0191, l1: 0.2403, vgg: 0.3963, mask: 0.3826\n",
      "step:   144760, time: 0.725, loss: 1.0055, l1: 0.1819, vgg: 0.4058, mask: 0.4178\n",
      "step:   144780, time: 0.763, loss: 0.9502, l1: 0.1778, vgg: 0.4364, mask: 0.3360\n",
      "step:   144800, time: 0.785, loss: 1.1282, l1: 0.2570, vgg: 0.4605, mask: 0.4107\n",
      "step:   144820, time: 0.735, loss: 0.9621, l1: 0.1774, vgg: 0.4117, mask: 0.3731\n",
      "step:   144840, time: 0.755, loss: 1.1484, l1: 0.2586, vgg: 0.4512, mask: 0.4385\n",
      "step:   144860, time: 0.754, loss: 1.0201, l1: 0.1809, vgg: 0.4675, mask: 0.3717\n",
      "step:   144880, time: 0.750, loss: 0.9940, l1: 0.2154, vgg: 0.3992, mask: 0.3794\n",
      "step:   144900, time: 0.783, loss: 0.9258, l1: 0.1654, vgg: 0.4104, mask: 0.3500\n",
      "step:   144920, time: 0.784, loss: 1.0418, l1: 0.2358, vgg: 0.3895, mask: 0.4165\n",
      "step:   144940, time: 0.747, loss: 1.0290, l1: 0.1661, vgg: 0.4663, mask: 0.3966\n",
      "step:   144960, time: 0.733, loss: 0.8819, l1: 0.1595, vgg: 0.3504, mask: 0.3720\n",
      "step:   144980, time: 0.738, loss: 1.0122, l1: 0.2077, vgg: 0.4350, mask: 0.3695\n",
      "step:   145000, time: 0.733, loss: 0.9032, l1: 0.1629, vgg: 0.4046, mask: 0.3357\n",
      "step:   145020, time: 0.717, loss: 0.9386, l1: 0.1635, vgg: 0.4277, mask: 0.3474\n",
      "step:   145040, time: 0.754, loss: 1.1464, l1: 0.2850, vgg: 0.4564, mask: 0.4050\n",
      "step:   145060, time: 0.802, loss: 1.0556, l1: 0.2058, vgg: 0.4554, mask: 0.3944\n",
      "step:   145080, time: 0.750, loss: 0.9662, l1: 0.1886, vgg: 0.3843, mask: 0.3933\n",
      "step:   145100, time: 0.763, loss: 1.0189, l1: 0.2158, vgg: 0.4241, mask: 0.3790\n",
      "step:   145120, time: 0.719, loss: 0.8665, l1: 0.1438, vgg: 0.3364, mask: 0.3863\n",
      "step:   145140, time: 0.735, loss: 1.0565, l1: 0.2101, vgg: 0.4306, mask: 0.4158\n",
      "step:   145160, time: 0.729, loss: 0.9828, l1: 0.1729, vgg: 0.4446, mask: 0.3653\n",
      "step:   145180, time: 0.747, loss: 1.1007, l1: 0.2442, vgg: 0.4472, mask: 0.4092\n",
      "step:   145200, time: 0.731, loss: 0.9901, l1: 0.1840, vgg: 0.4396, mask: 0.3664\n",
      "step:   145220, time: 0.771, loss: 1.0560, l1: 0.2288, vgg: 0.4022, mask: 0.4249\n",
      "step:   145240, time: 0.773, loss: 0.9540, l1: 0.1977, vgg: 0.3971, mask: 0.3593\n",
      "step:   145260, time: 0.794, loss: 1.1440, l1: 0.2996, vgg: 0.4224, mask: 0.4219\n",
      "step:   145280, time: 0.743, loss: 0.9976, l1: 0.2231, vgg: 0.4141, mask: 0.3604\n",
      "step:   145300, time: 0.751, loss: 1.0633, l1: 0.2416, vgg: 0.4747, mask: 0.3469\n",
      "step:   145320, time: 0.769, loss: 1.1095, l1: 0.2508, vgg: 0.4610, mask: 0.3977\n",
      "step:   145340, time: 0.745, loss: 1.0021, l1: 0.1616, vgg: 0.4479, mask: 0.3926\n",
      "step:   145360, time: 0.745, loss: 1.0647, l1: 0.2468, vgg: 0.4417, mask: 0.3762\n",
      "step:   145380, time: 0.755, loss: 1.1023, l1: 0.2769, vgg: 0.4031, mask: 0.4223\n",
      "step:   145400, time: 0.746, loss: 0.9258, l1: 0.1844, vgg: 0.3481, mask: 0.3934\n",
      "step:   145420, time: 0.739, loss: 1.0842, l1: 0.2260, vgg: 0.4490, mask: 0.4092\n",
      "step:   145440, time: 0.777, loss: 1.0475, l1: 0.2460, vgg: 0.4126, mask: 0.3889\n",
      "step:   145460, time: 0.758, loss: 0.9713, l1: 0.1805, vgg: 0.3942, mask: 0.3966\n",
      "step:   145480, time: 0.758, loss: 0.9873, l1: 0.2047, vgg: 0.4324, mask: 0.3502\n",
      "step:   145500, time: 0.761, loss: 1.1552, l1: 0.2570, vgg: 0.4774, mask: 0.4208\n",
      "step:   145520, time: 0.745, loss: 1.0508, l1: 0.2240, vgg: 0.4256, mask: 0.4012\n",
      "step:   145540, time: 0.782, loss: 1.1349, l1: 0.2731, vgg: 0.4490, mask: 0.4128\n",
      "step:   145560, time: 0.750, loss: 1.0787, l1: 0.2110, vgg: 0.4541, mask: 0.4136\n",
      "step:   145580, time: 0.749, loss: 1.1130, l1: 0.2587, vgg: 0.4621, mask: 0.3921\n",
      "step:   145600, time: 0.770, loss: 0.9416, l1: 0.1988, vgg: 0.4156, mask: 0.3271\n",
      "step:   145620, time: 0.740, loss: 1.0774, l1: 0.2361, vgg: 0.4066, mask: 0.4347\n",
      "step:   145640, time: 0.738, loss: 0.9825, l1: 0.1845, vgg: 0.4119, mask: 0.3860\n",
      "step:   145660, time: 0.733, loss: 0.9064, l1: 0.1601, vgg: 0.3897, mask: 0.3566\n",
      "step:   145680, time: 0.777, loss: 1.1259, l1: 0.2745, vgg: 0.4174, mask: 0.4341\n",
      "step:   145700, time: 0.726, loss: 1.0821, l1: 0.2208, vgg: 0.4640, mask: 0.3973\n",
      "step:   145720, time: 0.740, loss: 1.0353, l1: 0.2344, vgg: 0.4207, mask: 0.3802\n",
      "step:   145740, time: 0.798, loss: 1.0790, l1: 0.2035, vgg: 0.4927, mask: 0.3828\n",
      "step:   145760, time: 0.780, loss: 1.1262, l1: 0.2526, vgg: 0.4778, mask: 0.3958\n",
      "step:   145780, time: 0.749, loss: 1.0566, l1: 0.1869, vgg: 0.4937, mask: 0.3760\n",
      "step:   145800, time: 0.726, loss: 0.9311, l1: 0.1457, vgg: 0.4097, mask: 0.3757\n",
      "step:   145820, time: 0.742, loss: 1.1737, l1: 0.2558, vgg: 0.4941, mask: 0.4237\n",
      "step:   145840, time: 0.764, loss: 1.1173, l1: 0.2145, vgg: 0.5409, mask: 0.3620\n",
      "step:   145860, time: 0.738, loss: 1.0588, l1: 0.2401, vgg: 0.4163, mask: 0.4024\n",
      "step:   145880, time: 0.744, loss: 0.9709, l1: 0.1902, vgg: 0.4187, mask: 0.3620\n",
      "step:   145900, time: 0.733, loss: 1.0229, l1: 0.1832, vgg: 0.4768, mask: 0.3629\n",
      "step:   145920, time: 0.752, loss: 1.0903, l1: 0.2233, vgg: 0.4415, mask: 0.4254\n",
      "step:   145940, time: 0.742, loss: 0.9315, l1: 0.1459, vgg: 0.4264, mask: 0.3593\n",
      "step:   145960, time: 0.752, loss: 1.0542, l1: 0.2034, vgg: 0.4659, mask: 0.3850\n",
      "step:   145980, time: 0.742, loss: 0.9439, l1: 0.1477, vgg: 0.4324, mask: 0.3639\n",
      "step:   146000, time: 0.759, loss: 1.0080, l1: 0.2414, vgg: 0.3834, mask: 0.3831\n",
      "step:   146020, time: 0.735, loss: 0.9983, l1: 0.1932, vgg: 0.4565, mask: 0.3486\n",
      "step:   146040, time: 0.740, loss: 1.0322, l1: 0.2491, vgg: 0.4087, mask: 0.3744\n",
      "step:   146060, time: 0.759, loss: 1.0287, l1: 0.1853, vgg: 0.5179, mask: 0.3256\n",
      "step:   146080, time: 0.725, loss: 1.0061, l1: 0.1977, vgg: 0.4617, mask: 0.3468\n",
      "step:   146100, time: 0.753, loss: 0.9189, l1: 0.1753, vgg: 0.4070, mask: 0.3366\n",
      "step:   146120, time: 0.734, loss: 1.0431, l1: 0.2179, vgg: 0.4378, mask: 0.3875\n",
      "step:   146140, time: 0.744, loss: 0.9104, l1: 0.1573, vgg: 0.4139, mask: 0.3393\n",
      "step:   146160, time: 0.739, loss: 1.0083, l1: 0.2064, vgg: 0.3903, mask: 0.4116\n",
      "step:   146180, time: 0.723, loss: 1.0082, l1: 0.2285, vgg: 0.3917, mask: 0.3880\n",
      "step:   146200, time: 0.780, loss: 1.0373, l1: 0.2305, vgg: 0.4432, mask: 0.3636\n",
      "step:   146220, time: 0.751, loss: 1.0272, l1: 0.2217, vgg: 0.4376, mask: 0.3679\n",
      "step:   146240, time: 0.737, loss: 1.0224, l1: 0.1893, vgg: 0.4647, mask: 0.3684\n",
      "step:   146260, time: 0.715, loss: 1.0154, l1: 0.2226, vgg: 0.4525, mask: 0.3403\n",
      "step:   146280, time: 0.762, loss: 0.9676, l1: 0.1878, vgg: 0.4117, mask: 0.3681\n",
      "step:   146300, time: 0.763, loss: 1.1109, l1: 0.2757, vgg: 0.4179, mask: 0.4174\n",
      "step:   146320, time: 0.755, loss: 0.9728, l1: 0.1791, vgg: 0.4436, mask: 0.3501\n",
      "step:   146340, time: 0.730, loss: 0.9416, l1: 0.2111, vgg: 0.3529, mask: 0.3777\n",
      "step:   146360, time: 0.794, loss: 1.1388, l1: 0.2742, vgg: 0.4577, mask: 0.4069\n",
      "step:   146380, time: 0.786, loss: 0.9516, l1: 0.2027, vgg: 0.3812, mask: 0.3676\n",
      "step:   146400, time: 0.767, loss: 1.0614, l1: 0.2228, vgg: 0.4112, mask: 0.4273\n",
      "step:   146420, time: 0.756, loss: 1.0509, l1: 0.2201, vgg: 0.4462, mask: 0.3847\n",
      "step:   146440, time: 0.797, loss: 1.1076, l1: 0.2254, vgg: 0.4853, mask: 0.3969\n",
      "step:   146460, time: 0.740, loss: 1.0611, l1: 0.2255, vgg: 0.4559, mask: 0.3797\n",
      "step:   146480, time: 0.747, loss: 0.9442, l1: 0.1676, vgg: 0.4195, mask: 0.3570\n",
      "step:   146500, time: 0.743, loss: 1.0720, l1: 0.2031, vgg: 0.4884, mask: 0.3805\n",
      "step:   146520, time: 0.769, loss: 0.8966, l1: 0.1780, vgg: 0.3846, mask: 0.3340\n",
      "step:   146540, time: 0.752, loss: 1.0008, l1: 0.1753, vgg: 0.4519, mask: 0.3735\n",
      "step:   146560, time: 0.765, loss: 0.9403, l1: 0.1865, vgg: 0.3903, mask: 0.3635\n",
      "step:   146580, time: 0.731, loss: 0.9305, l1: 0.2025, vgg: 0.3783, mask: 0.3496\n",
      "step:   146600, time: 0.732, loss: 1.0538, l1: 0.2361, vgg: 0.4324, mask: 0.3853\n",
      "step:   146620, time: 0.757, loss: 1.0649, l1: 0.2136, vgg: 0.4394, mask: 0.4119\n",
      "step:   146640, time: 0.764, loss: 0.9327, l1: 0.1854, vgg: 0.4124, mask: 0.3350\n",
      "step:   146660, time: 0.746, loss: 1.0081, l1: 0.2344, vgg: 0.3856, mask: 0.3881\n",
      "step:   146680, time: 0.748, loss: 0.9947, l1: 0.2108, vgg: 0.4131, mask: 0.3708\n",
      "step:   146700, time: 0.745, loss: 0.9606, l1: 0.1743, vgg: 0.4319, mask: 0.3544\n",
      "step:   146720, time: 0.770, loss: 0.9310, l1: 0.1868, vgg: 0.3538, mask: 0.3905\n",
      "step:   146740, time: 0.762, loss: 1.0107, l1: 0.2030, vgg: 0.4231, mask: 0.3847\n",
      "step:   146760, time: 0.796, loss: 1.0411, l1: 0.2082, vgg: 0.4396, mask: 0.3934\n",
      "step:   146780, time: 0.745, loss: 1.0365, l1: 0.2542, vgg: 0.3910, mask: 0.3913\n",
      "step:   146800, time: 0.765, loss: 0.9942, l1: 0.1820, vgg: 0.4485, mask: 0.3637\n",
      "step:   146820, time: 0.748, loss: 1.1860, l1: 0.2557, vgg: 0.5307, mask: 0.3996\n",
      "step:   146840, time: 0.727, loss: 1.0045, l1: 0.2255, vgg: 0.3918, mask: 0.3872\n",
      "step:   146860, time: 0.765, loss: 1.0893, l1: 0.2286, vgg: 0.4724, mask: 0.3883\n",
      "step:   146880, time: 0.746, loss: 0.9400, l1: 0.1899, vgg: 0.4019, mask: 0.3481\n",
      "step:   146900, time: 0.786, loss: 1.0390, l1: 0.2411, vgg: 0.4007, mask: 0.3972\n",
      "step:   146920, time: 0.712, loss: 0.9014, l1: 0.1416, vgg: 0.3998, mask: 0.3600\n",
      "step:   146940, time: 0.741, loss: 1.1131, l1: 0.2741, vgg: 0.4179, mask: 0.4211\n",
      "step:   146960, time: 0.750, loss: 0.9196, l1: 0.1794, vgg: 0.4114, mask: 0.3288\n",
      "step:   146980, time: 0.733, loss: 0.9880, l1: 0.1955, vgg: 0.4203, mask: 0.3722\n",
      "step:   147000, time: 0.778, loss: 1.1562, l1: 0.2753, vgg: 0.4240, mask: 0.4569\n",
      "step:   147020, time: 0.783, loss: 0.9857, l1: 0.2156, vgg: 0.3961, mask: 0.3740\n",
      "step:   147040, time: 0.743, loss: 1.0216, l1: 0.1792, vgg: 0.4980, mask: 0.3444\n",
      "step:   147060, time: 0.739, loss: 0.8974, l1: 0.1664, vgg: 0.3515, mask: 0.3794\n",
      "step:   147080, time: 0.761, loss: 1.0229, l1: 0.2096, vgg: 0.4250, mask: 0.3883\n",
      "step:   147100, time: 0.764, loss: 1.0443, l1: 0.2357, vgg: 0.4140, mask: 0.3945\n",
      "step:   147120, time: 0.765, loss: 0.9474, l1: 0.1808, vgg: 0.3934, mask: 0.3732\n",
      "step:   147140, time: 0.748, loss: 1.0730, l1: 0.2589, vgg: 0.4439, mask: 0.3702\n",
      "step:   147160, time: 0.747, loss: 1.1003, l1: 0.2643, vgg: 0.4229, mask: 0.4131\n",
      "step:   147180, time: 0.744, loss: 0.9477, l1: 0.2197, vgg: 0.3815, mask: 0.3464\n",
      "step:   147200, time: 0.753, loss: 1.0017, l1: 0.2167, vgg: 0.3791, mask: 0.4058\n",
      "step:   147220, time: 0.748, loss: 0.9856, l1: 0.2009, vgg: 0.4247, mask: 0.3600\n",
      "step:   147240, time: 0.759, loss: 1.0931, l1: 0.2149, vgg: 0.4637, mask: 0.4145\n",
      "step:   147260, time: 0.735, loss: 0.9193, l1: 0.1762, vgg: 0.3849, mask: 0.3581\n",
      "step:   147280, time: 0.761, loss: 1.1237, l1: 0.2030, vgg: 0.4940, mask: 0.4267\n",
      "step:   147300, time: 0.755, loss: 1.1552, l1: 0.3067, vgg: 0.4325, mask: 0.4161\n",
      "step:   147320, time: 0.736, loss: 1.0306, l1: 0.1724, vgg: 0.4532, mask: 0.4050\n",
      "step:   147340, time: 0.756, loss: 1.0842, l1: 0.2251, vgg: 0.4774, mask: 0.3817\n",
      "step:   147360, time: 0.744, loss: 0.9307, l1: 0.1746, vgg: 0.3983, mask: 0.3578\n",
      "step:   147380, time: 0.760, loss: 1.0117, l1: 0.1852, vgg: 0.4319, mask: 0.3946\n",
      "step:   147400, time: 0.767, loss: 1.1595, l1: 0.2329, vgg: 0.5519, mask: 0.3748\n",
      "step:   147420, time: 0.783, loss: 1.0644, l1: 0.2416, vgg: 0.4577, mask: 0.3651\n",
      "step:   147440, time: 0.772, loss: 0.9627, l1: 0.2127, vgg: 0.3991, mask: 0.3509\n",
      "step:   147460, time: 0.751, loss: 1.0284, l1: 0.2230, vgg: 0.4272, mask: 0.3782\n",
      "step:   147480, time: 0.752, loss: 0.9393, l1: 0.1780, vgg: 0.4206, mask: 0.3407\n",
      "step:   147500, time: 0.786, loss: 0.9038, l1: 0.1495, vgg: 0.4042, mask: 0.3501\n",
      "step:   147520, time: 0.740, loss: 0.8792, l1: 0.1419, vgg: 0.3797, mask: 0.3576\n",
      "step:   147540, time: 0.741, loss: 0.8908, l1: 0.1330, vgg: 0.4167, mask: 0.3411\n",
      "step:   147560, time: 0.765, loss: 1.0461, l1: 0.2390, vgg: 0.4025, mask: 0.4045\n",
      "step:   147580, time: 0.741, loss: 1.0857, l1: 0.2287, vgg: 0.4921, mask: 0.3649\n",
      "step:   147600, time: 0.767, loss: 0.9886, l1: 0.2009, vgg: 0.4132, mask: 0.3744\n",
      "step:   147620, time: 0.786, loss: 0.9819, l1: 0.2052, vgg: 0.4119, mask: 0.3648\n",
      "step:   147640, time: 0.761, loss: 1.1179, l1: 0.2490, vgg: 0.4535, mask: 0.4153\n",
      "step:   147660, time: 0.758, loss: 1.1466, l1: 0.2801, vgg: 0.4337, mask: 0.4328\n",
      "step:   147680, time: 0.716, loss: 1.0314, l1: 0.2510, vgg: 0.4059, mask: 0.3744\n",
      "step:   147700, time: 0.752, loss: 0.9951, l1: 0.1912, vgg: 0.4223, mask: 0.3817\n",
      "step:   147720, time: 0.746, loss: 1.0634, l1: 0.2196, vgg: 0.4443, mask: 0.3995\n",
      "step:   147740, time: 0.745, loss: 1.0629, l1: 0.2418, vgg: 0.3980, mask: 0.4232\n",
      "step:   147760, time: 0.741, loss: 1.1324, l1: 0.2509, vgg: 0.4632, mask: 0.4182\n",
      "step:   147780, time: 0.750, loss: 1.0341, l1: 0.2338, vgg: 0.4089, mask: 0.3915\n",
      "step:   147800, time: 0.790, loss: 1.0961, l1: 0.2318, vgg: 0.4868, mask: 0.3775\n",
      "step:   147820, time: 0.765, loss: 1.0088, l1: 0.2403, vgg: 0.3865, mask: 0.3821\n",
      "step:   147840, time: 0.760, loss: 0.8798, l1: 0.1557, vgg: 0.3890, mask: 0.3352\n",
      "step:   147860, time: 0.743, loss: 1.0311, l1: 0.2329, vgg: 0.4272, mask: 0.3710\n",
      "step:   147880, time: 0.730, loss: 0.9367, l1: 0.2159, vgg: 0.3734, mask: 0.3474\n",
      "step:   147900, time: 0.763, loss: 1.2325, l1: 0.2438, vgg: 0.5574, mask: 0.4313\n",
      "step:   147920, time: 0.761, loss: 0.9569, l1: 0.1723, vgg: 0.4311, mask: 0.3535\n",
      "step:   147940, time: 0.747, loss: 1.0016, l1: 0.2084, vgg: 0.4056, mask: 0.3876\n",
      "step:   147960, time: 0.766, loss: 1.0138, l1: 0.2718, vgg: 0.3827, mask: 0.3592\n",
      "step:   147980, time: 0.756, loss: 1.0253, l1: 0.2025, vgg: 0.4522, mask: 0.3705\n",
      "step:   148000, time: 0.754, loss: 1.1150, l1: 0.2703, vgg: 0.4550, mask: 0.3897\n",
      "step:   148020, time: 0.751, loss: 0.9330, l1: 0.1731, vgg: 0.3969, mask: 0.3630\n",
      "step:   148040, time: 0.792, loss: 1.0196, l1: 0.1911, vgg: 0.4576, mask: 0.3709\n",
      "step:   148060, time: 0.724, loss: 1.0548, l1: 0.2043, vgg: 0.4740, mask: 0.3764\n",
      "step:   148080, time: 0.780, loss: 1.0526, l1: 0.2294, vgg: 0.4061, mask: 0.4172\n",
      "step:   148100, time: 0.775, loss: 1.0260, l1: 0.2045, vgg: 0.4372, mask: 0.3844\n",
      "step:   148120, time: 0.730, loss: 0.9527, l1: 0.1931, vgg: 0.3881, mask: 0.3714\n",
      "step:   148140, time: 0.749, loss: 1.0432, l1: 0.2055, vgg: 0.4505, mask: 0.3872\n",
      "step:   148160, time: 0.793, loss: 1.1635, l1: 0.2362, vgg: 0.5309, mask: 0.3964\n",
      "step:   148180, time: 0.742, loss: 1.0485, l1: 0.2101, vgg: 0.4491, mask: 0.3893\n",
      "step:   148200, time: 0.753, loss: 0.9627, l1: 0.2139, vgg: 0.3560, mask: 0.3928\n",
      "step:   148220, time: 0.777, loss: 1.0343, l1: 0.2155, vgg: 0.4345, mask: 0.3843\n",
      "step:   148240, time: 0.770, loss: 1.0515, l1: 0.2017, vgg: 0.4703, mask: 0.3796\n",
      "step:   148260, time: 0.758, loss: 1.0614, l1: 0.2094, vgg: 0.4706, mask: 0.3814\n",
      "step:   148280, time: 0.777, loss: 1.0298, l1: 0.1840, vgg: 0.4903, mask: 0.3555\n",
      "step:   148300, time: 0.756, loss: 0.8948, l1: 0.1640, vgg: 0.3877, mask: 0.3430\n",
      "step:   148320, time: 0.738, loss: 1.0503, l1: 0.2179, vgg: 0.4361, mask: 0.3963\n",
      "step:   148340, time: 0.744, loss: 1.1406, l1: 0.2390, vgg: 0.5273, mask: 0.3744\n",
      "step:   148360, time: 0.736, loss: 0.8552, l1: 0.1570, vgg: 0.3462, mask: 0.3520\n",
      "step:   148380, time: 0.836, loss: 1.0751, l1: 0.2335, vgg: 0.4443, mask: 0.3973\n",
      "step:   148400, time: 0.773, loss: 1.1652, l1: 0.2627, vgg: 0.4904, mask: 0.4121\n",
      "step:   148420, time: 0.785, loss: 0.9993, l1: 0.1831, vgg: 0.4696, mask: 0.3466\n",
      "step:   148440, time: 0.734, loss: 0.9817, l1: 0.1921, vgg: 0.4077, mask: 0.3819\n",
      "step:   148460, time: 0.749, loss: 0.9848, l1: 0.2408, vgg: 0.3803, mask: 0.3637\n",
      "step:   148480, time: 0.743, loss: 1.0176, l1: 0.1805, vgg: 0.4239, mask: 0.4132\n",
      "step:   148500, time: 0.753, loss: 1.0104, l1: 0.2356, vgg: 0.4077, mask: 0.3670\n",
      "step:   148520, time: 0.771, loss: 1.1492, l1: 0.2858, vgg: 0.4514, mask: 0.4121\n",
      "step:   148540, time: 0.784, loss: 1.1239, l1: 0.2088, vgg: 0.5568, mask: 0.3583\n",
      "step:   148560, time: 0.778, loss: 1.0140, l1: 0.2508, vgg: 0.3797, mask: 0.3835\n",
      "step:   148580, time: 0.754, loss: 0.9923, l1: 0.2153, vgg: 0.3721, mask: 0.4049\n",
      "step:   148600, time: 0.753, loss: 1.0810, l1: 0.2481, vgg: 0.4609, mask: 0.3720\n",
      "step:   148620, time: 0.757, loss: 1.0381, l1: 0.1983, vgg: 0.4616, mask: 0.3782\n",
      "step:   148640, time: 0.762, loss: 1.0919, l1: 0.2785, vgg: 0.4149, mask: 0.3985\n",
      "step:   148660, time: 0.805, loss: 1.0330, l1: 0.2064, vgg: 0.4608, mask: 0.3657\n",
      "step:   148680, time: 0.764, loss: 1.0250, l1: 0.1768, vgg: 0.4501, mask: 0.3982\n",
      "step:   148700, time: 0.720, loss: 0.9663, l1: 0.1982, vgg: 0.3773, mask: 0.3908\n",
      "step:   148720, time: 0.750, loss: 1.1163, l1: 0.2649, vgg: 0.4514, mask: 0.3999\n",
      "step:   148740, time: 0.767, loss: 0.9271, l1: 0.1709, vgg: 0.3849, mask: 0.3712\n",
      "step:   148760, time: 0.782, loss: 1.0177, l1: 0.1743, vgg: 0.4782, mask: 0.3652\n",
      "step:   148780, time: 0.768, loss: 1.0320, l1: 0.2302, vgg: 0.4097, mask: 0.3921\n",
      "step:   148800, time: 0.756, loss: 1.0817, l1: 0.2197, vgg: 0.4493, mask: 0.4126\n",
      "step:   148820, time: 0.802, loss: 1.0799, l1: 0.2172, vgg: 0.4429, mask: 0.4198\n",
      "step:   148840, time: 0.724, loss: 0.9332, l1: 0.1790, vgg: 0.3903, mask: 0.3639\n",
      "step:   148860, time: 0.761, loss: 1.1020, l1: 0.2519, vgg: 0.4579, mask: 0.3922\n",
      "step:   148880, time: 0.762, loss: 1.0109, l1: 0.1917, vgg: 0.4773, mask: 0.3419\n",
      "step:   148900, time: 0.737, loss: 1.0473, l1: 0.2663, vgg: 0.3395, mask: 0.4416\n",
      "step:   148920, time: 0.741, loss: 0.9879, l1: 0.1994, vgg: 0.3892, mask: 0.3993\n",
      "step:   148940, time: 0.736, loss: 0.9672, l1: 0.2047, vgg: 0.3860, mask: 0.3765\n",
      "step:   148960, time: 0.725, loss: 1.0019, l1: 0.2225, vgg: 0.3960, mask: 0.3834\n",
      "step:   148980, time: 0.757, loss: 0.9988, l1: 0.1905, vgg: 0.4204, mask: 0.3879\n",
      "step:   149000, time: 0.764, loss: 0.9967, l1: 0.2161, vgg: 0.4053, mask: 0.3752\n",
      "step:   149020, time: 0.765, loss: 1.2019, l1: 0.2938, vgg: 0.4900, mask: 0.4180\n",
      "step:   149040, time: 0.751, loss: 0.9500, l1: 0.1775, vgg: 0.4029, mask: 0.3697\n",
      "step:   149060, time: 0.757, loss: 1.0577, l1: 0.2312, vgg: 0.4493, mask: 0.3771\n",
      "step:   149080, time: 0.764, loss: 1.0766, l1: 0.2099, vgg: 0.4884, mask: 0.3783\n",
      "step:   149100, time: 0.723, loss: 0.9814, l1: 0.1884, vgg: 0.4173, mask: 0.3757\n",
      "step:   149120, time: 0.744, loss: 1.1410, l1: 0.3009, vgg: 0.4341, mask: 0.4060\n",
      "step:   149140, time: 0.756, loss: 1.0161, l1: 0.1994, vgg: 0.4190, mask: 0.3977\n",
      "step:   149160, time: 0.730, loss: 0.9610, l1: 0.1696, vgg: 0.4086, mask: 0.3829\n",
      "step:   149180, time: 0.752, loss: 1.0719, l1: 0.2100, vgg: 0.4574, mask: 0.4045\n",
      "step:   149200, time: 0.771, loss: 1.0722, l1: 0.2659, vgg: 0.4191, mask: 0.3872\n",
      "step:   149220, time: 0.747, loss: 1.0208, l1: 0.2295, vgg: 0.4257, mask: 0.3655\n",
      "step:   149240, time: 0.730, loss: 0.9688, l1: 0.1726, vgg: 0.4440, mask: 0.3523\n",
      "step:   149260, time: 0.782, loss: 1.0344, l1: 0.2293, vgg: 0.4279, mask: 0.3772\n",
      "step:   149280, time: 0.758, loss: 1.0615, l1: 0.2296, vgg: 0.4499, mask: 0.3820\n",
      "step:   149300, time: 0.784, loss: 1.1233, l1: 0.2295, vgg: 0.4842, mask: 0.4096\n",
      "step:   149320, time: 0.768, loss: 0.9416, l1: 0.1832, vgg: 0.4048, mask: 0.3536\n",
      "step:   149340, time: 0.737, loss: 1.0608, l1: 0.2755, vgg: 0.3523, mask: 0.4330\n",
      "step:   149360, time: 0.760, loss: 1.0841, l1: 0.2480, vgg: 0.4471, mask: 0.3890\n",
      "step:   149380, time: 0.757, loss: 1.0203, l1: 0.1766, vgg: 0.4726, mask: 0.3711\n",
      "step:   149400, time: 0.767, loss: 1.1632, l1: 0.2985, vgg: 0.4294, mask: 0.4353\n",
      "step:   149420, time: 0.733, loss: 1.0120, l1: 0.2429, vgg: 0.3815, mask: 0.3876\n",
      "step:   149440, time: 0.752, loss: 1.0511, l1: 0.1708, vgg: 0.5136, mask: 0.3667\n",
      "step:   149460, time: 0.728, loss: 0.9774, l1: 0.2233, vgg: 0.4087, mask: 0.3455\n",
      "step:   149480, time: 0.752, loss: 1.1261, l1: 0.2622, vgg: 0.4688, mask: 0.3951\n",
      "step:   149500, time: 0.775, loss: 1.1354, l1: 0.2342, vgg: 0.4725, mask: 0.4287\n",
      "step:   149520, time: 0.769, loss: 0.9717, l1: 0.2274, vgg: 0.3942, mask: 0.3501\n",
      "step:   149540, time: 0.735, loss: 1.0843, l1: 0.1930, vgg: 0.5043, mask: 0.3870\n",
      "step:   149560, time: 0.765, loss: 1.1682, l1: 0.2793, vgg: 0.4859, mask: 0.4029\n",
      "step:   149580, time: 0.742, loss: 0.9614, l1: 0.2004, vgg: 0.3833, mask: 0.3777\n",
      "step:   149600, time: 0.756, loss: 1.0741, l1: 0.2450, vgg: 0.4434, mask: 0.3857\n",
      "step:   149620, time: 0.741, loss: 0.9833, l1: 0.1798, vgg: 0.4146, mask: 0.3888\n",
      "step:   149640, time: 0.742, loss: 0.9214, l1: 0.1385, vgg: 0.3955, mask: 0.3875\n",
      "step:   149660, time: 0.752, loss: 1.2646, l1: 0.3203, vgg: 0.5119, mask: 0.4324\n",
      "step:   149680, time: 0.735, loss: 1.0468, l1: 0.1823, vgg: 0.5113, mask: 0.3532\n",
      "step:   149700, time: 0.736, loss: 0.9944, l1: 0.2014, vgg: 0.4206, mask: 0.3725\n",
      "step:   149720, time: 0.739, loss: 1.0238, l1: 0.2520, vgg: 0.3851, mask: 0.3867\n",
      "step:   149740, time: 0.738, loss: 0.9206, l1: 0.1945, vgg: 0.3546, mask: 0.3715\n",
      "step:   149760, time: 0.754, loss: 0.9531, l1: 0.1725, vgg: 0.4306, mask: 0.3501\n",
      "step:   149780, time: 0.810, loss: 0.9940, l1: 0.2024, vgg: 0.4200, mask: 0.3715\n",
      "step:   149800, time: 0.742, loss: 1.1133, l1: 0.2470, vgg: 0.4920, mask: 0.3743\n",
      "step:   149820, time: 0.757, loss: 1.1182, l1: 0.2182, vgg: 0.4798, mask: 0.4202\n",
      "step:   149840, time: 0.756, loss: 1.1501, l1: 0.2530, vgg: 0.4686, mask: 0.4285\n",
      "step:   149860, time: 0.722, loss: 0.9983, l1: 0.1942, vgg: 0.4223, mask: 0.3818\n",
      "step:   149880, time: 0.746, loss: 1.0784, l1: 0.2533, vgg: 0.4139, mask: 0.4112\n",
      "step:   149900, time: 0.750, loss: 1.0256, l1: 0.2547, vgg: 0.4139, mask: 0.3570\n",
      "step:   149920, time: 0.700, loss: 0.9713, l1: 0.2016, vgg: 0.3939, mask: 0.3757\n",
      "step:   149940, time: 0.751, loss: 1.1355, l1: 0.2200, vgg: 0.4871, mask: 0.4284\n",
      "step:   149960, time: 0.788, loss: 0.9636, l1: 0.2083, vgg: 0.4081, mask: 0.3472\n",
      "step:   149980, time: 0.779, loss: 1.1094, l1: 0.2440, vgg: 0.4525, mask: 0.4129\n",
      "step:   150000, time: 0.731, loss: 0.9646, l1: 0.1684, vgg: 0.4346, mask: 0.3617\n",
      "step:   150020, time: 0.756, loss: 1.1131, l1: 0.2706, vgg: 0.4460, mask: 0.3965\n",
      "step:   150040, time: 0.727, loss: 1.0945, l1: 0.2716, vgg: 0.4042, mask: 0.4187\n",
      "step:   150060, time: 0.715, loss: 0.9277, l1: 0.1516, vgg: 0.4488, mask: 0.3272\n",
      "step:   150080, time: 0.737, loss: 0.8819, l1: 0.1697, vgg: 0.3685, mask: 0.3437\n",
      "step:   150100, time: 0.771, loss: 1.1297, l1: 0.2342, vgg: 0.5192, mask: 0.3763\n",
      "step:   150120, time: 0.741, loss: 0.9832, l1: 0.1855, vgg: 0.4257, mask: 0.3721\n",
      "step:   150140, time: 0.745, loss: 1.0333, l1: 0.2262, vgg: 0.4100, mask: 0.3972\n",
      "step:   150160, time: 0.749, loss: 0.8591, l1: 0.1785, vgg: 0.3408, mask: 0.3399\n",
      "step:   150180, time: 0.776, loss: 1.1292, l1: 0.2358, vgg: 0.4966, mask: 0.3968\n",
      "step:   150200, time: 0.739, loss: 0.9229, l1: 0.2112, vgg: 0.3297, mask: 0.3820\n",
      "step:   150220, time: 0.768, loss: 1.0355, l1: 0.2050, vgg: 0.4326, mask: 0.3979\n",
      "step:   150240, time: 0.743, loss: 1.1019, l1: 0.2422, vgg: 0.4608, mask: 0.3990\n",
      "step:   150260, time: 0.746, loss: 1.0162, l1: 0.2233, vgg: 0.4156, mask: 0.3773\n",
      "step:   150280, time: 0.744, loss: 1.0435, l1: 0.1866, vgg: 0.4818, mask: 0.3750\n",
      "step:   150300, time: 0.742, loss: 0.9706, l1: 0.1897, vgg: 0.3816, mask: 0.3993\n",
      "step:   150320, time: 0.743, loss: 1.1465, l1: 0.2833, vgg: 0.4450, mask: 0.4182\n",
      "step:   150340, time: 0.780, loss: 0.9257, l1: 0.1921, vgg: 0.3384, mask: 0.3953\n",
      "step:   150360, time: 0.723, loss: 0.8694, l1: 0.1438, vgg: 0.3746, mask: 0.3510\n",
      "step:   150380, time: 0.720, loss: 1.1459, l1: 0.2498, vgg: 0.5253, mask: 0.3708\n",
      "step:   150400, time: 0.768, loss: 1.0404, l1: 0.2037, vgg: 0.4649, mask: 0.3718\n",
      "step:   150420, time: 0.761, loss: 1.1419, l1: 0.2646, vgg: 0.4751, mask: 0.4022\n",
      "step:   150440, time: 0.752, loss: 1.0055, l1: 0.2301, vgg: 0.3980, mask: 0.3774\n",
      "step:   150460, time: 0.706, loss: 1.0079, l1: 0.2234, vgg: 0.4098, mask: 0.3746\n",
      "step:   150480, time: 0.732, loss: 1.0480, l1: 0.2440, vgg: 0.4379, mask: 0.3661\n",
      "step:   150500, time: 0.716, loss: 1.0485, l1: 0.1880, vgg: 0.4512, mask: 0.4094\n",
      "step:   150520, time: 0.780, loss: 1.0347, l1: 0.2174, vgg: 0.4588, mask: 0.3585\n",
      "step:   150540, time: 0.750, loss: 1.0557, l1: 0.2273, vgg: 0.4413, mask: 0.3871\n",
      "step:   150560, time: 0.759, loss: 0.9387, l1: 0.1854, vgg: 0.3867, mask: 0.3666\n",
      "step:   150580, time: 0.753, loss: 0.9979, l1: 0.1891, vgg: 0.4325, mask: 0.3763\n",
      "step:   150600, time: 0.732, loss: 0.9954, l1: 0.1994, vgg: 0.4168, mask: 0.3792\n",
      "step:   150620, time: 0.749, loss: 0.9587, l1: 0.2052, vgg: 0.3985, mask: 0.3550\n",
      "step:   150640, time: 0.762, loss: 1.0204, l1: 0.2292, vgg: 0.4269, mask: 0.3643\n",
      "step:   150660, time: 0.719, loss: 0.8532, l1: 0.1428, vgg: 0.3740, mask: 0.3365\n",
      "step:   150680, time: 0.740, loss: 0.9995, l1: 0.1945, vgg: 0.4583, mask: 0.3466\n",
      "step:   150700, time: 0.758, loss: 0.9262, l1: 0.2043, vgg: 0.3464, mask: 0.3755\n",
      "step:   150720, time: 0.782, loss: 0.9224, l1: 0.1526, vgg: 0.4022, mask: 0.3676\n",
      "step:   150740, time: 0.752, loss: 1.0340, l1: 0.2594, vgg: 0.4049, mask: 0.3696\n",
      "step:   150760, time: 0.713, loss: 0.8701, l1: 0.1440, vgg: 0.3829, mask: 0.3432\n",
      "step:   150780, time: 0.740, loss: 1.0258, l1: 0.1859, vgg: 0.4558, mask: 0.3841\n",
      "step:   150800, time: 0.719, loss: 0.9148, l1: 0.1802, vgg: 0.3861, mask: 0.3486\n",
      "step:   150820, time: 0.732, loss: 0.9619, l1: 0.2067, vgg: 0.3548, mask: 0.4004\n",
      "step:   150840, time: 0.735, loss: 0.9818, l1: 0.1610, vgg: 0.4575, mask: 0.3633\n",
      "step:   150860, time: 0.770, loss: 1.1106, l1: 0.2585, vgg: 0.4588, mask: 0.3934\n",
      "step:   150880, time: 0.728, loss: 0.8827, l1: 0.1351, vgg: 0.4135, mask: 0.3341\n",
      "step:   150900, time: 0.738, loss: 1.0389, l1: 0.2215, vgg: 0.4578, mask: 0.3597\n",
      "step:   150920, time: 0.739, loss: 1.0503, l1: 0.2396, vgg: 0.4282, mask: 0.3825\n",
      "step:   150940, time: 0.759, loss: 1.1358, l1: 0.2285, vgg: 0.5258, mask: 0.3816\n",
      "step:   150960, time: 0.762, loss: 1.0045, l1: 0.1825, vgg: 0.4327, mask: 0.3893\n",
      "step:   150980, time: 0.726, loss: 1.0454, l1: 0.2096, vgg: 0.4414, mask: 0.3945\n",
      "step:   151000, time: 0.734, loss: 1.0119, l1: 0.2397, vgg: 0.3823, mask: 0.3900\n",
      "step:   151020, time: 0.738, loss: 0.8426, l1: 0.1397, vgg: 0.3781, mask: 0.3248\n",
      "step:   151040, time: 0.754, loss: 1.0414, l1: 0.2216, vgg: 0.4215, mask: 0.3982\n",
      "step:   151060, time: 0.722, loss: 0.9262, l1: 0.1624, vgg: 0.4054, mask: 0.3583\n",
      "step:   151080, time: 0.735, loss: 1.0008, l1: 0.2215, vgg: 0.3826, mask: 0.3967\n",
      "step:   151100, time: 0.774, loss: 0.9372, l1: 0.1998, vgg: 0.3672, mask: 0.3702\n",
      "step:   151120, time: 0.753, loss: 0.9828, l1: 0.1841, vgg: 0.4658, mask: 0.3329\n",
      "step:   151140, time: 0.754, loss: 1.1101, l1: 0.2143, vgg: 0.5083, mask: 0.3875\n",
      "step:   151160, time: 0.769, loss: 1.0345, l1: 0.2528, vgg: 0.4232, mask: 0.3585\n",
      "step:   151180, time: 0.744, loss: 0.9894, l1: 0.2160, vgg: 0.4091, mask: 0.3643\n",
      "step:   151200, time: 0.743, loss: 1.0575, l1: 0.2218, vgg: 0.4759, mask: 0.3598\n",
      "step:   151220, time: 0.742, loss: 0.9860, l1: 0.1798, vgg: 0.4203, mask: 0.3858\n",
      "step:   151240, time: 0.732, loss: 1.1155, l1: 0.2369, vgg: 0.4597, mask: 0.4189\n",
      "step:   151260, time: 0.756, loss: 1.1532, l1: 0.2468, vgg: 0.5134, mask: 0.3930\n",
      "step:   151280, time: 0.770, loss: 1.1227, l1: 0.2112, vgg: 0.5374, mask: 0.3741\n",
      "step:   151300, time: 0.746, loss: 0.9101, l1: 0.1703, vgg: 0.3988, mask: 0.3411\n",
      "step:   151320, time: 0.751, loss: 1.0637, l1: 0.1889, vgg: 0.4555, mask: 0.4192\n",
      "step:   151340, time: 0.765, loss: 1.0871, l1: 0.2392, vgg: 0.4656, mask: 0.3823\n",
      "step:   151360, time: 0.733, loss: 0.9635, l1: 0.1932, vgg: 0.4163, mask: 0.3540\n",
      "step:   151380, time: 0.718, loss: 0.9608, l1: 0.1919, vgg: 0.3802, mask: 0.3888\n",
      "step:   151400, time: 0.752, loss: 1.0303, l1: 0.2468, vgg: 0.3942, mask: 0.3893\n",
      "step:   151420, time: 0.752, loss: 1.0153, l1: 0.1807, vgg: 0.4679, mask: 0.3667\n",
      "step:   151440, time: 0.765, loss: 1.1144, l1: 0.2236, vgg: 0.5125, mask: 0.3783\n",
      "step:   151460, time: 0.754, loss: 0.9123, l1: 0.1721, vgg: 0.3767, mask: 0.3636\n",
      "step:   151480, time: 0.774, loss: 0.9989, l1: 0.1971, vgg: 0.4092, mask: 0.3926\n",
      "step:   151500, time: 0.722, loss: 0.8766, l1: 0.1562, vgg: 0.3757, mask: 0.3447\n",
      "step:   151520, time: 0.765, loss: 0.8864, l1: 0.1867, vgg: 0.3624, mask: 0.3373\n",
      "step:   151540, time: 0.756, loss: 1.0109, l1: 0.2473, vgg: 0.3986, mask: 0.3650\n",
      "step:   151560, time: 0.735, loss: 0.9948, l1: 0.2091, vgg: 0.4151, mask: 0.3705\n",
      "step:   151580, time: 0.735, loss: 1.0690, l1: 0.2038, vgg: 0.5167, mask: 0.3484\n",
      "step:   151600, time: 0.754, loss: 0.9880, l1: 0.1718, vgg: 0.4549, mask: 0.3612\n",
      "step:   151620, time: 0.843, loss: 1.0712, l1: 0.2459, vgg: 0.4113, mask: 0.4139\n",
      "step:   151640, time: 0.710, loss: 0.9916, l1: 0.1826, vgg: 0.4020, mask: 0.4070\n",
      "step:   151660, time: 0.743, loss: 1.1854, l1: 0.2654, vgg: 0.5163, mask: 0.4036\n",
      "step:   151680, time: 0.753, loss: 1.0147, l1: 0.2398, vgg: 0.3833, mask: 0.3917\n",
      "step:   151700, time: 0.726, loss: 0.9688, l1: 0.2090, vgg: 0.3623, mask: 0.3975\n",
      "step:   151720, time: 0.769, loss: 1.2222, l1: 0.2406, vgg: 0.5469, mask: 0.4346\n",
      "step:   151740, time: 0.771, loss: 0.9968, l1: 0.1958, vgg: 0.4265, mask: 0.3745\n",
      "step:   151760, time: 0.740, loss: 0.8943, l1: 0.1830, vgg: 0.3581, mask: 0.3532\n",
      "step:   151780, time: 0.749, loss: 1.0616, l1: 0.2336, vgg: 0.4493, mask: 0.3788\n",
      "step:   151800, time: 0.784, loss: 1.0526, l1: 0.2173, vgg: 0.4572, mask: 0.3781\n",
      "step:   151820, time: 0.743, loss: 1.0364, l1: 0.2350, vgg: 0.4187, mask: 0.3827\n",
      "step:   151840, time: 0.741, loss: 0.9834, l1: 0.1899, vgg: 0.4189, mask: 0.3747\n",
      "step:   151860, time: 0.729, loss: 1.0960, l1: 0.2444, vgg: 0.3983, mask: 0.4533\n",
      "step:   151880, time: 0.731, loss: 1.0109, l1: 0.2197, vgg: 0.3952, mask: 0.3960\n",
      "step:   151900, time: 0.763, loss: 1.1203, l1: 0.2516, vgg: 0.4621, mask: 0.4066\n",
      "step:   151920, time: 0.725, loss: 0.9569, l1: 0.1835, vgg: 0.3828, mask: 0.3906\n",
      "step:   151940, time: 0.733, loss: 1.0807, l1: 0.2324, vgg: 0.4438, mask: 0.4045\n",
      "step:   151960, time: 0.752, loss: 1.0741, l1: 0.2266, vgg: 0.4422, mask: 0.4053\n",
      "step:   151980, time: 0.774, loss: 1.0722, l1: 0.2550, vgg: 0.4289, mask: 0.3883\n",
      "step:   152000, time: 0.778, loss: 1.0126, l1: 0.2295, vgg: 0.4114, mask: 0.3717\n",
      "step:   152020, time: 0.744, loss: 1.0986, l1: 0.2518, vgg: 0.4462, mask: 0.4007\n",
      "step:   152040, time: 0.761, loss: 1.0950, l1: 0.2794, vgg: 0.4374, mask: 0.3782\n",
      "step:   152060, time: 0.757, loss: 0.9972, l1: 0.1997, vgg: 0.4024, mask: 0.3951\n",
      "step:   152080, time: 0.730, loss: 1.0188, l1: 0.2198, vgg: 0.3958, mask: 0.4032\n",
      "step:   152100, time: 0.746, loss: 1.1549, l1: 0.2740, vgg: 0.4797, mask: 0.4012\n",
      "step:   152120, time: 0.763, loss: 1.0352, l1: 0.2204, vgg: 0.4119, mask: 0.4029\n",
      "step:   152140, time: 0.750, loss: 1.2031, l1: 0.2678, vgg: 0.5211, mask: 0.4141\n",
      "step:   152160, time: 0.762, loss: 1.0447, l1: 0.2294, vgg: 0.4287, mask: 0.3866\n",
      "step:   152180, time: 0.728, loss: 1.0029, l1: 0.2075, vgg: 0.4265, mask: 0.3689\n",
      "step:   152200, time: 0.736, loss: 1.0397, l1: 0.2481, vgg: 0.3925, mask: 0.3991\n",
      "step:   152220, time: 0.739, loss: 0.9934, l1: 0.2308, vgg: 0.3675, mask: 0.3952\n",
      "step:   152240, time: 0.750, loss: 0.9407, l1: 0.1953, vgg: 0.4098, mask: 0.3356\n",
      "step:   152260, time: 0.736, loss: 1.0049, l1: 0.2278, vgg: 0.3781, mask: 0.3990\n",
      "step:   152280, time: 0.730, loss: 0.9991, l1: 0.2236, vgg: 0.3533, mask: 0.4222\n",
      "step:   152300, time: 0.729, loss: 0.9510, l1: 0.1900, vgg: 0.3722, mask: 0.3888\n",
      "step:   152320, time: 0.709, loss: 0.9128, l1: 0.1940, vgg: 0.3609, mask: 0.3580\n",
      "step:   152340, time: 0.771, loss: 1.0435, l1: 0.2275, vgg: 0.3966, mask: 0.4193\n",
      "step:   152360, time: 0.761, loss: 1.0977, l1: 0.2524, vgg: 0.4446, mask: 0.4007\n",
      "step:   152380, time: 0.749, loss: 0.9736, l1: 0.1483, vgg: 0.4526, mask: 0.3726\n",
      "step:   152400, time: 0.739, loss: 0.8792, l1: 0.1421, vgg: 0.4073, mask: 0.3298\n",
      "step:   152420, time: 0.775, loss: 0.9961, l1: 0.1898, vgg: 0.4238, mask: 0.3825\n",
      "step:   152440, time: 0.767, loss: 1.1056, l1: 0.2657, vgg: 0.4467, mask: 0.3933\n",
      "step:   152460, time: 0.786, loss: 1.1409, l1: 0.2113, vgg: 0.5046, mask: 0.4250\n",
      "step:   152480, time: 0.752, loss: 1.0778, l1: 0.2009, vgg: 0.5000, mask: 0.3770\n",
      "step:   152500, time: 0.763, loss: 1.2065, l1: 0.2658, vgg: 0.5262, mask: 0.4145\n",
      "step:   152520, time: 0.809, loss: 1.1113, l1: 0.2500, vgg: 0.4578, mask: 0.4034\n",
      "step:   152540, time: 0.723, loss: 1.0141, l1: 0.1909, vgg: 0.4153, mask: 0.4079\n",
      "step:   152560, time: 0.740, loss: 1.0185, l1: 0.2076, vgg: 0.4158, mask: 0.3951\n",
      "step:   152580, time: 0.789, loss: 1.1418, l1: 0.2759, vgg: 0.4781, mask: 0.3877\n",
      "step:   152600, time: 0.783, loss: 0.9453, l1: 0.1817, vgg: 0.3828, mask: 0.3808\n",
      "step:   152620, time: 0.754, loss: 1.0406, l1: 0.1959, vgg: 0.4545, mask: 0.3902\n",
      "step:   152640, time: 0.789, loss: 1.0161, l1: 0.2203, vgg: 0.4451, mask: 0.3506\n",
      "step:   152660, time: 0.751, loss: 1.0381, l1: 0.2162, vgg: 0.4708, mask: 0.3512\n",
      "step:   152680, time: 0.733, loss: 0.9634, l1: 0.1899, vgg: 0.4225, mask: 0.3510\n",
      "step:   152700, time: 0.771, loss: 1.0418, l1: 0.2024, vgg: 0.4798, mask: 0.3596\n",
      "step:   152720, time: 0.767, loss: 0.9671, l1: 0.1917, vgg: 0.4055, mask: 0.3699\n",
      "step:   152740, time: 0.760, loss: 1.0545, l1: 0.1858, vgg: 0.4736, mask: 0.3951\n",
      "step:   152760, time: 0.753, loss: 1.0377, l1: 0.2308, vgg: 0.4314, mask: 0.3755\n",
      "step:   152780, time: 0.741, loss: 1.0582, l1: 0.2591, vgg: 0.4135, mask: 0.3856\n",
      "step:   152800, time: 0.763, loss: 0.9840, l1: 0.1834, vgg: 0.4279, mask: 0.3727\n",
      "step:   152820, time: 0.764, loss: 1.0234, l1: 0.1988, vgg: 0.4392, mask: 0.3854\n",
      "step:   152840, time: 0.748, loss: 0.9885, l1: 0.1875, vgg: 0.4389, mask: 0.3621\n",
      "step:   152860, time: 0.751, loss: 1.1099, l1: 0.2148, vgg: 0.5061, mask: 0.3890\n",
      "step:   152880, time: 0.763, loss: 1.0493, l1: 0.2445, vgg: 0.4145, mask: 0.3902\n",
      "step:   152900, time: 0.705, loss: 0.9857, l1: 0.1892, vgg: 0.3754, mask: 0.4211\n",
      "step:   152920, time: 0.716, loss: 1.0097, l1: 0.2388, vgg: 0.4005, mask: 0.3704\n",
      "step:   152940, time: 0.799, loss: 1.1689, l1: 0.2762, vgg: 0.4702, mask: 0.4225\n",
      "step:   152960, time: 0.721, loss: 0.9435, l1: 0.1993, vgg: 0.3567, mask: 0.3874\n",
      "step:   152980, time: 0.763, loss: 1.0362, l1: 0.1861, vgg: 0.4683, mask: 0.3819\n",
      "step:   153000, time: 0.759, loss: 1.1148, l1: 0.2374, vgg: 0.4856, mask: 0.3917\n",
      "step:   153020, time: 0.760, loss: 1.0213, l1: 0.1908, vgg: 0.4705, mask: 0.3600\n",
      "step:   153040, time: 0.771, loss: 1.1432, l1: 0.2279, vgg: 0.5311, mask: 0.3842\n",
      "step:   153060, time: 0.758, loss: 1.0033, l1: 0.2366, vgg: 0.4092, mask: 0.3575\n",
      "step:   153080, time: 0.762, loss: 1.1687, l1: 0.2551, vgg: 0.5193, mask: 0.3944\n",
      "step:   153100, time: 0.738, loss: 1.0494, l1: 0.2287, vgg: 0.4182, mask: 0.4026\n",
      "step:   153120, time: 0.772, loss: 1.1537, l1: 0.2605, vgg: 0.4663, mask: 0.4269\n",
      "step:   153140, time: 0.754, loss: 1.2362, l1: 0.3059, vgg: 0.5121, mask: 0.4182\n",
      "step:   153160, time: 0.742, loss: 0.9355, l1: 0.1747, vgg: 0.3919, mask: 0.3689\n",
      "step:   153180, time: 0.742, loss: 1.1346, l1: 0.2750, vgg: 0.4564, mask: 0.4032\n",
      "step:   153200, time: 0.743, loss: 0.9200, l1: 0.1941, vgg: 0.3596, mask: 0.3663\n",
      "step:   153220, time: 0.732, loss: 1.0646, l1: 0.2182, vgg: 0.4351, mask: 0.4113\n",
      "step:   153240, time: 0.727, loss: 0.9616, l1: 0.2010, vgg: 0.4085, mask: 0.3522\n",
      "step:   153260, time: 0.706, loss: 0.9619, l1: 0.2145, vgg: 0.3750, mask: 0.3725\n",
      "step:   153280, time: 0.727, loss: 0.9541, l1: 0.1764, vgg: 0.4064, mask: 0.3713\n",
      "step:   153300, time: 0.779, loss: 1.0563, l1: 0.2558, vgg: 0.3992, mask: 0.4013\n",
      "step:   153320, time: 0.761, loss: 1.1162, l1: 0.2406, vgg: 0.4827, mask: 0.3930\n",
      "step:   153340, time: 0.753, loss: 0.9808, l1: 0.2251, vgg: 0.3975, mask: 0.3581\n",
      "step:   153360, time: 0.718, loss: 0.9818, l1: 0.2485, vgg: 0.3699, mask: 0.3634\n",
      "step:   153380, time: 0.751, loss: 0.9857, l1: 0.1708, vgg: 0.4600, mask: 0.3549\n",
      "step:   153400, time: 0.734, loss: 0.8980, l1: 0.1910, vgg: 0.3699, mask: 0.3371\n",
      "step:   153420, time: 0.727, loss: 0.8785, l1: 0.1505, vgg: 0.3969, mask: 0.3311\n",
      "step:   153440, time: 0.733, loss: 1.0027, l1: 0.1690, vgg: 0.4499, mask: 0.3838\n",
      "step:   153460, time: 0.739, loss: 0.9836, l1: 0.1842, vgg: 0.4210, mask: 0.3784\n",
      "step:   153480, time: 0.782, loss: 0.9879, l1: 0.1797, vgg: 0.4447, mask: 0.3635\n",
      "step:   153500, time: 0.743, loss: 0.9393, l1: 0.1401, vgg: 0.4212, mask: 0.3780\n",
      "step:   153520, time: 0.789, loss: 1.1048, l1: 0.2193, vgg: 0.4953, mask: 0.3902\n",
      "step:   153540, time: 0.732, loss: 1.0117, l1: 0.2237, vgg: 0.4103, mask: 0.3777\n",
      "step:   153560, time: 0.736, loss: 1.0030, l1: 0.1863, vgg: 0.4315, mask: 0.3852\n",
      "step:   153580, time: 0.738, loss: 0.9460, l1: 0.1667, vgg: 0.4245, mask: 0.3548\n",
      "step:   153600, time: 0.753, loss: 1.0523, l1: 0.2359, vgg: 0.4298, mask: 0.3866\n",
      "step:   153620, time: 0.714, loss: 0.9513, l1: 0.1657, vgg: 0.4313, mask: 0.3543\n",
      "step:   153640, time: 0.769, loss: 1.0784, l1: 0.2712, vgg: 0.4250, mask: 0.3822\n",
      "step:   153660, time: 0.738, loss: 0.9267, l1: 0.1888, vgg: 0.3860, mask: 0.3519\n",
      "step:   153680, time: 0.745, loss: 0.8881, l1: 0.1744, vgg: 0.3564, mask: 0.3573\n",
      "step:   153700, time: 0.731, loss: 1.0120, l1: 0.2129, vgg: 0.4278, mask: 0.3713\n",
      "step:   153720, time: 0.747, loss: 1.0895, l1: 0.2518, vgg: 0.4549, mask: 0.3827\n",
      "step:   153740, time: 0.757, loss: 0.9736, l1: 0.1775, vgg: 0.4233, mask: 0.3729\n",
      "step:   153760, time: 0.796, loss: 1.0257, l1: 0.1628, vgg: 0.5053, mask: 0.3576\n",
      "step:   153780, time: 0.758, loss: 1.0434, l1: 0.2360, vgg: 0.4260, mask: 0.3813\n",
      "step:   153800, time: 0.784, loss: 1.1094, l1: 0.2142, vgg: 0.5326, mask: 0.3626\n",
      "step:   153820, time: 0.777, loss: 1.2014, l1: 0.2650, vgg: 0.4923, mask: 0.4442\n",
      "step:   153840, time: 0.729, loss: 0.9734, l1: 0.1935, vgg: 0.4185, mask: 0.3614\n",
      "step:   153860, time: 0.757, loss: 1.0993, l1: 0.2518, vgg: 0.4450, mask: 0.4025\n",
      "step:   153880, time: 0.755, loss: 1.0290, l1: 0.2261, vgg: 0.4110, mask: 0.3918\n",
      "step:   153900, time: 0.741, loss: 1.0485, l1: 0.2130, vgg: 0.4298, mask: 0.4057\n",
      "step:   153920, time: 0.739, loss: 0.9289, l1: 0.1540, vgg: 0.4403, mask: 0.3346\n",
      "step:   153940, time: 0.744, loss: 1.2063, l1: 0.2567, vgg: 0.5174, mask: 0.4322\n",
      "step:   153960, time: 0.799, loss: 1.0796, l1: 0.2693, vgg: 0.3991, mask: 0.4112\n",
      "step:   153980, time: 0.760, loss: 1.1683, l1: 0.2808, vgg: 0.4861, mask: 0.4014\n",
      "step:   154000, time: 0.732, loss: 0.8210, l1: 0.1220, vgg: 0.3733, mask: 0.3257\n",
      "step:   154020, time: 0.754, loss: 1.1244, l1: 0.2361, vgg: 0.4816, mask: 0.4067\n",
      "step:   154040, time: 0.738, loss: 0.9937, l1: 0.1970, vgg: 0.3962, mask: 0.4005\n",
      "step:   154060, time: 0.744, loss: 0.8417, l1: 0.1361, vgg: 0.3827, mask: 0.3229\n",
      "step:   154080, time: 0.732, loss: 0.9704, l1: 0.2040, vgg: 0.4044, mask: 0.3620\n",
      "step:   154100, time: 0.769, loss: 1.1562, l1: 0.2135, vgg: 0.5682, mask: 0.3745\n",
      "step:   154120, time: 0.770, loss: 1.0336, l1: 0.1877, vgg: 0.4820, mask: 0.3639\n",
      "step:   154140, time: 0.765, loss: 1.0096, l1: 0.2120, vgg: 0.4047, mask: 0.3929\n",
      "step:   154160, time: 0.794, loss: 1.0791, l1: 0.2147, vgg: 0.5009, mask: 0.3636\n",
      "step:   154180, time: 0.743, loss: 0.9678, l1: 0.2016, vgg: 0.3798, mask: 0.3864\n",
      "step:   154200, time: 0.778, loss: 1.1291, l1: 0.2961, vgg: 0.4078, mask: 0.4252\n",
      "step:   154220, time: 0.772, loss: 0.9851, l1: 0.1870, vgg: 0.4051, mask: 0.3930\n",
      "step:   154240, time: 0.711, loss: 0.8829, l1: 0.1603, vgg: 0.3575, mask: 0.3651\n",
      "step:   154260, time: 0.747, loss: 0.9231, l1: 0.1654, vgg: 0.4039, mask: 0.3538\n",
      "step:   154280, time: 0.770, loss: 1.0648, l1: 0.1855, vgg: 0.4959, mask: 0.3834\n",
      "step:   154300, time: 0.729, loss: 1.0278, l1: 0.2141, vgg: 0.4359, mask: 0.3778\n",
      "step:   154320, time: 0.775, loss: 1.0194, l1: 0.2032, vgg: 0.4234, mask: 0.3928\n",
      "step:   154340, time: 0.754, loss: 0.9563, l1: 0.1775, vgg: 0.3668, mask: 0.4120\n",
      "step:   154360, time: 0.733, loss: 1.0053, l1: 0.1821, vgg: 0.4874, mask: 0.3358\n",
      "step:   154380, time: 0.709, loss: 0.8979, l1: 0.1438, vgg: 0.3834, mask: 0.3707\n",
      "step:   154400, time: 0.734, loss: 1.0447, l1: 0.1884, vgg: 0.4722, mask: 0.3840\n",
      "step:   154420, time: 0.715, loss: 0.8384, l1: 0.1321, vgg: 0.3530, mask: 0.3533\n",
      "step:   154440, time: 0.764, loss: 1.0883, l1: 0.2153, vgg: 0.4921, mask: 0.3809\n",
      "step:   154460, time: 0.746, loss: 0.9311, l1: 0.1894, vgg: 0.3696, mask: 0.3722\n",
      "step:   154480, time: 0.785, loss: 0.9337, l1: 0.1887, vgg: 0.3976, mask: 0.3474\n",
      "step:   154500, time: 0.713, loss: 0.9115, l1: 0.1868, vgg: 0.4010, mask: 0.3237\n",
      "step:   154520, time: 0.775, loss: 1.0081, l1: 0.2354, vgg: 0.3855, mask: 0.3872\n",
      "step:   154540, time: 0.733, loss: 0.9546, l1: 0.1942, vgg: 0.4218, mask: 0.3387\n",
      "step:   154560, time: 0.764, loss: 1.1074, l1: 0.2509, vgg: 0.4705, mask: 0.3860\n",
      "step:   154580, time: 0.742, loss: 1.0221, l1: 0.2211, vgg: 0.4288, mask: 0.3722\n",
      "step:   154600, time: 0.753, loss: 1.0071, l1: 0.1903, vgg: 0.4303, mask: 0.3866\n",
      "step:   154620, time: 0.738, loss: 0.9630, l1: 0.1773, vgg: 0.4454, mask: 0.3403\n",
      "step:   154640, time: 0.775, loss: 0.9618, l1: 0.2088, vgg: 0.4008, mask: 0.3521\n",
      "step:   154660, time: 0.792, loss: 0.8735, l1: 0.1389, vgg: 0.4131, mask: 0.3215\n",
      "step:   154680, time: 0.788, loss: 1.0937, l1: 0.2397, vgg: 0.4728, mask: 0.3812\n",
      "step:   154700, time: 0.746, loss: 1.0041, l1: 0.2194, vgg: 0.4230, mask: 0.3618\n",
      "step:   154720, time: 0.746, loss: 0.9432, l1: 0.1702, vgg: 0.4102, mask: 0.3628\n",
      "step:   154740, time: 0.783, loss: 1.1431, l1: 0.2296, vgg: 0.5501, mask: 0.3634\n",
      "step:   154760, time: 0.741, loss: 1.0159, l1: 0.2713, vgg: 0.3557, mask: 0.3889\n",
      "step:   154780, time: 0.752, loss: 1.0111, l1: 0.2127, vgg: 0.4046, mask: 0.3939\n",
      "step:   154800, time: 0.753, loss: 0.9801, l1: 0.1825, vgg: 0.4271, mask: 0.3705\n",
      "step:   154820, time: 0.769, loss: 1.1238, l1: 0.2141, vgg: 0.5259, mask: 0.3838\n",
      "step:   154840, time: 0.767, loss: 1.0636, l1: 0.2058, vgg: 0.4891, mask: 0.3687\n",
      "step:   154860, time: 0.761, loss: 1.1244, l1: 0.2214, vgg: 0.5048, mask: 0.3982\n",
      "step:   154880, time: 0.784, loss: 1.0801, l1: 0.2174, vgg: 0.4253, mask: 0.4374\n",
      "step:   154900, time: 0.728, loss: 0.9078, l1: 0.1655, vgg: 0.3681, mask: 0.3742\n",
      "step:   154920, time: 0.719, loss: 0.9922, l1: 0.1844, vgg: 0.4128, mask: 0.3950\n",
      "step:   154940, time: 0.743, loss: 1.0894, l1: 0.2674, vgg: 0.4170, mask: 0.4050\n",
      "step:   154960, time: 0.764, loss: 1.0959, l1: 0.2416, vgg: 0.4645, mask: 0.3898\n",
      "step:   154980, time: 0.750, loss: 1.0790, l1: 0.2373, vgg: 0.4377, mask: 0.4041\n",
      "step:   155000, time: 0.773, loss: 0.9327, l1: 0.1963, vgg: 0.3803, mask: 0.3561\n",
      "step:   155020, time: 0.730, loss: 0.9743, l1: 0.2149, vgg: 0.3909, mask: 0.3685\n",
      "step:   155040, time: 0.724, loss: 0.9401, l1: 0.2096, vgg: 0.3440, mask: 0.3865\n",
      "step:   155060, time: 0.763, loss: 1.0652, l1: 0.2070, vgg: 0.4710, mask: 0.3871\n",
      "step:   155080, time: 0.765, loss: 0.9996, l1: 0.1984, vgg: 0.4506, mask: 0.3506\n",
      "step:   155100, time: 0.721, loss: 1.0404, l1: 0.2368, vgg: 0.4272, mask: 0.3763\n",
      "step:   155120, time: 0.737, loss: 1.0821, l1: 0.2595, vgg: 0.4315, mask: 0.3911\n",
      "step:   155140, time: 0.752, loss: 0.9416, l1: 0.1818, vgg: 0.3958, mask: 0.3639\n",
      "step:   155160, time: 0.767, loss: 1.0544, l1: 0.2175, vgg: 0.4245, mask: 0.4123\n",
      "step:   155180, time: 0.754, loss: 0.9114, l1: 0.1351, vgg: 0.4091, mask: 0.3672\n",
      "step:   155200, time: 0.730, loss: 1.0612, l1: 0.2375, vgg: 0.4531, mask: 0.3706\n",
      "step:   155220, time: 0.767, loss: 1.0873, l1: 0.2477, vgg: 0.4645, mask: 0.3751\n",
      "step:   155240, time: 0.764, loss: 1.1572, l1: 0.2643, vgg: 0.4897, mask: 0.4033\n",
      "step:   155260, time: 0.764, loss: 1.1178, l1: 0.2408, vgg: 0.5091, mask: 0.3679\n",
      "step:   155280, time: 0.781, loss: 1.0116, l1: 0.2365, vgg: 0.3977, mask: 0.3774\n",
      "step:   155300, time: 0.772, loss: 1.1561, l1: 0.2475, vgg: 0.4754, mask: 0.4332\n",
      "step:   155320, time: 0.759, loss: 1.0063, l1: 0.1984, vgg: 0.4186, mask: 0.3893\n",
      "step:   155340, time: 0.762, loss: 1.0139, l1: 0.1910, vgg: 0.4600, mask: 0.3629\n",
      "step:   155360, time: 0.734, loss: 1.0401, l1: 0.2238, vgg: 0.4231, mask: 0.3933\n",
      "step:   155380, time: 0.757, loss: 0.9904, l1: 0.2017, vgg: 0.4322, mask: 0.3565\n",
      "step:   155400, time: 0.730, loss: 0.9644, l1: 0.1822, vgg: 0.4202, mask: 0.3620\n",
      "step:   155420, time: 0.726, loss: 1.0039, l1: 0.2191, vgg: 0.4202, mask: 0.3646\n",
      "step:   155440, time: 0.720, loss: 0.9141, l1: 0.1459, vgg: 0.4059, mask: 0.3623\n",
      "step:   155460, time: 0.724, loss: 1.0811, l1: 0.2176, vgg: 0.4795, mask: 0.3841\n",
      "step:   155480, time: 0.765, loss: 1.0383, l1: 0.2482, vgg: 0.3926, mask: 0.3975\n",
      "step:   155500, time: 0.734, loss: 0.9885, l1: 0.2354, vgg: 0.3684, mask: 0.3846\n",
      "step:   155520, time: 0.735, loss: 1.0719, l1: 0.2217, vgg: 0.4347, mask: 0.4156\n",
      "step:   155540, time: 0.790, loss: 1.0181, l1: 0.2148, vgg: 0.4374, mask: 0.3659\n",
      "step:   155560, time: 0.770, loss: 1.0525, l1: 0.2377, vgg: 0.4083, mask: 0.4065\n",
      "step:   155580, time: 0.777, loss: 0.9530, l1: 0.2231, vgg: 0.3917, mask: 0.3381\n",
      "step:   155600, time: 0.732, loss: 0.9254, l1: 0.1560, vgg: 0.4027, mask: 0.3667\n",
      "step:   155620, time: 0.766, loss: 0.9788, l1: 0.1744, vgg: 0.4155, mask: 0.3888\n",
      "step:   155640, time: 0.772, loss: 1.0634, l1: 0.1917, vgg: 0.4839, mask: 0.3879\n",
      "step:   155660, time: 0.812, loss: 1.0695, l1: 0.2273, vgg: 0.4236, mask: 0.4185\n",
      "step:   155680, time: 0.772, loss: 0.9796, l1: 0.2106, vgg: 0.3937, mask: 0.3754\n",
      "step:   155700, time: 0.751, loss: 0.9866, l1: 0.1996, vgg: 0.4053, mask: 0.3816\n",
      "step:   155720, time: 0.728, loss: 0.9688, l1: 0.2039, vgg: 0.3849, mask: 0.3800\n",
      "step:   155740, time: 0.774, loss: 1.1879, l1: 0.2813, vgg: 0.4660, mask: 0.4405\n",
      "step:   155760, time: 0.748, loss: 1.0344, l1: 0.2392, vgg: 0.3935, mask: 0.4018\n",
      "step:   155780, time: 0.733, loss: 1.0618, l1: 0.2154, vgg: 0.4516, mask: 0.3949\n",
      "step:   155800, time: 0.734, loss: 0.9056, l1: 0.1847, vgg: 0.3670, mask: 0.3539\n",
      "step:   155820, time: 0.717, loss: 1.1441, l1: 0.2512, vgg: 0.4790, mask: 0.4138\n",
      "step:   155840, time: 0.729, loss: 1.0136, l1: 0.2034, vgg: 0.4180, mask: 0.3922\n",
      "step:   155860, time: 0.759, loss: 1.0269, l1: 0.2055, vgg: 0.4739, mask: 0.3475\n",
      "step:   155880, time: 0.740, loss: 1.0348, l1: 0.1969, vgg: 0.4078, mask: 0.4301\n",
      "step:   155900, time: 0.736, loss: 0.9602, l1: 0.1880, vgg: 0.4014, mask: 0.3708\n",
      "step:   155920, time: 0.732, loss: 1.1545, l1: 0.2865, vgg: 0.4141, mask: 0.4539\n",
      "step:   155940, time: 0.755, loss: 1.1122, l1: 0.2614, vgg: 0.4391, mask: 0.4117\n",
      "step:   155960, time: 0.764, loss: 1.0883, l1: 0.2382, vgg: 0.4916, mask: 0.3586\n",
      "step:   155980, time: 0.735, loss: 0.9574, l1: 0.1799, vgg: 0.4022, mask: 0.3753\n",
      "step:   156000, time: 0.771, loss: 1.0595, l1: 0.2163, vgg: 0.4480, mask: 0.3951\n",
      "step:   156020, time: 0.753, loss: 0.9468, l1: 0.1603, vgg: 0.4411, mask: 0.3454\n",
      "step:   156040, time: 0.776, loss: 1.1186, l1: 0.2707, vgg: 0.4286, mask: 0.4193\n",
      "step:   156060, time: 0.735, loss: 0.9658, l1: 0.1924, vgg: 0.4246, mask: 0.3488\n",
      "step:   156080, time: 0.756, loss: 1.0444, l1: 0.1856, vgg: 0.4680, mask: 0.3908\n",
      "step:   156100, time: 0.787, loss: 1.0174, l1: 0.1974, vgg: 0.4342, mask: 0.3858\n",
      "step:   156120, time: 0.816, loss: 1.1912, l1: 0.2729, vgg: 0.4978, mask: 0.4204\n",
      "step:   156140, time: 0.740, loss: 1.0617, l1: 0.2311, vgg: 0.4351, mask: 0.3954\n",
      "step:   156160, time: 0.749, loss: 0.9603, l1: 0.1815, vgg: 0.3663, mask: 0.4125\n",
      "step:   156180, time: 0.773, loss: 0.9871, l1: 0.1704, vgg: 0.4545, mask: 0.3622\n",
      "step:   156200, time: 0.726, loss: 0.8935, l1: 0.1336, vgg: 0.3803, mask: 0.3795\n",
      "step:   156220, time: 0.741, loss: 0.9514, l1: 0.1798, vgg: 0.4012, mask: 0.3704\n",
      "step:   156240, time: 0.761, loss: 1.0374, l1: 0.2224, vgg: 0.4249, mask: 0.3901\n",
      "step:   156260, time: 0.770, loss: 1.0347, l1: 0.1995, vgg: 0.4431, mask: 0.3921\n",
      "step:   156280, time: 0.731, loss: 1.0072, l1: 0.2205, vgg: 0.4079, mask: 0.3788\n",
      "step:   156300, time: 0.766, loss: 1.1004, l1: 0.2227, vgg: 0.4958, mask: 0.3818\n",
      "step:   156320, time: 0.723, loss: 1.0432, l1: 0.2419, vgg: 0.4101, mask: 0.3912\n",
      "step:   156340, time: 0.743, loss: 1.0092, l1: 0.1790, vgg: 0.4544, mask: 0.3758\n",
      "step:   156360, time: 0.750, loss: 1.0842, l1: 0.2100, vgg: 0.4908, mask: 0.3833\n",
      "step:   156380, time: 0.736, loss: 1.0193, l1: 0.2206, vgg: 0.4168, mask: 0.3819\n",
      "step:   156400, time: 0.759, loss: 1.0430, l1: 0.2142, vgg: 0.4648, mask: 0.3640\n",
      "step:   156420, time: 0.739, loss: 0.9887, l1: 0.1795, vgg: 0.4184, mask: 0.3908\n",
      "step:   156440, time: 0.734, loss: 0.9585, l1: 0.1667, vgg: 0.4014, mask: 0.3903\n",
      "step:   156460, time: 0.750, loss: 1.0733, l1: 0.2054, vgg: 0.4648, mask: 0.4032\n",
      "step:   156480, time: 0.799, loss: 1.1021, l1: 0.2043, vgg: 0.5375, mask: 0.3603\n",
      "step:   156500, time: 0.716, loss: 0.8744, l1: 0.1633, vgg: 0.3717, mask: 0.3393\n",
      "step:   156520, time: 0.761, loss: 1.0506, l1: 0.2405, vgg: 0.4223, mask: 0.3879\n",
      "step:   156540, time: 0.725, loss: 0.8963, l1: 0.1476, vgg: 0.3683, mask: 0.3804\n",
      "step:   156560, time: 0.762, loss: 1.0200, l1: 0.2105, vgg: 0.4231, mask: 0.3864\n",
      "step:   156580, time: 0.749, loss: 1.1014, l1: 0.2314, vgg: 0.4726, mask: 0.3973\n",
      "step:   156600, time: 0.780, loss: 0.9795, l1: 0.1762, vgg: 0.4308, mask: 0.3725\n",
      "step:   156620, time: 0.737, loss: 1.0610, l1: 0.2659, vgg: 0.3901, mask: 0.4050\n",
      "step:   156640, time: 0.775, loss: 1.0773, l1: 0.2410, vgg: 0.4577, mask: 0.3786\n",
      "step:   156660, time: 0.750, loss: 0.9945, l1: 0.2000, vgg: 0.4117, mask: 0.3829\n",
      "step:   156680, time: 0.743, loss: 0.9705, l1: 0.2106, vgg: 0.3798, mask: 0.3802\n",
      "step:   156700, time: 0.728, loss: 1.0456, l1: 0.2482, vgg: 0.4079, mask: 0.3894\n",
      "step:   156720, time: 0.786, loss: 1.0522, l1: 0.2665, vgg: 0.4121, mask: 0.3736\n",
      "step:   156740, time: 0.733, loss: 0.9599, l1: 0.2028, vgg: 0.3939, mask: 0.3632\n",
      "step:   156760, time: 0.765, loss: 1.0781, l1: 0.2031, vgg: 0.4876, mask: 0.3874\n",
      "step:   156780, time: 0.776, loss: 1.0945, l1: 0.2198, vgg: 0.4741, mask: 0.4005\n",
      "step:   156800, time: 0.763, loss: 1.0793, l1: 0.2252, vgg: 0.4344, mask: 0.4198\n",
      "step:   156820, time: 0.768, loss: 1.1010, l1: 0.2264, vgg: 0.4792, mask: 0.3954\n",
      "step:   156840, time: 0.766, loss: 0.9449, l1: 0.2178, vgg: 0.3805, mask: 0.3466\n",
      "step:   156860, time: 0.735, loss: 1.0275, l1: 0.1715, vgg: 0.4749, mask: 0.3811\n",
      "step:   156880, time: 0.746, loss: 0.9522, l1: 0.1935, vgg: 0.3806, mask: 0.3781\n",
      "step:   156900, time: 0.742, loss: 0.9574, l1: 0.1558, vgg: 0.4521, mask: 0.3495\n",
      "step:   156920, time: 0.781, loss: 0.9273, l1: 0.1606, vgg: 0.4302, mask: 0.3365\n",
      "step:   156940, time: 0.781, loss: 1.0245, l1: 0.2279, vgg: 0.4153, mask: 0.3813\n",
      "step:   156960, time: 0.751, loss: 1.0313, l1: 0.2162, vgg: 0.4585, mask: 0.3566\n",
      "step:   156980, time: 0.761, loss: 1.0642, l1: 0.2215, vgg: 0.4585, mask: 0.3841\n",
      "step:   157000, time: 0.736, loss: 1.0482, l1: 0.2398, vgg: 0.3980, mask: 0.4104\n",
      "step:   157020, time: 0.757, loss: 1.0152, l1: 0.2021, vgg: 0.4466, mask: 0.3665\n",
      "step:   157040, time: 0.743, loss: 1.0301, l1: 0.2311, vgg: 0.4535, mask: 0.3455\n",
      "step:   157060, time: 0.746, loss: 0.9361, l1: 0.1742, vgg: 0.4058, mask: 0.3561\n",
      "step:   157080, time: 0.761, loss: 0.9260, l1: 0.1564, vgg: 0.4049, mask: 0.3647\n",
      "step:   157100, time: 0.786, loss: 1.0455, l1: 0.2089, vgg: 0.4072, mask: 0.4294\n",
      "step:   157120, time: 0.737, loss: 0.9825, l1: 0.2004, vgg: 0.4177, mask: 0.3644\n",
      "step:   157140, time: 0.770, loss: 1.0870, l1: 0.2185, vgg: 0.5081, mask: 0.3604\n",
      "step:   157160, time: 0.733, loss: 1.0571, l1: 0.2212, vgg: 0.4549, mask: 0.3810\n",
      "step:   157180, time: 0.732, loss: 0.9546, l1: 0.1788, vgg: 0.3935, mask: 0.3823\n",
      "step:   157200, time: 0.765, loss: 1.0529, l1: 0.2420, vgg: 0.4481, mask: 0.3627\n",
      "step:   157220, time: 0.746, loss: 1.0235, l1: 0.2175, vgg: 0.4196, mask: 0.3863\n",
      "step:   157240, time: 0.749, loss: 0.8905, l1: 0.1651, vgg: 0.3764, mask: 0.3490\n",
      "step:   157260, time: 0.783, loss: 1.1877, l1: 0.2763, vgg: 0.5124, mask: 0.3990\n",
      "step:   157280, time: 0.795, loss: 1.2043, l1: 0.3129, vgg: 0.4636, mask: 0.4278\n",
      "step:   157300, time: 0.718, loss: 0.8678, l1: 0.1617, vgg: 0.3459, mask: 0.3602\n",
      "step:   157320, time: 0.759, loss: 1.0859, l1: 0.2745, vgg: 0.3927, mask: 0.4187\n",
      "step:   157340, time: 0.744, loss: 0.8740, l1: 0.1634, vgg: 0.3529, mask: 0.3577\n",
      "step:   157360, time: 0.751, loss: 1.0139, l1: 0.2032, vgg: 0.4185, mask: 0.3922\n",
      "step:   157380, time: 0.760, loss: 1.0349, l1: 0.2175, vgg: 0.4374, mask: 0.3800\n",
      "step:   157400, time: 0.801, loss: 1.0231, l1: 0.2254, vgg: 0.4291, mask: 0.3686\n",
      "step:   157420, time: 0.780, loss: 1.0822, l1: 0.2633, vgg: 0.4167, mask: 0.4022\n",
      "step:   157440, time: 0.745, loss: 0.9609, l1: 0.2254, vgg: 0.3297, mask: 0.4058\n",
      "step:   157460, time: 0.745, loss: 1.0042, l1: 0.1722, vgg: 0.4541, mask: 0.3778\n",
      "step:   157480, time: 0.743, loss: 1.0108, l1: 0.1918, vgg: 0.4539, mask: 0.3650\n",
      "step:   157500, time: 0.752, loss: 1.0042, l1: 0.1843, vgg: 0.4110, mask: 0.4088\n",
      "step:   157520, time: 0.760, loss: 1.0463, l1: 0.2131, vgg: 0.4502, mask: 0.3829\n",
      "step:   157540, time: 0.750, loss: 0.9900, l1: 0.1927, vgg: 0.4160, mask: 0.3813\n",
      "step:   157560, time: 0.753, loss: 1.0365, l1: 0.2411, vgg: 0.4034, mask: 0.3920\n",
      "step:   157580, time: 0.753, loss: 0.9977, l1: 0.2097, vgg: 0.3996, mask: 0.3884\n",
      "step:   157600, time: 0.731, loss: 1.0100, l1: 0.2206, vgg: 0.3933, mask: 0.3961\n",
      "step:   157620, time: 0.748, loss: 0.9779, l1: 0.1595, vgg: 0.4434, mask: 0.3750\n",
      "step:   157640, time: 0.736, loss: 0.8576, l1: 0.1561, vgg: 0.3390, mask: 0.3625\n",
      "step:   157660, time: 0.730, loss: 1.0111, l1: 0.1993, vgg: 0.4088, mask: 0.4030\n",
      "step:   157680, time: 0.762, loss: 1.0318, l1: 0.2329, vgg: 0.3947, mask: 0.4043\n",
      "step:   157700, time: 0.770, loss: 1.0590, l1: 0.2110, vgg: 0.4596, mask: 0.3884\n",
      "step:   157720, time: 0.743, loss: 1.0282, l1: 0.2324, vgg: 0.3974, mask: 0.3985\n",
      "step:   157740, time: 0.733, loss: 0.9817, l1: 0.2069, vgg: 0.3885, mask: 0.3862\n",
      "step:   157760, time: 0.770, loss: 0.9781, l1: 0.1829, vgg: 0.4157, mask: 0.3794\n",
      "step:   157780, time: 0.754, loss: 1.0039, l1: 0.1478, vgg: 0.4691, mask: 0.3870\n",
      "step:   157800, time: 0.753, loss: 0.9524, l1: 0.1745, vgg: 0.4426, mask: 0.3353\n",
      "step:   157820, time: 0.750, loss: 1.0387, l1: 0.1912, vgg: 0.4440, mask: 0.4034\n",
      "step:   157840, time: 0.766, loss: 0.9578, l1: 0.1711, vgg: 0.4026, mask: 0.3842\n",
      "step:   157860, time: 0.783, loss: 0.9236, l1: 0.1510, vgg: 0.4089, mask: 0.3637\n",
      "step:   157880, time: 0.720, loss: 1.1463, l1: 0.2630, vgg: 0.4773, mask: 0.4060\n",
      "step:   157900, time: 0.757, loss: 0.8778, l1: 0.1383, vgg: 0.3476, mask: 0.3919\n",
      "step:   157920, time: 0.735, loss: 0.9724, l1: 0.2189, vgg: 0.3464, mask: 0.4072\n",
      "step:   157940, time: 0.776, loss: 1.2019, l1: 0.2333, vgg: 0.5515, mask: 0.4171\n",
      "step:   157960, time: 0.747, loss: 0.9914, l1: 0.2091, vgg: 0.4104, mask: 0.3720\n",
      "step:   157980, time: 0.765, loss: 1.0767, l1: 0.2491, vgg: 0.4193, mask: 0.4083\n",
      "step:   158000, time: 0.761, loss: 1.2196, l1: 0.2457, vgg: 0.5627, mask: 0.4112\n",
      "step:   158020, time: 0.818, loss: 1.1008, l1: 0.2171, vgg: 0.4957, mask: 0.3879\n",
      "step:   158040, time: 0.757, loss: 1.0291, l1: 0.1869, vgg: 0.4604, mask: 0.3819\n",
      "step:   158060, time: 0.780, loss: 1.1018, l1: 0.2622, vgg: 0.4443, mask: 0.3953\n",
      "step:   158080, time: 0.760, loss: 0.9623, l1: 0.1565, vgg: 0.4617, mask: 0.3442\n",
      "step:   158100, time: 0.782, loss: 1.1472, l1: 0.2207, vgg: 0.5195, mask: 0.4070\n",
      "step:   158120, time: 0.772, loss: 1.0737, l1: 0.2185, vgg: 0.4860, mask: 0.3692\n",
      "step:   158140, time: 0.757, loss: 1.1004, l1: 0.2600, vgg: 0.4383, mask: 0.4020\n",
      "step:   158160, time: 0.734, loss: 0.9499, l1: 0.1820, vgg: 0.4302, mask: 0.3377\n",
      "step:   158180, time: 0.753, loss: 0.8697, l1: 0.1642, vgg: 0.3783, mask: 0.3272\n",
      "step:   158200, time: 0.778, loss: 1.0571, l1: 0.2044, vgg: 0.4425, mask: 0.4102\n",
      "step:   158220, time: 0.737, loss: 0.8808, l1: 0.1246, vgg: 0.4108, mask: 0.3454\n",
      "step:   158240, time: 0.782, loss: 1.0087, l1: 0.2156, vgg: 0.4228, mask: 0.3703\n",
      "step:   158260, time: 0.808, loss: 0.9956, l1: 0.2095, vgg: 0.4167, mask: 0.3694\n",
      "step:   158280, time: 0.784, loss: 1.1749, l1: 0.3018, vgg: 0.4348, mask: 0.4383\n",
      "step:   158300, time: 0.771, loss: 0.9977, l1: 0.1723, vgg: 0.4563, mask: 0.3691\n",
      "step:   158320, time: 0.772, loss: 1.1697, l1: 0.2697, vgg: 0.4908, mask: 0.4092\n",
      "step:   158340, time: 0.769, loss: 1.0143, l1: 0.2314, vgg: 0.3998, mask: 0.3831\n",
      "step:   158360, time: 0.744, loss: 0.9661, l1: 0.2132, vgg: 0.3764, mask: 0.3764\n",
      "step:   158380, time: 0.730, loss: 1.0192, l1: 0.1952, vgg: 0.4332, mask: 0.3908\n",
      "step:   158400, time: 0.757, loss: 1.0180, l1: 0.1968, vgg: 0.4499, mask: 0.3713\n",
      "step:   158420, time: 0.747, loss: 0.9934, l1: 0.1899, vgg: 0.4250, mask: 0.3784\n",
      "step:   158440, time: 0.760, loss: 1.0302, l1: 0.2328, vgg: 0.4185, mask: 0.3788\n",
      "step:   158460, time: 0.772, loss: 1.0317, l1: 0.1889, vgg: 0.4727, mask: 0.3702\n",
      "step:   158480, time: 0.793, loss: 0.9630, l1: 0.1961, vgg: 0.3937, mask: 0.3732\n",
      "step:   158500, time: 0.747, loss: 1.1966, l1: 0.2729, vgg: 0.4930, mask: 0.4307\n",
      "step:   158520, time: 0.780, loss: 1.1233, l1: 0.2834, vgg: 0.4525, mask: 0.3873\n",
      "step:   158540, time: 0.792, loss: 1.0821, l1: 0.2567, vgg: 0.4350, mask: 0.3905\n",
      "step:   158560, time: 0.748, loss: 0.9867, l1: 0.2120, vgg: 0.4006, mask: 0.3741\n",
      "step:   158580, time: 0.744, loss: 0.9765, l1: 0.1800, vgg: 0.4426, mask: 0.3538\n",
      "step:   158600, time: 0.720, loss: 1.0746, l1: 0.2279, vgg: 0.4544, mask: 0.3922\n",
      "step:   158620, time: 0.797, loss: 1.0393, l1: 0.2529, vgg: 0.4076, mask: 0.3788\n",
      "step:   158640, time: 0.720, loss: 0.9049, l1: 0.1773, vgg: 0.3632, mask: 0.3644\n",
      "step:   158660, time: 0.730, loss: 1.0200, l1: 0.1896, vgg: 0.4544, mask: 0.3760\n",
      "step:   158680, time: 0.783, loss: 1.1370, l1: 0.2562, vgg: 0.4761, mask: 0.4048\n",
      "step:   158700, time: 0.729, loss: 0.9053, l1: 0.1791, vgg: 0.3540, mask: 0.3722\n",
      "step:   158720, time: 0.737, loss: 0.9568, l1: 0.1853, vgg: 0.4019, mask: 0.3696\n",
      "step:   158740, time: 0.767, loss: 1.1209, l1: 0.2891, vgg: 0.4514, mask: 0.3805\n",
      "step:   158760, time: 0.763, loss: 1.0111, l1: 0.2188, vgg: 0.4162, mask: 0.3761\n",
      "step:   158780, time: 0.783, loss: 1.1534, l1: 0.2081, vgg: 0.5807, mask: 0.3646\n",
      "step:   158800, time: 0.765, loss: 0.9471, l1: 0.1670, vgg: 0.3991, mask: 0.3810\n",
      "step:   158820, time: 0.742, loss: 0.9225, l1: 0.1576, vgg: 0.3998, mask: 0.3652\n",
      "step:   158840, time: 0.734, loss: 0.9887, l1: 0.2253, vgg: 0.3718, mask: 0.3916\n",
      "step:   158860, time: 0.742, loss: 1.0242, l1: 0.1809, vgg: 0.4372, mask: 0.4061\n",
      "step:   158880, time: 0.744, loss: 0.9518, l1: 0.1664, vgg: 0.4135, mask: 0.3720\n",
      "step:   158900, time: 0.742, loss: 1.0666, l1: 0.2656, vgg: 0.4075, mask: 0.3935\n",
      "step:   158920, time: 0.762, loss: 0.9793, l1: 0.1563, vgg: 0.4670, mask: 0.3559\n",
      "step:   158940, time: 0.789, loss: 1.1753, l1: 0.2753, vgg: 0.4706, mask: 0.4293\n",
      "step:   158960, time: 0.745, loss: 0.9252, l1: 0.1890, vgg: 0.3685, mask: 0.3677\n",
      "step:   158980, time: 0.742, loss: 1.0289, l1: 0.1908, vgg: 0.4454, mask: 0.3927\n",
      "step:   159000, time: 0.757, loss: 1.0948, l1: 0.2139, vgg: 0.5131, mask: 0.3678\n",
      "step:   159020, time: 0.789, loss: 1.0286, l1: 0.1965, vgg: 0.4259, mask: 0.4062\n",
      "step:   159040, time: 0.772, loss: 0.9753, l1: 0.2315, vgg: 0.3571, mask: 0.3867\n",
      "step:   159060, time: 0.796, loss: 1.0657, l1: 0.2311, vgg: 0.4331, mask: 0.4016\n",
      "step:   159080, time: 0.742, loss: 1.0274, l1: 0.2201, vgg: 0.4079, mask: 0.3993\n",
      "step:   159100, time: 0.737, loss: 0.9757, l1: 0.1969, vgg: 0.4324, mask: 0.3463\n",
      "step:   159120, time: 0.752, loss: 0.9907, l1: 0.2411, vgg: 0.3709, mask: 0.3787\n",
      "step:   159140, time: 0.743, loss: 1.0801, l1: 0.2529, vgg: 0.4191, mask: 0.4081\n",
      "step:   159160, time: 0.761, loss: 0.9465, l1: 0.1911, vgg: 0.3821, mask: 0.3733\n",
      "step:   159180, time: 0.775, loss: 0.9332, l1: 0.1868, vgg: 0.3678, mask: 0.3787\n",
      "step:   159200, time: 0.780, loss: 0.9821, l1: 0.2032, vgg: 0.3922, mask: 0.3866\n",
      "step:   159220, time: 0.759, loss: 0.9338, l1: 0.1575, vgg: 0.4052, mask: 0.3711\n",
      "step:   159240, time: 0.739, loss: 1.0864, l1: 0.2108, vgg: 0.4745, mask: 0.4011\n",
      "step:   159260, time: 0.756, loss: 1.1138, l1: 0.2178, vgg: 0.5240, mask: 0.3720\n",
      "step:   159280, time: 0.776, loss: 1.0830, l1: 0.2358, vgg: 0.4144, mask: 0.4328\n",
      "step:   159300, time: 0.735, loss: 1.1539, l1: 0.2731, vgg: 0.4930, mask: 0.3878\n",
      "step:   159320, time: 0.777, loss: 1.0228, l1: 0.2090, vgg: 0.4343, mask: 0.3795\n",
      "step:   159340, time: 0.730, loss: 0.9814, l1: 0.2126, vgg: 0.3780, mask: 0.3908\n",
      "step:   159360, time: 0.748, loss: 1.0720, l1: 0.2604, vgg: 0.4245, mask: 0.3871\n",
      "step:   159380, time: 0.742, loss: 0.9250, l1: 0.1967, vgg: 0.3552, mask: 0.3730\n",
      "step:   159400, time: 0.714, loss: 1.0933, l1: 0.2950, vgg: 0.3838, mask: 0.4145\n",
      "step:   159420, time: 0.759, loss: 0.9461, l1: 0.1702, vgg: 0.4214, mask: 0.3545\n",
      "step:   159440, time: 0.741, loss: 1.0082, l1: 0.2196, vgg: 0.4136, mask: 0.3750\n",
      "step:   159460, time: 0.762, loss: 1.0275, l1: 0.2107, vgg: 0.4496, mask: 0.3672\n",
      "step:   159480, time: 0.702, loss: 0.9355, l1: 0.1819, vgg: 0.3856, mask: 0.3680\n",
      "step:   159500, time: 0.744, loss: 1.0740, l1: 0.2191, vgg: 0.4233, mask: 0.4316\n",
      "step:   159520, time: 0.752, loss: 0.9470, l1: 0.1622, vgg: 0.4221, mask: 0.3627\n",
      "step:   159540, time: 0.810, loss: 1.0990, l1: 0.2414, vgg: 0.4573, mask: 0.4003\n",
      "step:   159560, time: 0.757, loss: 1.0024, l1: 0.1547, vgg: 0.4541, mask: 0.3936\n",
      "step:   159580, time: 0.748, loss: 1.0464, l1: 0.2045, vgg: 0.4796, mask: 0.3622\n",
      "step:   159600, time: 0.753, loss: 0.9695, l1: 0.2159, vgg: 0.4011, mask: 0.3525\n",
      "step:   159620, time: 0.809, loss: 1.1102, l1: 0.2548, vgg: 0.4780, mask: 0.3773\n",
      "step:   159640, time: 0.732, loss: 1.0302, l1: 0.1966, vgg: 0.4673, mask: 0.3663\n",
      "step:   159660, time: 0.739, loss: 1.0902, l1: 0.2645, vgg: 0.4615, mask: 0.3642\n",
      "step:   159680, time: 0.757, loss: 1.0997, l1: 0.2381, vgg: 0.4154, mask: 0.4462\n",
      "step:   159700, time: 0.765, loss: 1.1067, l1: 0.1948, vgg: 0.5140, mask: 0.3979\n",
      "step:   159720, time: 0.732, loss: 0.9369, l1: 0.1519, vgg: 0.4554, mask: 0.3296\n",
      "step:   159740, time: 0.799, loss: 1.0396, l1: 0.2193, vgg: 0.4519, mask: 0.3683\n",
      "step:   159760, time: 0.780, loss: 1.0550, l1: 0.2032, vgg: 0.4580, mask: 0.3938\n",
      "step:   159780, time: 0.785, loss: 1.1270, l1: 0.2405, vgg: 0.4793, mask: 0.4072\n",
      "step:   159800, time: 0.817, loss: 1.0761, l1: 0.2346, vgg: 0.4505, mask: 0.3911\n",
      "step:   159820, time: 0.745, loss: 0.8645, l1: 0.1378, vgg: 0.3730, mask: 0.3537\n",
      "step:   159840, time: 0.748, loss: 0.9379, l1: 0.1795, vgg: 0.3956, mask: 0.3629\n",
      "step:   159860, time: 0.771, loss: 0.9581, l1: 0.1990, vgg: 0.3980, mask: 0.3611\n",
      "step:   159880, time: 0.712, loss: 0.9433, l1: 0.2099, vgg: 0.3623, mask: 0.3710\n",
      "step:   159900, time: 0.770, loss: 0.9512, l1: 0.2022, vgg: 0.3801, mask: 0.3689\n",
      "step:   159920, time: 0.771, loss: 0.9468, l1: 0.1580, vgg: 0.4186, mask: 0.3702\n",
      "step:   159940, time: 0.745, loss: 1.0918, l1: 0.2149, vgg: 0.5322, mask: 0.3447\n",
      "step:   159960, time: 0.721, loss: 0.9578, l1: 0.1920, vgg: 0.4155, mask: 0.3503\n",
      "step:   159980, time: 0.764, loss: 1.0169, l1: 0.2218, vgg: 0.3870, mask: 0.4080\n",
      "step:   160000, time: 0.775, loss: 1.0387, l1: 0.2338, vgg: 0.3974, mask: 0.4075\n",
      "step:   160020, time: 0.256, loss: 1.1806, l1: 0.2996, vgg: 0.4475, mask: 0.4336\n",
      "step:   160040, time: 0.748, loss: 1.1323, l1: 0.3026, vgg: 0.4426, mask: 0.3871\n",
      "step:   160060, time: 0.809, loss: 1.1267, l1: 0.2442, vgg: 0.4614, mask: 0.4211\n",
      "step:   160080, time: 0.718, loss: 0.8618, l1: 0.1564, vgg: 0.3518, mask: 0.3537\n",
      "step:   160100, time: 0.745, loss: 0.9909, l1: 0.1958, vgg: 0.4265, mask: 0.3687\n",
      "step:   160120, time: 0.785, loss: 1.0929, l1: 0.2455, vgg: 0.4802, mask: 0.3672\n",
      "step:   160140, time: 0.764, loss: 1.0918, l1: 0.2097, vgg: 0.4898, mask: 0.3923\n",
      "step:   160160, time: 0.740, loss: 0.8961, l1: 0.1797, vgg: 0.3736, mask: 0.3427\n",
      "step:   160180, time: 0.727, loss: 1.0748, l1: 0.2517, vgg: 0.4346, mask: 0.3885\n",
      "step:   160200, time: 0.740, loss: 1.0095, l1: 0.2132, vgg: 0.4030, mask: 0.3934\n",
      "step:   160220, time: 0.751, loss: 1.0410, l1: 0.2329, vgg: 0.4149, mask: 0.3933\n",
      "step:   160240, time: 0.716, loss: 0.9106, l1: 0.1657, vgg: 0.3933, mask: 0.3516\n",
      "step:   160260, time: 0.707, loss: 0.9214, l1: 0.1858, vgg: 0.3696, mask: 0.3660\n",
      "step:   160280, time: 0.779, loss: 1.0106, l1: 0.1667, vgg: 0.4240, mask: 0.4199\n",
      "step:   160300, time: 0.744, loss: 0.9960, l1: 0.2127, vgg: 0.4158, mask: 0.3676\n",
      "step:   160320, time: 0.741, loss: 1.0461, l1: 0.2358, vgg: 0.4359, mask: 0.3744\n",
      "step:   160340, time: 0.744, loss: 1.0141, l1: 0.1988, vgg: 0.4357, mask: 0.3796\n",
      "step:   160360, time: 0.751, loss: 1.0665, l1: 0.2293, vgg: 0.4266, mask: 0.4106\n",
      "step:   160380, time: 0.738, loss: 0.9731, l1: 0.1802, vgg: 0.4034, mask: 0.3895\n",
      "step:   160400, time: 0.750, loss: 0.9530, l1: 0.1683, vgg: 0.4361, mask: 0.3486\n",
      "step:   160420, time: 0.748, loss: 0.9166, l1: 0.1773, vgg: 0.3697, mask: 0.3696\n",
      "step:   160440, time: 0.739, loss: 1.0149, l1: 0.2081, vgg: 0.4407, mask: 0.3661\n",
      "step:   160460, time: 0.775, loss: 1.1036, l1: 0.2564, vgg: 0.4402, mask: 0.4069\n",
      "step:   160480, time: 0.767, loss: 1.1143, l1: 0.2755, vgg: 0.4342, mask: 0.4046\n",
      "step:   160500, time: 0.731, loss: 0.8653, l1: 0.1398, vgg: 0.3502, mask: 0.3753\n",
      "step:   160520, time: 0.757, loss: 1.1466, l1: 0.2483, vgg: 0.4788, mask: 0.4196\n",
      "step:   160540, time: 0.778, loss: 1.0278, l1: 0.1895, vgg: 0.4762, mask: 0.3621\n",
      "step:   160560, time: 0.748, loss: 1.0610, l1: 0.2534, vgg: 0.4076, mask: 0.3999\n",
      "step:   160580, time: 0.751, loss: 0.9496, l1: 0.1774, vgg: 0.4133, mask: 0.3590\n",
      "step:   160600, time: 0.771, loss: 0.9910, l1: 0.1944, vgg: 0.4164, mask: 0.3802\n",
      "step:   160620, time: 0.707, loss: 0.8618, l1: 0.1536, vgg: 0.3578, mask: 0.3504\n",
      "step:   160640, time: 0.766, loss: 1.1509, l1: 0.2631, vgg: 0.4659, mask: 0.4220\n",
      "step:   160660, time: 0.745, loss: 1.0687, l1: 0.2658, vgg: 0.4270, mask: 0.3758\n",
      "step:   160680, time: 0.742, loss: 1.0207, l1: 0.2066, vgg: 0.4033, mask: 0.4109\n",
      "step:   160700, time: 0.745, loss: 1.0854, l1: 0.2291, vgg: 0.4591, mask: 0.3972\n",
      "step:   160720, time: 0.779, loss: 1.1108, l1: 0.2247, vgg: 0.4958, mask: 0.3904\n",
      "step:   160740, time: 0.823, loss: 1.1721, l1: 0.2516, vgg: 0.5048, mask: 0.4156\n",
      "step:   160760, time: 0.789, loss: 1.1143, l1: 0.2136, vgg: 0.5125, mask: 0.3883\n",
      "step:   160780, time: 0.745, loss: 0.9749, l1: 0.1787, vgg: 0.4135, mask: 0.3827\n",
      "step:   160800, time: 0.747, loss: 1.0126, l1: 0.2320, vgg: 0.3812, mask: 0.3995\n",
      "step:   160820, time: 0.761, loss: 0.9008, l1: 0.1638, vgg: 0.3805, mask: 0.3565\n",
      "step:   160840, time: 0.741, loss: 1.0952, l1: 0.2226, vgg: 0.4791, mask: 0.3936\n",
      "step:   160860, time: 0.745, loss: 1.0202, l1: 0.2023, vgg: 0.4377, mask: 0.3801\n",
      "step:   160880, time: 0.738, loss: 0.9576, l1: 0.1901, vgg: 0.4088, mask: 0.3587\n",
      "step:   160900, time: 0.780, loss: 1.0561, l1: 0.2054, vgg: 0.4830, mask: 0.3677\n",
      "step:   160920, time: 0.788, loss: 1.0206, l1: 0.2255, vgg: 0.3775, mask: 0.4177\n",
      "step:   160940, time: 0.743, loss: 1.0025, l1: 0.2163, vgg: 0.3967, mask: 0.3894\n",
      "step:   160960, time: 0.746, loss: 1.0675, l1: 0.2443, vgg: 0.4345, mask: 0.3886\n",
      "step:   160980, time: 0.733, loss: 1.0032, l1: 0.2343, vgg: 0.3611, mask: 0.4078\n",
      "step:   161000, time: 0.760, loss: 1.1653, l1: 0.2674, vgg: 0.4975, mask: 0.4005\n",
      "step:   161020, time: 0.740, loss: 1.0637, l1: 0.2000, vgg: 0.4844, mask: 0.3794\n",
      "step:   161040, time: 0.748, loss: 1.0653, l1: 0.2362, vgg: 0.4487, mask: 0.3803\n",
      "step:   161060, time: 0.730, loss: 0.8894, l1: 0.1784, vgg: 0.3707, mask: 0.3404\n",
      "step:   161080, time: 0.748, loss: 0.9571, l1: 0.2297, vgg: 0.3728, mask: 0.3545\n",
      "step:   161100, time: 0.739, loss: 1.0431, l1: 0.2412, vgg: 0.4229, mask: 0.3790\n",
      "step:   161120, time: 0.783, loss: 0.9768, l1: 0.1950, vgg: 0.4015, mask: 0.3803\n",
      "step:   161140, time: 0.737, loss: 1.0129, l1: 0.2302, vgg: 0.3849, mask: 0.3978\n",
      "step:   161160, time: 0.743, loss: 1.0651, l1: 0.2354, vgg: 0.4355, mask: 0.3941\n",
      "step:   161180, time: 0.746, loss: 0.9469, l1: 0.1947, vgg: 0.3876, mask: 0.3646\n",
      "step:   161200, time: 0.752, loss: 1.0027, l1: 0.2234, vgg: 0.3575, mask: 0.4218\n",
      "step:   161220, time: 0.777, loss: 1.1215, l1: 0.2384, vgg: 0.4904, mask: 0.3926\n",
      "step:   161240, time: 0.765, loss: 0.9913, l1: 0.2319, vgg: 0.3907, mask: 0.3688\n",
      "step:   161260, time: 0.762, loss: 1.1009, l1: 0.2478, vgg: 0.4472, mask: 0.4059\n",
      "step:   161280, time: 0.773, loss: 0.9517, l1: 0.1963, vgg: 0.3685, mask: 0.3869\n",
      "step:   161300, time: 0.746, loss: 0.9829, l1: 0.2098, vgg: 0.4210, mask: 0.3521\n",
      "step:   161320, time: 0.779, loss: 1.0869, l1: 0.2318, vgg: 0.4196, mask: 0.4355\n",
      "step:   161340, time: 0.759, loss: 1.0873, l1: 0.2441, vgg: 0.4029, mask: 0.4404\n",
      "step:   161360, time: 0.745, loss: 0.9933, l1: 0.2205, vgg: 0.4048, mask: 0.3681\n",
      "step:   161380, time: 0.793, loss: 1.0253, l1: 0.2094, vgg: 0.4471, mask: 0.3688\n",
      "step:   161400, time: 0.804, loss: 1.0495, l1: 0.2230, vgg: 0.4310, mask: 0.3956\n",
      "step:   161420, time: 0.749, loss: 0.9099, l1: 0.1524, vgg: 0.3875, mask: 0.3700\n",
      "step:   161440, time: 0.731, loss: 1.0968, l1: 0.2744, vgg: 0.4064, mask: 0.4160\n",
      "step:   161460, time: 0.752, loss: 1.0177, l1: 0.1914, vgg: 0.4448, mask: 0.3815\n",
      "step:   161480, time: 0.742, loss: 1.0354, l1: 0.2177, vgg: 0.4055, mask: 0.4121\n",
      "step:   161500, time: 0.777, loss: 1.0610, l1: 0.2144, vgg: 0.4401, mask: 0.4065\n",
      "step:   161520, time: 0.749, loss: 1.0182, l1: 0.2004, vgg: 0.4318, mask: 0.3860\n",
      "step:   161540, time: 0.780, loss: 1.1442, l1: 0.2594, vgg: 0.4777, mask: 0.4071\n",
      "step:   161560, time: 0.724, loss: 0.9899, l1: 0.2024, vgg: 0.3800, mask: 0.4075\n",
      "step:   161580, time: 0.814, loss: 1.0458, l1: 0.2109, vgg: 0.4351, mask: 0.3997\n",
      "step:   161600, time: 0.757, loss: 1.0357, l1: 0.2345, vgg: 0.4267, mask: 0.3745\n",
      "step:   161620, time: 0.743, loss: 1.0109, l1: 0.1982, vgg: 0.4338, mask: 0.3790\n",
      "step:   161640, time: 0.739, loss: 1.0153, l1: 0.1857, vgg: 0.4229, mask: 0.4067\n",
      "step:   161660, time: 0.747, loss: 0.9565, l1: 0.2173, vgg: 0.4047, mask: 0.3345\n",
      "step:   161680, time: 0.755, loss: 1.0079, l1: 0.1570, vgg: 0.4665, mask: 0.3844\n",
      "step:   161700, time: 0.779, loss: 1.1807, l1: 0.2645, vgg: 0.4837, mask: 0.4324\n",
      "step:   161720, time: 0.774, loss: 0.9847, l1: 0.1970, vgg: 0.4431, mask: 0.3445\n",
      "step:   161740, time: 0.753, loss: 1.0752, l1: 0.2134, vgg: 0.4891, mask: 0.3727\n",
      "step:   161760, time: 0.746, loss: 1.0477, l1: 0.1881, vgg: 0.4412, mask: 0.4185\n",
      "step:   161780, time: 0.765, loss: 0.9663, l1: 0.2133, vgg: 0.3621, mask: 0.3909\n",
      "step:   161800, time: 0.763, loss: 0.9712, l1: 0.1903, vgg: 0.3782, mask: 0.4027\n",
      "step:   161820, time: 0.722, loss: 0.9623, l1: 0.1939, vgg: 0.3954, mask: 0.3730\n",
      "step:   161840, time: 0.723, loss: 0.8881, l1: 0.1625, vgg: 0.3736, mask: 0.3521\n",
      "step:   161860, time: 0.736, loss: 0.8514, l1: 0.1242, vgg: 0.3823, mask: 0.3449\n",
      "step:   161880, time: 0.775, loss: 1.0958, l1: 0.2160, vgg: 0.5057, mask: 0.3741\n",
      "step:   161900, time: 0.766, loss: 1.0614, l1: 0.2400, vgg: 0.4456, mask: 0.3758\n",
      "step:   161920, time: 0.765, loss: 1.0166, l1: 0.2388, vgg: 0.3912, mask: 0.3866\n",
      "step:   161940, time: 0.734, loss: 1.0707, l1: 0.2158, vgg: 0.4297, mask: 0.4252\n",
      "step:   161960, time: 0.752, loss: 0.9490, l1: 0.1709, vgg: 0.4251, mask: 0.3530\n",
      "step:   161980, time: 0.748, loss: 0.9640, l1: 0.1994, vgg: 0.3724, mask: 0.3922\n",
      "step:   162000, time: 0.753, loss: 1.0307, l1: 0.1954, vgg: 0.4766, mask: 0.3587\n",
      "step:   162020, time: 0.728, loss: 0.9967, l1: 0.2068, vgg: 0.4248, mask: 0.3651\n",
      "step:   162040, time: 0.747, loss: 1.1190, l1: 0.2156, vgg: 0.4867, mask: 0.4167\n",
      "step:   162060, time: 0.775, loss: 1.0662, l1: 0.2217, vgg: 0.4581, mask: 0.3864\n",
      "step:   162080, time: 0.774, loss: 0.9987, l1: 0.1983, vgg: 0.4087, mask: 0.3918\n",
      "step:   162100, time: 0.754, loss: 1.0664, l1: 0.2052, vgg: 0.4373, mask: 0.4239\n",
      "step:   162120, time: 0.796, loss: 1.2147, l1: 0.2488, vgg: 0.6000, mask: 0.3659\n",
      "step:   162140, time: 0.753, loss: 1.0031, l1: 0.1890, vgg: 0.4202, mask: 0.3940\n",
      "step:   162160, time: 0.768, loss: 0.9417, l1: 0.1575, vgg: 0.3543, mask: 0.4299\n",
      "step:   162180, time: 0.748, loss: 1.0111, l1: 0.2083, vgg: 0.4190, mask: 0.3838\n",
      "step:   162200, time: 0.728, loss: 1.0212, l1: 0.2169, vgg: 0.4092, mask: 0.3951\n",
      "step:   162220, time: 0.788, loss: 1.0579, l1: 0.2064, vgg: 0.4321, mask: 0.4194\n",
      "step:   162240, time: 0.772, loss: 1.0148, l1: 0.2100, vgg: 0.4379, mask: 0.3670\n",
      "step:   162260, time: 0.739, loss: 1.1029, l1: 0.2420, vgg: 0.4858, mask: 0.3751\n",
      "step:   162280, time: 0.750, loss: 1.0649, l1: 0.2325, vgg: 0.4422, mask: 0.3902\n",
      "step:   162300, time: 0.759, loss: 1.0198, l1: 0.2171, vgg: 0.4067, mask: 0.3960\n",
      "step:   162320, time: 0.786, loss: 1.0078, l1: 0.1997, vgg: 0.4224, mask: 0.3857\n",
      "step:   162340, time: 0.734, loss: 1.0165, l1: 0.1663, vgg: 0.4831, mask: 0.3670\n",
      "step:   162360, time: 0.757, loss: 0.9859, l1: 0.2041, vgg: 0.4009, mask: 0.3809\n",
      "step:   162380, time: 0.741, loss: 1.0613, l1: 0.2091, vgg: 0.4492, mask: 0.4029\n",
      "step:   162400, time: 0.772, loss: 1.0112, l1: 0.2229, vgg: 0.4377, mask: 0.3507\n",
      "step:   162420, time: 0.747, loss: 1.0499, l1: 0.2281, vgg: 0.4303, mask: 0.3915\n",
      "step:   162440, time: 0.727, loss: 0.9723, l1: 0.2114, vgg: 0.4111, mask: 0.3498\n",
      "step:   162460, time: 0.760, loss: 1.0009, l1: 0.1977, vgg: 0.4380, mask: 0.3652\n",
      "step:   162480, time: 0.738, loss: 1.0634, l1: 0.2214, vgg: 0.4163, mask: 0.4258\n",
      "step:   162500, time: 0.734, loss: 0.9533, l1: 0.1915, vgg: 0.4166, mask: 0.3451\n",
      "step:   162520, time: 0.725, loss: 0.9200, l1: 0.1833, vgg: 0.3559, mask: 0.3808\n",
      "step:   162540, time: 0.735, loss: 0.9748, l1: 0.1672, vgg: 0.4098, mask: 0.3978\n",
      "step:   162560, time: 0.729, loss: 0.9874, l1: 0.1959, vgg: 0.4043, mask: 0.3872\n",
      "step:   162580, time: 0.748, loss: 1.0881, l1: 0.2185, vgg: 0.4730, mask: 0.3966\n",
      "step:   162600, time: 0.737, loss: 0.9569, l1: 0.1944, vgg: 0.4119, mask: 0.3506\n",
      "step:   162620, time: 0.771, loss: 1.0116, l1: 0.2018, vgg: 0.4205, mask: 0.3892\n",
      "step:   162640, time: 0.751, loss: 0.9959, l1: 0.2041, vgg: 0.3879, mask: 0.4038\n",
      "step:   162660, time: 0.746, loss: 0.9711, l1: 0.1933, vgg: 0.3823, mask: 0.3955\n",
      "step:   162680, time: 0.749, loss: 0.9797, l1: 0.1859, vgg: 0.4234, mask: 0.3705\n",
      "step:   162700, time: 0.740, loss: 0.9777, l1: 0.1537, vgg: 0.4329, mask: 0.3911\n",
      "step:   162720, time: 0.729, loss: 0.9799, l1: 0.1923, vgg: 0.3735, mask: 0.4141\n",
      "step:   162740, time: 0.758, loss: 1.0781, l1: 0.2077, vgg: 0.5131, mask: 0.3573\n",
      "step:   162760, time: 0.803, loss: 1.0473, l1: 0.2402, vgg: 0.4233, mask: 0.3839\n",
      "step:   162780, time: 0.743, loss: 0.9354, l1: 0.1674, vgg: 0.4396, mask: 0.3284\n",
      "step:   162800, time: 0.760, loss: 1.0318, l1: 0.2212, vgg: 0.4016, mask: 0.4090\n",
      "step:   162820, time: 0.762, loss: 1.0067, l1: 0.2209, vgg: 0.3896, mask: 0.3962\n",
      "step:   162840, time: 0.731, loss: 0.9437, l1: 0.1946, vgg: 0.3771, mask: 0.3720\n",
      "step:   162860, time: 0.776, loss: 1.0473, l1: 0.2078, vgg: 0.4401, mask: 0.3994\n",
      "step:   162880, time: 0.721, loss: 0.9550, l1: 0.1978, vgg: 0.3912, mask: 0.3660\n",
      "step:   162900, time: 0.769, loss: 1.0890, l1: 0.2463, vgg: 0.4261, mask: 0.4166\n",
      "step:   162920, time: 0.705, loss: 0.9849, l1: 0.2187, vgg: 0.3614, mask: 0.4049\n",
      "step:   162940, time: 0.763, loss: 1.0297, l1: 0.1626, vgg: 0.4686, mask: 0.3985\n",
      "step:   162960, time: 0.766, loss: 1.0229, l1: 0.1982, vgg: 0.4574, mask: 0.3673\n",
      "step:   162980, time: 0.749, loss: 0.9004, l1: 0.1563, vgg: 0.4060, mask: 0.3381\n",
      "step:   163000, time: 0.775, loss: 1.1405, l1: 0.2297, vgg: 0.5189, mask: 0.3919\n",
      "step:   163020, time: 0.753, loss: 1.1001, l1: 0.2360, vgg: 0.4294, mask: 0.4346\n",
      "step:   163040, time: 0.752, loss: 0.9640, l1: 0.1615, vgg: 0.4230, mask: 0.3794\n",
      "step:   163060, time: 0.748, loss: 0.9807, l1: 0.1975, vgg: 0.3863, mask: 0.3968\n",
      "step:   163080, time: 0.746, loss: 0.9923, l1: 0.2183, vgg: 0.4072, mask: 0.3667\n",
      "step:   163100, time: 0.747, loss: 0.9997, l1: 0.1826, vgg: 0.4644, mask: 0.3527\n",
      "step:   163120, time: 0.781, loss: 1.0472, l1: 0.2535, vgg: 0.4237, mask: 0.3700\n",
      "step:   163140, time: 0.738, loss: 1.0537, l1: 0.2855, vgg: 0.3883, mask: 0.3799\n",
      "step:   163160, time: 0.751, loss: 0.9078, l1: 0.1758, vgg: 0.3760, mask: 0.3559\n",
      "step:   163180, time: 0.757, loss: 1.0988, l1: 0.2892, vgg: 0.3904, mask: 0.4192\n",
      "step:   163200, time: 0.742, loss: 1.0062, l1: 0.1943, vgg: 0.4542, mask: 0.3577\n",
      "step:   163220, time: 0.786, loss: 0.9195, l1: 0.1354, vgg: 0.4650, mask: 0.3191\n",
      "step:   163240, time: 0.714, loss: 0.9297, l1: 0.1620, vgg: 0.3831, mask: 0.3846\n",
      "step:   163260, time: 0.740, loss: 0.8715, l1: 0.1388, vgg: 0.4030, mask: 0.3297\n",
      "step:   163280, time: 0.753, loss: 0.9861, l1: 0.2114, vgg: 0.4252, mask: 0.3494\n",
      "step:   163300, time: 0.795, loss: 1.1113, l1: 0.2550, vgg: 0.4512, mask: 0.4052\n",
      "step:   163320, time: 0.791, loss: 1.1284, l1: 0.2340, vgg: 0.5094, mask: 0.3850\n",
      "step:   163340, time: 0.713, loss: 1.0308, l1: 0.2391, vgg: 0.4034, mask: 0.3884\n",
      "step:   163360, time: 0.754, loss: 1.0030, l1: 0.1903, vgg: 0.4554, mask: 0.3572\n",
      "step:   163380, time: 0.731, loss: 1.0306, l1: 0.2301, vgg: 0.4060, mask: 0.3945\n",
      "step:   163400, time: 0.779, loss: 1.0311, l1: 0.2129, vgg: 0.4478, mask: 0.3704\n",
      "step:   163420, time: 0.756, loss: 1.0469, l1: 0.2313, vgg: 0.4422, mask: 0.3734\n",
      "step:   163440, time: 0.757, loss: 1.0555, l1: 0.2328, vgg: 0.4286, mask: 0.3940\n",
      "step:   163460, time: 0.780, loss: 1.1158, l1: 0.2467, vgg: 0.4426, mask: 0.4264\n",
      "step:   163480, time: 0.736, loss: 1.0495, l1: 0.2120, vgg: 0.4835, mask: 0.3540\n",
      "step:   163500, time: 0.776, loss: 0.9541, l1: 0.1871, vgg: 0.4181, mask: 0.3489\n",
      "step:   163520, time: 0.749, loss: 1.0664, l1: 0.2097, vgg: 0.4851, mask: 0.3716\n",
      "step:   163540, time: 0.755, loss: 0.9909, l1: 0.2228, vgg: 0.4102, mask: 0.3578\n",
      "step:   163560, time: 0.754, loss: 1.1425, l1: 0.2931, vgg: 0.4192, mask: 0.4302\n",
      "step:   163580, time: 0.763, loss: 1.0992, l1: 0.2267, vgg: 0.4904, mask: 0.3821\n",
      "step:   163600, time: 0.715, loss: 0.9479, l1: 0.1551, vgg: 0.4278, mask: 0.3651\n",
      "step:   163620, time: 0.734, loss: 0.9149, l1: 0.1710, vgg: 0.4094, mask: 0.3345\n",
      "step:   163640, time: 0.783, loss: 1.1283, l1: 0.2562, vgg: 0.4738, mask: 0.3983\n",
      "step:   163660, time: 0.724, loss: 1.0950, l1: 0.2600, vgg: 0.4514, mask: 0.3835\n",
      "step:   163680, time: 0.726, loss: 1.0680, l1: 0.2723, vgg: 0.3754, mask: 0.4202\n",
      "step:   163700, time: 0.731, loss: 0.9968, l1: 0.1908, vgg: 0.4236, mask: 0.3824\n",
      "step:   163720, time: 0.769, loss: 1.0211, l1: 0.2196, vgg: 0.4370, mask: 0.3646\n",
      "step:   163740, time: 0.764, loss: 0.9426, l1: 0.1724, vgg: 0.3958, mask: 0.3744\n",
      "step:   163760, time: 0.750, loss: 1.0443, l1: 0.2134, vgg: 0.4446, mask: 0.3864\n",
      "step:   163780, time: 0.725, loss: 0.9699, l1: 0.2072, vgg: 0.3927, mask: 0.3700\n",
      "step:   163800, time: 0.741, loss: 0.9817, l1: 0.2160, vgg: 0.3987, mask: 0.3670\n",
      "step:   163820, time: 0.759, loss: 1.0013, l1: 0.2110, vgg: 0.3971, mask: 0.3932\n",
      "step:   163840, time: 0.774, loss: 1.1288, l1: 0.2235, vgg: 0.4982, mask: 0.4071\n",
      "step:   163860, time: 0.748, loss: 1.0820, l1: 0.2251, vgg: 0.4682, mask: 0.3887\n",
      "step:   163880, time: 0.751, loss: 0.9283, l1: 0.2004, vgg: 0.3667, mask: 0.3612\n",
      "step:   163900, time: 0.758, loss: 0.9981, l1: 0.2149, vgg: 0.3806, mask: 0.4026\n",
      "step:   163920, time: 0.768, loss: 0.9063, l1: 0.1774, vgg: 0.3580, mask: 0.3709\n",
      "step:   163940, time: 0.748, loss: 1.0556, l1: 0.2366, vgg: 0.4227, mask: 0.3963\n",
      "step:   163960, time: 0.727, loss: 1.1430, l1: 0.2467, vgg: 0.4718, mask: 0.4244\n",
      "step:   163980, time: 0.746, loss: 0.9906, l1: 0.1759, vgg: 0.4614, mask: 0.3534\n",
      "step:   164000, time: 0.753, loss: 1.0816, l1: 0.2494, vgg: 0.4184, mask: 0.4138\n",
      "step:   164020, time: 0.765, loss: 1.0554, l1: 0.2087, vgg: 0.4485, mask: 0.3982\n",
      "step:   164040, time: 0.749, loss: 0.9985, l1: 0.1934, vgg: 0.4363, mask: 0.3688\n",
      "step:   164060, time: 0.728, loss: 0.9602, l1: 0.1866, vgg: 0.3616, mask: 0.4120\n",
      "step:   164080, time: 0.776, loss: 1.1273, l1: 0.2197, vgg: 0.5371, mask: 0.3704\n",
      "step:   164100, time: 0.744, loss: 1.0917, l1: 0.2339, vgg: 0.4471, mask: 0.4107\n",
      "step:   164120, time: 0.781, loss: 1.0099, l1: 0.2003, vgg: 0.4277, mask: 0.3819\n",
      "step:   164140, time: 0.761, loss: 0.9511, l1: 0.1835, vgg: 0.3937, mask: 0.3739\n",
      "step:   164160, time: 0.742, loss: 1.1385, l1: 0.2282, vgg: 0.5073, mask: 0.4030\n",
      "step:   164180, time: 0.754, loss: 1.1246, l1: 0.2659, vgg: 0.4161, mask: 0.4426\n",
      "step:   164200, time: 0.723, loss: 0.9111, l1: 0.1677, vgg: 0.4054, mask: 0.3380\n",
      "step:   164220, time: 0.767, loss: 1.1163, l1: 0.2642, vgg: 0.4686, mask: 0.3835\n",
      "step:   164240, time: 0.739, loss: 1.2198, l1: 0.3517, vgg: 0.4309, mask: 0.4372\n",
      "step:   164260, time: 0.771, loss: 0.9591, l1: 0.1804, vgg: 0.4274, mask: 0.3513\n",
      "step:   164280, time: 0.773, loss: 1.0969, l1: 0.2431, vgg: 0.4467, mask: 0.4071\n",
      "step:   164300, time: 0.719, loss: 0.9856, l1: 0.2092, vgg: 0.4129, mask: 0.3634\n",
      "step:   164320, time: 0.721, loss: 1.0861, l1: 0.2112, vgg: 0.5028, mask: 0.3721\n",
      "step:   164340, time: 0.758, loss: 1.0476, l1: 0.2062, vgg: 0.4677, mask: 0.3737\n",
      "step:   164360, time: 0.792, loss: 0.9664, l1: 0.1870, vgg: 0.4360, mask: 0.3434\n",
      "step:   164380, time: 0.772, loss: 1.0306, l1: 0.1955, vgg: 0.4328, mask: 0.4023\n",
      "step:   164400, time: 0.762, loss: 1.0693, l1: 0.2375, vgg: 0.4217, mask: 0.4102\n",
      "step:   164420, time: 0.744, loss: 1.0629, l1: 0.2228, vgg: 0.4406, mask: 0.3995\n",
      "step:   164440, time: 0.750, loss: 1.1371, l1: 0.2640, vgg: 0.4514, mask: 0.4217\n",
      "step:   164460, time: 0.715, loss: 0.9269, l1: 0.2175, vgg: 0.3287, mask: 0.3807\n",
      "step:   164480, time: 0.752, loss: 1.0335, l1: 0.1925, vgg: 0.4663, mask: 0.3748\n",
      "step:   164500, time: 0.760, loss: 1.1007, l1: 0.2544, vgg: 0.4364, mask: 0.4099\n",
      "step:   164520, time: 0.785, loss: 1.0516, l1: 0.2088, vgg: 0.4348, mask: 0.4081\n",
      "step:   164540, time: 0.758, loss: 0.9837, l1: 0.2043, vgg: 0.4138, mask: 0.3657\n",
      "step:   164560, time: 0.754, loss: 0.9664, l1: 0.1762, vgg: 0.4005, mask: 0.3897\n",
      "step:   164580, time: 0.756, loss: 1.1742, l1: 0.2795, vgg: 0.4880, mask: 0.4067\n",
      "step:   164600, time: 0.745, loss: 1.2027, l1: 0.2747, vgg: 0.5053, mask: 0.4228\n",
      "step:   164620, time: 0.795, loss: 1.1061, l1: 0.2581, vgg: 0.4340, mask: 0.4140\n",
      "step:   164640, time: 0.779, loss: 0.9433, l1: 0.2040, vgg: 0.4046, mask: 0.3347\n",
      "step:   164660, time: 0.801, loss: 1.0919, l1: 0.2472, vgg: 0.4627, mask: 0.3820\n",
      "step:   164680, time: 0.776, loss: 1.1389, l1: 0.2721, vgg: 0.4596, mask: 0.4072\n",
      "step:   164700, time: 0.762, loss: 1.1150, l1: 0.2305, vgg: 0.4785, mask: 0.4060\n",
      "step:   164720, time: 0.799, loss: 1.0700, l1: 0.2035, vgg: 0.4936, mask: 0.3730\n",
      "step:   164740, time: 0.752, loss: 0.9839, l1: 0.1937, vgg: 0.4246, mask: 0.3656\n",
      "step:   164760, time: 0.773, loss: 1.0400, l1: 0.1787, vgg: 0.4766, mask: 0.3847\n",
      "step:   164780, time: 0.756, loss: 0.9999, l1: 0.2249, vgg: 0.4013, mask: 0.3737\n",
      "step:   164800, time: 0.749, loss: 0.9703, l1: 0.2247, vgg: 0.3621, mask: 0.3836\n",
      "step:   164820, time: 0.751, loss: 1.0120, l1: 0.2310, vgg: 0.4122, mask: 0.3687\n",
      "step:   164840, time: 0.745, loss: 1.0653, l1: 0.2359, vgg: 0.4396, mask: 0.3897\n",
      "step:   164860, time: 0.796, loss: 0.9227, l1: 0.1700, vgg: 0.4044, mask: 0.3484\n",
      "step:   164880, time: 0.762, loss: 1.0149, l1: 0.1960, vgg: 0.4260, mask: 0.3928\n",
      "step:   164900, time: 0.749, loss: 0.9965, l1: 0.1920, vgg: 0.4400, mask: 0.3645\n",
      "step:   164920, time: 0.785, loss: 1.0051, l1: 0.2224, vgg: 0.4306, mask: 0.3521\n",
      "step:   164940, time: 0.745, loss: 0.9684, l1: 0.2287, vgg: 0.3622, mask: 0.3775\n",
      "step:   164960, time: 0.746, loss: 1.0154, l1: 0.2006, vgg: 0.4292, mask: 0.3855\n",
      "step:   164980, time: 0.760, loss: 1.0829, l1: 0.2609, vgg: 0.4447, mask: 0.3773\n",
      "step:   165000, time: 0.740, loss: 0.9264, l1: 0.2044, vgg: 0.3652, mask: 0.3568\n",
      "step:   165020, time: 0.771, loss: 0.9413, l1: 0.2037, vgg: 0.3426, mask: 0.3950\n",
      "step:   165040, time: 0.735, loss: 0.9414, l1: 0.1674, vgg: 0.4094, mask: 0.3647\n",
      "step:   165060, time: 0.782, loss: 1.1325, l1: 0.2862, vgg: 0.4284, mask: 0.4180\n",
      "step:   165080, time: 0.766, loss: 1.0536, l1: 0.2230, vgg: 0.4490, mask: 0.3816\n",
      "step:   165100, time: 0.755, loss: 0.9567, l1: 0.2010, vgg: 0.3906, mask: 0.3651\n",
      "step:   165120, time: 0.759, loss: 1.1623, l1: 0.3142, vgg: 0.4203, mask: 0.4278\n",
      "step:   165140, time: 0.804, loss: 1.2313, l1: 0.2813, vgg: 0.5331, mask: 0.4169\n",
      "step:   165160, time: 0.746, loss: 1.1356, l1: 0.2642, vgg: 0.4529, mask: 0.4186\n",
      "step:   165180, time: 0.728, loss: 0.9425, l1: 0.1779, vgg: 0.3976, mask: 0.3669\n",
      "step:   165200, time: 0.753, loss: 1.0216, l1: 0.1999, vgg: 0.4265, mask: 0.3951\n",
      "step:   165220, time: 0.721, loss: 1.0361, l1: 0.2414, vgg: 0.3950, mask: 0.3998\n",
      "step:   165240, time: 0.763, loss: 1.1208, l1: 0.2473, vgg: 0.4683, mask: 0.4052\n",
      "step:   165260, time: 0.733, loss: 0.9030, l1: 0.1732, vgg: 0.3667, mask: 0.3632\n",
      "step:   165280, time: 0.745, loss: 1.0831, l1: 0.2289, vgg: 0.4681, mask: 0.3860\n",
      "step:   165300, time: 0.741, loss: 0.8985, l1: 0.1667, vgg: 0.3688, mask: 0.3629\n",
      "step:   165320, time: 0.755, loss: 1.0584, l1: 0.2329, vgg: 0.4279, mask: 0.3976\n",
      "step:   165340, time: 0.755, loss: 1.1153, l1: 0.2505, vgg: 0.4836, mask: 0.3812\n",
      "step:   165360, time: 0.764, loss: 0.9758, l1: 0.1885, vgg: 0.4305, mask: 0.3568\n",
      "step:   165380, time: 0.739, loss: 0.9956, l1: 0.2033, vgg: 0.4194, mask: 0.3729\n",
      "step:   165400, time: 0.739, loss: 1.0446, l1: 0.2164, vgg: 0.4362, mask: 0.3920\n",
      "step:   165420, time: 0.794, loss: 1.1725, l1: 0.2418, vgg: 0.5038, mask: 0.4269\n",
      "step:   165440, time: 0.764, loss: 1.0052, l1: 0.1983, vgg: 0.4353, mask: 0.3716\n",
      "step:   165460, time: 0.741, loss: 0.9269, l1: 0.1801, vgg: 0.3767, mask: 0.3701\n",
      "step:   165480, time: 0.733, loss: 1.0573, l1: 0.2282, vgg: 0.4531, mask: 0.3760\n",
      "step:   165500, time: 0.798, loss: 1.0482, l1: 0.2058, vgg: 0.4121, mask: 0.4304\n",
      "step:   165520, time: 0.729, loss: 0.9887, l1: 0.2072, vgg: 0.4118, mask: 0.3696\n",
      "step:   165540, time: 0.763, loss: 1.0737, l1: 0.2415, vgg: 0.4406, mask: 0.3916\n",
      "step:   165560, time: 0.743, loss: 1.0258, l1: 0.2423, vgg: 0.3907, mask: 0.3928\n",
      "step:   165580, time: 0.752, loss: 0.9834, l1: 0.1834, vgg: 0.4272, mask: 0.3728\n",
      "step:   165600, time: 0.737, loss: 1.0371, l1: 0.2481, vgg: 0.4182, mask: 0.3708\n",
      "step:   165620, time: 0.733, loss: 1.0685, l1: 0.2650, vgg: 0.3998, mask: 0.4037\n",
      "step:   165640, time: 0.756, loss: 0.9524, l1: 0.1829, vgg: 0.4077, mask: 0.3618\n",
      "step:   165660, time: 0.768, loss: 1.0018, l1: 0.2087, vgg: 0.4055, mask: 0.3876\n",
      "step:   165680, time: 0.753, loss: 1.0921, l1: 0.2660, vgg: 0.4291, mask: 0.3970\n",
      "step:   165700, time: 0.744, loss: 1.0625, l1: 0.2067, vgg: 0.4333, mask: 0.4225\n",
      "step:   165720, time: 0.725, loss: 0.9416, l1: 0.1914, vgg: 0.3931, mask: 0.3571\n",
      "step:   165740, time: 0.732, loss: 0.9611, l1: 0.2107, vgg: 0.3836, mask: 0.3668\n",
      "step:   165760, time: 0.732, loss: 0.8540, l1: 0.1567, vgg: 0.3370, mask: 0.3603\n",
      "step:   165780, time: 0.776, loss: 1.1594, l1: 0.2433, vgg: 0.5039, mask: 0.4122\n",
      "step:   165800, time: 0.733, loss: 1.1163, l1: 0.2742, vgg: 0.4317, mask: 0.4104\n",
      "step:   165820, time: 0.734, loss: 0.9180, l1: 0.1975, vgg: 0.3505, mask: 0.3700\n",
      "step:   165840, time: 0.816, loss: 1.1063, l1: 0.2702, vgg: 0.4504, mask: 0.3857\n",
      "step:   165860, time: 0.718, loss: 0.9282, l1: 0.1615, vgg: 0.4053, mask: 0.3614\n",
      "step:   165880, time: 0.745, loss: 1.0665, l1: 0.2159, vgg: 0.4591, mask: 0.3914\n",
      "step:   165900, time: 0.786, loss: 1.0228, l1: 0.2269, vgg: 0.4069, mask: 0.3889\n",
      "step:   165920, time: 0.757, loss: 0.9536, l1: 0.1762, vgg: 0.4021, mask: 0.3753\n",
      "step:   165940, time: 0.761, loss: 0.9464, l1: 0.1833, vgg: 0.4052, mask: 0.3579\n",
      "step:   165960, time: 0.766, loss: 1.0355, l1: 0.2182, vgg: 0.4339, mask: 0.3834\n",
      "step:   165980, time: 0.769, loss: 1.0953, l1: 0.2575, vgg: 0.4253, mask: 0.4124\n",
      "step:   166000, time: 0.770, loss: 1.1772, l1: 0.2218, vgg: 0.5684, mask: 0.3870\n",
      "step:   166020, time: 0.712, loss: 0.9285, l1: 0.1965, vgg: 0.3656, mask: 0.3664\n",
      "step:   166040, time: 0.753, loss: 0.9953, l1: 0.1906, vgg: 0.4389, mask: 0.3658\n",
      "step:   166060, time: 0.725, loss: 1.0477, l1: 0.2299, vgg: 0.4326, mask: 0.3852\n",
      "step:   166080, time: 0.762, loss: 1.0311, l1: 0.1704, vgg: 0.4816, mask: 0.3791\n",
      "step:   166100, time: 0.720, loss: 0.9913, l1: 0.2324, vgg: 0.4016, mask: 0.3573\n",
      "step:   166120, time: 0.743, loss: 1.0814, l1: 0.2882, vgg: 0.4097, mask: 0.3836\n",
      "step:   166140, time: 0.749, loss: 1.1324, l1: 0.2272, vgg: 0.5277, mask: 0.3774\n",
      "step:   166160, time: 0.744, loss: 1.0058, l1: 0.2152, vgg: 0.3906, mask: 0.4000\n",
      "step:   166180, time: 0.756, loss: 0.9548, l1: 0.1867, vgg: 0.3792, mask: 0.3889\n",
      "step:   166200, time: 0.764, loss: 1.1355, l1: 0.2463, vgg: 0.4822, mask: 0.4070\n",
      "step:   166220, time: 0.727, loss: 1.0801, l1: 0.2666, vgg: 0.4124, mask: 0.4011\n",
      "step:   166240, time: 0.734, loss: 1.0207, l1: 0.1878, vgg: 0.4402, mask: 0.3928\n",
      "step:   166260, time: 0.760, loss: 0.9528, l1: 0.1915, vgg: 0.3798, mask: 0.3815\n",
      "step:   166280, time: 0.733, loss: 1.1142, l1: 0.2609, vgg: 0.4271, mask: 0.4262\n",
      "step:   166300, time: 0.750, loss: 1.0732, l1: 0.1995, vgg: 0.4944, mask: 0.3794\n",
      "step:   166320, time: 0.758, loss: 1.1414, l1: 0.2443, vgg: 0.5045, mask: 0.3926\n",
      "step:   166340, time: 0.779, loss: 1.0701, l1: 0.2529, vgg: 0.4194, mask: 0.3977\n",
      "step:   166360, time: 0.773, loss: 1.0585, l1: 0.1882, vgg: 0.4973, mask: 0.3731\n",
      "step:   166380, time: 0.753, loss: 1.1197, l1: 0.2865, vgg: 0.4303, mask: 0.4028\n",
      "step:   166400, time: 0.758, loss: 0.9727, l1: 0.1900, vgg: 0.4055, mask: 0.3771\n",
      "step:   166420, time: 0.749, loss: 1.0491, l1: 0.1954, vgg: 0.4637, mask: 0.3900\n",
      "step:   166440, time: 0.783, loss: 1.0316, l1: 0.2046, vgg: 0.4330, mask: 0.3940\n",
      "step:   166460, time: 0.754, loss: 1.0828, l1: 0.2531, vgg: 0.4427, mask: 0.3871\n",
      "step:   166480, time: 0.730, loss: 0.9699, l1: 0.1969, vgg: 0.4215, mask: 0.3516\n",
      "step:   166500, time: 0.787, loss: 0.9658, l1: 0.1666, vgg: 0.4218, mask: 0.3774\n",
      "step:   166520, time: 0.745, loss: 0.9771, l1: 0.2077, vgg: 0.3537, mask: 0.4157\n",
      "step:   166540, time: 0.757, loss: 0.9903, l1: 0.2286, vgg: 0.3899, mask: 0.3718\n",
      "step:   166560, time: 0.752, loss: 1.0352, l1: 0.1916, vgg: 0.4559, mask: 0.3876\n",
      "step:   166580, time: 0.776, loss: 1.1214, l1: 0.2311, vgg: 0.5070, mask: 0.3832\n",
      "step:   166600, time: 0.752, loss: 0.9809, l1: 0.2127, vgg: 0.4016, mask: 0.3666\n",
      "step:   166620, time: 0.724, loss: 1.0018, l1: 0.1737, vgg: 0.4346, mask: 0.3935\n",
      "step:   166640, time: 0.732, loss: 0.9907, l1: 0.1583, vgg: 0.4704, mask: 0.3620\n",
      "step:   166660, time: 0.717, loss: 1.0423, l1: 0.2166, vgg: 0.4369, mask: 0.3888\n",
      "step:   166680, time: 0.737, loss: 0.9722, l1: 0.1917, vgg: 0.4145, mask: 0.3659\n",
      "step:   166700, time: 0.749, loss: 0.9399, l1: 0.2025, vgg: 0.3787, mask: 0.3587\n",
      "step:   166720, time: 0.720, loss: 1.0856, l1: 0.2493, vgg: 0.4248, mask: 0.4115\n",
      "step:   166740, time: 0.774, loss: 0.9802, l1: 0.1856, vgg: 0.3710, mask: 0.4236\n",
      "step:   166760, time: 0.736, loss: 0.9671, l1: 0.1896, vgg: 0.4489, mask: 0.3286\n",
      "step:   166780, time: 0.735, loss: 0.9521, l1: 0.2094, vgg: 0.3658, mask: 0.3769\n",
      "step:   166800, time: 0.740, loss: 0.9557, l1: 0.2025, vgg: 0.3726, mask: 0.3806\n",
      "step:   166820, time: 0.736, loss: 0.9605, l1: 0.1996, vgg: 0.3541, mask: 0.4069\n",
      "step:   166840, time: 0.731, loss: 1.0304, l1: 0.2286, vgg: 0.3974, mask: 0.4043\n",
      "step:   166860, time: 0.749, loss: 1.1744, l1: 0.2474, vgg: 0.5097, mask: 0.4173\n",
      "step:   166880, time: 0.745, loss: 1.2093, l1: 0.3006, vgg: 0.4896, mask: 0.4190\n",
      "step:   166900, time: 0.739, loss: 0.9414, l1: 0.1758, vgg: 0.4275, mask: 0.3380\n",
      "step:   166920, time: 0.735, loss: 1.1238, l1: 0.2878, vgg: 0.4279, mask: 0.4081\n",
      "step:   166940, time: 0.748, loss: 0.9818, l1: 0.1831, vgg: 0.3935, mask: 0.4052\n",
      "step:   166960, time: 0.788, loss: 0.9543, l1: 0.1811, vgg: 0.4239, mask: 0.3493\n",
      "step:   166980, time: 0.741, loss: 1.0908, l1: 0.2517, vgg: 0.4353, mask: 0.4038\n",
      "step:   167000, time: 0.793, loss: 0.9639, l1: 0.1719, vgg: 0.4358, mask: 0.3563\n",
      "step:   167020, time: 0.753, loss: 1.0832, l1: 0.2595, vgg: 0.4286, mask: 0.3950\n",
      "step:   167040, time: 0.734, loss: 1.0155, l1: 0.2373, vgg: 0.4073, mask: 0.3709\n",
      "step:   167060, time: 0.751, loss: 0.9822, l1: 0.2098, vgg: 0.4049, mask: 0.3675\n",
      "step:   167080, time: 0.732, loss: 0.9330, l1: 0.1974, vgg: 0.3662, mask: 0.3695\n",
      "step:   167100, time: 0.700, loss: 0.8391, l1: 0.1404, vgg: 0.3556, mask: 0.3431\n",
      "step:   167120, time: 0.756, loss: 1.0400, l1: 0.2194, vgg: 0.4219, mask: 0.3987\n",
      "step:   167140, time: 0.767, loss: 0.9653, l1: 0.2120, vgg: 0.4036, mask: 0.3497\n",
      "step:   167160, time: 0.760, loss: 1.0319, l1: 0.2558, vgg: 0.3656, mask: 0.4106\n",
      "step:   167180, time: 0.788, loss: 1.1155, l1: 0.2139, vgg: 0.5175, mask: 0.3842\n",
      "step:   167200, time: 0.777, loss: 1.0252, l1: 0.1910, vgg: 0.4716, mask: 0.3627\n",
      "step:   167220, time: 0.762, loss: 0.9949, l1: 0.2194, vgg: 0.3824, mask: 0.3931\n",
      "step:   167240, time: 0.781, loss: 1.1264, l1: 0.2697, vgg: 0.4519, mask: 0.4047\n",
      "step:   167260, time: 0.723, loss: 0.9306, l1: 0.1807, vgg: 0.4040, mask: 0.3459\n",
      "step:   167280, time: 0.736, loss: 0.9660, l1: 0.1952, vgg: 0.3759, mask: 0.3948\n",
      "step:   167300, time: 0.728, loss: 0.9866, l1: 0.1971, vgg: 0.3858, mask: 0.4036\n",
      "step:   167320, time: 0.799, loss: 0.9803, l1: 0.1744, vgg: 0.4292, mask: 0.3766\n",
      "step:   167340, time: 0.728, loss: 0.9256, l1: 0.1634, vgg: 0.3917, mask: 0.3705\n",
      "step:   167360, time: 0.737, loss: 1.0502, l1: 0.2361, vgg: 0.4150, mask: 0.3991\n",
      "step:   167380, time: 0.774, loss: 0.9929, l1: 0.1938, vgg: 0.4277, mask: 0.3714\n",
      "step:   167400, time: 0.763, loss: 0.9964, l1: 0.2154, vgg: 0.3969, mask: 0.3841\n",
      "step:   167420, time: 0.730, loss: 1.0273, l1: 0.2174, vgg: 0.4260, mask: 0.3839\n",
      "step:   167440, time: 0.751, loss: 1.0262, l1: 0.2112, vgg: 0.4131, mask: 0.4018\n",
      "step:   167460, time: 0.716, loss: 0.9737, l1: 0.1723, vgg: 0.4474, mask: 0.3540\n",
      "step:   167480, time: 0.737, loss: 1.0168, l1: 0.1894, vgg: 0.4458, mask: 0.3815\n",
      "step:   167500, time: 0.737, loss: 1.0803, l1: 0.2254, vgg: 0.4978, mask: 0.3571\n",
      "step:   167520, time: 0.772, loss: 1.2293, l1: 0.2496, vgg: 0.5493, mask: 0.4305\n",
      "step:   167540, time: 0.766, loss: 1.1034, l1: 0.2233, vgg: 0.4818, mask: 0.3983\n",
      "step:   167560, time: 0.746, loss: 1.0623, l1: 0.2137, vgg: 0.4208, mask: 0.4278\n",
      "step:   167580, time: 0.749, loss: 0.9567, l1: 0.1742, vgg: 0.4439, mask: 0.3386\n",
      "step:   167600, time: 0.737, loss: 0.9317, l1: 0.2047, vgg: 0.3825, mask: 0.3445\n",
      "step:   167620, time: 0.740, loss: 0.9397, l1: 0.1833, vgg: 0.4130, mask: 0.3433\n",
      "step:   167640, time: 0.779, loss: 1.1702, l1: 0.2484, vgg: 0.5075, mask: 0.4143\n",
      "step:   167660, time: 0.773, loss: 1.1047, l1: 0.2237, vgg: 0.4800, mask: 0.4010\n",
      "step:   167680, time: 0.784, loss: 1.1604, l1: 0.2569, vgg: 0.5025, mask: 0.4010\n",
      "step:   167700, time: 0.781, loss: 0.9706, l1: 0.1586, vgg: 0.4420, mask: 0.3700\n",
      "step:   167720, time: 0.773, loss: 1.0844, l1: 0.2777, vgg: 0.4389, mask: 0.3678\n",
      "step:   167740, time: 0.738, loss: 0.8903, l1: 0.1604, vgg: 0.3830, mask: 0.3469\n",
      "step:   167760, time: 0.738, loss: 1.1352, l1: 0.2274, vgg: 0.4974, mask: 0.4103\n",
      "step:   167780, time: 0.746, loss: 0.9200, l1: 0.1946, vgg: 0.3622, mask: 0.3632\n",
      "step:   167800, time: 0.716, loss: 0.9961, l1: 0.2129, vgg: 0.3989, mask: 0.3842\n",
      "step:   167820, time: 0.802, loss: 1.0327, l1: 0.1942, vgg: 0.4391, mask: 0.3994\n",
      "step:   167840, time: 0.734, loss: 0.9500, l1: 0.1539, vgg: 0.4156, mask: 0.3805\n",
      "step:   167860, time: 0.758, loss: 0.9995, l1: 0.1817, vgg: 0.4463, mask: 0.3715\n",
      "step:   167880, time: 0.753, loss: 1.0487, l1: 0.2411, vgg: 0.4229, mask: 0.3847\n",
      "step:   167900, time: 0.747, loss: 1.1872, l1: 0.2884, vgg: 0.5192, mask: 0.3796\n",
      "step:   167920, time: 0.730, loss: 0.8669, l1: 0.1452, vgg: 0.3772, mask: 0.3445\n",
      "step:   167940, time: 0.722, loss: 0.9106, l1: 0.2020, vgg: 0.3159, mask: 0.3927\n",
      "step:   167960, time: 0.735, loss: 0.8872, l1: 0.1878, vgg: 0.3158, mask: 0.3836\n",
      "step:   167980, time: 0.773, loss: 0.9514, l1: 0.2085, vgg: 0.3777, mask: 0.3653\n",
      "step:   168000, time: 0.712, loss: 0.9678, l1: 0.1856, vgg: 0.3958, mask: 0.3865\n",
      "step:   168020, time: 0.734, loss: 0.9192, l1: 0.2193, vgg: 0.3581, mask: 0.3418\n",
      "step:   168040, time: 0.753, loss: 1.0725, l1: 0.1923, vgg: 0.4867, mask: 0.3936\n",
      "step:   168060, time: 0.751, loss: 1.0471, l1: 0.2019, vgg: 0.4748, mask: 0.3705\n",
      "step:   168080, time: 0.743, loss: 1.0501, l1: 0.1906, vgg: 0.4710, mask: 0.3885\n",
      "step:   168100, time: 0.765, loss: 1.0100, l1: 0.1903, vgg: 0.4327, mask: 0.3870\n",
      "step:   168120, time: 0.780, loss: 1.1003, l1: 0.2486, vgg: 0.4260, mask: 0.4257\n",
      "step:   168140, time: 0.800, loss: 1.1260, l1: 0.2095, vgg: 0.5216, mask: 0.3948\n",
      "step:   168160, time: 0.797, loss: 1.1276, l1: 0.2750, vgg: 0.4533, mask: 0.3993\n",
      "step:   168180, time: 0.735, loss: 0.9990, l1: 0.1884, vgg: 0.4423, mask: 0.3683\n",
      "step:   168200, time: 0.757, loss: 1.1074, l1: 0.2646, vgg: 0.4815, mask: 0.3613\n",
      "step:   168220, time: 0.781, loss: 1.0113, l1: 0.1859, vgg: 0.4494, mask: 0.3760\n",
      "step:   168240, time: 0.747, loss: 0.9873, l1: 0.2062, vgg: 0.4120, mask: 0.3692\n",
      "step:   168260, time: 0.750, loss: 0.9727, l1: 0.1881, vgg: 0.4190, mask: 0.3656\n",
      "step:   168280, time: 0.740, loss: 0.9518, l1: 0.1754, vgg: 0.4037, mask: 0.3728\n",
      "step:   168300, time: 0.771, loss: 1.0296, l1: 0.2234, vgg: 0.4479, mask: 0.3582\n",
      "step:   168320, time: 0.776, loss: 1.1373, l1: 0.2400, vgg: 0.5153, mask: 0.3819\n",
      "step:   168340, time: 0.753, loss: 1.0429, l1: 0.2328, vgg: 0.4217, mask: 0.3884\n",
      "step:   168360, time: 0.760, loss: 0.9895, l1: 0.2045, vgg: 0.4071, mask: 0.3779\n",
      "step:   168380, time: 0.755, loss: 0.9892, l1: 0.2243, vgg: 0.3798, mask: 0.3852\n",
      "step:   168400, time: 0.761, loss: 1.0239, l1: 0.2136, vgg: 0.4410, mask: 0.3693\n",
      "step:   168420, time: 0.791, loss: 0.9528, l1: 0.1953, vgg: 0.4035, mask: 0.3541\n",
      "step:   168440, time: 0.717, loss: 0.9282, l1: 0.1616, vgg: 0.3979, mask: 0.3687\n",
      "step:   168460, time: 0.764, loss: 1.0943, l1: 0.2772, vgg: 0.4074, mask: 0.4098\n",
      "step:   168480, time: 0.762, loss: 0.9728, l1: 0.2280, vgg: 0.3547, mask: 0.3901\n",
      "step:   168500, time: 0.763, loss: 1.0211, l1: 0.1783, vgg: 0.4640, mask: 0.3788\n",
      "step:   168520, time: 0.762, loss: 1.0728, l1: 0.2095, vgg: 0.4685, mask: 0.3947\n",
      "step:   168540, time: 0.736, loss: 0.9905, l1: 0.1879, vgg: 0.4200, mask: 0.3826\n",
      "step:   168560, time: 0.771, loss: 0.9745, l1: 0.2150, vgg: 0.3742, mask: 0.3854\n",
      "step:   168580, time: 0.715, loss: 0.9552, l1: 0.1960, vgg: 0.3998, mask: 0.3594\n",
      "step:   168600, time: 0.745, loss: 0.9297, l1: 0.1996, vgg: 0.3825, mask: 0.3476\n",
      "step:   168620, time: 0.744, loss: 0.9616, l1: 0.1997, vgg: 0.4271, mask: 0.3348\n",
      "step:   168640, time: 0.732, loss: 1.0362, l1: 0.2322, vgg: 0.4023, mask: 0.4017\n",
      "step:   168660, time: 0.754, loss: 0.9925, l1: 0.2565, vgg: 0.3664, mask: 0.3697\n",
      "step:   168680, time: 0.767, loss: 1.0116, l1: 0.2158, vgg: 0.3995, mask: 0.3962\n",
      "step:   168700, time: 0.804, loss: 0.9149, l1: 0.1967, vgg: 0.3547, mask: 0.3635\n",
      "step:   168720, time: 0.753, loss: 1.0724, l1: 0.2007, vgg: 0.4863, mask: 0.3855\n",
      "step:   168740, time: 0.748, loss: 1.0058, l1: 0.1889, vgg: 0.4311, mask: 0.3858\n",
      "step:   168760, time: 0.756, loss: 1.1574, l1: 0.2531, vgg: 0.5010, mask: 0.4033\n",
      "step:   168780, time: 0.706, loss: 0.9125, l1: 0.1927, vgg: 0.3572, mask: 0.3626\n",
      "step:   168800, time: 0.741, loss: 1.0108, l1: 0.1922, vgg: 0.4386, mask: 0.3800\n",
      "step:   168820, time: 0.723, loss: 1.0350, l1: 0.2452, vgg: 0.3950, mask: 0.3948\n",
      "step:   168840, time: 0.727, loss: 1.0259, l1: 0.2019, vgg: 0.4662, mask: 0.3577\n",
      "step:   168860, time: 0.755, loss: 1.1304, l1: 0.2713, vgg: 0.4670, mask: 0.3921\n",
      "step:   168880, time: 0.757, loss: 0.9566, l1: 0.2238, vgg: 0.3724, mask: 0.3604\n",
      "step:   168900, time: 0.765, loss: 0.9717, l1: 0.2114, vgg: 0.3898, mask: 0.3704\n",
      "step:   168920, time: 0.759, loss: 1.1366, l1: 0.2495, vgg: 0.5042, mask: 0.3829\n",
      "step:   168940, time: 0.720, loss: 0.9353, l1: 0.1699, vgg: 0.3712, mask: 0.3941\n",
      "step:   168960, time: 0.767, loss: 0.9970, l1: 0.2092, vgg: 0.4282, mask: 0.3596\n",
      "step:   168980, time: 0.773, loss: 0.9910, l1: 0.1790, vgg: 0.4319, mask: 0.3802\n",
      "step:   169000, time: 0.759, loss: 0.9109, l1: 0.1668, vgg: 0.3885, mask: 0.3555\n",
      "step:   169020, time: 0.768, loss: 1.0884, l1: 0.2427, vgg: 0.4211, mask: 0.4246\n",
      "step:   169040, time: 0.754, loss: 1.0785, l1: 0.2212, vgg: 0.4778, mask: 0.3796\n",
      "step:   169060, time: 0.744, loss: 1.0044, l1: 0.1645, vgg: 0.4961, mask: 0.3438\n",
      "step:   169080, time: 0.737, loss: 0.8512, l1: 0.1738, vgg: 0.3449, mask: 0.3325\n",
      "step:   169100, time: 0.731, loss: 0.9868, l1: 0.2199, vgg: 0.3669, mask: 0.4001\n",
      "step:   169120, time: 0.713, loss: 0.9234, l1: 0.1620, vgg: 0.4141, mask: 0.3472\n",
      "step:   169140, time: 0.750, loss: 1.0010, l1: 0.2518, vgg: 0.3652, mask: 0.3841\n",
      "step:   169160, time: 0.796, loss: 1.1915, l1: 0.2589, vgg: 0.5490, mask: 0.3837\n",
      "step:   169180, time: 0.768, loss: 1.1372, l1: 0.2876, vgg: 0.4490, mask: 0.4007\n",
      "step:   169200, time: 0.738, loss: 0.9216, l1: 0.1529, vgg: 0.3559, mask: 0.4127\n",
      "step:   169220, time: 0.783, loss: 1.1373, l1: 0.2611, vgg: 0.4469, mask: 0.4293\n",
      "step:   169240, time: 0.716, loss: 0.9016, l1: 0.1646, vgg: 0.3547, mask: 0.3823\n",
      "step:   169260, time: 0.802, loss: 0.9872, l1: 0.2282, vgg: 0.3581, mask: 0.4010\n",
      "step:   169280, time: 0.725, loss: 1.0129, l1: 0.2371, vgg: 0.3903, mask: 0.3856\n",
      "step:   169300, time: 0.783, loss: 1.1012, l1: 0.2898, vgg: 0.4037, mask: 0.4076\n",
      "step:   169320, time: 0.781, loss: 1.1480, l1: 0.2379, vgg: 0.4988, mask: 0.4112\n",
      "step:   169340, time: 0.752, loss: 1.0738, l1: 0.2439, vgg: 0.4276, mask: 0.4023\n",
      "step:   169360, time: 0.750, loss: 0.9073, l1: 0.1674, vgg: 0.3646, mask: 0.3752\n",
      "step:   169380, time: 0.743, loss: 0.9935, l1: 0.2169, vgg: 0.3826, mask: 0.3940\n",
      "step:   169400, time: 0.771, loss: 0.9536, l1: 0.1869, vgg: 0.4074, mask: 0.3593\n",
      "step:   169420, time: 0.747, loss: 1.0246, l1: 0.2283, vgg: 0.4087, mask: 0.3877\n",
      "step:   169440, time: 0.787, loss: 0.9967, l1: 0.1887, vgg: 0.4135, mask: 0.3945\n",
      "step:   169460, time: 0.745, loss: 1.0095, l1: 0.2389, vgg: 0.3810, mask: 0.3896\n",
      "step:   169480, time: 0.744, loss: 1.0028, l1: 0.2162, vgg: 0.3995, mask: 0.3870\n",
      "step:   169500, time: 0.762, loss: 0.9405, l1: 0.1801, vgg: 0.3979, mask: 0.3625\n",
      "step:   169520, time: 0.773, loss: 1.0411, l1: 0.1864, vgg: 0.4601, mask: 0.3946\n",
      "step:   169540, time: 0.740, loss: 0.8934, l1: 0.1513, vgg: 0.3797, mask: 0.3623\n",
      "step:   169560, time: 0.734, loss: 1.0039, l1: 0.1934, vgg: 0.4279, mask: 0.3826\n",
      "step:   169580, time: 0.744, loss: 1.1040, l1: 0.2643, vgg: 0.4676, mask: 0.3721\n",
      "step:   169600, time: 0.746, loss: 1.0748, l1: 0.2152, vgg: 0.4753, mask: 0.3843\n",
      "step:   169620, time: 0.721, loss: 0.8882, l1: 0.1674, vgg: 0.3624, mask: 0.3585\n",
      "step:   169640, time: 0.736, loss: 1.0109, l1: 0.2290, vgg: 0.3760, mask: 0.4058\n",
      "step:   169660, time: 0.716, loss: 1.0088, l1: 0.2312, vgg: 0.4201, mask: 0.3575\n",
      "step:   169680, time: 0.742, loss: 0.9250, l1: 0.1466, vgg: 0.4447, mask: 0.3336\n",
      "step:   169700, time: 0.764, loss: 1.1601, l1: 0.3016, vgg: 0.4584, mask: 0.4001\n",
      "step:   169720, time: 0.734, loss: 1.0161, l1: 0.1925, vgg: 0.4244, mask: 0.3992\n",
      "step:   169740, time: 0.752, loss: 0.9472, l1: 0.1735, vgg: 0.3817, mask: 0.3920\n",
      "step:   169760, time: 0.792, loss: 1.1221, l1: 0.2683, vgg: 0.4425, mask: 0.4113\n",
      "step:   169780, time: 0.730, loss: 1.0897, l1: 0.2611, vgg: 0.4194, mask: 0.4092\n",
      "step:   169800, time: 0.735, loss: 0.9418, l1: 0.1854, vgg: 0.4000, mask: 0.3564\n",
      "step:   169820, time: 0.730, loss: 0.9802, l1: 0.2368, vgg: 0.3458, mask: 0.3976\n",
      "step:   169840, time: 0.728, loss: 0.9610, l1: 0.2064, vgg: 0.3876, mask: 0.3669\n",
      "step:   169860, time: 0.721, loss: 0.8742, l1: 0.1645, vgg: 0.3713, mask: 0.3384\n",
      "step:   169880, time: 0.753, loss: 1.0350, l1: 0.2266, vgg: 0.4276, mask: 0.3808\n",
      "step:   169900, time: 0.734, loss: 0.9147, l1: 0.1604, vgg: 0.3978, mask: 0.3565\n",
      "step:   169920, time: 0.723, loss: 0.9148, l1: 0.1712, vgg: 0.3873, mask: 0.3563\n",
      "step:   169940, time: 0.743, loss: 1.0298, l1: 0.2280, vgg: 0.4272, mask: 0.3746\n",
      "step:   169960, time: 0.800, loss: 1.0983, l1: 0.2300, vgg: 0.4650, mask: 0.4032\n",
      "step:   169980, time: 0.753, loss: 0.9751, l1: 0.1662, vgg: 0.4185, mask: 0.3903\n",
      "step:   170000, time: 0.742, loss: 1.0210, l1: 0.2566, vgg: 0.3890, mask: 0.3754\n",
      "step:   170020, time: 0.736, loss: 0.8638, l1: 0.1499, vgg: 0.3569, mask: 0.3570\n",
      "step:   170040, time: 0.732, loss: 0.9314, l1: 0.1912, vgg: 0.4022, mask: 0.3381\n",
      "step:   170060, time: 0.748, loss: 0.8779, l1: 0.1605, vgg: 0.3585, mask: 0.3588\n",
      "step:   170080, time: 0.748, loss: 0.9728, l1: 0.2143, vgg: 0.3879, mask: 0.3706\n",
      "step:   170100, time: 0.747, loss: 0.9569, l1: 0.2015, vgg: 0.4287, mask: 0.3267\n",
      "step:   170120, time: 0.751, loss: 0.9806, l1: 0.1984, vgg: 0.4069, mask: 0.3754\n",
      "step:   170140, time: 0.774, loss: 1.0762, l1: 0.2314, vgg: 0.4315, mask: 0.4134\n",
      "step:   170160, time: 0.765, loss: 1.0964, l1: 0.2564, vgg: 0.4231, mask: 0.4169\n",
      "step:   170180, time: 0.749, loss: 1.0376, l1: 0.2022, vgg: 0.4653, mask: 0.3700\n",
      "step:   170200, time: 0.708, loss: 1.0820, l1: 0.2430, vgg: 0.4355, mask: 0.4036\n",
      "step:   170220, time: 0.764, loss: 1.0540, l1: 0.2464, vgg: 0.4297, mask: 0.3779\n",
      "step:   170240, time: 0.732, loss: 1.0172, l1: 0.2152, vgg: 0.4361, mask: 0.3659\n",
      "step:   170260, time: 0.731, loss: 0.9719, l1: 0.2060, vgg: 0.3976, mask: 0.3683\n",
      "step:   170280, time: 0.746, loss: 0.9758, l1: 0.1980, vgg: 0.4173, mask: 0.3606\n",
      "step:   170300, time: 0.789, loss: 1.1241, l1: 0.2689, vgg: 0.4612, mask: 0.3940\n",
      "step:   170320, time: 0.728, loss: 0.9696, l1: 0.1922, vgg: 0.3807, mask: 0.3967\n",
      "step:   170340, time: 0.736, loss: 1.0086, l1: 0.2456, vgg: 0.3954, mask: 0.3676\n",
      "step:   170360, time: 0.774, loss: 1.0542, l1: 0.2183, vgg: 0.4218, mask: 0.4140\n",
      "step:   170380, time: 0.744, loss: 1.0198, l1: 0.2344, vgg: 0.4013, mask: 0.3841\n",
      "step:   170400, time: 0.736, loss: 1.0082, l1: 0.2343, vgg: 0.3825, mask: 0.3913\n",
      "step:   170420, time: 0.737, loss: 0.8890, l1: 0.1572, vgg: 0.3625, mask: 0.3694\n",
      "step:   170440, time: 0.794, loss: 1.0706, l1: 0.2280, vgg: 0.4265, mask: 0.4162\n",
      "step:   170460, time: 0.751, loss: 0.9854, l1: 0.1806, vgg: 0.4435, mask: 0.3613\n",
      "step:   170480, time: 0.732, loss: 0.9869, l1: 0.2112, vgg: 0.3863, mask: 0.3894\n",
      "step:   170500, time: 0.734, loss: 1.0171, l1: 0.1745, vgg: 0.3943, mask: 0.4483\n",
      "step:   170520, time: 0.762, loss: 1.0445, l1: 0.2137, vgg: 0.4268, mask: 0.4041\n",
      "step:   170540, time: 0.764, loss: 1.0846, l1: 0.2195, vgg: 0.4768, mask: 0.3883\n",
      "step:   170560, time: 0.705, loss: 1.0374, l1: 0.2277, vgg: 0.4257, mask: 0.3840\n",
      "step:   170580, time: 0.733, loss: 0.9769, l1: 0.1985, vgg: 0.4300, mask: 0.3484\n",
      "step:   170600, time: 0.761, loss: 0.9190, l1: 0.1827, vgg: 0.3658, mask: 0.3704\n",
      "step:   170620, time: 0.757, loss: 0.9807, l1: 0.2095, vgg: 0.3945, mask: 0.3767\n",
      "step:   170640, time: 0.752, loss: 1.0693, l1: 0.2389, vgg: 0.4001, mask: 0.4303\n",
      "step:   170660, time: 0.723, loss: 1.0228, l1: 0.2058, vgg: 0.4453, mask: 0.3717\n",
      "step:   170680, time: 0.740, loss: 0.9695, l1: 0.1702, vgg: 0.4389, mask: 0.3604\n",
      "step:   170700, time: 0.738, loss: 1.0140, l1: 0.1988, vgg: 0.4250, mask: 0.3903\n",
      "step:   170720, time: 0.757, loss: 1.0399, l1: 0.2362, vgg: 0.4408, mask: 0.3628\n",
      "step:   170740, time: 0.759, loss: 0.9617, l1: 0.1851, vgg: 0.4053, mask: 0.3713\n",
      "step:   170760, time: 0.732, loss: 0.9405, l1: 0.1869, vgg: 0.4034, mask: 0.3502\n",
      "step:   170780, time: 0.742, loss: 0.9734, l1: 0.1992, vgg: 0.4300, mask: 0.3442\n",
      "step:   170800, time: 0.789, loss: 1.0867, l1: 0.2335, vgg: 0.4475, mask: 0.4056\n",
      "step:   170820, time: 0.742, loss: 0.9364, l1: 0.1738, vgg: 0.4287, mask: 0.3339\n",
      "step:   170840, time: 0.726, loss: 0.8667, l1: 0.1818, vgg: 0.3452, mask: 0.3397\n",
      "step:   170860, time: 0.753, loss: 1.0184, l1: 0.1889, vgg: 0.4620, mask: 0.3675\n",
      "step:   170880, time: 0.721, loss: 0.9345, l1: 0.1809, vgg: 0.4164, mask: 0.3372\n",
      "step:   170900, time: 0.758, loss: 1.0049, l1: 0.2329, vgg: 0.4058, mask: 0.3662\n",
      "step:   170920, time: 0.804, loss: 1.2014, l1: 0.3074, vgg: 0.4690, mask: 0.4250\n",
      "step:   170940, time: 0.735, loss: 0.8155, l1: 0.1478, vgg: 0.3474, mask: 0.3203\n",
      "step:   170960, time: 0.731, loss: 0.9558, l1: 0.2102, vgg: 0.3907, mask: 0.3549\n",
      "step:   170980, time: 0.747, loss: 1.1413, l1: 0.2408, vgg: 0.4948, mask: 0.4058\n",
      "step:   171000, time: 0.722, loss: 0.9002, l1: 0.1509, vgg: 0.3866, mask: 0.3628\n",
      "step:   171020, time: 0.772, loss: 1.1165, l1: 0.2633, vgg: 0.4314, mask: 0.4218\n",
      "step:   171040, time: 0.735, loss: 1.0741, l1: 0.2142, vgg: 0.4774, mask: 0.3824\n",
      "step:   171060, time: 0.777, loss: 1.1689, l1: 0.2339, vgg: 0.5359, mask: 0.3991\n",
      "step:   171080, time: 0.751, loss: 0.9281, l1: 0.1814, vgg: 0.3989, mask: 0.3479\n",
      "step:   171100, time: 0.749, loss: 0.9917, l1: 0.2134, vgg: 0.4118, mask: 0.3665\n",
      "step:   171120, time: 0.728, loss: 0.9078, l1: 0.2021, vgg: 0.3539, mask: 0.3519\n",
      "step:   171140, time: 0.825, loss: 1.0360, l1: 0.2627, vgg: 0.3846, mask: 0.3887\n",
      "step:   171160, time: 0.751, loss: 0.9749, l1: 0.1877, vgg: 0.4153, mask: 0.3719\n",
      "step:   171180, time: 0.738, loss: 1.0079, l1: 0.1722, vgg: 0.4616, mask: 0.3741\n",
      "step:   171200, time: 0.758, loss: 1.0208, l1: 0.2108, vgg: 0.4400, mask: 0.3699\n",
      "step:   171220, time: 0.740, loss: 0.9478, l1: 0.1716, vgg: 0.4138, mask: 0.3624\n",
      "step:   171240, time: 0.748, loss: 1.0802, l1: 0.1823, vgg: 0.4442, mask: 0.4536\n",
      "step:   171260, time: 0.771, loss: 1.1703, l1: 0.2984, vgg: 0.4296, mask: 0.4423\n",
      "step:   171280, time: 0.764, loss: 0.8713, l1: 0.1677, vgg: 0.3603, mask: 0.3432\n",
      "step:   171300, time: 0.767, loss: 1.1807, l1: 0.2640, vgg: 0.5171, mask: 0.3996\n",
      "step:   171320, time: 0.746, loss: 1.0252, l1: 0.2249, vgg: 0.4148, mask: 0.3855\n",
      "step:   171340, time: 0.753, loss: 0.9646, l1: 0.1850, vgg: 0.4061, mask: 0.3735\n",
      "step:   171360, time: 0.737, loss: 1.0641, l1: 0.2572, vgg: 0.3945, mask: 0.4124\n",
      "step:   171380, time: 0.784, loss: 1.1037, l1: 0.2817, vgg: 0.4099, mask: 0.4121\n",
      "step:   171400, time: 0.770, loss: 0.9971, l1: 0.2242, vgg: 0.3658, mask: 0.4071\n",
      "step:   171420, time: 0.759, loss: 0.8844, l1: 0.1510, vgg: 0.3781, mask: 0.3554\n",
      "step:   171440, time: 0.758, loss: 1.0342, l1: 0.2406, vgg: 0.4327, mask: 0.3609\n",
      "step:   171460, time: 0.779, loss: 1.0262, l1: 0.2178, vgg: 0.3931, mask: 0.4152\n",
      "step:   171480, time: 0.738, loss: 0.9458, l1: 0.1541, vgg: 0.4375, mask: 0.3542\n",
      "step:   171500, time: 0.788, loss: 0.9861, l1: 0.2052, vgg: 0.3973, mask: 0.3837\n",
      "step:   171520, time: 0.776, loss: 0.8815, l1: 0.1473, vgg: 0.3229, mask: 0.4114\n",
      "step:   171540, time: 0.750, loss: 0.9355, l1: 0.1567, vgg: 0.4284, mask: 0.3504\n",
      "step:   171560, time: 0.759, loss: 1.2004, l1: 0.2898, vgg: 0.4885, mask: 0.4221\n",
      "step:   171580, time: 0.738, loss: 1.0031, l1: 0.2026, vgg: 0.4262, mask: 0.3742\n",
      "step:   171600, time: 0.755, loss: 1.0792, l1: 0.2426, vgg: 0.4104, mask: 0.4263\n",
      "step:   171620, time: 0.733, loss: 1.0148, l1: 0.2138, vgg: 0.4508, mask: 0.3502\n",
      "step:   171640, time: 0.760, loss: 0.9188, l1: 0.1554, vgg: 0.4233, mask: 0.3401\n",
      "step:   171660, time: 0.761, loss: 1.0629, l1: 0.2007, vgg: 0.4906, mask: 0.3716\n",
      "step:   171680, time: 0.728, loss: 0.9821, l1: 0.1942, vgg: 0.4053, mask: 0.3825\n",
      "step:   171700, time: 0.758, loss: 1.0259, l1: 0.2451, vgg: 0.3691, mask: 0.4117\n",
      "step:   171720, time: 0.720, loss: 1.0051, l1: 0.1815, vgg: 0.4616, mask: 0.3619\n",
      "step:   171740, time: 0.779, loss: 1.1023, l1: 0.2480, vgg: 0.4591, mask: 0.3953\n",
      "step:   171760, time: 0.749, loss: 1.0636, l1: 0.2547, vgg: 0.4209, mask: 0.3880\n",
      "step:   171780, time: 0.769, loss: 1.1278, l1: 0.2633, vgg: 0.4614, mask: 0.4030\n",
      "step:   171800, time: 0.765, loss: 1.1619, l1: 0.2971, vgg: 0.4449, mask: 0.4200\n",
      "step:   171820, time: 0.757, loss: 1.0810, l1: 0.2362, vgg: 0.4245, mask: 0.4202\n",
      "step:   171840, time: 0.724, loss: 0.9436, l1: 0.2009, vgg: 0.3928, mask: 0.3499\n",
      "step:   171860, time: 0.757, loss: 1.0919, l1: 0.2459, vgg: 0.4078, mask: 0.4382\n",
      "step:   171880, time: 0.772, loss: 0.9804, l1: 0.1996, vgg: 0.4378, mask: 0.3430\n",
      "step:   171900, time: 0.713, loss: 0.8608, l1: 0.1640, vgg: 0.3623, mask: 0.3344\n",
      "step:   171920, time: 0.795, loss: 1.1186, l1: 0.2184, vgg: 0.5170, mask: 0.3832\n",
      "step:   171940, time: 0.751, loss: 1.0015, l1: 0.2405, vgg: 0.3823, mask: 0.3787\n",
      "step:   171960, time: 0.733, loss: 0.9492, l1: 0.1918, vgg: 0.4008, mask: 0.3566\n",
      "step:   171980, time: 0.769, loss: 1.0144, l1: 0.2074, vgg: 0.4064, mask: 0.4005\n",
      "step:   172000, time: 0.740, loss: 0.9870, l1: 0.1688, vgg: 0.4505, mask: 0.3678\n",
      "step:   172020, time: 0.789, loss: 1.2948, l1: 0.3049, vgg: 0.5564, mask: 0.4335\n",
      "step:   172040, time: 0.737, loss: 1.0014, l1: 0.2010, vgg: 0.4240, mask: 0.3764\n",
      "step:   172060, time: 0.731, loss: 0.9558, l1: 0.1698, vgg: 0.4341, mask: 0.3520\n",
      "step:   172080, time: 0.761, loss: 1.0741, l1: 0.2201, vgg: 0.4499, mask: 0.4041\n",
      "step:   172100, time: 0.770, loss: 1.0225, l1: 0.2363, vgg: 0.3943, mask: 0.3918\n",
      "step:   172120, time: 0.749, loss: 0.9335, l1: 0.1785, vgg: 0.4051, mask: 0.3499\n",
      "step:   172140, time: 0.768, loss: 1.0741, l1: 0.2343, vgg: 0.4426, mask: 0.3972\n",
      "step:   172160, time: 0.753, loss: 0.9809, l1: 0.2000, vgg: 0.4276, mask: 0.3533\n",
      "step:   172180, time: 0.746, loss: 0.9095, l1: 0.1737, vgg: 0.3833, mask: 0.3525\n",
      "step:   172200, time: 0.748, loss: 0.9937, l1: 0.2026, vgg: 0.4258, mask: 0.3653\n",
      "step:   172220, time: 0.713, loss: 0.9411, l1: 0.1735, vgg: 0.4097, mask: 0.3580\n",
      "step:   172240, time: 0.729, loss: 1.0378, l1: 0.1964, vgg: 0.4686, mask: 0.3729\n",
      "step:   172260, time: 0.737, loss: 1.0501, l1: 0.2320, vgg: 0.4180, mask: 0.4001\n",
      "step:   172280, time: 0.754, loss: 0.9404, l1: 0.1359, vgg: 0.4332, mask: 0.3713\n",
      "step:   172300, time: 0.790, loss: 1.0728, l1: 0.2315, vgg: 0.4660, mask: 0.3754\n",
      "step:   172320, time: 0.747, loss: 1.2138, l1: 0.2547, vgg: 0.5600, mask: 0.3992\n",
      "step:   172340, time: 0.741, loss: 1.0881, l1: 0.2441, vgg: 0.4306, mask: 0.4134\n",
      "step:   172360, time: 0.745, loss: 0.9408, l1: 0.1789, vgg: 0.3845, mask: 0.3775\n",
      "step:   172380, time: 0.759, loss: 1.0064, l1: 0.2116, vgg: 0.4089, mask: 0.3859\n",
      "step:   172400, time: 0.745, loss: 0.9624, l1: 0.2026, vgg: 0.4162, mask: 0.3436\n",
      "step:   172420, time: 0.789, loss: 0.9705, l1: 0.1974, vgg: 0.3943, mask: 0.3788\n",
      "step:   172440, time: 0.723, loss: 1.0029, l1: 0.2227, vgg: 0.3704, mask: 0.4098\n",
      "step:   172460, time: 0.746, loss: 0.9018, l1: 0.1606, vgg: 0.3733, mask: 0.3679\n",
      "step:   172480, time: 0.751, loss: 1.0752, l1: 0.2516, vgg: 0.4084, mask: 0.4151\n",
      "step:   172500, time: 0.719, loss: 0.9981, l1: 0.2003, vgg: 0.4166, mask: 0.3812\n",
      "step:   172520, time: 0.725, loss: 0.9915, l1: 0.2168, vgg: 0.3820, mask: 0.3927\n",
      "step:   172540, time: 0.744, loss: 0.8934, l1: 0.1464, vgg: 0.4096, mask: 0.3375\n",
      "step:   172560, time: 0.751, loss: 0.9803, l1: 0.2004, vgg: 0.3950, mask: 0.3850\n",
      "step:   172580, time: 0.743, loss: 0.9567, l1: 0.1732, vgg: 0.4406, mask: 0.3429\n",
      "step:   172600, time: 0.725, loss: 1.0876, l1: 0.2573, vgg: 0.4390, mask: 0.3913\n",
      "step:   172620, time: 0.744, loss: 0.9726, l1: 0.2082, vgg: 0.3941, mask: 0.3703\n",
      "step:   172640, time: 0.715, loss: 1.0091, l1: 0.2192, vgg: 0.4151, mask: 0.3747\n",
      "step:   172660, time: 0.734, loss: 0.9841, l1: 0.2105, vgg: 0.3974, mask: 0.3763\n",
      "step:   172680, time: 0.762, loss: 1.2338, l1: 0.2994, vgg: 0.5394, mask: 0.3950\n",
      "step:   172700, time: 0.745, loss: 1.0080, l1: 0.2178, vgg: 0.4038, mask: 0.3865\n",
      "step:   172720, time: 0.731, loss: 1.1026, l1: 0.2366, vgg: 0.4476, mask: 0.4184\n",
      "step:   172740, time: 0.778, loss: 1.0629, l1: 0.2206, vgg: 0.4572, mask: 0.3851\n",
      "step:   172760, time: 0.750, loss: 0.9912, l1: 0.2061, vgg: 0.3784, mask: 0.4066\n",
      "step:   172780, time: 0.741, loss: 0.9589, l1: 0.1535, vgg: 0.4527, mask: 0.3527\n",
      "step:   172800, time: 0.720, loss: 1.0261, l1: 0.2670, vgg: 0.3665, mask: 0.3927\n",
      "step:   172820, time: 0.747, loss: 0.9799, l1: 0.1985, vgg: 0.4227, mask: 0.3587\n",
      "step:   172840, time: 0.752, loss: 1.0915, l1: 0.2309, vgg: 0.4700, mask: 0.3907\n",
      "step:   172860, time: 0.740, loss: 0.9319, l1: 0.1813, vgg: 0.3999, mask: 0.3507\n",
      "step:   172880, time: 0.745, loss: 0.9323, l1: 0.1876, vgg: 0.3729, mask: 0.3718\n",
      "step:   172900, time: 0.788, loss: 1.1485, l1: 0.3017, vgg: 0.4323, mask: 0.4145\n",
      "step:   172920, time: 0.772, loss: 1.1032, l1: 0.2212, vgg: 0.4859, mask: 0.3961\n",
      "step:   172940, time: 0.764, loss: 1.0600, l1: 0.2154, vgg: 0.4754, mask: 0.3691\n",
      "step:   172960, time: 0.732, loss: 1.0050, l1: 0.2367, vgg: 0.3853, mask: 0.3830\n",
      "step:   172980, time: 0.734, loss: 1.0125, l1: 0.2174, vgg: 0.4094, mask: 0.3856\n",
      "step:   173000, time: 0.716, loss: 0.9507, l1: 0.1723, vgg: 0.4176, mask: 0.3607\n",
      "step:   173020, time: 0.767, loss: 1.0077, l1: 0.2000, vgg: 0.4487, mask: 0.3591\n",
      "step:   173040, time: 0.748, loss: 1.1058, l1: 0.2224, vgg: 0.5215, mask: 0.3619\n",
      "step:   173060, time: 0.740, loss: 1.0620, l1: 0.1903, vgg: 0.5019, mask: 0.3698\n",
      "step:   173080, time: 0.755, loss: 1.0362, l1: 0.2180, vgg: 0.4500, mask: 0.3682\n",
      "step:   173100, time: 0.776, loss: 1.0145, l1: 0.2384, vgg: 0.4140, mask: 0.3621\n",
      "step:   173120, time: 0.745, loss: 1.0302, l1: 0.1738, vgg: 0.4666, mask: 0.3899\n",
      "step:   173140, time: 0.743, loss: 1.0014, l1: 0.2151, vgg: 0.4098, mask: 0.3764\n",
      "step:   173160, time: 0.749, loss: 0.9821, l1: 0.1573, vgg: 0.4524, mask: 0.3724\n",
      "step:   173180, time: 0.750, loss: 1.1056, l1: 0.2502, vgg: 0.4696, mask: 0.3859\n",
      "step:   173200, time: 0.730, loss: 0.9148, l1: 0.1570, vgg: 0.4187, mask: 0.3391\n",
      "step:   173220, time: 0.754, loss: 0.9863, l1: 0.2405, vgg: 0.3752, mask: 0.3705\n",
      "step:   173240, time: 0.727, loss: 0.9386, l1: 0.2050, vgg: 0.3597, mask: 0.3739\n",
      "step:   173260, time: 0.763, loss: 1.1623, l1: 0.2761, vgg: 0.4956, mask: 0.3906\n",
      "step:   173280, time: 0.727, loss: 1.0671, l1: 0.2192, vgg: 0.4437, mask: 0.4043\n",
      "step:   173300, time: 0.747, loss: 1.0261, l1: 0.1938, vgg: 0.4428, mask: 0.3895\n",
      "step:   173320, time: 0.750, loss: 0.9982, l1: 0.2022, vgg: 0.4303, mask: 0.3658\n",
      "step:   173340, time: 0.745, loss: 0.9941, l1: 0.2081, vgg: 0.4105, mask: 0.3755\n",
      "step:   173360, time: 0.703, loss: 0.8054, l1: 0.1460, vgg: 0.3157, mask: 0.3437\n",
      "step:   173380, time: 0.808, loss: 1.0183, l1: 0.2140, vgg: 0.4233, mask: 0.3810\n",
      "step:   173400, time: 0.838, loss: 1.0031, l1: 0.2146, vgg: 0.3940, mask: 0.3944\n",
      "step:   173420, time: 0.778, loss: 1.0029, l1: 0.1996, vgg: 0.4272, mask: 0.3761\n",
      "step:   173440, time: 0.775, loss: 0.9227, l1: 0.2172, vgg: 0.3825, mask: 0.3230\n",
      "step:   173460, time: 0.738, loss: 1.0375, l1: 0.1975, vgg: 0.4779, mask: 0.3621\n",
      "step:   173480, time: 0.754, loss: 0.9727, l1: 0.2020, vgg: 0.4011, mask: 0.3696\n",
      "step:   173500, time: 0.724, loss: 0.9008, l1: 0.1659, vgg: 0.3613, mask: 0.3735\n",
      "step:   173520, time: 0.745, loss: 1.0522, l1: 0.2537, vgg: 0.4288, mask: 0.3698\n",
      "step:   173540, time: 0.780, loss: 1.1929, l1: 0.2822, vgg: 0.4906, mask: 0.4201\n",
      "step:   173560, time: 0.792, loss: 1.0121, l1: 0.1973, vgg: 0.4650, mask: 0.3499\n",
      "step:   173580, time: 0.767, loss: 1.0241, l1: 0.1990, vgg: 0.4214, mask: 0.4037\n",
      "step:   173600, time: 0.759, loss: 0.9519, l1: 0.1463, vgg: 0.4420, mask: 0.3637\n",
      "step:   173620, time: 0.730, loss: 1.0100, l1: 0.2072, vgg: 0.4462, mask: 0.3567\n",
      "step:   173640, time: 0.734, loss: 0.9802, l1: 0.2350, vgg: 0.3537, mask: 0.3915\n",
      "step:   173660, time: 0.753, loss: 1.0552, l1: 0.2336, vgg: 0.4105, mask: 0.4111\n",
      "step:   173680, time: 0.729, loss: 1.0534, l1: 0.2073, vgg: 0.4596, mask: 0.3866\n",
      "step:   173700, time: 0.797, loss: 1.1665, l1: 0.2714, vgg: 0.4871, mask: 0.4079\n",
      "step:   173720, time: 0.740, loss: 1.0802, l1: 0.2610, vgg: 0.3923, mask: 0.4270\n",
      "step:   173740, time: 0.788, loss: 0.9529, l1: 0.1898, vgg: 0.4098, mask: 0.3533\n",
      "step:   173760, time: 0.737, loss: 1.0564, l1: 0.2610, vgg: 0.4233, mask: 0.3721\n",
      "step:   173780, time: 0.762, loss: 1.0683, l1: 0.2550, vgg: 0.4126, mask: 0.4008\n",
      "step:   173800, time: 0.772, loss: 1.0231, l1: 0.2088, vgg: 0.4192, mask: 0.3951\n",
      "step:   173820, time: 0.747, loss: 1.0604, l1: 0.2200, vgg: 0.4373, mask: 0.4031\n",
      "step:   173840, time: 0.748, loss: 1.0487, l1: 0.1851, vgg: 0.4581, mask: 0.4055\n",
      "step:   173860, time: 0.727, loss: 0.9762, l1: 0.2055, vgg: 0.3955, mask: 0.3752\n",
      "step:   173880, time: 0.726, loss: 1.0189, l1: 0.2200, vgg: 0.4305, mask: 0.3684\n",
      "step:   173900, time: 0.758, loss: 1.0636, l1: 0.1961, vgg: 0.4381, mask: 0.4294\n",
      "step:   173920, time: 0.777, loss: 1.0466, l1: 0.2201, vgg: 0.4543, mask: 0.3721\n",
      "step:   173940, time: 0.756, loss: 1.1426, l1: 0.2542, vgg: 0.4608, mask: 0.4276\n",
      "step:   173960, time: 0.739, loss: 0.9967, l1: 0.2223, vgg: 0.3639, mask: 0.4104\n",
      "step:   173980, time: 0.778, loss: 0.9947, l1: 0.2311, vgg: 0.4056, mask: 0.3579\n",
      "step:   174000, time: 0.745, loss: 1.0255, l1: 0.2086, vgg: 0.4292, mask: 0.3877\n",
      "step:   174020, time: 0.726, loss: 1.0112, l1: 0.1938, vgg: 0.4269, mask: 0.3905\n",
      "step:   174040, time: 0.758, loss: 0.9485, l1: 0.1888, vgg: 0.4032, mask: 0.3565\n",
      "step:   174060, time: 0.775, loss: 1.0277, l1: 0.2208, vgg: 0.4196, mask: 0.3873\n",
      "step:   174080, time: 0.728, loss: 0.8751, l1: 0.1652, vgg: 0.3335, mask: 0.3763\n",
      "step:   174100, time: 0.750, loss: 1.0368, l1: 0.2315, vgg: 0.4407, mask: 0.3646\n",
      "step:   174120, time: 0.709, loss: 0.8769, l1: 0.1288, vgg: 0.3748, mask: 0.3734\n",
      "step:   174140, time: 0.731, loss: 1.0076, l1: 0.2177, vgg: 0.4136, mask: 0.3763\n",
      "step:   174160, time: 0.742, loss: 0.9898, l1: 0.2069, vgg: 0.4102, mask: 0.3727\n",
      "step:   174180, time: 0.741, loss: 1.0552, l1: 0.2510, vgg: 0.4231, mask: 0.3811\n",
      "step:   174200, time: 0.748, loss: 1.0101, l1: 0.2121, vgg: 0.4289, mask: 0.3690\n",
      "step:   174220, time: 0.759, loss: 1.0163, l1: 0.1884, vgg: 0.4613, mask: 0.3666\n",
      "step:   174240, time: 0.744, loss: 1.0250, l1: 0.2647, vgg: 0.3635, mask: 0.3968\n",
      "step:   174260, time: 0.770, loss: 1.0267, l1: 0.2079, vgg: 0.4558, mask: 0.3630\n",
      "step:   174280, time: 0.758, loss: 1.0352, l1: 0.2701, vgg: 0.3591, mask: 0.4059\n",
      "step:   174300, time: 0.779, loss: 0.9631, l1: 0.2302, vgg: 0.3714, mask: 0.3616\n",
      "step:   174320, time: 0.730, loss: 1.1229, l1: 0.2597, vgg: 0.4569, mask: 0.4063\n",
      "step:   174340, time: 0.773, loss: 1.0872, l1: 0.2551, vgg: 0.4570, mask: 0.3751\n",
      "step:   174360, time: 0.714, loss: 1.0163, l1: 0.2265, vgg: 0.4119, mask: 0.3778\n",
      "step:   174380, time: 0.808, loss: 1.1134, l1: 0.2753, vgg: 0.4009, mask: 0.4372\n",
      "step:   174400, time: 0.748, loss: 0.9194, l1: 0.1556, vgg: 0.4121, mask: 0.3516\n",
      "step:   174420, time: 0.773, loss: 1.0001, l1: 0.1726, vgg: 0.4239, mask: 0.4036\n",
      "step:   174440, time: 0.729, loss: 0.9493, l1: 0.2115, vgg: 0.3725, mask: 0.3654\n",
      "step:   174460, time: 0.770, loss: 1.0953, l1: 0.2446, vgg: 0.4326, mask: 0.4181\n",
      "step:   174480, time: 0.742, loss: 1.0894, l1: 0.2419, vgg: 0.4488, mask: 0.3986\n",
      "step:   174500, time: 0.774, loss: 1.1638, l1: 0.2667, vgg: 0.4898, mask: 0.4073\n",
      "step:   174520, time: 0.772, loss: 0.8854, l1: 0.1788, vgg: 0.3432, mask: 0.3635\n",
      "step:   174540, time: 0.760, loss: 0.9531, l1: 0.1898, vgg: 0.3906, mask: 0.3726\n",
      "step:   174560, time: 0.783, loss: 1.0113, l1: 0.2263, vgg: 0.4018, mask: 0.3831\n",
      "step:   174580, time: 0.744, loss: 1.0890, l1: 0.2210, vgg: 0.4408, mask: 0.4272\n",
      "step:   174600, time: 0.720, loss: 0.9541, l1: 0.2107, vgg: 0.3723, mask: 0.3711\n",
      "step:   174620, time: 0.750, loss: 0.9969, l1: 0.2224, vgg: 0.3919, mask: 0.3826\n",
      "step:   174640, time: 0.749, loss: 0.9642, l1: 0.1861, vgg: 0.4141, mask: 0.3640\n",
      "step:   174660, time: 0.761, loss: 0.9988, l1: 0.2035, vgg: 0.4326, mask: 0.3626\n",
      "step:   174680, time: 0.730, loss: 0.9083, l1: 0.1564, vgg: 0.4343, mask: 0.3176\n",
      "step:   174700, time: 0.777, loss: 1.0420, l1: 0.2359, vgg: 0.4085, mask: 0.3975\n",
      "step:   174720, time: 0.784, loss: 0.9918, l1: 0.1975, vgg: 0.4261, mask: 0.3682\n",
      "step:   174740, time: 0.764, loss: 1.0069, l1: 0.2235, vgg: 0.4055, mask: 0.3780\n",
      "step:   174760, time: 0.732, loss: 1.0118, l1: 0.2228, vgg: 0.3960, mask: 0.3930\n",
      "step:   174780, time: 0.748, loss: 1.0326, l1: 0.2253, vgg: 0.4149, mask: 0.3924\n",
      "step:   174800, time: 0.726, loss: 0.9657, l1: 0.2129, vgg: 0.3985, mask: 0.3543\n",
      "step:   174820, time: 0.739, loss: 1.0505, l1: 0.2233, vgg: 0.4256, mask: 0.4016\n",
      "step:   174840, time: 0.733, loss: 0.9486, l1: 0.1661, vgg: 0.4603, mask: 0.3221\n",
      "step:   174860, time: 0.759, loss: 1.0073, l1: 0.2434, vgg: 0.4173, mask: 0.3466\n",
      "step:   174880, time: 0.799, loss: 0.9170, l1: 0.1750, vgg: 0.3470, mask: 0.3950\n",
      "step:   174900, time: 0.747, loss: 0.9153, l1: 0.1630, vgg: 0.3858, mask: 0.3664\n",
      "step:   174920, time: 0.786, loss: 0.9974, l1: 0.2042, vgg: 0.4022, mask: 0.3910\n",
      "step:   174940, time: 0.776, loss: 1.0065, l1: 0.2181, vgg: 0.4075, mask: 0.3808\n",
      "step:   174960, time: 0.783, loss: 1.0094, l1: 0.1727, vgg: 0.4791, mask: 0.3577\n",
      "step:   174980, time: 0.778, loss: 1.0265, l1: 0.2141, vgg: 0.4523, mask: 0.3601\n",
      "step:   175000, time: 0.764, loss: 1.1066, l1: 0.2344, vgg: 0.4549, mask: 0.4173\n",
      "step:   175020, time: 0.782, loss: 1.0862, l1: 0.2628, vgg: 0.4250, mask: 0.3984\n",
      "step:   175040, time: 0.810, loss: 1.0206, l1: 0.2083, vgg: 0.4262, mask: 0.3862\n",
      "step:   175060, time: 0.798, loss: 1.0370, l1: 0.2268, vgg: 0.3981, mask: 0.4120\n",
      "step:   175080, time: 0.780, loss: 1.0531, l1: 0.2354, vgg: 0.4388, mask: 0.3789\n",
      "step:   175100, time: 0.799, loss: 1.1418, l1: 0.2381, vgg: 0.5017, mask: 0.4021\n",
      "step:   175120, time: 0.762, loss: 1.0091, l1: 0.2048, vgg: 0.4471, mask: 0.3571\n",
      "step:   175140, time: 0.778, loss: 1.0161, l1: 0.2084, vgg: 0.4110, mask: 0.3967\n",
      "step:   175160, time: 0.762, loss: 0.9857, l1: 0.2279, vgg: 0.3615, mask: 0.3963\n",
      "step:   175180, time: 0.773, loss: 1.1140, l1: 0.2676, vgg: 0.4277, mask: 0.4187\n",
      "step:   175200, time: 0.754, loss: 1.0348, l1: 0.2376, vgg: 0.3747, mask: 0.4226\n",
      "step:   175220, time: 0.758, loss: 0.9627, l1: 0.1567, vgg: 0.4663, mask: 0.3398\n",
      "step:   175240, time: 0.784, loss: 1.2154, l1: 0.3420, vgg: 0.4577, mask: 0.4157\n",
      "step:   175260, time: 0.817, loss: 1.1335, l1: 0.2949, vgg: 0.4203, mask: 0.4183\n",
      "step:   175280, time: 0.750, loss: 0.9412, l1: 0.1850, vgg: 0.3743, mask: 0.3819\n",
      "step:   175300, time: 0.740, loss: 1.0269, l1: 0.2063, vgg: 0.3863, mask: 0.4343\n",
      "step:   175320, time: 0.755, loss: 0.8872, l1: 0.1966, vgg: 0.3380, mask: 0.3526\n",
      "step:   175340, time: 0.741, loss: 0.9143, l1: 0.1662, vgg: 0.3721, mask: 0.3760\n",
      "step:   175360, time: 0.789, loss: 1.0929, l1: 0.2308, vgg: 0.4552, mask: 0.4069\n",
      "step:   175380, time: 0.746, loss: 0.9994, l1: 0.2098, vgg: 0.4213, mask: 0.3682\n",
      "step:   175400, time: 0.761, loss: 1.0984, l1: 0.2457, vgg: 0.4671, mask: 0.3856\n",
      "step:   175420, time: 0.742, loss: 0.9958, l1: 0.2127, vgg: 0.4168, mask: 0.3663\n",
      "step:   175440, time: 0.794, loss: 1.1260, l1: 0.2550, vgg: 0.4890, mask: 0.3820\n",
      "step:   175460, time: 0.753, loss: 1.0419, l1: 0.2130, vgg: 0.4571, mask: 0.3718\n",
      "step:   175480, time: 0.755, loss: 0.9117, l1: 0.1637, vgg: 0.3848, mask: 0.3632\n",
      "step:   175500, time: 0.785, loss: 1.1856, l1: 0.2511, vgg: 0.5285, mask: 0.4061\n",
      "step:   175520, time: 0.798, loss: 1.0302, l1: 0.2182, vgg: 0.3924, mask: 0.4196\n",
      "step:   175540, time: 0.739, loss: 1.0589, l1: 0.2533, vgg: 0.4005, mask: 0.4051\n",
      "step:   175560, time: 0.769, loss: 0.9911, l1: 0.2513, vgg: 0.3490, mask: 0.3908\n",
      "step:   175580, time: 0.745, loss: 0.9230, l1: 0.1690, vgg: 0.3814, mask: 0.3726\n",
      "step:   175600, time: 0.718, loss: 0.8843, l1: 0.1767, vgg: 0.3719, mask: 0.3357\n",
      "step:   175620, time: 0.743, loss: 0.9407, l1: 0.1882, vgg: 0.4126, mask: 0.3399\n",
      "step:   175640, time: 0.738, loss: 1.1441, l1: 0.3117, vgg: 0.3865, mask: 0.4458\n",
      "step:   175660, time: 0.729, loss: 0.9538, l1: 0.2109, vgg: 0.3640, mask: 0.3788\n",
      "step:   175680, time: 0.726, loss: 0.9743, l1: 0.1836, vgg: 0.4274, mask: 0.3633\n",
      "step:   175700, time: 0.746, loss: 0.8474, l1: 0.1388, vgg: 0.3702, mask: 0.3384\n",
      "step:   175720, time: 0.749, loss: 1.0407, l1: 0.2130, vgg: 0.4636, mask: 0.3641\n",
      "step:   175740, time: 0.742, loss: 0.9915, l1: 0.2249, vgg: 0.4041, mask: 0.3625\n",
      "step:   175760, time: 0.761, loss: 1.0329, l1: 0.1901, vgg: 0.4431, mask: 0.3997\n",
      "step:   175780, time: 0.736, loss: 0.9447, l1: 0.1851, vgg: 0.3947, mask: 0.3648\n",
      "step:   175800, time: 0.725, loss: 0.9125, l1: 0.1679, vgg: 0.4027, mask: 0.3419\n",
      "step:   175820, time: 0.762, loss: 1.1475, l1: 0.2353, vgg: 0.5093, mask: 0.4029\n",
      "step:   175840, time: 0.744, loss: 0.9604, l1: 0.1952, vgg: 0.3852, mask: 0.3801\n",
      "step:   175860, time: 0.740, loss: 1.0407, l1: 0.2450, vgg: 0.4361, mask: 0.3596\n",
      "step:   175880, time: 0.783, loss: 1.0438, l1: 0.2363, vgg: 0.4144, mask: 0.3931\n",
      "step:   175900, time: 0.733, loss: 0.8303, l1: 0.1793, vgg: 0.3189, mask: 0.3321\n",
      "step:   175920, time: 0.771, loss: 1.0507, l1: 0.2057, vgg: 0.4446, mask: 0.4004\n",
      "step:   175940, time: 0.732, loss: 1.0423, l1: 0.2296, vgg: 0.4319, mask: 0.3808\n",
      "step:   175960, time: 0.753, loss: 1.0641, l1: 0.2076, vgg: 0.4645, mask: 0.3920\n",
      "step:   175980, time: 0.735, loss: 1.0338, l1: 0.2552, vgg: 0.3834, mask: 0.3952\n",
      "step:   176000, time: 0.746, loss: 1.0198, l1: 0.2383, vgg: 0.3926, mask: 0.3888\n",
      "step:   176020, time: 0.767, loss: 1.0068, l1: 0.1928, vgg: 0.4331, mask: 0.3809\n",
      "step:   176040, time: 0.757, loss: 1.0038, l1: 0.2123, vgg: 0.4272, mask: 0.3644\n",
      "step:   176060, time: 0.789, loss: 0.9651, l1: 0.1569, vgg: 0.4017, mask: 0.4065\n",
      "step:   176080, time: 0.772, loss: 1.0508, l1: 0.2039, vgg: 0.4492, mask: 0.3977\n",
      "step:   176100, time: 0.762, loss: 1.1034, l1: 0.2199, vgg: 0.4498, mask: 0.4337\n",
      "step:   176120, time: 0.746, loss: 0.9771, l1: 0.2049, vgg: 0.4234, mask: 0.3488\n",
      "step:   176140, time: 0.789, loss: 1.0516, l1: 0.1833, vgg: 0.5188, mask: 0.3495\n",
      "step:   176160, time: 0.789, loss: 1.0552, l1: 0.2622, vgg: 0.4229, mask: 0.3701\n",
      "step:   176180, time: 0.817, loss: 1.0253, l1: 0.1991, vgg: 0.4175, mask: 0.4086\n",
      "step:   176200, time: 0.740, loss: 1.0742, l1: 0.2140, vgg: 0.4566, mask: 0.4035\n",
      "step:   176220, time: 0.769, loss: 1.2282, l1: 0.3122, vgg: 0.4718, mask: 0.4442\n",
      "step:   176240, time: 0.780, loss: 1.1236, l1: 0.2725, vgg: 0.4511, mask: 0.4000\n",
      "step:   176260, time: 0.718, loss: 0.9539, l1: 0.1820, vgg: 0.3973, mask: 0.3747\n",
      "step:   176280, time: 0.753, loss: 0.9764, l1: 0.1934, vgg: 0.4325, mask: 0.3506\n",
      "step:   176300, time: 0.763, loss: 1.1760, l1: 0.2544, vgg: 0.5338, mask: 0.3878\n",
      "step:   176320, time: 0.749, loss: 0.8782, l1: 0.1847, vgg: 0.3558, mask: 0.3377\n",
      "step:   176340, time: 0.731, loss: 1.1060, l1: 0.2709, vgg: 0.4092, mask: 0.4259\n",
      "step:   176360, time: 0.769, loss: 1.0609, l1: 0.2003, vgg: 0.4578, mask: 0.4028\n",
      "step:   176380, time: 0.742, loss: 1.0486, l1: 0.2375, vgg: 0.4142, mask: 0.3969\n",
      "step:   176400, time: 0.738, loss: 1.0169, l1: 0.2301, vgg: 0.4251, mask: 0.3617\n",
      "step:   176420, time: 0.750, loss: 1.0390, l1: 0.2381, vgg: 0.4196, mask: 0.3813\n",
      "step:   176440, time: 0.744, loss: 0.9962, l1: 0.2047, vgg: 0.3958, mask: 0.3956\n",
      "step:   176460, time: 0.752, loss: 1.0354, l1: 0.2408, vgg: 0.4068, mask: 0.3878\n",
      "step:   176480, time: 0.765, loss: 0.9718, l1: 0.1573, vgg: 0.4302, mask: 0.3842\n",
      "step:   176500, time: 0.774, loss: 0.9385, l1: 0.1790, vgg: 0.3693, mask: 0.3902\n",
      "step:   176520, time: 0.778, loss: 0.8860, l1: 0.1696, vgg: 0.3619, mask: 0.3544\n",
      "step:   176540, time: 0.768, loss: 1.0371, l1: 0.2207, vgg: 0.4082, mask: 0.4082\n",
      "step:   176560, time: 0.752, loss: 1.0838, l1: 0.2799, vgg: 0.3982, mask: 0.4057\n",
      "step:   176580, time: 0.743, loss: 0.9840, l1: 0.2172, vgg: 0.4102, mask: 0.3566\n",
      "step:   176600, time: 0.745, loss: 1.0775, l1: 0.2286, vgg: 0.4465, mask: 0.4024\n",
      "step:   176620, time: 0.739, loss: 1.0209, l1: 0.2091, vgg: 0.4132, mask: 0.3986\n",
      "step:   176640, time: 0.748, loss: 0.9967, l1: 0.1764, vgg: 0.4225, mask: 0.3978\n",
      "step:   176660, time: 0.799, loss: 1.0079, l1: 0.2207, vgg: 0.4095, mask: 0.3777\n",
      "step:   176680, time: 0.754, loss: 0.9051, l1: 0.1748, vgg: 0.3688, mask: 0.3614\n",
      "step:   176700, time: 0.775, loss: 1.1275, l1: 0.2283, vgg: 0.5252, mask: 0.3740\n",
      "step:   176720, time: 0.734, loss: 1.0153, l1: 0.2280, vgg: 0.4071, mask: 0.3802\n",
      "step:   176740, time: 0.743, loss: 1.0210, l1: 0.2024, vgg: 0.4552, mask: 0.3635\n",
      "step:   176760, time: 0.787, loss: 1.0367, l1: 0.2155, vgg: 0.4536, mask: 0.3676\n",
      "step:   176780, time: 0.730, loss: 0.9988, l1: 0.1764, vgg: 0.4764, mask: 0.3461\n",
      "step:   176800, time: 0.756, loss: 0.9759, l1: 0.2278, vgg: 0.3678, mask: 0.3803\n",
      "step:   176820, time: 0.748, loss: 1.0334, l1: 0.2493, vgg: 0.3860, mask: 0.3981\n",
      "step:   176840, time: 0.745, loss: 0.8866, l1: 0.1918, vgg: 0.3379, mask: 0.3568\n",
      "step:   176860, time: 0.761, loss: 0.9219, l1: 0.1671, vgg: 0.4192, mask: 0.3357\n",
      "step:   176880, time: 0.786, loss: 0.9850, l1: 0.1844, vgg: 0.3947, mask: 0.4059\n",
      "step:   176900, time: 0.779, loss: 1.1067, l1: 0.2748, vgg: 0.4356, mask: 0.3963\n",
      "step:   176920, time: 0.791, loss: 0.9840, l1: 0.1807, vgg: 0.4227, mask: 0.3805\n",
      "step:   176940, time: 0.736, loss: 1.0605, l1: 0.2719, vgg: 0.3998, mask: 0.3888\n",
      "step:   176960, time: 0.773, loss: 1.1254, l1: 0.2634, vgg: 0.4674, mask: 0.3945\n",
      "step:   176980, time: 0.751, loss: 0.9072, l1: 0.1516, vgg: 0.4025, mask: 0.3530\n",
      "step:   177000, time: 0.774, loss: 1.0714, l1: 0.2151, vgg: 0.5004, mask: 0.3558\n",
      "step:   177020, time: 0.750, loss: 1.0543, l1: 0.2216, vgg: 0.4457, mask: 0.3869\n",
      "step:   177040, time: 0.799, loss: 0.9471, l1: 0.2056, vgg: 0.3750, mask: 0.3665\n",
      "step:   177060, time: 0.756, loss: 1.1092, l1: 0.2346, vgg: 0.4604, mask: 0.4142\n",
      "step:   177080, time: 0.763, loss: 1.1731, l1: 0.2714, vgg: 0.4581, mask: 0.4437\n",
      "step:   177100, time: 0.781, loss: 1.1013, l1: 0.2314, vgg: 0.4900, mask: 0.3799\n",
      "step:   177120, time: 0.758, loss: 0.9328, l1: 0.2136, vgg: 0.3461, mask: 0.3731\n",
      "step:   177140, time: 0.728, loss: 1.0382, l1: 0.2398, vgg: 0.3745, mask: 0.4238\n",
      "step:   177160, time: 0.739, loss: 1.0298, l1: 0.2002, vgg: 0.4069, mask: 0.4226\n",
      "step:   177180, time: 0.741, loss: 0.8574, l1: 0.1457, vgg: 0.3660, mask: 0.3457\n",
      "step:   177200, time: 0.745, loss: 0.9799, l1: 0.1862, vgg: 0.3771, mask: 0.4165\n",
      "step:   177220, time: 0.720, loss: 0.9272, l1: 0.1517, vgg: 0.4137, mask: 0.3617\n",
      "step:   177240, time: 0.741, loss: 0.9082, l1: 0.1999, vgg: 0.3545, mask: 0.3538\n",
      "step:   177260, time: 0.730, loss: 1.0863, l1: 0.2394, vgg: 0.4651, mask: 0.3818\n",
      "step:   177280, time: 0.749, loss: 0.9869, l1: 0.1785, vgg: 0.4233, mask: 0.3850\n",
      "step:   177300, time: 0.747, loss: 1.1639, l1: 0.3118, vgg: 0.4191, mask: 0.4330\n",
      "step:   177320, time: 0.778, loss: 1.0766, l1: 0.2366, vgg: 0.4560, mask: 0.3840\n",
      "step:   177340, time: 0.753, loss: 1.0137, l1: 0.2153, vgg: 0.4228, mask: 0.3755\n",
      "step:   177360, time: 0.751, loss: 1.1022, l1: 0.2228, vgg: 0.4759, mask: 0.4035\n",
      "step:   177380, time: 0.722, loss: 0.8304, l1: 0.1416, vgg: 0.3610, mask: 0.3277\n",
      "step:   177400, time: 0.740, loss: 0.9419, l1: 0.2072, vgg: 0.3778, mask: 0.3569\n",
      "step:   177420, time: 0.757, loss: 1.0673, l1: 0.2807, vgg: 0.3932, mask: 0.3934\n",
      "step:   177440, time: 0.750, loss: 1.1103, l1: 0.2798, vgg: 0.4210, mask: 0.4095\n",
      "step:   177460, time: 0.727, loss: 0.8394, l1: 0.1457, vgg: 0.3609, mask: 0.3328\n",
      "step:   177480, time: 0.768, loss: 1.0307, l1: 0.1716, vgg: 0.4679, mask: 0.3912\n",
      "step:   177500, time: 0.732, loss: 0.9335, l1: 0.1723, vgg: 0.3632, mask: 0.3981\n",
      "step:   177520, time: 0.748, loss: 0.9486, l1: 0.1998, vgg: 0.3953, mask: 0.3535\n",
      "step:   177540, time: 0.775, loss: 1.0469, l1: 0.2317, vgg: 0.4161, mask: 0.3991\n",
      "step:   177560, time: 0.738, loss: 1.0453, l1: 0.2499, vgg: 0.4070, mask: 0.3884\n",
      "step:   177580, time: 0.767, loss: 1.1213, l1: 0.2274, vgg: 0.4717, mask: 0.4222\n",
      "step:   177600, time: 0.777, loss: 1.0627, l1: 0.2269, vgg: 0.4167, mask: 0.4191\n",
      "step:   177620, time: 0.741, loss: 0.9963, l1: 0.1743, vgg: 0.4385, mask: 0.3835\n",
      "step:   177640, time: 0.759, loss: 1.0941, l1: 0.2470, vgg: 0.4532, mask: 0.3940\n",
      "step:   177660, time: 0.782, loss: 1.0244, l1: 0.2118, vgg: 0.4298, mask: 0.3828\n",
      "step:   177680, time: 0.761, loss: 1.0185, l1: 0.2007, vgg: 0.4157, mask: 0.4021\n",
      "step:   177700, time: 0.833, loss: 1.1190, l1: 0.3072, vgg: 0.4009, mask: 0.4109\n",
      "step:   177720, time: 0.774, loss: 1.0736, l1: 0.2100, vgg: 0.4913, mask: 0.3724\n",
      "step:   177740, time: 0.742, loss: 1.0057, l1: 0.2018, vgg: 0.4516, mask: 0.3523\n",
      "step:   177760, time: 0.745, loss: 1.0409, l1: 0.2455, vgg: 0.4331, mask: 0.3622\n",
      "step:   177780, time: 0.719, loss: 0.9196, l1: 0.1689, vgg: 0.3875, mask: 0.3631\n",
      "step:   177800, time: 0.282, loss: 1.3588, l1: 0.2880, vgg: 0.6521, mask: 0.4187\n",
      "step:   177820, time: 0.745, loss: 1.0299, l1: 0.2558, vgg: 0.3937, mask: 0.3804\n",
      "step:   177840, time: 0.781, loss: 0.9104, l1: 0.1935, vgg: 0.3422, mask: 0.3748\n",
      "step:   177860, time: 0.773, loss: 1.1541, l1: 0.2472, vgg: 0.5096, mask: 0.3973\n",
      "step:   177880, time: 0.727, loss: 0.9341, l1: 0.1807, vgg: 0.3875, mask: 0.3658\n",
      "step:   177900, time: 0.766, loss: 1.1443, l1: 0.2252, vgg: 0.5427, mask: 0.3764\n",
      "step:   177920, time: 0.734, loss: 1.0308, l1: 0.2051, vgg: 0.4185, mask: 0.4072\n",
      "step:   177940, time: 0.736, loss: 1.0648, l1: 0.2117, vgg: 0.4659, mask: 0.3871\n",
      "step:   177960, time: 0.730, loss: 0.9456, l1: 0.1889, vgg: 0.3674, mask: 0.3894\n",
      "step:   177980, time: 0.737, loss: 0.9867, l1: 0.1973, vgg: 0.3965, mask: 0.3930\n",
      "step:   178000, time: 0.755, loss: 1.0056, l1: 0.1846, vgg: 0.4478, mask: 0.3731\n",
      "step:   178020, time: 0.719, loss: 0.9189, l1: 0.1836, vgg: 0.3691, mask: 0.3662\n",
      "step:   178040, time: 0.729, loss: 0.9148, l1: 0.2208, vgg: 0.3296, mask: 0.3644\n",
      "step:   178060, time: 0.734, loss: 0.9534, l1: 0.2069, vgg: 0.3892, mask: 0.3573\n",
      "step:   178080, time: 0.787, loss: 1.1726, l1: 0.3059, vgg: 0.4373, mask: 0.4294\n",
      "step:   178100, time: 0.734, loss: 0.9347, l1: 0.1480, vgg: 0.4085, mask: 0.3782\n",
      "step:   178120, time: 0.713, loss: 0.9503, l1: 0.1992, vgg: 0.3777, mask: 0.3734\n",
      "step:   178140, time: 0.764, loss: 1.0127, l1: 0.2244, vgg: 0.4089, mask: 0.3795\n",
      "step:   178160, time: 0.760, loss: 1.1351, l1: 0.2404, vgg: 0.5247, mask: 0.3700\n",
      "step:   178180, time: 0.747, loss: 0.9306, l1: 0.2149, vgg: 0.3405, mask: 0.3752\n",
      "step:   178200, time: 0.782, loss: 1.1469, l1: 0.2406, vgg: 0.5550, mask: 0.3513\n",
      "step:   178220, time: 0.759, loss: 1.1113, l1: 0.2473, vgg: 0.4393, mask: 0.4246\n",
      "step:   178240, time: 0.777, loss: 0.9885, l1: 0.1748, vgg: 0.4333, mask: 0.3804\n",
      "step:   178260, time: 0.767, loss: 1.1048, l1: 0.2443, vgg: 0.4890, mask: 0.3716\n",
      "step:   178280, time: 0.786, loss: 0.9783, l1: 0.1554, vgg: 0.4871, mask: 0.3358\n",
      "step:   178300, time: 0.730, loss: 0.8812, l1: 0.1951, vgg: 0.3179, mask: 0.3682\n",
      "step:   178320, time: 0.738, loss: 0.9829, l1: 0.2297, vgg: 0.3616, mask: 0.3916\n",
      "step:   178340, time: 0.719, loss: 0.9518, l1: 0.2134, vgg: 0.3396, mask: 0.3987\n",
      "step:   178360, time: 0.717, loss: 0.9145, l1: 0.1670, vgg: 0.4041, mask: 0.3434\n",
      "step:   178380, time: 0.724, loss: 0.9338, l1: 0.1844, vgg: 0.4020, mask: 0.3474\n",
      "step:   178400, time: 0.759, loss: 1.0818, l1: 0.2274, vgg: 0.4422, mask: 0.4123\n",
      "step:   178420, time: 0.759, loss: 1.0835, l1: 0.2201, vgg: 0.4608, mask: 0.4026\n",
      "step:   178440, time: 0.747, loss: 0.9684, l1: 0.1968, vgg: 0.3948, mask: 0.3769\n",
      "step:   178460, time: 0.758, loss: 1.0498, l1: 0.2254, vgg: 0.4012, mask: 0.4233\n",
      "step:   178480, time: 0.800, loss: 0.9965, l1: 0.2061, vgg: 0.4322, mask: 0.3582\n",
      "step:   178500, time: 0.753, loss: 1.0760, l1: 0.2450, vgg: 0.4163, mask: 0.4147\n",
      "step:   178520, time: 0.739, loss: 0.9712, l1: 0.2036, vgg: 0.3899, mask: 0.3777\n",
      "step:   178540, time: 0.712, loss: 0.9317, l1: 0.1706, vgg: 0.3997, mask: 0.3615\n",
      "step:   178560, time: 0.769, loss: 1.0326, l1: 0.2132, vgg: 0.4151, mask: 0.4043\n",
      "step:   178580, time: 0.748, loss: 1.0177, l1: 0.2140, vgg: 0.4457, mask: 0.3580\n",
      "step:   178600, time: 0.747, loss: 0.8654, l1: 0.1675, vgg: 0.3437, mask: 0.3542\n",
      "step:   178620, time: 0.751, loss: 1.0003, l1: 0.2212, vgg: 0.3707, mask: 0.4084\n",
      "step:   178640, time: 0.732, loss: 1.0907, l1: 0.2618, vgg: 0.4037, mask: 0.4252\n",
      "step:   178660, time: 0.765, loss: 1.0287, l1: 0.2104, vgg: 0.3992, mask: 0.4191\n",
      "step:   178680, time: 0.754, loss: 0.9339, l1: 0.1892, vgg: 0.3781, mask: 0.3665\n",
      "step:   178700, time: 0.754, loss: 1.0562, l1: 0.1955, vgg: 0.4890, mask: 0.3717\n",
      "step:   178720, time: 0.754, loss: 0.8944, l1: 0.1185, vgg: 0.4500, mask: 0.3259\n",
      "step:   178740, time: 0.758, loss: 1.0938, l1: 0.2370, vgg: 0.4764, mask: 0.3804\n",
      "step:   178760, time: 0.742, loss: 1.0612, l1: 0.2141, vgg: 0.4515, mask: 0.3956\n",
      "step:   178780, time: 0.738, loss: 1.0726, l1: 0.2461, vgg: 0.4214, mask: 0.4051\n",
      "step:   178800, time: 0.751, loss: 1.1182, l1: 0.2586, vgg: 0.4485, mask: 0.4111\n",
      "step:   178820, time: 0.741, loss: 1.0841, l1: 0.2643, vgg: 0.3992, mask: 0.4206\n",
      "step:   178840, time: 0.799, loss: 1.0723, l1: 0.2236, vgg: 0.4530, mask: 0.3958\n",
      "step:   178860, time: 0.732, loss: 0.9408, l1: 0.1985, vgg: 0.3880, mask: 0.3543\n",
      "step:   178880, time: 0.772, loss: 0.9981, l1: 0.2206, vgg: 0.3756, mask: 0.4019\n",
      "step:   178900, time: 0.804, loss: 1.0638, l1: 0.2387, vgg: 0.4056, mask: 0.4194\n",
      "step:   178920, time: 0.742, loss: 1.1213, l1: 0.2609, vgg: 0.4676, mask: 0.3928\n",
      "step:   178940, time: 0.768, loss: 1.0258, l1: 0.1909, vgg: 0.4319, mask: 0.4030\n",
      "step:   178960, time: 0.744, loss: 0.9893, l1: 0.1779, vgg: 0.4668, mask: 0.3446\n",
      "step:   178980, time: 0.769, loss: 0.9986, l1: 0.2068, vgg: 0.4072, mask: 0.3846\n",
      "step:   179000, time: 0.800, loss: 0.9922, l1: 0.1961, vgg: 0.4344, mask: 0.3618\n",
      "step:   179020, time: 0.746, loss: 0.9923, l1: 0.1817, vgg: 0.4676, mask: 0.3430\n",
      "step:   179040, time: 0.759, loss: 0.9318, l1: 0.1586, vgg: 0.4175, mask: 0.3557\n",
      "step:   179060, time: 0.737, loss: 1.0164, l1: 0.1874, vgg: 0.4511, mask: 0.3779\n",
      "step:   179080, time: 0.717, loss: 0.8896, l1: 0.1413, vgg: 0.4021, mask: 0.3462\n",
      "step:   179100, time: 0.719, loss: 0.8593, l1: 0.1637, vgg: 0.3640, mask: 0.3315\n",
      "step:   179120, time: 0.744, loss: 0.9405, l1: 0.1651, vgg: 0.3985, mask: 0.3770\n",
      "step:   179140, time: 0.736, loss: 0.9839, l1: 0.2051, vgg: 0.4001, mask: 0.3787\n",
      "step:   179160, time: 0.748, loss: 1.0088, l1: 0.2235, vgg: 0.3784, mask: 0.4068\n",
      "step:   179180, time: 0.744, loss: 1.0441, l1: 0.2308, vgg: 0.4373, mask: 0.3760\n",
      "step:   179200, time: 0.751, loss: 1.1164, l1: 0.2674, vgg: 0.4519, mask: 0.3971\n",
      "step:   179220, time: 0.753, loss: 1.0109, l1: 0.2288, vgg: 0.3921, mask: 0.3900\n",
      "step:   179240, time: 0.755, loss: 1.0229, l1: 0.2099, vgg: 0.4160, mask: 0.3970\n",
      "step:   179260, time: 0.733, loss: 0.9802, l1: 0.1930, vgg: 0.3870, mask: 0.4002\n",
      "step:   179280, time: 0.771, loss: 1.0638, l1: 0.2435, vgg: 0.3861, mask: 0.4341\n",
      "step:   179300, time: 0.767, loss: 1.0195, l1: 0.2058, vgg: 0.4429, mask: 0.3707\n",
      "step:   179320, time: 0.751, loss: 1.0611, l1: 0.2158, vgg: 0.4785, mask: 0.3669\n",
      "step:   179340, time: 0.711, loss: 0.9639, l1: 0.2141, vgg: 0.3643, mask: 0.3855\n",
      "step:   179360, time: 0.762, loss: 0.9638, l1: 0.2213, vgg: 0.3766, mask: 0.3658\n",
      "step:   179380, time: 0.745, loss: 0.9887, l1: 0.2403, vgg: 0.3586, mask: 0.3898\n",
      "step:   179400, time: 0.710, loss: 0.9118, l1: 0.1619, vgg: 0.3773, mask: 0.3727\n",
      "step:   179420, time: 0.754, loss: 0.9929, l1: 0.2463, vgg: 0.3636, mask: 0.3829\n",
      "step:   179440, time: 0.724, loss: 1.0264, l1: 0.2222, vgg: 0.3883, mask: 0.4159\n",
      "step:   179460, time: 0.757, loss: 0.9660, l1: 0.1863, vgg: 0.3988, mask: 0.3810\n",
      "step:   179480, time: 0.767, loss: 1.0297, l1: 0.2041, vgg: 0.4301, mask: 0.3955\n",
      "step:   179500, time: 0.769, loss: 1.0774, l1: 0.2605, vgg: 0.4034, mask: 0.4134\n",
      "step:   179520, time: 0.749, loss: 0.9711, l1: 0.2068, vgg: 0.3902, mask: 0.3741\n",
      "step:   179540, time: 0.741, loss: 0.9488, l1: 0.1927, vgg: 0.3905, mask: 0.3656\n",
      "step:   179560, time: 0.749, loss: 1.0293, l1: 0.2212, vgg: 0.3985, mask: 0.4097\n",
      "step:   179580, time: 0.774, loss: 1.0802, l1: 0.2467, vgg: 0.4338, mask: 0.3997\n",
      "step:   179600, time: 0.740, loss: 1.0324, l1: 0.2338, vgg: 0.4001, mask: 0.3985\n",
      "step:   179620, time: 0.763, loss: 0.9574, l1: 0.1971, vgg: 0.3998, mask: 0.3605\n",
      "step:   179640, time: 0.738, loss: 1.0276, l1: 0.2187, vgg: 0.4390, mask: 0.3700\n",
      "step:   179660, time: 0.786, loss: 1.0788, l1: 0.2354, vgg: 0.4629, mask: 0.3805\n",
      "step:   179680, time: 0.772, loss: 1.0809, l1: 0.2596, vgg: 0.4289, mask: 0.3924\n",
      "step:   179700, time: 0.767, loss: 0.9800, l1: 0.2182, vgg: 0.3752, mask: 0.3866\n",
      "step:   179720, time: 0.759, loss: 1.1842, l1: 0.2924, vgg: 0.4786, mask: 0.4132\n",
      "step:   179740, time: 0.756, loss: 1.0131, l1: 0.2098, vgg: 0.3392, mask: 0.4641\n",
      "step:   179760, time: 0.751, loss: 0.9997, l1: 0.1700, vgg: 0.4607, mask: 0.3690\n",
      "step:   179780, time: 0.732, loss: 1.0210, l1: 0.1985, vgg: 0.4373, mask: 0.3852\n",
      "step:   179800, time: 0.733, loss: 1.0320, l1: 0.2150, vgg: 0.4388, mask: 0.3781\n",
      "step:   179820, time: 0.718, loss: 1.0270, l1: 0.1880, vgg: 0.4770, mask: 0.3619\n",
      "step:   179840, time: 0.815, loss: 1.0234, l1: 0.2019, vgg: 0.4109, mask: 0.4106\n",
      "step:   179860, time: 0.731, loss: 0.8705, l1: 0.1472, vgg: 0.4022, mask: 0.3210\n",
      "step:   179880, time: 0.758, loss: 1.0229, l1: 0.2041, vgg: 0.4384, mask: 0.3804\n",
      "step:   179900, time: 0.741, loss: 0.9428, l1: 0.2107, vgg: 0.3910, mask: 0.3412\n",
      "step:   179920, time: 0.756, loss: 1.0720, l1: 0.2361, vgg: 0.4802, mask: 0.3557\n",
      "step:   179940, time: 0.763, loss: 0.9402, l1: 0.2078, vgg: 0.3488, mask: 0.3836\n",
      "step:   179960, time: 0.727, loss: 0.9646, l1: 0.2203, vgg: 0.3718, mask: 0.3725\n",
      "step:   179980, time: 0.725, loss: 0.9028, l1: 0.2028, vgg: 0.3493, mask: 0.3507\n",
      "step:   180000, time: 0.768, loss: 1.0533, l1: 0.2119, vgg: 0.4637, mask: 0.3777\n",
      "step:   180020, time: 0.778, loss: 1.1006, l1: 0.2393, vgg: 0.4651, mask: 0.3963\n",
      "step:   180040, time: 0.706, loss: 0.8709, l1: 0.1967, vgg: 0.2995, mask: 0.3747\n",
      "step:   180060, time: 0.763, loss: 0.9720, l1: 0.1719, vgg: 0.4220, mask: 0.3780\n",
      "step:   180080, time: 0.757, loss: 0.9279, l1: 0.1781, vgg: 0.3963, mask: 0.3535\n",
      "step:   180100, time: 0.729, loss: 0.9410, l1: 0.1720, vgg: 0.4017, mask: 0.3673\n",
      "step:   180120, time: 0.752, loss: 0.9585, l1: 0.2093, vgg: 0.3506, mask: 0.3987\n",
      "step:   180140, time: 0.771, loss: 1.1372, l1: 0.2487, vgg: 0.4638, mask: 0.4246\n",
      "step:   180160, time: 0.743, loss: 0.9908, l1: 0.1594, vgg: 0.4881, mask: 0.3434\n",
      "step:   180180, time: 0.745, loss: 0.9595, l1: 0.1890, vgg: 0.3329, mask: 0.4376\n",
      "step:   180200, time: 0.801, loss: 0.9960, l1: 0.2206, vgg: 0.3605, mask: 0.4149\n",
      "step:   180220, time: 0.802, loss: 0.9720, l1: 0.2453, vgg: 0.3413, mask: 0.3854\n",
      "step:   180240, time: 0.749, loss: 0.9856, l1: 0.2362, vgg: 0.3754, mask: 0.3740\n",
      "step:   180260, time: 0.785, loss: 1.0787, l1: 0.2219, vgg: 0.4572, mask: 0.3995\n",
      "step:   180280, time: 0.796, loss: 1.0645, l1: 0.2114, vgg: 0.4739, mask: 0.3792\n",
      "step:   180300, time: 0.756, loss: 1.1001, l1: 0.2654, vgg: 0.4480, mask: 0.3867\n",
      "step:   180320, time: 0.740, loss: 1.1019, l1: 0.2512, vgg: 0.4374, mask: 0.4133\n",
      "step:   180340, time: 0.765, loss: 1.1530, l1: 0.2740, vgg: 0.4382, mask: 0.4407\n",
      "step:   180360, time: 0.752, loss: 0.9449, l1: 0.1471, vgg: 0.4544, mask: 0.3434\n",
      "step:   180380, time: 0.769, loss: 1.0162, l1: 0.2014, vgg: 0.4272, mask: 0.3877\n",
      "step:   180400, time: 0.757, loss: 1.0250, l1: 0.2143, vgg: 0.4558, mask: 0.3549\n",
      "step:   180420, time: 0.800, loss: 1.0176, l1: 0.2372, vgg: 0.3990, mask: 0.3813\n",
      "step:   180440, time: 0.735, loss: 1.0062, l1: 0.2282, vgg: 0.4096, mask: 0.3683\n",
      "step:   180460, time: 0.753, loss: 1.0909, l1: 0.2206, vgg: 0.4466, mask: 0.4237\n",
      "step:   180480, time: 0.837, loss: 1.0726, l1: 0.2104, vgg: 0.4526, mask: 0.4096\n",
      "step:   180500, time: 0.761, loss: 1.0220, l1: 0.2100, vgg: 0.4364, mask: 0.3756\n",
      "step:   180520, time: 0.739, loss: 0.9469, l1: 0.1803, vgg: 0.4109, mask: 0.3557\n",
      "step:   180540, time: 0.815, loss: 1.0185, l1: 0.2173, vgg: 0.4295, mask: 0.3717\n",
      "step:   180560, time: 0.726, loss: 0.9714, l1: 0.2112, vgg: 0.3667, mask: 0.3935\n",
      "step:   180580, time: 0.743, loss: 0.9452, l1: 0.2225, vgg: 0.3453, mask: 0.3773\n",
      "step:   180600, time: 0.727, loss: 0.8547, l1: 0.1510, vgg: 0.3533, mask: 0.3503\n",
      "step:   180620, time: 0.739, loss: 0.9073, l1: 0.1851, vgg: 0.3608, mask: 0.3613\n",
      "step:   180640, time: 0.767, loss: 0.9865, l1: 0.2355, vgg: 0.3928, mask: 0.3583\n",
      "step:   180660, time: 0.770, loss: 1.0427, l1: 0.2185, vgg: 0.4684, mask: 0.3558\n",
      "step:   180680, time: 0.740, loss: 1.0443, l1: 0.2387, vgg: 0.4247, mask: 0.3809\n",
      "step:   180700, time: 0.755, loss: 1.0209, l1: 0.2214, vgg: 0.4060, mask: 0.3935\n",
      "step:   180720, time: 0.738, loss: 0.9891, l1: 0.2090, vgg: 0.3729, mask: 0.4073\n",
      "step:   180740, time: 0.756, loss: 1.0208, l1: 0.2302, vgg: 0.4276, mask: 0.3630\n",
      "step:   180760, time: 0.775, loss: 1.0219, l1: 0.2229, vgg: 0.4270, mask: 0.3720\n",
      "step:   180780, time: 0.764, loss: 1.0094, l1: 0.2252, vgg: 0.4136, mask: 0.3705\n",
      "step:   180800, time: 0.766, loss: 1.0896, l1: 0.2753, vgg: 0.4158, mask: 0.3986\n",
      "step:   180820, time: 0.741, loss: 0.9922, l1: 0.2322, vgg: 0.3852, mask: 0.3748\n",
      "step:   180840, time: 0.729, loss: 0.9253, l1: 0.1658, vgg: 0.3773, mask: 0.3821\n",
      "step:   180860, time: 0.725, loss: 0.9073, l1: 0.1631, vgg: 0.3873, mask: 0.3569\n",
      "step:   180880, time: 0.763, loss: 1.0305, l1: 0.2120, vgg: 0.4501, mask: 0.3685\n",
      "step:   180900, time: 0.755, loss: 1.0628, l1: 0.2561, vgg: 0.3999, mask: 0.4069\n",
      "step:   180920, time: 0.742, loss: 0.9316, l1: 0.1554, vgg: 0.3820, mask: 0.3942\n",
      "step:   180940, time: 0.775, loss: 1.0405, l1: 0.2054, vgg: 0.4531, mask: 0.3820\n",
      "step:   180960, time: 0.736, loss: 0.9605, l1: 0.1746, vgg: 0.4227, mask: 0.3633\n",
      "step:   180980, time: 0.719, loss: 0.9735, l1: 0.1865, vgg: 0.3997, mask: 0.3872\n",
      "step:   181000, time: 0.749, loss: 1.0140, l1: 0.2200, vgg: 0.4001, mask: 0.3940\n",
      "step:   181020, time: 0.730, loss: 1.1221, l1: 0.2699, vgg: 0.4691, mask: 0.3830\n",
      "step:   181040, time: 0.767, loss: 1.2059, l1: 0.2982, vgg: 0.4651, mask: 0.4426\n",
      "step:   181060, time: 0.754, loss: 1.0919, l1: 0.2483, vgg: 0.4497, mask: 0.3939\n",
      "step:   181080, time: 0.747, loss: 1.1157, l1: 0.2741, vgg: 0.4370, mask: 0.4046\n",
      "step:   181100, time: 0.740, loss: 1.0209, l1: 0.2082, vgg: 0.4367, mask: 0.3761\n",
      "step:   181120, time: 0.765, loss: 1.0075, l1: 0.1936, vgg: 0.4521, mask: 0.3618\n",
      "step:   181140, time: 0.754, loss: 1.1079, l1: 0.2478, vgg: 0.4661, mask: 0.3939\n",
      "step:   181160, time: 0.759, loss: 1.0053, l1: 0.2051, vgg: 0.4066, mask: 0.3936\n",
      "step:   181180, time: 0.742, loss: 0.9336, l1: 0.1604, vgg: 0.3550, mask: 0.4183\n",
      "step:   181200, time: 0.756, loss: 0.9290, l1: 0.1872, vgg: 0.3769, mask: 0.3649\n",
      "step:   181220, time: 0.740, loss: 0.9463, l1: 0.2024, vgg: 0.3594, mask: 0.3845\n",
      "step:   181240, time: 0.742, loss: 1.0994, l1: 0.2467, vgg: 0.4383, mask: 0.4143\n",
      "step:   181260, time: 0.749, loss: 1.0133, l1: 0.2034, vgg: 0.4266, mask: 0.3833\n",
      "step:   181280, time: 0.758, loss: 1.0396, l1: 0.2366, vgg: 0.4230, mask: 0.3800\n",
      "step:   181300, time: 0.752, loss: 0.9845, l1: 0.1699, vgg: 0.4331, mask: 0.3814\n",
      "step:   181320, time: 0.762, loss: 1.0133, l1: 0.2138, vgg: 0.4144, mask: 0.3852\n",
      "step:   181340, time: 0.740, loss: 0.9669, l1: 0.1884, vgg: 0.4326, mask: 0.3459\n",
      "step:   181360, time: 0.737, loss: 0.9999, l1: 0.2261, vgg: 0.3985, mask: 0.3753\n",
      "step:   181380, time: 0.736, loss: 1.0209, l1: 0.2187, vgg: 0.4139, mask: 0.3884\n",
      "step:   181400, time: 0.780, loss: 1.1405, l1: 0.2488, vgg: 0.4824, mask: 0.4093\n",
      "step:   181420, time: 0.723, loss: 0.8984, l1: 0.1923, vgg: 0.3466, mask: 0.3595\n",
      "step:   181440, time: 0.768, loss: 0.9658, l1: 0.1676, vgg: 0.3936, mask: 0.4047\n",
      "step:   181460, time: 0.738, loss: 1.0466, l1: 0.2435, vgg: 0.4128, mask: 0.3904\n",
      "step:   181480, time: 0.759, loss: 0.9844, l1: 0.1525, vgg: 0.4591, mask: 0.3728\n",
      "step:   181500, time: 0.757, loss: 0.9635, l1: 0.1935, vgg: 0.4080, mask: 0.3620\n",
      "step:   181520, time: 0.741, loss: 0.9753, l1: 0.1873, vgg: 0.4297, mask: 0.3583\n",
      "step:   181540, time: 0.754, loss: 0.9896, l1: 0.2212, vgg: 0.3753, mask: 0.3932\n",
      "step:   181560, time: 0.789, loss: 0.9553, l1: 0.1917, vgg: 0.4020, mask: 0.3617\n",
      "step:   181580, time: 0.800, loss: 0.9619, l1: 0.1561, vgg: 0.4230, mask: 0.3829\n",
      "step:   181600, time: 0.749, loss: 1.1140, l1: 0.2519, vgg: 0.4560, mask: 0.4061\n",
      "step:   181620, time: 0.791, loss: 1.0217, l1: 0.2578, vgg: 0.3700, mask: 0.3940\n",
      "step:   181640, time: 0.758, loss: 1.1069, l1: 0.2276, vgg: 0.4989, mask: 0.3805\n",
      "step:   181660, time: 0.753, loss: 0.9896, l1: 0.2317, vgg: 0.3695, mask: 0.3885\n",
      "step:   181680, time: 0.726, loss: 1.0743, l1: 0.2045, vgg: 0.5095, mask: 0.3603\n",
      "step:   181700, time: 0.725, loss: 0.9739, l1: 0.2220, vgg: 0.3714, mask: 0.3805\n",
      "step:   181720, time: 0.750, loss: 1.0830, l1: 0.2515, vgg: 0.4209, mask: 0.4107\n",
      "step:   181740, time: 0.748, loss: 0.9748, l1: 0.2194, vgg: 0.4243, mask: 0.3311\n",
      "step:   181760, time: 0.739, loss: 0.9696, l1: 0.1718, vgg: 0.4295, mask: 0.3683\n",
      "step:   181780, time: 0.761, loss: 0.9295, l1: 0.1619, vgg: 0.3715, mask: 0.3962\n",
      "step:   181800, time: 0.746, loss: 0.8423, l1: 0.1739, vgg: 0.3338, mask: 0.3346\n",
      "step:   181820, time: 0.796, loss: 1.0563, l1: 0.1974, vgg: 0.4595, mask: 0.3994\n",
      "step:   181840, time: 0.752, loss: 0.9566, l1: 0.2035, vgg: 0.3745, mask: 0.3786\n",
      "step:   181860, time: 0.735, loss: 1.0067, l1: 0.1969, vgg: 0.4293, mask: 0.3805\n",
      "step:   181880, time: 0.759, loss: 0.8935, l1: 0.1950, vgg: 0.3477, mask: 0.3508\n",
      "step:   181900, time: 0.774, loss: 1.0009, l1: 0.2106, vgg: 0.4139, mask: 0.3764\n",
      "step:   181920, time: 0.730, loss: 0.9305, l1: 0.2098, vgg: 0.3446, mask: 0.3761\n",
      "step:   181940, time: 0.737, loss: 1.0228, l1: 0.2523, vgg: 0.3754, mask: 0.3950\n",
      "step:   181960, time: 0.780, loss: 1.0782, l1: 0.2393, vgg: 0.4419, mask: 0.3970\n",
      "step:   181980, time: 0.734, loss: 0.9666, l1: 0.1951, vgg: 0.3835, mask: 0.3879\n",
      "step:   182000, time: 0.787, loss: 1.1717, l1: 0.2261, vgg: 0.5571, mask: 0.3885\n",
      "step:   182020, time: 0.759, loss: 1.1171, l1: 0.2605, vgg: 0.4506, mask: 0.4060\n",
      "step:   182040, time: 0.747, loss: 0.9164, l1: 0.1608, vgg: 0.3976, mask: 0.3580\n",
      "step:   182060, time: 0.749, loss: 1.0387, l1: 0.2336, vgg: 0.4117, mask: 0.3934\n",
      "step:   182080, time: 0.767, loss: 0.9869, l1: 0.2012, vgg: 0.3951, mask: 0.3906\n",
      "step:   182100, time: 0.729, loss: 0.9953, l1: 0.2162, vgg: 0.4067, mask: 0.3725\n",
      "step:   182120, time: 0.738, loss: 0.9582, l1: 0.1791, vgg: 0.3881, mask: 0.3910\n",
      "step:   182140, time: 0.752, loss: 1.0307, l1: 0.2329, vgg: 0.4101, mask: 0.3878\n",
      "step:   182160, time: 0.770, loss: 1.0509, l1: 0.2299, vgg: 0.4402, mask: 0.3808\n",
      "step:   182180, time: 0.801, loss: 0.8794, l1: 0.1739, vgg: 0.3875, mask: 0.3179\n",
      "step:   182200, time: 0.780, loss: 1.1321, l1: 0.2379, vgg: 0.4863, mask: 0.4080\n",
      "step:   182220, time: 0.726, loss: 0.8821, l1: 0.1555, vgg: 0.3945, mask: 0.3321\n",
      "step:   182240, time: 0.772, loss: 1.0654, l1: 0.2166, vgg: 0.4461, mask: 0.4026\n",
      "step:   182260, time: 0.794, loss: 1.0053, l1: 0.2076, vgg: 0.3738, mask: 0.4238\n",
      "step:   182280, time: 0.757, loss: 1.0048, l1: 0.2178, vgg: 0.3954, mask: 0.3916\n",
      "step:   182300, time: 0.733, loss: 0.9688, l1: 0.1762, vgg: 0.4436, mask: 0.3490\n",
      "step:   182320, time: 0.720, loss: 0.8733, l1: 0.1354, vgg: 0.3555, mask: 0.3824\n",
      "step:   182340, time: 0.740, loss: 1.0506, l1: 0.2493, vgg: 0.4102, mask: 0.3910\n",
      "step:   182360, time: 0.737, loss: 0.9294, l1: 0.1838, vgg: 0.3832, mask: 0.3624\n",
      "step:   182380, time: 0.778, loss: 0.9544, l1: 0.2040, vgg: 0.3802, mask: 0.3702\n",
      "step:   182400, time: 0.735, loss: 1.0986, l1: 0.2943, vgg: 0.3970, mask: 0.4073\n",
      "step:   182420, time: 0.733, loss: 1.0288, l1: 0.2158, vgg: 0.4305, mask: 0.3825\n",
      "step:   182440, time: 0.746, loss: 0.9903, l1: 0.2368, vgg: 0.3700, mask: 0.3835\n",
      "step:   182460, time: 0.749, loss: 0.8678, l1: 0.1638, vgg: 0.3638, mask: 0.3402\n",
      "step:   182480, time: 0.756, loss: 0.9641, l1: 0.2011, vgg: 0.4008, mask: 0.3622\n",
      "step:   182500, time: 0.744, loss: 1.0103, l1: 0.1910, vgg: 0.4263, mask: 0.3930\n",
      "step:   182520, time: 0.755, loss: 0.9886, l1: 0.1829, vgg: 0.4464, mask: 0.3594\n",
      "step:   182540, time: 0.739, loss: 0.9644, l1: 0.1672, vgg: 0.4323, mask: 0.3649\n",
      "step:   182560, time: 0.730, loss: 0.9504, l1: 0.1789, vgg: 0.4095, mask: 0.3620\n",
      "step:   182580, time: 0.761, loss: 1.0977, l1: 0.2068, vgg: 0.4798, mask: 0.4111\n",
      "step:   182600, time: 0.753, loss: 1.0387, l1: 0.1996, vgg: 0.4565, mask: 0.3825\n",
      "step:   182620, time: 0.744, loss: 1.1220, l1: 0.2192, vgg: 0.4974, mask: 0.4053\n",
      "step:   182640, time: 0.725, loss: 0.9214, l1: 0.2119, vgg: 0.3229, mask: 0.3866\n",
      "step:   182660, time: 0.751, loss: 1.0239, l1: 0.1984, vgg: 0.4259, mask: 0.3996\n",
      "step:   182680, time: 0.744, loss: 1.0166, l1: 0.2070, vgg: 0.4084, mask: 0.4012\n",
      "step:   182700, time: 0.790, loss: 1.0325, l1: 0.2319, vgg: 0.4169, mask: 0.3836\n",
      "step:   182720, time: 0.754, loss: 1.0296, l1: 0.2321, vgg: 0.4042, mask: 0.3933\n",
      "step:   182740, time: 0.764, loss: 0.9533, l1: 0.1658, vgg: 0.4050, mask: 0.3825\n",
      "step:   182760, time: 0.733, loss: 1.0550, l1: 0.2576, vgg: 0.4224, mask: 0.3751\n",
      "step:   182780, time: 0.755, loss: 1.0916, l1: 0.2671, vgg: 0.4252, mask: 0.3993\n",
      "step:   182800, time: 0.758, loss: 0.9911, l1: 0.2260, vgg: 0.4052, mask: 0.3599\n",
      "step:   182820, time: 0.753, loss: 0.9546, l1: 0.1707, vgg: 0.4187, mask: 0.3652\n",
      "step:   182840, time: 0.732, loss: 1.0009, l1: 0.2088, vgg: 0.4025, mask: 0.3896\n",
      "step:   182860, time: 0.739, loss: 0.8948, l1: 0.1804, vgg: 0.3429, mask: 0.3715\n",
      "step:   182880, time: 0.771, loss: 1.1516, l1: 0.2975, vgg: 0.4314, mask: 0.4227\n",
      "step:   182900, time: 0.762, loss: 0.9364, l1: 0.1696, vgg: 0.3864, mask: 0.3804\n",
      "step:   182920, time: 0.772, loss: 1.0988, l1: 0.2427, vgg: 0.4797, mask: 0.3763\n",
      "step:   182940, time: 0.748, loss: 0.9965, l1: 0.2125, vgg: 0.3787, mask: 0.4052\n",
      "step:   182960, time: 0.753, loss: 1.0361, l1: 0.2463, vgg: 0.3858, mask: 0.4039\n",
      "step:   182980, time: 0.767, loss: 1.1194, l1: 0.2762, vgg: 0.4406, mask: 0.4026\n",
      "step:   183000, time: 0.737, loss: 0.9501, l1: 0.1874, vgg: 0.4085, mask: 0.3542\n",
      "step:   183020, time: 0.764, loss: 0.9982, l1: 0.2032, vgg: 0.3932, mask: 0.4018\n",
      "step:   183040, time: 0.735, loss: 0.9919, l1: 0.1951, vgg: 0.4231, mask: 0.3736\n",
      "step:   183060, time: 0.759, loss: 1.0451, l1: 0.2163, vgg: 0.4439, mask: 0.3850\n",
      "step:   183080, time: 0.771, loss: 1.0865, l1: 0.2829, vgg: 0.4246, mask: 0.3790\n",
      "step:   183100, time: 0.764, loss: 1.0712, l1: 0.2310, vgg: 0.4168, mask: 0.4234\n",
      "step:   183120, time: 0.749, loss: 0.9428, l1: 0.1695, vgg: 0.4121, mask: 0.3612\n",
      "step:   183140, time: 0.763, loss: 1.1642, l1: 0.2330, vgg: 0.5579, mask: 0.3734\n",
      "step:   183160, time: 0.733, loss: 0.9564, l1: 0.1883, vgg: 0.3989, mask: 0.3691\n",
      "step:   183180, time: 0.746, loss: 1.1036, l1: 0.2504, vgg: 0.4587, mask: 0.3944\n",
      "step:   183200, time: 0.772, loss: 0.8880, l1: 0.1806, vgg: 0.3378, mask: 0.3696\n",
      "step:   183220, time: 0.755, loss: 0.9350, l1: 0.1794, vgg: 0.4133, mask: 0.3423\n",
      "step:   183240, time: 0.790, loss: 0.9278, l1: 0.1612, vgg: 0.4076, mask: 0.3590\n",
      "step:   183260, time: 0.777, loss: 1.1582, l1: 0.3104, vgg: 0.4422, mask: 0.4057\n",
      "step:   183280, time: 0.752, loss: 0.9301, l1: 0.1963, vgg: 0.3514, mask: 0.3824\n",
      "step:   183300, time: 0.778, loss: 1.0671, l1: 0.2339, vgg: 0.4663, mask: 0.3668\n",
      "step:   183320, time: 0.733, loss: 1.0559, l1: 0.2259, vgg: 0.4470, mask: 0.3829\n",
      "step:   183340, time: 0.778, loss: 1.0907, l1: 0.2402, vgg: 0.4898, mask: 0.3607\n",
      "step:   183360, time: 0.796, loss: 1.0976, l1: 0.2484, vgg: 0.4451, mask: 0.4041\n",
      "step:   183380, time: 0.747, loss: 1.0523, l1: 0.2054, vgg: 0.4864, mask: 0.3605\n",
      "step:   183400, time: 0.739, loss: 0.9856, l1: 0.1954, vgg: 0.4425, mask: 0.3478\n",
      "step:   183420, time: 0.731, loss: 1.0658, l1: 0.2402, vgg: 0.4222, mask: 0.4034\n",
      "step:   183440, time: 0.784, loss: 1.0348, l1: 0.2298, vgg: 0.3807, mask: 0.4244\n",
      "step:   183460, time: 0.728, loss: 0.9444, l1: 0.2027, vgg: 0.3328, mask: 0.4089\n",
      "step:   183480, time: 0.743, loss: 0.8807, l1: 0.1657, vgg: 0.3973, mask: 0.3177\n",
      "step:   183500, time: 0.740, loss: 0.9905, l1: 0.2034, vgg: 0.4215, mask: 0.3655\n",
      "step:   183520, time: 0.745, loss: 0.8956, l1: 0.1592, vgg: 0.3775, mask: 0.3589\n",
      "step:   183540, time: 0.733, loss: 0.9264, l1: 0.1756, vgg: 0.3932, mask: 0.3576\n",
      "step:   183560, time: 0.762, loss: 1.2469, l1: 0.2991, vgg: 0.5294, mask: 0.4184\n",
      "step:   183580, time: 0.748, loss: 1.2294, l1: 0.2918, vgg: 0.5179, mask: 0.4198\n",
      "step:   183600, time: 0.758, loss: 0.9246, l1: 0.1547, vgg: 0.4287, mask: 0.3412\n",
      "step:   183620, time: 0.741, loss: 0.9044, l1: 0.1590, vgg: 0.3997, mask: 0.3457\n",
      "step:   183640, time: 0.732, loss: 1.0729, l1: 0.2303, vgg: 0.4453, mask: 0.3972\n",
      "step:   183660, time: 0.723, loss: 0.8953, l1: 0.2094, vgg: 0.3519, mask: 0.3341\n",
      "step:   183680, time: 0.796, loss: 0.8826, l1: 0.1455, vgg: 0.3729, mask: 0.3642\n",
      "step:   183700, time: 0.770, loss: 1.0500, l1: 0.2575, vgg: 0.3756, mask: 0.4169\n",
      "step:   183720, time: 0.745, loss: 1.0325, l1: 0.2465, vgg: 0.3662, mask: 0.4199\n",
      "step:   183740, time: 0.778, loss: 0.9830, l1: 0.1991, vgg: 0.4204, mask: 0.3636\n",
      "step:   183760, time: 0.743, loss: 0.9248, l1: 0.1816, vgg: 0.3799, mask: 0.3633\n",
      "step:   183780, time: 0.737, loss: 1.0524, l1: 0.1636, vgg: 0.4618, mask: 0.4269\n",
      "step:   183800, time: 0.763, loss: 1.1213, l1: 0.2576, vgg: 0.4602, mask: 0.4035\n",
      "step:   183820, time: 0.760, loss: 1.0088, l1: 0.2325, vgg: 0.3808, mask: 0.3956\n",
      "step:   183840, time: 0.780, loss: 1.1003, l1: 0.2721, vgg: 0.4416, mask: 0.3866\n",
      "step:   183860, time: 0.725, loss: 1.0204, l1: 0.1724, vgg: 0.4497, mask: 0.3982\n",
      "step:   183880, time: 0.754, loss: 1.1091, l1: 0.1946, vgg: 0.5222, mask: 0.3923\n",
      "step:   183900, time: 0.761, loss: 1.1130, l1: 0.2598, vgg: 0.4755, mask: 0.3776\n",
      "step:   183920, time: 0.741, loss: 1.0475, l1: 0.2418, vgg: 0.3954, mask: 0.4103\n",
      "step:   183940, time: 0.751, loss: 1.0068, l1: 0.2360, vgg: 0.3377, mask: 0.4330\n",
      "step:   183960, time: 0.738, loss: 1.0504, l1: 0.2216, vgg: 0.4369, mask: 0.3919\n",
      "step:   183980, time: 0.743, loss: 1.0179, l1: 0.2247, vgg: 0.3867, mask: 0.4065\n",
      "step:   184000, time: 0.743, loss: 1.0012, l1: 0.2114, vgg: 0.4431, mask: 0.3468\n",
      "step:   184020, time: 0.785, loss: 1.0298, l1: 0.1873, vgg: 0.4249, mask: 0.4177\n",
      "step:   184040, time: 0.726, loss: 1.0733, l1: 0.2551, vgg: 0.4342, mask: 0.3840\n",
      "step:   184060, time: 0.774, loss: 1.0655, l1: 0.2472, vgg: 0.4393, mask: 0.3789\n",
      "step:   184080, time: 0.829, loss: 0.9694, l1: 0.1666, vgg: 0.4289, mask: 0.3739\n",
      "step:   184100, time: 0.751, loss: 1.0463, l1: 0.2214, vgg: 0.4171, mask: 0.4078\n",
      "step:   184120, time: 0.764, loss: 1.1500, l1: 0.2558, vgg: 0.5069, mask: 0.3872\n",
      "step:   184140, time: 0.753, loss: 1.0284, l1: 0.2202, vgg: 0.4150, mask: 0.3932\n",
      "step:   184160, time: 0.736, loss: 0.9509, l1: 0.2097, vgg: 0.3682, mask: 0.3730\n",
      "step:   184180, time: 0.739, loss: 0.9709, l1: 0.1978, vgg: 0.4011, mask: 0.3719\n",
      "step:   184200, time: 0.744, loss: 0.9060, l1: 0.1652, vgg: 0.3716, mask: 0.3692\n",
      "step:   184220, time: 0.706, loss: 0.9955, l1: 0.2136, vgg: 0.3966, mask: 0.3854\n",
      "step:   184240, time: 0.776, loss: 1.1578, l1: 0.2616, vgg: 0.4768, mask: 0.4194\n",
      "step:   184260, time: 0.825, loss: 1.0892, l1: 0.2251, vgg: 0.4635, mask: 0.4005\n",
      "step:   184280, time: 0.800, loss: 1.0592, l1: 0.2407, vgg: 0.4216, mask: 0.3968\n",
      "step:   184300, time: 0.729, loss: 0.9414, l1: 0.1669, vgg: 0.4091, mask: 0.3654\n",
      "step:   184320, time: 0.748, loss: 1.0186, l1: 0.1733, vgg: 0.4323, mask: 0.4130\n",
      "step:   184340, time: 0.742, loss: 0.9535, l1: 0.1853, vgg: 0.4036, mask: 0.3645\n",
      "step:   184360, time: 0.743, loss: 1.0847, l1: 0.1979, vgg: 0.5088, mask: 0.3780\n",
      "step:   184380, time: 0.729, loss: 1.0381, l1: 0.2175, vgg: 0.4304, mask: 0.3902\n",
      "step:   184400, time: 0.738, loss: 1.0169, l1: 0.2118, vgg: 0.4168, mask: 0.3883\n",
      "step:   184420, time: 0.762, loss: 1.1184, l1: 0.2383, vgg: 0.4847, mask: 0.3954\n",
      "step:   184440, time: 0.741, loss: 0.9340, l1: 0.1910, vgg: 0.3862, mask: 0.3568\n",
      "step:   184460, time: 0.779, loss: 0.9620, l1: 0.1944, vgg: 0.4070, mask: 0.3606\n",
      "step:   184480, time: 0.737, loss: 0.9231, l1: 0.1712, vgg: 0.3746, mask: 0.3773\n",
      "step:   184500, time: 0.761, loss: 1.1801, l1: 0.2755, vgg: 0.4953, mask: 0.4093\n",
      "step:   184520, time: 0.774, loss: 1.1348, l1: 0.2425, vgg: 0.4774, mask: 0.4148\n",
      "step:   184540, time: 0.741, loss: 0.9499, l1: 0.2113, vgg: 0.3827, mask: 0.3559\n",
      "step:   184560, time: 0.749, loss: 1.0046, l1: 0.2364, vgg: 0.3765, mask: 0.3916\n",
      "step:   184580, time: 0.780, loss: 1.0396, l1: 0.2278, vgg: 0.4412, mask: 0.3706\n",
      "step:   184600, time: 0.735, loss: 1.0183, l1: 0.2563, vgg: 0.3730, mask: 0.3889\n",
      "step:   184620, time: 0.750, loss: 1.0750, l1: 0.2294, vgg: 0.4239, mask: 0.4217\n",
      "step:   184640, time: 0.738, loss: 0.9783, l1: 0.2258, vgg: 0.3940, mask: 0.3585\n",
      "step:   184660, time: 0.780, loss: 1.0595, l1: 0.2288, vgg: 0.4342, mask: 0.3965\n",
      "step:   184680, time: 0.753, loss: 1.0272, l1: 0.2388, vgg: 0.4102, mask: 0.3782\n",
      "step:   184700, time: 0.812, loss: 1.0513, l1: 0.2061, vgg: 0.4290, mask: 0.4162\n",
      "step:   184720, time: 0.754, loss: 1.0230, l1: 0.2196, vgg: 0.4375, mask: 0.3659\n",
      "step:   184740, time: 0.790, loss: 0.9217, l1: 0.1728, vgg: 0.3750, mask: 0.3739\n",
      "step:   184760, time: 0.778, loss: 1.0426, l1: 0.2375, vgg: 0.4219, mask: 0.3832\n",
      "step:   184780, time: 0.769, loss: 1.0041, l1: 0.2042, vgg: 0.4308, mask: 0.3691\n",
      "step:   184800, time: 0.756, loss: 1.0423, l1: 0.2176, vgg: 0.4454, mask: 0.3793\n",
      "step:   184820, time: 0.768, loss: 1.0418, l1: 0.2416, vgg: 0.4376, mask: 0.3627\n",
      "step:   184840, time: 0.731, loss: 0.9234, l1: 0.1770, vgg: 0.3961, mask: 0.3502\n",
      "step:   184860, time: 0.779, loss: 1.0477, l1: 0.2176, vgg: 0.4218, mask: 0.4084\n",
      "step:   184880, time: 0.724, loss: 1.0113, l1: 0.2180, vgg: 0.4253, mask: 0.3681\n",
      "step:   184900, time: 0.764, loss: 0.9628, l1: 0.1665, vgg: 0.4129, mask: 0.3835\n",
      "step:   184920, time: 0.718, loss: 0.9145, l1: 0.1766, vgg: 0.3747, mask: 0.3632\n",
      "step:   184940, time: 0.759, loss: 0.9627, l1: 0.1906, vgg: 0.4203, mask: 0.3518\n",
      "step:   184960, time: 0.722, loss: 0.9695, l1: 0.2195, vgg: 0.3899, mask: 0.3601\n",
      "step:   184980, time: 0.755, loss: 0.9469, l1: 0.1609, vgg: 0.4178, mask: 0.3682\n",
      "step:   185000, time: 0.820, loss: 1.0140, l1: 0.2050, vgg: 0.4227, mask: 0.3864\n",
      "step:   185020, time: 0.757, loss: 0.9081, l1: 0.1482, vgg: 0.4156, mask: 0.3443\n",
      "step:   185040, time: 0.779, loss: 1.0443, l1: 0.1929, vgg: 0.4838, mask: 0.3676\n",
      "step:   185060, time: 0.741, loss: 0.9176, l1: 0.1894, vgg: 0.3602, mask: 0.3680\n",
      "step:   185080, time: 0.749, loss: 0.9816, l1: 0.2257, vgg: 0.3863, mask: 0.3695\n",
      "step:   185100, time: 0.750, loss: 0.9820, l1: 0.2009, vgg: 0.3948, mask: 0.3862\n",
      "step:   185120, time: 0.731, loss: 0.9562, l1: 0.1742, vgg: 0.4192, mask: 0.3629\n",
      "step:   185140, time: 0.726, loss: 0.9213, l1: 0.1712, vgg: 0.3809, mask: 0.3692\n",
      "step:   185160, time: 0.756, loss: 0.9812, l1: 0.1992, vgg: 0.4121, mask: 0.3699\n",
      "step:   185180, time: 0.737, loss: 0.9682, l1: 0.1702, vgg: 0.4221, mask: 0.3759\n",
      "step:   185200, time: 0.794, loss: 0.9146, l1: 0.1794, vgg: 0.3598, mask: 0.3754\n",
      "step:   185220, time: 0.810, loss: 1.2761, l1: 0.2959, vgg: 0.5734, mask: 0.4068\n",
      "step:   185240, time: 0.770, loss: 0.8940, l1: 0.1654, vgg: 0.3803, mask: 0.3483\n",
      "step:   185260, time: 0.737, loss: 0.9820, l1: 0.1925, vgg: 0.3959, mask: 0.3936\n",
      "step:   185280, time: 0.732, loss: 0.8866, l1: 0.1425, vgg: 0.3719, mask: 0.3723\n",
      "step:   185300, time: 0.795, loss: 1.1123, l1: 0.2377, vgg: 0.4940, mask: 0.3807\n",
      "step:   185320, time: 0.733, loss: 0.9286, l1: 0.1762, vgg: 0.3706, mask: 0.3818\n",
      "step:   185340, time: 0.766, loss: 0.9597, l1: 0.1908, vgg: 0.4047, mask: 0.3642\n",
      "step:   185360, time: 0.728, loss: 1.0142, l1: 0.2205, vgg: 0.3823, mask: 0.4114\n",
      "step:   185380, time: 0.741, loss: 0.9776, l1: 0.2027, vgg: 0.4000, mask: 0.3749\n",
      "step:   185400, time: 0.768, loss: 0.9923, l1: 0.2231, vgg: 0.4147, mask: 0.3545\n",
      "step:   185420, time: 0.767, loss: 0.8536, l1: 0.1390, vgg: 0.3815, mask: 0.3332\n",
      "step:   185440, time: 0.748, loss: 1.1087, l1: 0.2924, vgg: 0.4178, mask: 0.3985\n",
      "step:   185460, time: 0.759, loss: 0.9431, l1: 0.1783, vgg: 0.3845, mask: 0.3803\n",
      "step:   185480, time: 0.796, loss: 1.1689, l1: 0.2773, vgg: 0.5159, mask: 0.3757\n",
      "step:   185500, time: 0.753, loss: 1.0246, l1: 0.1819, vgg: 0.4746, mask: 0.3681\n",
      "step:   185520, time: 0.742, loss: 0.9468, l1: 0.2063, vgg: 0.3880, mask: 0.3525\n",
      "step:   185540, time: 0.780, loss: 1.0855, l1: 0.2063, vgg: 0.4672, mask: 0.4120\n",
      "step:   185560, time: 0.792, loss: 0.9620, l1: 0.1945, vgg: 0.3994, mask: 0.3681\n",
      "step:   185580, time: 0.753, loss: 0.9951, l1: 0.1832, vgg: 0.4454, mask: 0.3666\n",
      "step:   185600, time: 0.775, loss: 1.0216, l1: 0.2305, vgg: 0.4247, mask: 0.3664\n",
      "step:   185620, time: 0.768, loss: 1.1020, l1: 0.2921, vgg: 0.3984, mask: 0.4114\n",
      "step:   185640, time: 0.780, loss: 0.9998, l1: 0.2037, vgg: 0.4382, mask: 0.3578\n",
      "step:   185660, time: 0.719, loss: 0.9842, l1: 0.2434, vgg: 0.3374, mask: 0.4035\n",
      "step:   185680, time: 0.735, loss: 0.9633, l1: 0.2052, vgg: 0.3776, mask: 0.3804\n",
      "step:   185700, time: 0.740, loss: 0.9076, l1: 0.1746, vgg: 0.3675, mask: 0.3655\n",
      "step:   185720, time: 0.756, loss: 0.9589, l1: 0.2041, vgg: 0.3631, mask: 0.3917\n",
      "step:   185740, time: 0.781, loss: 1.2355, l1: 0.3352, vgg: 0.4440, mask: 0.4563\n",
      "step:   185760, time: 0.791, loss: 0.9782, l1: 0.1710, vgg: 0.4504, mask: 0.3569\n",
      "step:   185780, time: 0.766, loss: 1.1028, l1: 0.2589, vgg: 0.4351, mask: 0.4088\n",
      "step:   185800, time: 0.750, loss: 1.0381, l1: 0.2320, vgg: 0.4031, mask: 0.4029\n",
      "step:   185820, time: 0.778, loss: 1.1151, l1: 0.2482, vgg: 0.4681, mask: 0.3988\n",
      "step:   185840, time: 0.746, loss: 0.9967, l1: 0.2541, vgg: 0.3773, mask: 0.3653\n",
      "step:   185860, time: 0.770, loss: 0.9731, l1: 0.1962, vgg: 0.3975, mask: 0.3793\n",
      "step:   185880, time: 0.738, loss: 0.9617, l1: 0.2154, vgg: 0.3685, mask: 0.3779\n",
      "step:   185900, time: 0.740, loss: 0.9548, l1: 0.2044, vgg: 0.3734, mask: 0.3770\n",
      "step:   185920, time: 0.733, loss: 0.9620, l1: 0.2180, vgg: 0.3668, mask: 0.3771\n",
      "step:   185940, time: 0.765, loss: 1.0754, l1: 0.2026, vgg: 0.5000, mask: 0.3729\n",
      "step:   185960, time: 0.784, loss: 0.9421, l1: 0.1776, vgg: 0.3700, mask: 0.3945\n",
      "step:   185980, time: 0.762, loss: 0.9793, l1: 0.1816, vgg: 0.4207, mask: 0.3770\n",
      "step:   186000, time: 0.714, loss: 0.9215, l1: 0.1578, vgg: 0.4009, mask: 0.3628\n",
      "step:   186020, time: 0.743, loss: 0.9696, l1: 0.1981, vgg: 0.3984, mask: 0.3731\n",
      "step:   186040, time: 0.761, loss: 1.0802, l1: 0.2458, vgg: 0.4113, mask: 0.4231\n",
      "step:   186060, time: 0.735, loss: 0.9898, l1: 0.2453, vgg: 0.3561, mask: 0.3884\n",
      "step:   186080, time: 0.771, loss: 1.0072, l1: 0.1964, vgg: 0.4462, mask: 0.3647\n",
      "step:   186100, time: 0.715, loss: 1.0617, l1: 0.2361, vgg: 0.4393, mask: 0.3864\n",
      "step:   186120, time: 0.779, loss: 0.9954, l1: 0.2149, vgg: 0.3943, mask: 0.3862\n",
      "step:   186140, time: 0.815, loss: 0.9809, l1: 0.2372, vgg: 0.3572, mask: 0.3865\n",
      "step:   186160, time: 0.769, loss: 1.0219, l1: 0.2041, vgg: 0.4245, mask: 0.3933\n",
      "step:   186180, time: 0.767, loss: 1.0907, l1: 0.2189, vgg: 0.4780, mask: 0.3938\n",
      "step:   186200, time: 0.723, loss: 1.0032, l1: 0.2496, vgg: 0.3667, mask: 0.3869\n",
      "step:   186220, time: 0.790, loss: 1.0236, l1: 0.2459, vgg: 0.3944, mask: 0.3833\n",
      "step:   186240, time: 0.746, loss: 1.1046, l1: 0.2789, vgg: 0.4005, mask: 0.4252\n",
      "step:   186260, time: 0.758, loss: 1.0058, l1: 0.2015, vgg: 0.4365, mask: 0.3678\n",
      "step:   186280, time: 0.745, loss: 1.0054, l1: 0.2181, vgg: 0.3991, mask: 0.3882\n",
      "step:   186300, time: 0.742, loss: 0.9179, l1: 0.2021, vgg: 0.3434, mask: 0.3724\n",
      "step:   186320, time: 0.765, loss: 1.0927, l1: 0.2696, vgg: 0.4168, mask: 0.4063\n",
      "step:   186340, time: 0.744, loss: 1.1124, l1: 0.2394, vgg: 0.4720, mask: 0.4010\n",
      "step:   186360, time: 0.759, loss: 0.9996, l1: 0.1939, vgg: 0.4250, mask: 0.3807\n",
      "step:   186380, time: 0.755, loss: 0.9049, l1: 0.1522, vgg: 0.4048, mask: 0.3479\n",
      "step:   186400, time: 0.801, loss: 1.0391, l1: 0.2435, vgg: 0.4087, mask: 0.3869\n",
      "step:   186420, time: 0.728, loss: 0.8558, l1: 0.1628, vgg: 0.3498, mask: 0.3432\n",
      "step:   186440, time: 0.735, loss: 0.9644, l1: 0.2088, vgg: 0.3823, mask: 0.3733\n",
      "step:   186460, time: 0.739, loss: 0.9454, l1: 0.1762, vgg: 0.4197, mask: 0.3495\n",
      "step:   186480, time: 0.753, loss: 1.0215, l1: 0.2264, vgg: 0.4149, mask: 0.3802\n",
      "step:   186500, time: 0.739, loss: 0.9386, l1: 0.1903, vgg: 0.4001, mask: 0.3481\n",
      "step:   186520, time: 0.749, loss: 0.9629, l1: 0.1901, vgg: 0.4125, mask: 0.3602\n",
      "step:   186540, time: 0.770, loss: 1.0996, l1: 0.2499, vgg: 0.4166, mask: 0.4332\n",
      "step:   186560, time: 0.728, loss: 0.9273, l1: 0.1982, vgg: 0.3828, mask: 0.3462\n",
      "step:   186580, time: 0.750, loss: 1.0745, l1: 0.2947, vgg: 0.3814, mask: 0.3984\n",
      "step:   186600, time: 0.766, loss: 0.9550, l1: 0.2320, vgg: 0.3498, mask: 0.3732\n",
      "step:   186620, time: 0.753, loss: 0.9706, l1: 0.2182, vgg: 0.4031, mask: 0.3494\n",
      "step:   186640, time: 0.761, loss: 1.0708, l1: 0.2115, vgg: 0.4461, mask: 0.4131\n",
      "step:   186660, time: 0.788, loss: 1.0788, l1: 0.2715, vgg: 0.4207, mask: 0.3866\n",
      "step:   186680, time: 0.734, loss: 0.8907, l1: 0.1745, vgg: 0.3835, mask: 0.3327\n",
      "step:   186700, time: 0.752, loss: 1.0764, l1: 0.2516, vgg: 0.3971, mask: 0.4277\n",
      "step:   186720, time: 0.727, loss: 1.0569, l1: 0.2105, vgg: 0.4459, mask: 0.4006\n",
      "step:   186740, time: 0.768, loss: 1.0726, l1: 0.2826, vgg: 0.3770, mask: 0.4130\n",
      "step:   186760, time: 0.798, loss: 0.9489, l1: 0.2201, vgg: 0.3295, mask: 0.3993\n",
      "step:   186780, time: 0.744, loss: 0.9582, l1: 0.2135, vgg: 0.3745, mask: 0.3701\n",
      "step:   186800, time: 0.746, loss: 0.8762, l1: 0.1706, vgg: 0.3498, mask: 0.3559\n",
      "step:   186820, time: 0.744, loss: 1.1229, l1: 0.3033, vgg: 0.3892, mask: 0.4305\n",
      "step:   186840, time: 0.799, loss: 1.0572, l1: 0.2400, vgg: 0.4439, mask: 0.3732\n",
      "step:   186860, time: 0.731, loss: 0.8754, l1: 0.1844, vgg: 0.3477, mask: 0.3434\n",
      "step:   186880, time: 0.767, loss: 1.1320, l1: 0.2634, vgg: 0.4521, mask: 0.4166\n",
      "step:   186900, time: 0.714, loss: 0.9175, l1: 0.1682, vgg: 0.3970, mask: 0.3523\n",
      "step:   186920, time: 0.765, loss: 1.0933, l1: 0.2406, vgg: 0.4352, mask: 0.4175\n",
      "step:   186940, time: 0.778, loss: 1.0469, l1: 0.2192, vgg: 0.4303, mask: 0.3974\n",
      "step:   186960, time: 0.740, loss: 0.9928, l1: 0.1834, vgg: 0.4041, mask: 0.4053\n",
      "step:   186980, time: 0.778, loss: 0.9866, l1: 0.2097, vgg: 0.3612, mask: 0.4157\n",
      "step:   187000, time: 0.748, loss: 1.0331, l1: 0.2288, vgg: 0.4299, mask: 0.3745\n",
      "step:   187020, time: 0.754, loss: 1.0101, l1: 0.2182, vgg: 0.4169, mask: 0.3751\n",
      "step:   187040, time: 0.750, loss: 1.0925, l1: 0.2352, vgg: 0.4744, mask: 0.3829\n",
      "step:   187060, time: 0.719, loss: 0.8911, l1: 0.1702, vgg: 0.3209, mask: 0.4000\n",
      "step:   187080, time: 0.767, loss: 1.0949, l1: 0.2339, vgg: 0.4255, mask: 0.4355\n",
      "step:   187100, time: 0.762, loss: 1.0064, l1: 0.2125, vgg: 0.3818, mask: 0.4120\n",
      "step:   187120, time: 0.774, loss: 1.0443, l1: 0.2507, vgg: 0.3750, mask: 0.4186\n",
      "step:   187140, time: 0.764, loss: 1.0207, l1: 0.1928, vgg: 0.4548, mask: 0.3731\n",
      "step:   187160, time: 0.731, loss: 1.0020, l1: 0.1820, vgg: 0.4474, mask: 0.3726\n",
      "step:   187180, time: 0.751, loss: 0.9951, l1: 0.2122, vgg: 0.4039, mask: 0.3790\n",
      "step:   187200, time: 0.766, loss: 1.1230, l1: 0.2429, vgg: 0.4924, mask: 0.3878\n",
      "step:   187220, time: 0.810, loss: 0.9909, l1: 0.2231, vgg: 0.3684, mask: 0.3994\n",
      "step:   187240, time: 0.752, loss: 0.9438, l1: 0.1667, vgg: 0.3845, mask: 0.3925\n",
      "step:   187260, time: 0.740, loss: 1.0062, l1: 0.2344, vgg: 0.3713, mask: 0.4005\n",
      "step:   187280, time: 0.762, loss: 0.9438, l1: 0.1997, vgg: 0.4047, mask: 0.3394\n",
      "step:   187300, time: 0.728, loss: 1.0006, l1: 0.2339, vgg: 0.3738, mask: 0.3928\n",
      "step:   187320, time: 0.772, loss: 1.1366, l1: 0.2515, vgg: 0.4750, mask: 0.4101\n",
      "step:   187340, time: 0.728, loss: 0.9227, l1: 0.1601, vgg: 0.3944, mask: 0.3683\n",
      "step:   187360, time: 0.768, loss: 1.0161, l1: 0.1725, vgg: 0.4458, mask: 0.3977\n",
      "step:   187380, time: 0.810, loss: 1.1985, l1: 0.2376, vgg: 0.5591, mask: 0.4019\n",
      "step:   187400, time: 0.770, loss: 1.1757, l1: 0.2699, vgg: 0.5001, mask: 0.4057\n",
      "step:   187420, time: 0.770, loss: 0.9518, l1: 0.1793, vgg: 0.4219, mask: 0.3506\n",
      "step:   187440, time: 0.803, loss: 1.0606, l1: 0.2270, vgg: 0.4534, mask: 0.3802\n",
      "step:   187460, time: 0.756, loss: 0.9411, l1: 0.2011, vgg: 0.3766, mask: 0.3634\n",
      "step:   187480, time: 0.740, loss: 1.0093, l1: 0.2202, vgg: 0.4086, mask: 0.3805\n",
      "step:   187500, time: 0.739, loss: 1.0313, l1: 0.1868, vgg: 0.5064, mask: 0.3381\n",
      "step:   187520, time: 0.753, loss: 1.0831, l1: 0.2444, vgg: 0.4282, mask: 0.4105\n",
      "step:   187540, time: 0.756, loss: 1.0091, l1: 0.2139, vgg: 0.4366, mask: 0.3586\n",
      "step:   187560, time: 0.766, loss: 0.9317, l1: 0.1821, vgg: 0.4007, mask: 0.3489\n",
      "step:   187580, time: 0.758, loss: 1.0724, l1: 0.2407, vgg: 0.4473, mask: 0.3845\n",
      "step:   187600, time: 0.784, loss: 1.0308, l1: 0.1963, vgg: 0.4467, mask: 0.3877\n",
      "step:   187620, time: 0.739, loss: 0.9651, l1: 0.1865, vgg: 0.4108, mask: 0.3678\n",
      "step:   187640, time: 0.746, loss: 1.0110, l1: 0.2323, vgg: 0.3857, mask: 0.3931\n",
      "step:   187660, time: 0.747, loss: 1.0002, l1: 0.1770, vgg: 0.4634, mask: 0.3598\n",
      "step:   187680, time: 0.762, loss: 1.0519, l1: 0.2607, vgg: 0.3976, mask: 0.3936\n",
      "step:   187700, time: 0.759, loss: 1.0167, l1: 0.2279, vgg: 0.4028, mask: 0.3859\n",
      "step:   187720, time: 0.714, loss: 0.8903, l1: 0.1811, vgg: 0.3515, mask: 0.3577\n",
      "step:   187740, time: 0.757, loss: 1.0333, l1: 0.2412, vgg: 0.4183, mask: 0.3739\n",
      "step:   187760, time: 0.725, loss: 0.9206, l1: 0.1544, vgg: 0.4059, mask: 0.3603\n",
      "step:   187780, time: 0.742, loss: 0.9912, l1: 0.2101, vgg: 0.4043, mask: 0.3767\n",
      "step:   187800, time: 0.772, loss: 1.0731, l1: 0.2528, vgg: 0.4100, mask: 0.4102\n",
      "step:   187820, time: 0.736, loss: 1.0270, l1: 0.2307, vgg: 0.4080, mask: 0.3882\n",
      "step:   187840, time: 0.742, loss: 1.1055, l1: 0.2183, vgg: 0.4683, mask: 0.4190\n",
      "step:   187860, time: 0.765, loss: 1.0553, l1: 0.2024, vgg: 0.4612, mask: 0.3917\n",
      "step:   187880, time: 0.771, loss: 0.9383, l1: 0.1966, vgg: 0.3696, mask: 0.3721\n",
      "step:   187900, time: 0.753, loss: 0.9484, l1: 0.1567, vgg: 0.3942, mask: 0.3975\n",
      "step:   187920, time: 0.753, loss: 1.0168, l1: 0.2291, vgg: 0.3858, mask: 0.4019\n",
      "step:   187940, time: 0.779, loss: 0.9905, l1: 0.2263, vgg: 0.3630, mask: 0.4012\n",
      "step:   187960, time: 0.769, loss: 1.0789, l1: 0.2636, vgg: 0.4427, mask: 0.3726\n",
      "step:   187980, time: 0.785, loss: 1.0722, l1: 0.2254, vgg: 0.4467, mask: 0.4001\n",
      "step:   188000, time: 0.741, loss: 0.9559, l1: 0.1678, vgg: 0.4222, mask: 0.3658\n",
      "step:   188020, time: 0.753, loss: 1.1418, l1: 0.2301, vgg: 0.4948, mask: 0.4169\n",
      "step:   188040, time: 0.741, loss: 0.8653, l1: 0.1524, vgg: 0.3680, mask: 0.3449\n",
      "step:   188060, time: 0.774, loss: 1.1312, l1: 0.2422, vgg: 0.4916, mask: 0.3975\n",
      "step:   188080, time: 0.735, loss: 0.9214, l1: 0.1598, vgg: 0.4275, mask: 0.3340\n",
      "step:   188100, time: 0.737, loss: 1.0772, l1: 0.2841, vgg: 0.3763, mask: 0.4168\n",
      "step:   188120, time: 0.744, loss: 0.8221, l1: 0.1347, vgg: 0.3343, mask: 0.3531\n",
      "step:   188140, time: 0.731, loss: 1.0176, l1: 0.2103, vgg: 0.4340, mask: 0.3733\n",
      "step:   188160, time: 0.734, loss: 0.9969, l1: 0.2484, vgg: 0.3380, mask: 0.4105\n",
      "step:   188180, time: 0.763, loss: 1.0603, l1: 0.2388, vgg: 0.4199, mask: 0.4017\n",
      "step:   188200, time: 0.770, loss: 1.0261, l1: 0.2009, vgg: 0.4528, mask: 0.3724\n",
      "step:   188220, time: 0.764, loss: 1.1138, l1: 0.2091, vgg: 0.4870, mask: 0.4177\n",
      "step:   188240, time: 0.754, loss: 0.9693, l1: 0.2020, vgg: 0.3847, mask: 0.3826\n",
      "step:   188260, time: 0.781, loss: 0.9942, l1: 0.2310, vgg: 0.3917, mask: 0.3714\n",
      "step:   188280, time: 0.734, loss: 0.9925, l1: 0.1952, vgg: 0.4386, mask: 0.3586\n",
      "step:   188300, time: 0.769, loss: 1.0759, l1: 0.2431, vgg: 0.4512, mask: 0.3816\n",
      "step:   188320, time: 0.809, loss: 1.0725, l1: 0.1997, vgg: 0.4730, mask: 0.3998\n",
      "step:   188340, time: 0.751, loss: 1.0103, l1: 0.2406, vgg: 0.3777, mask: 0.3920\n",
      "step:   188360, time: 0.738, loss: 1.0436, l1: 0.2179, vgg: 0.4389, mask: 0.3867\n",
      "step:   188380, time: 0.756, loss: 0.9452, l1: 0.2060, vgg: 0.3570, mask: 0.3821\n",
      "step:   188400, time: 0.763, loss: 1.0235, l1: 0.2558, vgg: 0.3755, mask: 0.3922\n",
      "step:   188420, time: 0.776, loss: 1.0501, l1: 0.2252, vgg: 0.4449, mask: 0.3801\n",
      "step:   188440, time: 0.790, loss: 0.9696, l1: 0.1756, vgg: 0.3919, mask: 0.4021\n",
      "step:   188460, time: 0.745, loss: 0.9268, l1: 0.1539, vgg: 0.4424, mask: 0.3305\n",
      "step:   188480, time: 0.764, loss: 0.9297, l1: 0.1890, vgg: 0.3797, mask: 0.3610\n",
      "step:   188500, time: 0.746, loss: 1.0016, l1: 0.1933, vgg: 0.4204, mask: 0.3879\n",
      "step:   188520, time: 0.763, loss: 1.0217, l1: 0.2187, vgg: 0.4216, mask: 0.3814\n",
      "step:   188540, time: 0.734, loss: 1.0520, l1: 0.2544, vgg: 0.4274, mask: 0.3703\n",
      "step:   188560, time: 0.738, loss: 0.9533, l1: 0.2001, vgg: 0.3859, mask: 0.3673\n",
      "step:   188580, time: 0.751, loss: 1.0032, l1: 0.1966, vgg: 0.4453, mask: 0.3613\n",
      "step:   188600, time: 0.766, loss: 1.0266, l1: 0.1890, vgg: 0.4268, mask: 0.4108\n",
      "step:   188620, time: 0.735, loss: 0.8819, l1: 0.1406, vgg: 0.3983, mask: 0.3430\n",
      "step:   188640, time: 0.760, loss: 1.0257, l1: 0.2311, vgg: 0.4207, mask: 0.3739\n",
      "step:   188660, time: 0.758, loss: 1.0502, l1: 0.1889, vgg: 0.4201, mask: 0.4412\n",
      "step:   188680, time: 0.765, loss: 0.9539, l1: 0.1737, vgg: 0.4342, mask: 0.3460\n",
      "step:   188700, time: 0.731, loss: 0.8985, l1: 0.1711, vgg: 0.3773, mask: 0.3501\n",
      "step:   188720, time: 0.740, loss: 1.0217, l1: 0.1941, vgg: 0.4153, mask: 0.4123\n",
      "step:   188740, time: 0.752, loss: 1.0178, l1: 0.2251, vgg: 0.4053, mask: 0.3874\n",
      "step:   188760, time: 0.817, loss: 1.0960, l1: 0.2314, vgg: 0.4979, mask: 0.3666\n",
      "step:   188780, time: 0.749, loss: 1.1156, l1: 0.2911, vgg: 0.3953, mask: 0.4292\n",
      "step:   188800, time: 0.754, loss: 1.1255, l1: 0.2565, vgg: 0.4585, mask: 0.4106\n",
      "step:   188820, time: 0.718, loss: 0.9194, l1: 0.2247, vgg: 0.3276, mask: 0.3672\n",
      "step:   188840, time: 0.758, loss: 1.2019, l1: 0.3155, vgg: 0.4492, mask: 0.4372\n",
      "step:   188860, time: 0.739, loss: 1.0117, l1: 0.2292, vgg: 0.3808, mask: 0.4017\n",
      "step:   188880, time: 0.748, loss: 0.8644, l1: 0.1821, vgg: 0.3271, mask: 0.3552\n",
      "step:   188900, time: 0.742, loss: 0.8786, l1: 0.1542, vgg: 0.3817, mask: 0.3427\n",
      "step:   188920, time: 0.759, loss: 1.0971, l1: 0.2436, vgg: 0.4360, mask: 0.4175\n",
      "step:   188940, time: 0.748, loss: 0.9403, l1: 0.1884, vgg: 0.3972, mask: 0.3546\n",
      "step:   188960, time: 0.743, loss: 0.9742, l1: 0.1721, vgg: 0.4401, mask: 0.3620\n",
      "step:   188980, time: 0.719, loss: 0.9833, l1: 0.1739, vgg: 0.4189, mask: 0.3906\n",
      "step:   189000, time: 0.748, loss: 1.0461, l1: 0.2324, vgg: 0.4180, mask: 0.3957\n",
      "step:   189020, time: 0.750, loss: 1.0148, l1: 0.2368, vgg: 0.3778, mask: 0.4002\n",
      "step:   189040, time: 0.722, loss: 0.9213, l1: 0.1925, vgg: 0.3364, mask: 0.3924\n",
      "step:   189060, time: 0.730, loss: 1.0151, l1: 0.2526, vgg: 0.3847, mask: 0.3778\n",
      "step:   189080, time: 0.750, loss: 1.0166, l1: 0.1812, vgg: 0.4652, mask: 0.3702\n",
      "step:   189100, time: 0.770, loss: 0.9812, l1: 0.2146, vgg: 0.3880, mask: 0.3786\n",
      "step:   189120, time: 0.764, loss: 1.1218, l1: 0.2264, vgg: 0.4950, mask: 0.4004\n",
      "step:   189140, time: 0.774, loss: 1.0066, l1: 0.2002, vgg: 0.4399, mask: 0.3665\n",
      "step:   189160, time: 0.742, loss: 1.1429, l1: 0.2589, vgg: 0.4907, mask: 0.3933\n",
      "step:   189180, time: 0.769, loss: 1.0301, l1: 0.2015, vgg: 0.4256, mask: 0.4031\n",
      "step:   189200, time: 0.810, loss: 1.1764, l1: 0.2759, vgg: 0.4780, mask: 0.4225\n",
      "step:   189220, time: 0.775, loss: 1.0975, l1: 0.2454, vgg: 0.4357, mask: 0.4164\n",
      "step:   189240, time: 0.763, loss: 1.0779, l1: 0.2001, vgg: 0.5001, mask: 0.3776\n",
      "step:   189260, time: 0.724, loss: 0.8463, l1: 0.1709, vgg: 0.3442, mask: 0.3311\n",
      "step:   189280, time: 0.733, loss: 1.0521, l1: 0.2352, vgg: 0.4010, mask: 0.4159\n",
      "step:   189300, time: 0.733, loss: 1.0139, l1: 0.2248, vgg: 0.4000, mask: 0.3890\n",
      "step:   189320, time: 0.781, loss: 1.0766, l1: 0.1802, vgg: 0.5255, mask: 0.3709\n",
      "step:   189340, time: 0.738, loss: 0.9311, l1: 0.1678, vgg: 0.4285, mask: 0.3349\n",
      "step:   189360, time: 0.767, loss: 0.9843, l1: 0.2148, vgg: 0.3604, mask: 0.4090\n",
      "step:   189380, time: 0.766, loss: 0.9876, l1: 0.2152, vgg: 0.3952, mask: 0.3772\n",
      "step:   189400, time: 0.734, loss: 0.9654, l1: 0.2258, vgg: 0.3483, mask: 0.3913\n",
      "step:   189420, time: 0.821, loss: 1.1042, l1: 0.2548, vgg: 0.4583, mask: 0.3911\n",
      "step:   189440, time: 0.742, loss: 1.0276, l1: 0.2250, vgg: 0.4140, mask: 0.3885\n",
      "step:   189460, time: 0.748, loss: 1.0418, l1: 0.2130, vgg: 0.3769, mask: 0.4518\n",
      "step:   189480, time: 0.719, loss: 0.9108, l1: 0.1469, vgg: 0.4357, mask: 0.3281\n",
      "step:   189500, time: 0.764, loss: 0.9979, l1: 0.2200, vgg: 0.4027, mask: 0.3752\n",
      "step:   189520, time: 0.783, loss: 1.1039, l1: 0.2540, vgg: 0.4259, mask: 0.4239\n",
      "step:   189540, time: 0.788, loss: 0.9402, l1: 0.2147, vgg: 0.3535, mask: 0.3719\n",
      "step:   189560, time: 0.740, loss: 1.0983, l1: 0.2601, vgg: 0.4332, mask: 0.4049\n",
      "step:   189580, time: 0.767, loss: 1.0200, l1: 0.2351, vgg: 0.3815, mask: 0.4034\n",
      "step:   189600, time: 0.754, loss: 1.0957, l1: 0.2374, vgg: 0.4408, mask: 0.4175\n",
      "step:   189620, time: 0.748, loss: 1.1629, l1: 0.2875, vgg: 0.4409, mask: 0.4346\n",
      "step:   189640, time: 0.763, loss: 1.0371, l1: 0.2257, vgg: 0.4192, mask: 0.3922\n",
      "step:   189660, time: 0.706, loss: 0.8468, l1: 0.1358, vgg: 0.3489, mask: 0.3621\n",
      "step:   189680, time: 0.739, loss: 1.1400, l1: 0.2830, vgg: 0.4258, mask: 0.4312\n",
      "step:   189700, time: 0.778, loss: 1.1031, l1: 0.2259, vgg: 0.5127, mask: 0.3645\n",
      "step:   189720, time: 0.752, loss: 0.9566, l1: 0.2042, vgg: 0.3936, mask: 0.3589\n",
      "step:   189740, time: 0.759, loss: 0.9488, l1: 0.1696, vgg: 0.3759, mask: 0.4033\n",
      "step:   189760, time: 0.735, loss: 0.9699, l1: 0.2031, vgg: 0.3597, mask: 0.4072\n",
      "step:   189780, time: 0.764, loss: 0.9874, l1: 0.1791, vgg: 0.4551, mask: 0.3532\n",
      "step:   189800, time: 0.712, loss: 0.9675, l1: 0.1990, vgg: 0.3625, mask: 0.4060\n",
      "step:   189820, time: 0.778, loss: 1.0211, l1: 0.2180, vgg: 0.4164, mask: 0.3866\n",
      "step:   189840, time: 0.757, loss: 0.9956, l1: 0.2192, vgg: 0.3880, mask: 0.3884\n",
      "step:   189860, time: 0.759, loss: 0.9588, l1: 0.2176, vgg: 0.3681, mask: 0.3732\n",
      "step:   189880, time: 0.725, loss: 0.9003, l1: 0.1710, vgg: 0.3839, mask: 0.3454\n",
      "step:   189900, time: 0.752, loss: 1.0817, l1: 0.2688, vgg: 0.4246, mask: 0.3882\n",
      "step:   189920, time: 0.787, loss: 1.1617, l1: 0.2445, vgg: 0.5302, mask: 0.3869\n",
      "step:   189940, time: 0.725, loss: 1.0057, l1: 0.1992, vgg: 0.4373, mask: 0.3692\n",
      "step:   189960, time: 0.749, loss: 0.9624, l1: 0.1868, vgg: 0.4252, mask: 0.3505\n",
      "step:   189980, time: 0.746, loss: 0.9519, l1: 0.2244, vgg: 0.3532, mask: 0.3743\n",
      "step:   190000, time: 0.785, loss: 1.0233, l1: 0.2434, vgg: 0.3966, mask: 0.3832\n",
      "step:   190020, time: 0.717, loss: 0.9480, l1: 0.1984, vgg: 0.3534, mask: 0.3962\n",
      "step:   190040, time: 0.732, loss: 0.9506, l1: 0.1817, vgg: 0.3882, mask: 0.3807\n",
      "step:   190060, time: 0.741, loss: 1.0292, l1: 0.2275, vgg: 0.4286, mask: 0.3732\n",
      "step:   190080, time: 0.726, loss: 0.8892, l1: 0.1480, vgg: 0.4336, mask: 0.3077\n",
      "step:   190100, time: 0.725, loss: 0.9874, l1: 0.1849, vgg: 0.3599, mask: 0.4427\n",
      "step:   190120, time: 0.777, loss: 1.0534, l1: 0.2290, vgg: 0.4072, mask: 0.4173\n",
      "step:   190140, time: 0.775, loss: 1.0135, l1: 0.2492, vgg: 0.3449, mask: 0.4194\n",
      "step:   190160, time: 0.752, loss: 1.0643, l1: 0.2583, vgg: 0.3969, mask: 0.4091\n",
      "step:   190180, time: 0.774, loss: 0.8594, l1: 0.1349, vgg: 0.3774, mask: 0.3470\n",
      "step:   190200, time: 0.750, loss: 1.1004, l1: 0.2685, vgg: 0.4417, mask: 0.3903\n",
      "step:   190220, time: 0.743, loss: 1.0674, l1: 0.2630, vgg: 0.4056, mask: 0.3988\n",
      "step:   190240, time: 0.776, loss: 1.1301, l1: 0.2433, vgg: 0.4690, mask: 0.4178\n",
      "step:   190260, time: 0.794, loss: 1.0819, l1: 0.2242, vgg: 0.4685, mask: 0.3891\n",
      "step:   190280, time: 0.750, loss: 0.8974, l1: 0.1637, vgg: 0.3607, mask: 0.3729\n",
      "step:   190300, time: 0.754, loss: 1.0451, l1: 0.2355, vgg: 0.4513, mask: 0.3583\n",
      "step:   190320, time: 0.798, loss: 1.0483, l1: 0.2215, vgg: 0.4585, mask: 0.3683\n",
      "step:   190340, time: 0.734, loss: 1.0772, l1: 0.2441, vgg: 0.3934, mask: 0.4397\n",
      "step:   190360, time: 0.747, loss: 0.9748, l1: 0.1934, vgg: 0.3965, mask: 0.3849\n",
      "step:   190380, time: 0.743, loss: 1.0181, l1: 0.2313, vgg: 0.3888, mask: 0.3979\n",
      "step:   190400, time: 0.739, loss: 1.0120, l1: 0.2524, vgg: 0.3817, mask: 0.3780\n",
      "step:   190420, time: 0.727, loss: 1.1217, l1: 0.2482, vgg: 0.4602, mask: 0.4133\n",
      "step:   190440, time: 0.770, loss: 1.1703, l1: 0.3122, vgg: 0.4280, mask: 0.4300\n",
      "step:   190460, time: 0.774, loss: 0.9504, l1: 0.2254, vgg: 0.3532, mask: 0.3719\n",
      "step:   190480, time: 0.776, loss: 1.1749, l1: 0.2888, vgg: 0.4668, mask: 0.4193\n",
      "step:   190500, time: 0.767, loss: 0.9881, l1: 0.1860, vgg: 0.4298, mask: 0.3723\n",
      "step:   190520, time: 0.753, loss: 0.9242, l1: 0.1693, vgg: 0.4130, mask: 0.3419\n",
      "step:   190540, time: 0.799, loss: 1.1243, l1: 0.2591, vgg: 0.4773, mask: 0.3879\n",
      "step:   190560, time: 0.776, loss: 1.0582, l1: 0.2098, vgg: 0.4599, mask: 0.3885\n",
      "step:   190580, time: 0.720, loss: 0.8805, l1: 0.1670, vgg: 0.3519, mask: 0.3616\n",
      "step:   190600, time: 0.710, loss: 0.8901, l1: 0.1736, vgg: 0.3550, mask: 0.3615\n",
      "step:   190620, time: 0.742, loss: 1.0510, l1: 0.2335, vgg: 0.4103, mask: 0.4071\n",
      "step:   190640, time: 0.738, loss: 0.9492, l1: 0.2034, vgg: 0.3682, mask: 0.3776\n",
      "step:   190660, time: 0.760, loss: 1.0798, l1: 0.1983, vgg: 0.4474, mask: 0.4341\n",
      "step:   190680, time: 0.709, loss: 0.9054, l1: 0.1418, vgg: 0.3920, mask: 0.3716\n",
      "step:   190700, time: 0.759, loss: 1.0876, l1: 0.2262, vgg: 0.4400, mask: 0.4215\n",
      "step:   190720, time: 0.735, loss: 1.0166, l1: 0.2225, vgg: 0.4320, mask: 0.3621\n",
      "step:   190740, time: 0.747, loss: 1.1199, l1: 0.2473, vgg: 0.4598, mask: 0.4128\n",
      "step:   190760, time: 0.754, loss: 0.9156, l1: 0.1777, vgg: 0.3942, mask: 0.3437\n",
      "step:   190780, time: 0.754, loss: 0.9093, l1: 0.1678, vgg: 0.3869, mask: 0.3546\n",
      "step:   190800, time: 0.748, loss: 1.0433, l1: 0.2135, vgg: 0.4332, mask: 0.3967\n",
      "step:   190820, time: 0.747, loss: 0.9747, l1: 0.2279, vgg: 0.3861, mask: 0.3608\n",
      "step:   190840, time: 0.776, loss: 1.0950, l1: 0.2145, vgg: 0.4673, mask: 0.4132\n",
      "step:   190860, time: 0.753, loss: 1.0850, l1: 0.2172, vgg: 0.4971, mask: 0.3707\n",
      "step:   190880, time: 0.749, loss: 1.0414, l1: 0.2093, vgg: 0.4636, mask: 0.3685\n",
      "step:   190900, time: 0.736, loss: 1.0709, l1: 0.2338, vgg: 0.4465, mask: 0.3906\n",
      "step:   190920, time: 0.731, loss: 0.8798, l1: 0.1454, vgg: 0.3987, mask: 0.3356\n",
      "step:   190940, time: 0.734, loss: 0.9966, l1: 0.2396, vgg: 0.3654, mask: 0.3917\n",
      "step:   190960, time: 0.748, loss: 1.0336, l1: 0.1995, vgg: 0.4686, mask: 0.3656\n",
      "step:   190980, time: 0.759, loss: 1.0286, l1: 0.1937, vgg: 0.4578, mask: 0.3770\n",
      "step:   191000, time: 0.778, loss: 0.9958, l1: 0.2146, vgg: 0.4033, mask: 0.3780\n",
      "step:   191020, time: 0.740, loss: 1.0474, l1: 0.2159, vgg: 0.4517, mask: 0.3798\n",
      "step:   191040, time: 0.758, loss: 1.0595, l1: 0.2025, vgg: 0.4896, mask: 0.3675\n",
      "step:   191060, time: 0.757, loss: 1.0587, l1: 0.2035, vgg: 0.4878, mask: 0.3673\n",
      "step:   191080, time: 0.741, loss: 0.9156, l1: 0.1611, vgg: 0.4161, mask: 0.3384\n",
      "step:   191100, time: 0.750, loss: 1.0660, l1: 0.2179, vgg: 0.4673, mask: 0.3809\n",
      "step:   191120, time: 0.738, loss: 1.0249, l1: 0.2213, vgg: 0.3967, mask: 0.4069\n",
      "step:   191140, time: 0.732, loss: 1.0052, l1: 0.2508, vgg: 0.3493, mask: 0.4051\n",
      "step:   191160, time: 0.808, loss: 1.0710, l1: 0.2273, vgg: 0.4612, mask: 0.3826\n",
      "step:   191180, time: 0.741, loss: 0.9739, l1: 0.2039, vgg: 0.3498, mask: 0.4202\n",
      "step:   191200, time: 0.740, loss: 0.8547, l1: 0.1349, vgg: 0.3658, mask: 0.3539\n",
      "step:   191220, time: 0.721, loss: 0.9055, l1: 0.2031, vgg: 0.3400, mask: 0.3624\n",
      "step:   191240, time: 0.766, loss: 1.0262, l1: 0.2179, vgg: 0.4138, mask: 0.3945\n",
      "step:   191260, time: 0.766, loss: 1.0372, l1: 0.2000, vgg: 0.4433, mask: 0.3939\n",
      "step:   191280, time: 0.729, loss: 1.0050, l1: 0.1810, vgg: 0.4610, mask: 0.3631\n",
      "step:   191300, time: 0.749, loss: 0.9616, l1: 0.2083, vgg: 0.3885, mask: 0.3648\n",
      "step:   191320, time: 0.733, loss: 0.9507, l1: 0.1782, vgg: 0.4018, mask: 0.3707\n",
      "step:   191340, time: 0.733, loss: 0.9077, l1: 0.1903, vgg: 0.3338, mask: 0.3835\n",
      "step:   191360, time: 0.760, loss: 0.9575, l1: 0.1907, vgg: 0.3847, mask: 0.3820\n",
      "step:   191380, time: 0.762, loss: 0.9622, l1: 0.1861, vgg: 0.3587, mask: 0.4175\n",
      "step:   191400, time: 0.715, loss: 0.8497, l1: 0.1623, vgg: 0.3372, mask: 0.3502\n",
      "step:   191420, time: 0.738, loss: 0.9487, l1: 0.2222, vgg: 0.3501, mask: 0.3764\n",
      "step:   191440, time: 0.742, loss: 0.9810, l1: 0.2323, vgg: 0.3580, mask: 0.3907\n",
      "step:   191460, time: 0.739, loss: 1.0679, l1: 0.2462, vgg: 0.4054, mask: 0.4163\n",
      "step:   191480, time: 0.781, loss: 1.1156, l1: 0.2612, vgg: 0.4471, mask: 0.4072\n",
      "step:   191500, time: 0.765, loss: 0.9332, l1: 0.2028, vgg: 0.3615, mask: 0.3690\n",
      "step:   191520, time: 0.802, loss: 1.0058, l1: 0.1954, vgg: 0.4616, mask: 0.3489\n",
      "step:   191540, time: 0.782, loss: 1.0315, l1: 0.2617, vgg: 0.3723, mask: 0.3975\n",
      "step:   191560, time: 0.741, loss: 1.0231, l1: 0.2139, vgg: 0.3980, mask: 0.4112\n",
      "step:   191580, time: 0.765, loss: 1.0034, l1: 0.1902, vgg: 0.4378, mask: 0.3754\n",
      "step:   191600, time: 0.774, loss: 1.1753, l1: 0.2747, vgg: 0.4722, mask: 0.4284\n",
      "step:   191620, time: 0.761, loss: 1.0294, l1: 0.2031, vgg: 0.4575, mask: 0.3689\n",
      "step:   191640, time: 0.753, loss: 1.0256, l1: 0.2515, vgg: 0.3638, mask: 0.4102\n",
      "step:   191660, time: 0.792, loss: 1.0856, l1: 0.2406, vgg: 0.4482, mask: 0.3969\n",
      "step:   191680, time: 0.731, loss: 0.9568, l1: 0.1856, vgg: 0.3495, mask: 0.4217\n",
      "step:   191700, time: 0.775, loss: 1.0644, l1: 0.2509, vgg: 0.3859, mask: 0.4275\n",
      "step:   191720, time: 0.758, loss: 0.9938, l1: 0.1859, vgg: 0.4108, mask: 0.3970\n",
      "step:   191740, time: 0.770, loss: 1.0087, l1: 0.2301, vgg: 0.3589, mask: 0.4197\n",
      "step:   191760, time: 0.758, loss: 0.9068, l1: 0.1889, vgg: 0.3300, mask: 0.3879\n",
      "step:   191780, time: 0.749, loss: 1.0199, l1: 0.2408, vgg: 0.3726, mask: 0.4065\n",
      "step:   191800, time: 0.761, loss: 1.0575, l1: 0.2352, vgg: 0.3595, mask: 0.4629\n",
      "step:   191820, time: 0.813, loss: 1.0886, l1: 0.2587, vgg: 0.4114, mask: 0.4185\n",
      "step:   191840, time: 0.772, loss: 1.1247, l1: 0.2311, vgg: 0.5088, mask: 0.3848\n",
      "step:   191860, time: 0.714, loss: 0.9636, l1: 0.1969, vgg: 0.3945, mask: 0.3722\n",
      "step:   191880, time: 0.749, loss: 1.0143, l1: 0.2231, vgg: 0.3709, mask: 0.4203\n",
      "step:   191900, time: 0.727, loss: 0.9668, l1: 0.1918, vgg: 0.3873, mask: 0.3877\n",
      "step:   191920, time: 0.709, loss: 0.8789, l1: 0.1673, vgg: 0.3498, mask: 0.3618\n",
      "step:   191940, time: 0.765, loss: 1.0420, l1: 0.2255, vgg: 0.4466, mask: 0.3699\n",
      "step:   191960, time: 0.753, loss: 1.0560, l1: 0.2330, vgg: 0.4212, mask: 0.4017\n",
      "step:   191980, time: 0.747, loss: 0.9832, l1: 0.2432, vgg: 0.3292, mask: 0.4107\n",
      "step:   192000, time: 0.769, loss: 1.0315, l1: 0.2156, vgg: 0.4295, mask: 0.3863\n",
      "step:   192020, time: 0.759, loss: 1.0459, l1: 0.2142, vgg: 0.4528, mask: 0.3789\n",
      "step:   192040, time: 0.730, loss: 1.0191, l1: 0.2016, vgg: 0.4132, mask: 0.4043\n",
      "step:   192060, time: 0.750, loss: 1.0890, l1: 0.2345, vgg: 0.4513, mask: 0.4032\n",
      "step:   192080, time: 0.747, loss: 0.9937, l1: 0.1731, vgg: 0.4747, mask: 0.3460\n",
      "step:   192100, time: 0.743, loss: 0.9229, l1: 0.1863, vgg: 0.3991, mask: 0.3375\n",
      "step:   192120, time: 0.732, loss: 0.9003, l1: 0.1420, vgg: 0.3973, mask: 0.3610\n",
      "step:   192140, time: 0.764, loss: 1.2368, l1: 0.2952, vgg: 0.5210, mask: 0.4206\n",
      "step:   192160, time: 0.750, loss: 0.9755, l1: 0.1871, vgg: 0.4218, mask: 0.3666\n",
      "step:   192180, time: 0.776, loss: 1.0532, l1: 0.2639, vgg: 0.4075, mask: 0.3819\n",
      "step:   192200, time: 0.746, loss: 0.9763, l1: 0.1956, vgg: 0.3939, mask: 0.3867\n",
      "step:   192220, time: 0.752, loss: 1.0111, l1: 0.2104, vgg: 0.4163, mask: 0.3845\n",
      "step:   192240, time: 0.750, loss: 0.9755, l1: 0.2039, vgg: 0.3923, mask: 0.3793\n",
      "step:   192260, time: 0.762, loss: 0.9389, l1: 0.1807, vgg: 0.3995, mask: 0.3586\n",
      "step:   192280, time: 0.758, loss: 1.0600, l1: 0.2166, vgg: 0.4341, mask: 0.4093\n",
      "step:   192300, time: 0.721, loss: 0.9451, l1: 0.2005, vgg: 0.3883, mask: 0.3564\n",
      "step:   192320, time: 0.777, loss: 1.0850, l1: 0.2274, vgg: 0.4889, mask: 0.3686\n",
      "step:   192340, time: 0.733, loss: 0.9751, l1: 0.2069, vgg: 0.4162, mask: 0.3520\n",
      "step:   192360, time: 0.731, loss: 1.1070, l1: 0.2535, vgg: 0.4512, mask: 0.4024\n",
      "step:   192380, time: 0.769, loss: 0.8839, l1: 0.1462, vgg: 0.3371, mask: 0.4006\n",
      "step:   192400, time: 0.719, loss: 0.9786, l1: 0.2363, vgg: 0.3635, mask: 0.3788\n",
      "step:   192420, time: 0.743, loss: 1.0354, l1: 0.2355, vgg: 0.4174, mask: 0.3824\n",
      "step:   192440, time: 0.751, loss: 1.0405, l1: 0.2307, vgg: 0.4015, mask: 0.4082\n",
      "step:   192460, time: 0.705, loss: 0.9191, l1: 0.1508, vgg: 0.4416, mask: 0.3267\n",
      "step:   192480, time: 0.758, loss: 1.0118, l1: 0.2120, vgg: 0.3912, mask: 0.4087\n",
      "step:   192500, time: 0.796, loss: 1.0305, l1: 0.2030, vgg: 0.4459, mask: 0.3816\n",
      "step:   192520, time: 0.730, loss: 0.9505, l1: 0.2056, vgg: 0.3664, mask: 0.3785\n",
      "step:   192540, time: 0.776, loss: 1.1355, l1: 0.2371, vgg: 0.4941, mask: 0.4043\n",
      "step:   192560, time: 0.781, loss: 1.1849, l1: 0.2776, vgg: 0.4966, mask: 0.4107\n",
      "step:   192580, time: 0.767, loss: 1.2030, l1: 0.2950, vgg: 0.4772, mask: 0.4307\n",
      "step:   192600, time: 0.793, loss: 0.9551, l1: 0.2183, vgg: 0.3856, mask: 0.3512\n",
      "step:   192620, time: 0.762, loss: 1.0565, l1: 0.2569, vgg: 0.4086, mask: 0.3910\n",
      "step:   192640, time: 0.750, loss: 1.0440, l1: 0.2401, vgg: 0.4219, mask: 0.3820\n",
      "step:   192660, time: 0.779, loss: 1.0757, l1: 0.2401, vgg: 0.4589, mask: 0.3767\n",
      "step:   192680, time: 0.774, loss: 1.0544, l1: 0.2613, vgg: 0.3877, mask: 0.4053\n",
      "step:   192700, time: 0.749, loss: 1.0085, l1: 0.1877, vgg: 0.4281, mask: 0.3927\n",
      "step:   192720, time: 0.764, loss: 1.0266, l1: 0.2232, vgg: 0.4311, mask: 0.3723\n",
      "step:   192740, time: 0.746, loss: 1.1117, l1: 0.2515, vgg: 0.4553, mask: 0.4050\n",
      "step:   192760, time: 0.767, loss: 1.0087, l1: 0.2335, vgg: 0.4231, mask: 0.3521\n",
      "step:   192780, time: 0.779, loss: 0.9229, l1: 0.1614, vgg: 0.3919, mask: 0.3695\n",
      "step:   192800, time: 0.754, loss: 1.0715, l1: 0.2364, vgg: 0.4581, mask: 0.3770\n",
      "step:   192820, time: 0.771, loss: 0.9283, l1: 0.1998, vgg: 0.3645, mask: 0.3640\n",
      "step:   192840, time: 0.758, loss: 1.0828, l1: 0.2417, vgg: 0.4402, mask: 0.4009\n",
      "step:   192860, time: 0.755, loss: 1.0054, l1: 0.2151, vgg: 0.4202, mask: 0.3701\n",
      "step:   192880, time: 0.729, loss: 1.0525, l1: 0.2435, vgg: 0.4004, mask: 0.4086\n",
      "step:   192900, time: 0.764, loss: 1.0085, l1: 0.2452, vgg: 0.3778, mask: 0.3855\n",
      "step:   192920, time: 0.767, loss: 1.0537, l1: 0.2306, vgg: 0.4503, mask: 0.3728\n",
      "step:   192940, time: 0.724, loss: 0.8927, l1: 0.1629, vgg: 0.3576, mask: 0.3722\n",
      "step:   192960, time: 0.753, loss: 1.0319, l1: 0.2182, vgg: 0.4143, mask: 0.3994\n",
      "step:   192980, time: 0.791, loss: 1.0681, l1: 0.2258, vgg: 0.4507, mask: 0.3917\n",
      "step:   193000, time: 0.752, loss: 1.0391, l1: 0.2467, vgg: 0.4061, mask: 0.3863\n",
      "step:   193020, time: 0.732, loss: 1.0918, l1: 0.2260, vgg: 0.4606, mask: 0.4052\n",
      "step:   193040, time: 0.800, loss: 0.9812, l1: 0.1985, vgg: 0.4125, mask: 0.3703\n",
      "step:   193060, time: 0.741, loss: 0.9296, l1: 0.1783, vgg: 0.3948, mask: 0.3566\n",
      "step:   193080, time: 0.720, loss: 0.9685, l1: 0.1742, vgg: 0.4200, mask: 0.3743\n",
      "step:   193100, time: 0.730, loss: 0.9257, l1: 0.2036, vgg: 0.3757, mask: 0.3463\n",
      "step:   193120, time: 0.767, loss: 0.9122, l1: 0.2061, vgg: 0.3326, mask: 0.3735\n",
      "step:   193140, time: 0.772, loss: 1.0320, l1: 0.2546, vgg: 0.4031, mask: 0.3743\n",
      "step:   193160, time: 0.744, loss: 1.0755, l1: 0.2877, vgg: 0.3661, mask: 0.4217\n",
      "step:   193180, time: 0.757, loss: 1.1454, l1: 0.2498, vgg: 0.4869, mask: 0.4088\n",
      "step:   193200, time: 0.729, loss: 0.9374, l1: 0.1689, vgg: 0.3772, mask: 0.3913\n",
      "step:   193220, time: 0.729, loss: 0.9970, l1: 0.2190, vgg: 0.3714, mask: 0.4066\n",
      "step:   193240, time: 0.764, loss: 1.0067, l1: 0.2014, vgg: 0.4388, mask: 0.3665\n",
      "step:   193260, time: 0.773, loss: 0.9892, l1: 0.2318, vgg: 0.3583, mask: 0.3991\n",
      "step:   193280, time: 0.799, loss: 1.2504, l1: 0.2868, vgg: 0.5382, mask: 0.4254\n",
      "step:   193300, time: 0.748, loss: 0.9866, l1: 0.2297, vgg: 0.3918, mask: 0.3652\n",
      "step:   193320, time: 0.745, loss: 0.8657, l1: 0.1450, vgg: 0.3536, mask: 0.3671\n",
      "step:   193340, time: 0.755, loss: 1.0519, l1: 0.2238, vgg: 0.4210, mask: 0.4070\n",
      "step:   193360, time: 0.747, loss: 1.0178, l1: 0.2072, vgg: 0.4153, mask: 0.3953\n",
      "step:   193380, time: 0.754, loss: 1.0844, l1: 0.2296, vgg: 0.4515, mask: 0.4033\n",
      "step:   193400, time: 0.751, loss: 0.9846, l1: 0.1837, vgg: 0.4413, mask: 0.3596\n",
      "step:   193420, time: 0.759, loss: 0.9007, l1: 0.1495, vgg: 0.4082, mask: 0.3430\n",
      "step:   193440, time: 0.740, loss: 0.9678, l1: 0.1806, vgg: 0.4335, mask: 0.3536\n",
      "step:   193460, time: 0.762, loss: 0.9999, l1: 0.1869, vgg: 0.3911, mask: 0.4219\n",
      "step:   193480, time: 0.738, loss: 0.8929, l1: 0.1655, vgg: 0.3642, mask: 0.3631\n",
      "step:   193500, time: 0.766, loss: 0.9057, l1: 0.1801, vgg: 0.3780, mask: 0.3477\n",
      "step:   193520, time: 0.775, loss: 1.1410, l1: 0.2166, vgg: 0.5350, mask: 0.3894\n",
      "step:   193540, time: 0.792, loss: 1.0678, l1: 0.1813, vgg: 0.5002, mask: 0.3863\n",
      "step:   193560, time: 0.769, loss: 1.0048, l1: 0.1849, vgg: 0.4470, mask: 0.3729\n",
      "step:   193580, time: 0.742, loss: 0.9254, l1: 0.1799, vgg: 0.3818, mask: 0.3636\n",
      "step:   193600, time: 0.722, loss: 0.9707, l1: 0.1750, vgg: 0.4223, mask: 0.3734\n",
      "step:   193620, time: 0.748, loss: 0.9314, l1: 0.1981, vgg: 0.3986, mask: 0.3347\n",
      "step:   193640, time: 0.760, loss: 0.9781, l1: 0.1998, vgg: 0.3763, mask: 0.4020\n",
      "step:   193660, time: 0.760, loss: 1.0602, l1: 0.2299, vgg: 0.4448, mask: 0.3855\n",
      "step:   193680, time: 0.788, loss: 1.0377, l1: 0.2401, vgg: 0.3935, mask: 0.4041\n",
      "step:   193700, time: 0.782, loss: 1.0057, l1: 0.2377, vgg: 0.3404, mask: 0.4276\n",
      "step:   193720, time: 0.775, loss: 1.0402, l1: 0.1947, vgg: 0.4673, mask: 0.3783\n",
      "step:   193740, time: 0.768, loss: 1.0739, l1: 0.2790, vgg: 0.3859, mask: 0.4089\n",
      "step:   193760, time: 0.719, loss: 1.0108, l1: 0.2034, vgg: 0.4346, mask: 0.3728\n",
      "step:   193780, time: 0.753, loss: 1.0246, l1: 0.2158, vgg: 0.3904, mask: 0.4183\n",
      "step:   193800, time: 0.745, loss: 0.9613, l1: 0.1755, vgg: 0.3932, mask: 0.3925\n",
      "step:   193820, time: 0.728, loss: 1.0226, l1: 0.1841, vgg: 0.4585, mask: 0.3800\n",
      "step:   193840, time: 0.785, loss: 1.1032, l1: 0.2665, vgg: 0.3930, mask: 0.4438\n",
      "step:   193860, time: 0.740, loss: 1.0237, l1: 0.2045, vgg: 0.4155, mask: 0.4037\n",
      "step:   193880, time: 0.746, loss: 0.9841, l1: 0.1903, vgg: 0.4370, mask: 0.3568\n",
      "step:   193900, time: 0.768, loss: 0.9807, l1: 0.2031, vgg: 0.3915, mask: 0.3860\n",
      "step:   193920, time: 0.708, loss: 0.9246, l1: 0.1883, vgg: 0.3651, mask: 0.3711\n",
      "step:   193940, time: 0.771, loss: 1.0966, l1: 0.2320, vgg: 0.4796, mask: 0.3849\n",
      "step:   193960, time: 0.780, loss: 0.9100, l1: 0.1802, vgg: 0.3897, mask: 0.3401\n",
      "step:   193980, time: 0.756, loss: 0.9958, l1: 0.2188, vgg: 0.4171, mask: 0.3599\n",
      "step:   194000, time: 0.778, loss: 1.0065, l1: 0.2083, vgg: 0.4312, mask: 0.3670\n",
      "step:   194020, time: 0.759, loss: 0.9146, l1: 0.1846, vgg: 0.3843, mask: 0.3458\n",
      "step:   194040, time: 0.750, loss: 1.0275, l1: 0.2223, vgg: 0.4057, mask: 0.3995\n",
      "step:   194060, time: 0.771, loss: 1.1017, l1: 0.2576, vgg: 0.4638, mask: 0.3804\n",
      "step:   194080, time: 0.742, loss: 1.0511, l1: 0.2704, vgg: 0.3685, mask: 0.4122\n",
      "step:   194100, time: 0.763, loss: 1.0444, l1: 0.2353, vgg: 0.4269, mask: 0.3822\n",
      "step:   194120, time: 0.748, loss: 1.1059, l1: 0.2754, vgg: 0.4194, mask: 0.4112\n",
      "step:   194140, time: 0.741, loss: 1.0253, l1: 0.2127, vgg: 0.4218, mask: 0.3908\n",
      "step:   194160, time: 0.797, loss: 1.1763, l1: 0.2831, vgg: 0.4671, mask: 0.4262\n",
      "step:   194180, time: 0.745, loss: 1.0117, l1: 0.2059, vgg: 0.3892, mask: 0.4167\n",
      "step:   194200, time: 0.748, loss: 0.9824, l1: 0.2021, vgg: 0.3895, mask: 0.3908\n",
      "step:   194220, time: 0.769, loss: 1.0233, l1: 0.2188, vgg: 0.4397, mask: 0.3649\n",
      "step:   194240, time: 0.731, loss: 0.8488, l1: 0.1564, vgg: 0.3354, mask: 0.3570\n",
      "step:   194260, time: 0.760, loss: 1.0999, l1: 0.2781, vgg: 0.4113, mask: 0.4104\n",
      "step:   194280, time: 0.728, loss: 0.9841, l1: 0.2075, vgg: 0.3955, mask: 0.3811\n",
      "step:   194300, time: 0.789, loss: 1.0497, l1: 0.2418, vgg: 0.4087, mask: 0.3992\n",
      "step:   194320, time: 0.782, loss: 0.9819, l1: 0.1729, vgg: 0.4520, mask: 0.3571\n",
      "step:   194340, time: 0.768, loss: 1.0255, l1: 0.2122, vgg: 0.4171, mask: 0.3961\n",
      "step:   194360, time: 0.755, loss: 1.0772, l1: 0.2588, vgg: 0.4074, mask: 0.4110\n",
      "step:   194380, time: 0.754, loss: 1.0991, l1: 0.2286, vgg: 0.4673, mask: 0.4033\n",
      "step:   194400, time: 0.774, loss: 0.9541, l1: 0.2016, vgg: 0.3783, mask: 0.3742\n",
      "step:   194420, time: 0.798, loss: 1.1091, l1: 0.2482, vgg: 0.4621, mask: 0.3988\n",
      "step:   194440, time: 0.746, loss: 0.8846, l1: 0.1552, vgg: 0.3577, mask: 0.3717\n",
      "step:   194460, time: 0.749, loss: 1.0423, l1: 0.1732, vgg: 0.4979, mask: 0.3711\n",
      "step:   194480, time: 0.734, loss: 0.8985, l1: 0.1748, vgg: 0.3496, mask: 0.3741\n",
      "step:   194500, time: 0.736, loss: 0.9439, l1: 0.2072, vgg: 0.3659, mask: 0.3708\n",
      "step:   194520, time: 0.745, loss: 1.0424, l1: 0.2674, vgg: 0.3891, mask: 0.3859\n",
      "step:   194540, time: 0.708, loss: 0.9259, l1: 0.1802, vgg: 0.4105, mask: 0.3351\n",
      "step:   194560, time: 0.751, loss: 1.0318, l1: 0.2613, vgg: 0.3636, mask: 0.4069\n",
      "step:   194580, time: 0.757, loss: 0.9961, l1: 0.2196, vgg: 0.3992, mask: 0.3774\n",
      "step:   194600, time: 0.782, loss: 0.9827, l1: 0.2017, vgg: 0.4102, mask: 0.3708\n",
      "step:   194620, time: 0.746, loss: 0.9861, l1: 0.2259, vgg: 0.3867, mask: 0.3735\n",
      "step:   194640, time: 0.795, loss: 0.9533, l1: 0.1917, vgg: 0.3975, mask: 0.3640\n",
      "step:   194660, time: 0.742, loss: 0.9778, l1: 0.2155, vgg: 0.3807, mask: 0.3816\n",
      "step:   194680, time: 0.768, loss: 1.0210, l1: 0.2120, vgg: 0.4285, mask: 0.3805\n",
      "step:   194700, time: 0.721, loss: 0.8542, l1: 0.1578, vgg: 0.3665, mask: 0.3299\n",
      "step:   194720, time: 0.714, loss: 0.8603, l1: 0.1905, vgg: 0.3427, mask: 0.3271\n",
      "step:   194740, time: 0.727, loss: 0.8975, l1: 0.1832, vgg: 0.3606, mask: 0.3537\n",
      "step:   194760, time: 0.768, loss: 1.0519, l1: 0.2092, vgg: 0.4560, mask: 0.3867\n",
      "step:   194780, time: 0.763, loss: 1.0817, l1: 0.2101, vgg: 0.4783, mask: 0.3933\n",
      "step:   194800, time: 0.738, loss: 0.8801, l1: 0.1660, vgg: 0.3415, mask: 0.3725\n",
      "step:   194820, time: 0.762, loss: 0.9835, l1: 0.1945, vgg: 0.4166, mask: 0.3724\n",
      "step:   194840, time: 0.761, loss: 1.0089, l1: 0.1924, vgg: 0.4263, mask: 0.3902\n",
      "step:   194860, time: 0.768, loss: 1.0317, l1: 0.2340, vgg: 0.3929, mask: 0.4048\n",
      "step:   194880, time: 0.761, loss: 1.1128, l1: 0.2837, vgg: 0.3958, mask: 0.4333\n",
      "step:   194900, time: 0.795, loss: 1.0950, l1: 0.2602, vgg: 0.4212, mask: 0.4135\n",
      "step:   194920, time: 0.742, loss: 0.8985, l1: 0.1810, vgg: 0.3583, mask: 0.3592\n",
      "step:   194940, time: 0.735, loss: 0.9882, l1: 0.1964, vgg: 0.4231, mask: 0.3687\n",
      "step:   194960, time: 0.786, loss: 1.0739, l1: 0.2301, vgg: 0.4947, mask: 0.3490\n",
      "step:   194980, time: 0.749, loss: 1.0971, l1: 0.2547, vgg: 0.4478, mask: 0.3946\n",
      "step:   195000, time: 0.753, loss: 0.9739, l1: 0.2159, vgg: 0.3867, mask: 0.3714\n",
      "step:   195020, time: 0.745, loss: 0.9410, l1: 0.1891, vgg: 0.3797, mask: 0.3721\n",
      "step:   195040, time: 0.739, loss: 1.0834, l1: 0.2139, vgg: 0.4782, mask: 0.3912\n",
      "step:   195060, time: 0.783, loss: 0.8395, l1: 0.1327, vgg: 0.3505, mask: 0.3563\n",
      "step:   195080, time: 0.779, loss: 1.0782, l1: 0.2007, vgg: 0.4398, mask: 0.4377\n",
      "step:   195100, time: 0.711, loss: 0.9675, l1: 0.2130, vgg: 0.3848, mask: 0.3697\n",
      "step:   195120, time: 0.773, loss: 0.9352, l1: 0.1534, vgg: 0.4195, mask: 0.3623\n",
      "step:   195140, time: 0.764, loss: 0.9703, l1: 0.1884, vgg: 0.4161, mask: 0.3658\n",
      "step:   195160, time: 0.770, loss: 0.9715, l1: 0.1711, vgg: 0.4379, mask: 0.3625\n",
      "step:   195180, time: 0.792, loss: 1.0121, l1: 0.2315, vgg: 0.3809, mask: 0.3997\n",
      "step:   195200, time: 0.761, loss: 0.9877, l1: 0.2103, vgg: 0.4089, mask: 0.3685\n",
      "step:   195220, time: 0.778, loss: 0.9694, l1: 0.1864, vgg: 0.3812, mask: 0.4017\n",
      "step:   195240, time: 0.761, loss: 0.9418, l1: 0.2216, vgg: 0.3501, mask: 0.3700\n",
      "step:   195260, time: 0.769, loss: 0.9895, l1: 0.1994, vgg: 0.4220, mask: 0.3680\n",
      "step:   195280, time: 0.755, loss: 0.9313, l1: 0.1645, vgg: 0.3692, mask: 0.3975\n",
      "step:   195300, time: 0.770, loss: 1.0343, l1: 0.1906, vgg: 0.4449, mask: 0.3987\n",
      "step:   195320, time: 0.761, loss: 1.0729, l1: 0.2412, vgg: 0.4625, mask: 0.3692\n",
      "step:   195340, time: 0.762, loss: 0.9136, l1: 0.1703, vgg: 0.4042, mask: 0.3391\n",
      "step:   195360, time: 0.756, loss: 1.0251, l1: 0.2379, vgg: 0.3655, mask: 0.4217\n",
      "step:   195380, time: 0.783, loss: 0.9373, l1: 0.1674, vgg: 0.3914, mask: 0.3785\n",
      "step:   195400, time: 0.817, loss: 1.0448, l1: 0.2089, vgg: 0.4717, mask: 0.3641\n",
      "step:   195420, time: 0.735, loss: 0.8550, l1: 0.1408, vgg: 0.3999, mask: 0.3143\n",
      "step:   195440, time: 0.744, loss: 0.9011, l1: 0.1726, vgg: 0.3425, mask: 0.3860\n",
      "step:   195460, time: 0.747, loss: 0.9556, l1: 0.1838, vgg: 0.3948, mask: 0.3770\n",
      "step:   195480, time: 0.731, loss: 0.8365, l1: 0.1451, vgg: 0.3776, mask: 0.3137\n",
      "step:   195500, time: 0.772, loss: 1.0965, l1: 0.2320, vgg: 0.4603, mask: 0.4042\n",
      "step:   195520, time: 0.731, loss: 0.9807, l1: 0.2033, vgg: 0.3781, mask: 0.3993\n",
      "step:   195540, time: 0.735, loss: 0.8135, l1: 0.1632, vgg: 0.3187, mask: 0.3316\n",
      "step:   195560, time: 0.710, loss: 1.0149, l1: 0.2374, vgg: 0.3760, mask: 0.4015\n",
      "step:   195580, time: 0.308, loss: 1.3007, l1: 0.3343, vgg: 0.5291, mask: 0.4373\n",
      "step:   195600, time: 0.780, loss: 1.0641, l1: 0.2591, vgg: 0.4141, mask: 0.3909\n",
      "step:   195620, time: 0.770, loss: 1.0177, l1: 0.2340, vgg: 0.4111, mask: 0.3726\n",
      "step:   195640, time: 0.777, loss: 1.0066, l1: 0.2294, vgg: 0.4142, mask: 0.3630\n",
      "step:   195660, time: 0.740, loss: 1.0218, l1: 0.2423, vgg: 0.3892, mask: 0.3903\n",
      "step:   195680, time: 0.720, loss: 0.9729, l1: 0.1814, vgg: 0.4200, mask: 0.3716\n",
      "step:   195700, time: 0.748, loss: 1.1284, l1: 0.2770, vgg: 0.4589, mask: 0.3925\n",
      "step:   195720, time: 0.724, loss: 1.0281, l1: 0.1999, vgg: 0.4533, mask: 0.3749\n",
      "step:   195740, time: 0.770, loss: 0.9177, l1: 0.1880, vgg: 0.3563, mask: 0.3734\n",
      "step:   195760, time: 0.740, loss: 0.9154, l1: 0.1694, vgg: 0.3932, mask: 0.3528\n",
      "step:   195780, time: 0.708, loss: 1.0521, l1: 0.2742, vgg: 0.3848, mask: 0.3930\n",
      "step:   195800, time: 0.737, loss: 1.0117, l1: 0.2208, vgg: 0.3962, mask: 0.3947\n",
      "step:   195820, time: 0.747, loss: 0.9757, l1: 0.1962, vgg: 0.4089, mask: 0.3707\n",
      "step:   195840, time: 0.753, loss: 0.9179, l1: 0.1842, vgg: 0.3691, mask: 0.3647\n",
      "step:   195860, time: 0.743, loss: 1.0796, l1: 0.2456, vgg: 0.4407, mask: 0.3934\n",
      "step:   195880, time: 0.756, loss: 0.9343, l1: 0.1904, vgg: 0.3889, mask: 0.3551\n",
      "step:   195900, time: 0.753, loss: 0.9673, l1: 0.2057, vgg: 0.3659, mask: 0.3957\n",
      "step:   195920, time: 0.760, loss: 0.9049, l1: 0.1807, vgg: 0.3677, mask: 0.3566\n",
      "step:   195940, time: 0.758, loss: 1.0761, l1: 0.2431, vgg: 0.4387, mask: 0.3943\n",
      "step:   195960, time: 0.757, loss: 0.9123, l1: 0.1776, vgg: 0.3481, mask: 0.3866\n",
      "step:   195980, time: 0.770, loss: 0.9489, l1: 0.2168, vgg: 0.3650, mask: 0.3672\n",
      "step:   196000, time: 0.773, loss: 1.0039, l1: 0.2202, vgg: 0.3553, mask: 0.4284\n",
      "step:   196020, time: 0.754, loss: 0.9402, l1: 0.1732, vgg: 0.4196, mask: 0.3474\n",
      "step:   196040, time: 0.764, loss: 1.0818, l1: 0.2399, vgg: 0.3990, mask: 0.4429\n",
      "step:   196060, time: 0.796, loss: 1.0786, l1: 0.2517, vgg: 0.4278, mask: 0.3991\n",
      "step:   196080, time: 0.782, loss: 0.8632, l1: 0.1459, vgg: 0.3441, mask: 0.3732\n",
      "step:   196100, time: 0.763, loss: 0.9199, l1: 0.1722, vgg: 0.3956, mask: 0.3521\n",
      "step:   196120, time: 0.779, loss: 0.8515, l1: 0.1648, vgg: 0.3543, mask: 0.3324\n",
      "step:   196140, time: 0.753, loss: 0.9035, l1: 0.1332, vgg: 0.4113, mask: 0.3589\n",
      "step:   196160, time: 0.761, loss: 1.0410, l1: 0.1866, vgg: 0.4754, mask: 0.3789\n",
      "step:   196180, time: 0.777, loss: 0.9700, l1: 0.1853, vgg: 0.4022, mask: 0.3825\n",
      "step:   196200, time: 0.749, loss: 0.9571, l1: 0.1640, vgg: 0.4254, mask: 0.3678\n",
      "step:   196220, time: 0.800, loss: 1.1391, l1: 0.2957, vgg: 0.4115, mask: 0.4319\n",
      "step:   196240, time: 0.729, loss: 1.0301, l1: 0.2325, vgg: 0.3711, mask: 0.4265\n",
      "step:   196260, time: 0.751, loss: 1.0142, l1: 0.1896, vgg: 0.4334, mask: 0.3912\n",
      "step:   196280, time: 0.794, loss: 1.0520, l1: 0.2256, vgg: 0.4310, mask: 0.3954\n",
      "step:   196300, time: 0.764, loss: 0.9925, l1: 0.1703, vgg: 0.4631, mask: 0.3591\n",
      "step:   196320, time: 0.750, loss: 1.1568, l1: 0.2812, vgg: 0.4631, mask: 0.4126\n",
      "step:   196340, time: 0.734, loss: 0.8774, l1: 0.1838, vgg: 0.3627, mask: 0.3309\n",
      "step:   196360, time: 0.780, loss: 1.0986, l1: 0.2175, vgg: 0.4705, mask: 0.4106\n",
      "step:   196380, time: 0.755, loss: 0.9161, l1: 0.1945, vgg: 0.3577, mask: 0.3640\n",
      "step:   196400, time: 0.764, loss: 1.0382, l1: 0.2103, vgg: 0.4201, mask: 0.4079\n",
      "step:   196420, time: 0.754, loss: 1.0357, l1: 0.2095, vgg: 0.4495, mask: 0.3767\n",
      "step:   196440, time: 0.781, loss: 1.0340, l1: 0.2224, vgg: 0.4595, mask: 0.3522\n",
      "step:   196460, time: 0.742, loss: 1.0046, l1: 0.2431, vgg: 0.3720, mask: 0.3894\n",
      "step:   196480, time: 0.739, loss: 0.9622, l1: 0.2084, vgg: 0.3718, mask: 0.3820\n",
      "step:   196500, time: 0.766, loss: 1.0437, l1: 0.1901, vgg: 0.4615, mask: 0.3921\n",
      "step:   196520, time: 0.734, loss: 1.0636, l1: 0.2149, vgg: 0.4670, mask: 0.3818\n",
      "step:   196540, time: 0.798, loss: 1.1291, l1: 0.2621, vgg: 0.4633, mask: 0.4037\n",
      "step:   196560, time: 0.732, loss: 0.9073, l1: 0.1797, vgg: 0.3600, mask: 0.3676\n",
      "step:   196580, time: 0.794, loss: 1.0532, l1: 0.2160, vgg: 0.4647, mask: 0.3726\n",
      "step:   196600, time: 0.780, loss: 1.0323, l1: 0.1877, vgg: 0.4704, mask: 0.3742\n",
      "step:   196620, time: 0.727, loss: 1.0404, l1: 0.1882, vgg: 0.4559, mask: 0.3964\n",
      "step:   196640, time: 0.734, loss: 0.9714, l1: 0.2088, vgg: 0.3714, mask: 0.3912\n",
      "step:   196660, time: 0.739, loss: 0.9224, l1: 0.1760, vgg: 0.4103, mask: 0.3361\n",
      "step:   196680, time: 0.708, loss: 0.8936, l1: 0.1507, vgg: 0.3788, mask: 0.3641\n",
      "step:   196700, time: 0.765, loss: 1.0295, l1: 0.2188, vgg: 0.4113, mask: 0.3994\n",
      "step:   196720, time: 0.761, loss: 1.0707, l1: 0.2095, vgg: 0.4801, mask: 0.3811\n",
      "step:   196740, time: 0.765, loss: 1.1543, l1: 0.2826, vgg: 0.4620, mask: 0.4097\n",
      "step:   196760, time: 0.734, loss: 0.9152, l1: 0.1961, vgg: 0.3665, mask: 0.3526\n",
      "step:   196780, time: 0.738, loss: 0.8463, l1: 0.1259, vgg: 0.3753, mask: 0.3451\n",
      "step:   196800, time: 0.779, loss: 0.9459, l1: 0.2004, vgg: 0.3924, mask: 0.3530\n",
      "step:   196820, time: 0.733, loss: 0.9962, l1: 0.2465, vgg: 0.3755, mask: 0.3742\n",
      "step:   196840, time: 0.753, loss: 1.0026, l1: 0.2077, vgg: 0.4057, mask: 0.3891\n",
      "step:   196860, time: 0.740, loss: 0.9531, l1: 0.2065, vgg: 0.3861, mask: 0.3605\n",
      "step:   196880, time: 0.727, loss: 0.9317, l1: 0.2027, vgg: 0.3684, mask: 0.3607\n",
      "step:   196900, time: 0.793, loss: 1.1745, l1: 0.2435, vgg: 0.5022, mask: 0.4287\n",
      "step:   196920, time: 0.748, loss: 1.0368, l1: 0.1881, vgg: 0.4187, mask: 0.4300\n",
      "step:   196940, time: 0.788, loss: 1.1308, l1: 0.2727, vgg: 0.4463, mask: 0.4118\n",
      "step:   196960, time: 0.760, loss: 0.9672, l1: 0.2052, vgg: 0.3793, mask: 0.3827\n",
      "step:   196980, time: 0.762, loss: 1.0697, l1: 0.2453, vgg: 0.4368, mask: 0.3876\n",
      "step:   197000, time: 0.738, loss: 0.9803, l1: 0.2037, vgg: 0.3865, mask: 0.3901\n",
      "step:   197020, time: 0.768, loss: 0.9877, l1: 0.1764, vgg: 0.4647, mask: 0.3467\n",
      "step:   197040, time: 0.759, loss: 0.9612, l1: 0.1960, vgg: 0.3923, mask: 0.3728\n",
      "step:   197060, time: 0.739, loss: 0.9467, l1: 0.1920, vgg: 0.3727, mask: 0.3819\n",
      "step:   197080, time: 0.739, loss: 0.9476, l1: 0.1742, vgg: 0.4273, mask: 0.3460\n",
      "step:   197100, time: 0.766, loss: 1.0599, l1: 0.2588, vgg: 0.4032, mask: 0.3979\n",
      "step:   197120, time: 0.766, loss: 0.9770, l1: 0.2071, vgg: 0.3759, mask: 0.3940\n",
      "step:   197140, time: 0.735, loss: 0.9898, l1: 0.2179, vgg: 0.3842, mask: 0.3878\n",
      "step:   197160, time: 0.798, loss: 1.0310, l1: 0.2295, vgg: 0.4042, mask: 0.3972\n",
      "step:   197180, time: 0.750, loss: 1.1174, l1: 0.2452, vgg: 0.4869, mask: 0.3853\n",
      "step:   197200, time: 0.730, loss: 0.9898, l1: 0.2250, vgg: 0.3480, mask: 0.4168\n",
      "step:   197220, time: 0.758, loss: 1.0695, l1: 0.2349, vgg: 0.4190, mask: 0.4156\n",
      "step:   197240, time: 0.752, loss: 0.9697, l1: 0.2116, vgg: 0.3864, mask: 0.3717\n",
      "step:   197260, time: 0.759, loss: 1.0583, l1: 0.2471, vgg: 0.3809, mask: 0.4303\n",
      "step:   197280, time: 0.760, loss: 1.0109, l1: 0.2468, vgg: 0.3580, mask: 0.4061\n",
      "step:   197300, time: 0.733, loss: 0.9707, l1: 0.1968, vgg: 0.4141, mask: 0.3597\n",
      "step:   197320, time: 0.757, loss: 1.0899, l1: 0.2721, vgg: 0.3967, mask: 0.4211\n",
      "step:   197340, time: 0.721, loss: 0.9920, l1: 0.2234, vgg: 0.3771, mask: 0.3915\n",
      "step:   197360, time: 0.759, loss: 1.0862, l1: 0.2358, vgg: 0.4455, mask: 0.4049\n",
      "step:   197380, time: 0.722, loss: 0.9368, l1: 0.2257, vgg: 0.3348, mask: 0.3762\n",
      "step:   197400, time: 0.780, loss: 0.9724, l1: 0.2037, vgg: 0.3664, mask: 0.4023\n",
      "step:   197420, time: 0.757, loss: 0.9550, l1: 0.1992, vgg: 0.3858, mask: 0.3701\n",
      "step:   197440, time: 0.719, loss: 0.9393, l1: 0.1874, vgg: 0.3922, mask: 0.3597\n",
      "step:   197460, time: 0.775, loss: 0.9907, l1: 0.1934, vgg: 0.4148, mask: 0.3825\n",
      "step:   197480, time: 0.758, loss: 1.1000, l1: 0.2659, vgg: 0.4464, mask: 0.3877\n",
      "step:   197500, time: 0.776, loss: 1.0581, l1: 0.2164, vgg: 0.4208, mask: 0.4210\n",
      "step:   197520, time: 0.732, loss: 1.0346, l1: 0.1993, vgg: 0.4314, mask: 0.4039\n",
      "step:   197540, time: 0.730, loss: 0.9739, l1: 0.2150, vgg: 0.3835, mask: 0.3754\n",
      "step:   197560, time: 0.756, loss: 1.0289, l1: 0.2258, vgg: 0.4275, mask: 0.3756\n",
      "step:   197580, time: 0.768, loss: 0.9013, l1: 0.1625, vgg: 0.4150, mask: 0.3238\n",
      "step:   197600, time: 0.763, loss: 0.9737, l1: 0.2126, vgg: 0.3713, mask: 0.3898\n",
      "step:   197620, time: 0.760, loss: 1.0407, l1: 0.2186, vgg: 0.4150, mask: 0.4072\n",
      "step:   197640, time: 0.773, loss: 1.1254, l1: 0.2681, vgg: 0.4672, mask: 0.3901\n",
      "step:   197660, time: 0.735, loss: 0.9602, l1: 0.1775, vgg: 0.4193, mask: 0.3634\n",
      "step:   197680, time: 0.766, loss: 1.0594, l1: 0.2640, vgg: 0.4045, mask: 0.3909\n",
      "step:   197700, time: 0.797, loss: 1.0784, l1: 0.2403, vgg: 0.4784, mask: 0.3597\n",
      "step:   197720, time: 0.763, loss: 1.0200, l1: 0.2296, vgg: 0.4146, mask: 0.3757\n",
      "step:   197740, time: 0.725, loss: 0.8828, l1: 0.1477, vgg: 0.3516, mask: 0.3836\n",
      "step:   197760, time: 0.780, loss: 1.0445, l1: 0.2144, vgg: 0.4609, mask: 0.3692\n",
      "step:   197780, time: 0.717, loss: 0.9381, l1: 0.1656, vgg: 0.3774, mask: 0.3952\n",
      "step:   197800, time: 0.752, loss: 0.9524, l1: 0.1532, vgg: 0.4304, mask: 0.3688\n",
      "step:   197820, time: 0.761, loss: 1.0777, l1: 0.2429, vgg: 0.4541, mask: 0.3807\n",
      "step:   197840, time: 0.744, loss: 1.1164, l1: 0.2181, vgg: 0.4945, mask: 0.4039\n",
      "step:   197860, time: 0.741, loss: 0.9814, l1: 0.1713, vgg: 0.4201, mask: 0.3901\n",
      "step:   197880, time: 0.750, loss: 1.0693, l1: 0.2291, vgg: 0.4442, mask: 0.3961\n",
      "step:   197900, time: 0.804, loss: 1.0375, l1: 0.2217, vgg: 0.4335, mask: 0.3823\n",
      "step:   197920, time: 0.796, loss: 1.0683, l1: 0.2563, vgg: 0.4125, mask: 0.3995\n",
      "step:   197940, time: 0.717, loss: 1.0256, l1: 0.2305, vgg: 0.3983, mask: 0.3968\n",
      "step:   197960, time: 0.736, loss: 0.9766, l1: 0.2211, vgg: 0.3642, mask: 0.3912\n",
      "step:   197980, time: 0.780, loss: 0.9187, l1: 0.1886, vgg: 0.3869, mask: 0.3433\n",
      "step:   198000, time: 0.766, loss: 0.9658, l1: 0.1966, vgg: 0.4192, mask: 0.3500\n",
      "step:   198020, time: 0.763, loss: 0.9820, l1: 0.2189, vgg: 0.3927, mask: 0.3705\n",
      "step:   198040, time: 0.739, loss: 0.9599, l1: 0.2010, vgg: 0.4044, mask: 0.3545\n",
      "step:   198060, time: 0.767, loss: 0.9349, l1: 0.1656, vgg: 0.4253, mask: 0.3439\n",
      "step:   198080, time: 0.762, loss: 1.0353, l1: 0.2279, vgg: 0.3942, mask: 0.4132\n",
      "step:   198100, time: 0.801, loss: 0.9794, l1: 0.2093, vgg: 0.3795, mask: 0.3906\n",
      "step:   198120, time: 0.770, loss: 0.9782, l1: 0.2214, vgg: 0.3695, mask: 0.3873\n",
      "step:   198140, time: 0.750, loss: 1.0269, l1: 0.2172, vgg: 0.4532, mask: 0.3566\n",
      "step:   198160, time: 0.750, loss: 0.9393, l1: 0.1977, vgg: 0.3781, mask: 0.3634\n",
      "step:   198180, time: 0.728, loss: 1.1181, l1: 0.3020, vgg: 0.3971, mask: 0.4191\n",
      "step:   198200, time: 0.810, loss: 1.1309, l1: 0.1945, vgg: 0.5202, mask: 0.4162\n",
      "step:   198220, time: 0.742, loss: 0.9176, l1: 0.1764, vgg: 0.3831, mask: 0.3581\n",
      "step:   198240, time: 0.716, loss: 1.0736, l1: 0.2580, vgg: 0.4076, mask: 0.4081\n",
      "step:   198260, time: 0.771, loss: 1.0734, l1: 0.2207, vgg: 0.4505, mask: 0.4022\n",
      "step:   198280, time: 0.822, loss: 0.9797, l1: 0.1893, vgg: 0.4039, mask: 0.3864\n",
      "step:   198300, time: 0.732, loss: 1.0138, l1: 0.2314, vgg: 0.3757, mask: 0.4066\n",
      "step:   198320, time: 0.743, loss: 0.9715, l1: 0.2025, vgg: 0.3977, mask: 0.3713\n",
      "step:   198340, time: 0.760, loss: 1.0767, l1: 0.2464, vgg: 0.4257, mask: 0.4046\n",
      "step:   198360, time: 0.756, loss: 0.9936, l1: 0.2425, vgg: 0.3671, mask: 0.3840\n",
      "step:   198380, time: 0.751, loss: 1.0705, l1: 0.2481, vgg: 0.4139, mask: 0.4085\n",
      "step:   198400, time: 0.746, loss: 1.0799, l1: 0.2387, vgg: 0.4319, mask: 0.4093\n",
      "step:   198420, time: 0.802, loss: 1.0697, l1: 0.2315, vgg: 0.4185, mask: 0.4197\n",
      "step:   198440, time: 0.785, loss: 0.9908, l1: 0.1903, vgg: 0.4401, mask: 0.3604\n",
      "step:   198460, time: 0.814, loss: 1.0215, l1: 0.1817, vgg: 0.4521, mask: 0.3877\n",
      "step:   198480, time: 0.759, loss: 1.0007, l1: 0.2268, vgg: 0.4328, mask: 0.3412\n",
      "step:   198500, time: 0.756, loss: 1.0087, l1: 0.1895, vgg: 0.4094, mask: 0.4098\n",
      "step:   198520, time: 0.761, loss: 0.9780, l1: 0.1768, vgg: 0.4354, mask: 0.3658\n",
      "step:   198540, time: 0.785, loss: 1.0342, l1: 0.2234, vgg: 0.4380, mask: 0.3729\n",
      "step:   198560, time: 0.754, loss: 0.9668, l1: 0.1900, vgg: 0.3857, mask: 0.3911\n",
      "step:   198580, time: 0.744, loss: 0.8669, l1: 0.1655, vgg: 0.3748, mask: 0.3266\n",
      "step:   198600, time: 0.765, loss: 1.1703, l1: 0.2502, vgg: 0.5194, mask: 0.4007\n",
      "step:   198620, time: 0.790, loss: 1.0856, l1: 0.2856, vgg: 0.3802, mask: 0.4198\n",
      "step:   198640, time: 0.736, loss: 0.8789, l1: 0.1685, vgg: 0.3451, mask: 0.3653\n",
      "step:   198660, time: 0.765, loss: 0.9067, l1: 0.1798, vgg: 0.3784, mask: 0.3486\n",
      "step:   198680, time: 0.738, loss: 1.1027, l1: 0.2730, vgg: 0.4189, mask: 0.4109\n",
      "step:   198700, time: 0.734, loss: 1.0905, l1: 0.2461, vgg: 0.4213, mask: 0.4232\n",
      "step:   198720, time: 0.784, loss: 1.0975, l1: 0.2292, vgg: 0.4466, mask: 0.4218\n",
      "step:   198740, time: 0.745, loss: 0.9856, l1: 0.2158, vgg: 0.3811, mask: 0.3886\n",
      "step:   198760, time: 0.750, loss: 1.0423, l1: 0.2554, vgg: 0.4007, mask: 0.3862\n",
      "step:   198780, time: 0.763, loss: 1.0025, l1: 0.2130, vgg: 0.3958, mask: 0.3938\n",
      "step:   198800, time: 0.726, loss: 0.8652, l1: 0.1695, vgg: 0.3445, mask: 0.3512\n",
      "step:   198820, time: 0.742, loss: 1.0339, l1: 0.1974, vgg: 0.4363, mask: 0.4002\n",
      "step:   198840, time: 0.768, loss: 0.9760, l1: 0.2415, vgg: 0.3686, mask: 0.3659\n",
      "step:   198860, time: 0.774, loss: 1.1456, l1: 0.2542, vgg: 0.4734, mask: 0.4181\n",
      "step:   198880, time: 0.736, loss: 0.9327, l1: 0.1677, vgg: 0.4385, mask: 0.3266\n",
      "step:   198900, time: 0.721, loss: 0.9608, l1: 0.2367, vgg: 0.3508, mask: 0.3733\n",
      "step:   198920, time: 0.741, loss: 0.9725, l1: 0.2086, vgg: 0.3848, mask: 0.3792\n",
      "step:   198940, time: 0.739, loss: 0.9638, l1: 0.1828, vgg: 0.4024, mask: 0.3786\n",
      "step:   198960, time: 0.726, loss: 0.9316, l1: 0.1873, vgg: 0.3787, mask: 0.3656\n",
      "step:   198980, time: 0.798, loss: 0.9778, l1: 0.2223, vgg: 0.3742, mask: 0.3813\n",
      "step:   199000, time: 0.734, loss: 0.9719, l1: 0.1930, vgg: 0.4125, mask: 0.3663\n",
      "step:   199020, time: 0.778, loss: 1.1794, l1: 0.2686, vgg: 0.4730, mask: 0.4378\n",
      "step:   199040, time: 0.755, loss: 1.0170, l1: 0.2317, vgg: 0.4047, mask: 0.3805\n",
      "step:   199060, time: 0.721, loss: 0.9969, l1: 0.2368, vgg: 0.3188, mask: 0.4412\n",
      "step:   199080, time: 0.759, loss: 0.9609, l1: 0.1749, vgg: 0.3934, mask: 0.3926\n",
      "step:   199100, time: 0.785, loss: 0.9728, l1: 0.2055, vgg: 0.3971, mask: 0.3702\n",
      "step:   199120, time: 0.787, loss: 1.0735, l1: 0.2300, vgg: 0.4459, mask: 0.3976\n",
      "step:   199140, time: 0.790, loss: 1.0087, l1: 0.2164, vgg: 0.4261, mask: 0.3662\n",
      "step:   199160, time: 0.740, loss: 0.9112, l1: 0.1670, vgg: 0.3889, mask: 0.3552\n",
      "step:   199180, time: 0.788, loss: 1.0039, l1: 0.2025, vgg: 0.4202, mask: 0.3812\n",
      "step:   199200, time: 0.778, loss: 1.0120, l1: 0.2158, vgg: 0.4321, mask: 0.3641\n",
      "step:   199220, time: 0.770, loss: 0.9682, l1: 0.2136, vgg: 0.3556, mask: 0.3991\n",
      "step:   199240, time: 0.749, loss: 1.0007, l1: 0.2057, vgg: 0.4190, mask: 0.3760\n",
      "step:   199260, time: 0.778, loss: 1.0832, l1: 0.2293, vgg: 0.4487, mask: 0.4052\n",
      "step:   199280, time: 0.748, loss: 1.0779, l1: 0.2594, vgg: 0.4037, mask: 0.4148\n",
      "step:   199300, time: 0.765, loss: 1.1022, l1: 0.2544, vgg: 0.4312, mask: 0.4167\n",
      "step:   199320, time: 0.748, loss: 0.9199, l1: 0.1760, vgg: 0.3966, mask: 0.3473\n",
      "step:   199340, time: 0.724, loss: 1.0262, l1: 0.2010, vgg: 0.4316, mask: 0.3936\n",
      "step:   199360, time: 0.755, loss: 1.0646, l1: 0.2129, vgg: 0.4702, mask: 0.3815\n",
      "step:   199380, time: 0.788, loss: 1.0124, l1: 0.2285, vgg: 0.3968, mask: 0.3871\n",
      "step:   199400, time: 0.743, loss: 1.0585, l1: 0.2410, vgg: 0.4167, mask: 0.4009\n",
      "step:   199420, time: 0.770, loss: 0.9628, l1: 0.1836, vgg: 0.4025, mask: 0.3767\n",
      "step:   199440, time: 0.733, loss: 0.9586, l1: 0.2449, vgg: 0.3620, mask: 0.3517\n",
      "step:   199460, time: 0.758, loss: 1.0235, l1: 0.2206, vgg: 0.4407, mask: 0.3623\n",
      "step:   199480, time: 0.756, loss: 0.9859, l1: 0.2219, vgg: 0.3774, mask: 0.3867\n",
      "step:   199500, time: 0.729, loss: 1.0405, l1: 0.2210, vgg: 0.4270, mask: 0.3925\n",
      "step:   199520, time: 0.763, loss: 1.0035, l1: 0.2238, vgg: 0.3715, mask: 0.4082\n",
      "step:   199540, time: 0.726, loss: 0.9663, l1: 0.2329, vgg: 0.3134, mask: 0.4200\n",
      "step:   199560, time: 0.750, loss: 0.9220, l1: 0.1732, vgg: 0.3729, mask: 0.3760\n",
      "step:   199580, time: 0.764, loss: 1.1062, l1: 0.2477, vgg: 0.4528, mask: 0.4057\n",
      "step:   199600, time: 0.757, loss: 1.0024, l1: 0.2032, vgg: 0.4037, mask: 0.3955\n",
      "step:   199620, time: 0.740, loss: 0.9454, l1: 0.2075, vgg: 0.3511, mask: 0.3867\n",
      "step:   199640, time: 0.779, loss: 1.1533, l1: 0.2258, vgg: 0.5272, mask: 0.4003\n",
      "step:   199660, time: 0.762, loss: 1.0122, l1: 0.2190, vgg: 0.4187, mask: 0.3745\n",
      "step:   199680, time: 0.734, loss: 0.9846, l1: 0.2196, vgg: 0.3900, mask: 0.3749\n",
      "step:   199700, time: 0.742, loss: 0.9823, l1: 0.2184, vgg: 0.3650, mask: 0.3988\n",
      "step:   199720, time: 0.734, loss: 0.9892, l1: 0.2019, vgg: 0.4173, mask: 0.3700\n",
      "step:   199740, time: 0.760, loss: 1.0743, l1: 0.2421, vgg: 0.4457, mask: 0.3865\n",
      "step:   199760, time: 0.731, loss: 0.9240, l1: 0.1865, vgg: 0.3710, mask: 0.3666\n",
      "step:   199780, time: 0.790, loss: 1.0526, l1: 0.2469, vgg: 0.3889, mask: 0.4169\n",
      "step:   199800, time: 0.762, loss: 0.9408, l1: 0.1648, vgg: 0.3729, mask: 0.4032\n",
      "step:   199820, time: 0.740, loss: 0.9877, l1: 0.2062, vgg: 0.4122, mask: 0.3692\n",
      "step:   199840, time: 0.809, loss: 1.0218, l1: 0.2454, vgg: 0.4088, mask: 0.3677\n",
      "step:   199860, time: 0.752, loss: 1.0364, l1: 0.2041, vgg: 0.4308, mask: 0.4015\n",
      "step:   199880, time: 0.744, loss: 0.9165, l1: 0.1763, vgg: 0.3815, mask: 0.3587\n",
      "step:   199900, time: 0.779, loss: 0.9698, l1: 0.1790, vgg: 0.4502, mask: 0.3406\n",
      "step:   199920, time: 0.759, loss: 0.9818, l1: 0.2154, vgg: 0.3880, mask: 0.3784\n",
      "step:   199940, time: 0.783, loss: 1.0509, l1: 0.2374, vgg: 0.4126, mask: 0.4010\n",
      "step:   199960, time: 0.716, loss: 0.9829, l1: 0.1955, vgg: 0.3922, mask: 0.3952\n",
      "step:   199980, time: 0.753, loss: 0.9727, l1: 0.1734, vgg: 0.4379, mask: 0.3614\n",
      "step:   200000, time: 0.795, loss: 0.9680, l1: 0.1907, vgg: 0.3959, mask: 0.3814\n",
      "Finished training TOM, nameed: tom_train_new!\n"
     ]
    }
   ],
   "source": [
    "!python train.py --name tom_train_new --stage TOM --workers 4 --save_count 5000 --shuffle "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=4, checkpoint='checkpoints/tom_train_new/tom_final.pth', data_list='test_pairs.txt', datamode='test', dataroot='data', display_count=1, fine_height=256, fine_width=192, gpu_ids='', grid_size=5, name='tom_test_new', radius=5, result_dir='result', shuffle=False, stage='TOM', tensorboard_dir='tensorboard', workers=4)\n",
      "Start to test stage: TOM, named: tom_test_new!\n",
      "Dataset size: 02032!\n",
      "step:        1, time: 2.331\n",
      "step:        2, time: 0.640\n",
      "step:        3, time: 0.612\n",
      "step:        4, time: 0.604\n",
      "step:        5, time: 0.594\n",
      "step:        6, time: 0.641\n",
      "step:        7, time: 0.614\n",
      "step:        8, time: 0.595\n",
      "step:        9, time: 0.635\n",
      "step:       10, time: 0.594\n",
      "step:       11, time: 0.604\n",
      "step:       12, time: 0.600\n",
      "step:       13, time: 0.567\n",
      "step:       14, time: 0.599\n",
      "step:       15, time: 0.578\n",
      "step:       16, time: 0.616\n",
      "step:       17, time: 0.584\n",
      "step:       18, time: 0.626\n",
      "step:       19, time: 0.616\n",
      "step:       20, time: 0.593\n",
      "step:       21, time: 0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:3118: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:       22, time: 0.601\n",
      "step:       23, time: 0.600\n",
      "step:       24, time: 0.619\n",
      "step:       25, time: 0.627\n",
      "step:       26, time: 0.586\n",
      "step:       27, time: 0.549\n",
      "step:       28, time: 0.568\n",
      "step:       29, time: 0.557\n",
      "step:       30, time: 0.566\n",
      "step:       31, time: 0.571\n",
      "step:       32, time: 0.597\n",
      "step:       33, time: 0.643\n",
      "step:       34, time: 0.609\n",
      "step:       35, time: 0.599\n",
      "step:       36, time: 0.614\n",
      "step:       37, time: 0.577\n",
      "step:       38, time: 0.555\n",
      "step:       39, time: 0.576\n",
      "step:       40, time: 0.577\n",
      "step:       41, time: 0.589\n",
      "step:       42, time: 0.631\n",
      "step:       43, time: 0.598\n",
      "step:       44, time: 0.612\n",
      "step:       45, time: 0.581\n",
      "step:       46, time: 0.594\n",
      "step:       47, time: 0.633\n",
      "step:       48, time: 0.577\n",
      "step:       49, time: 0.573\n",
      "step:       50, time: 0.621\n",
      "step:       51, time: 0.624\n",
      "step:       52, time: 0.625\n",
      "step:       53, time: 0.574\n",
      "step:       54, time: 0.585\n",
      "step:       55, time: 0.612\n",
      "step:       56, time: 0.624\n",
      "step:       57, time: 0.638\n",
      "step:       58, time: 0.640\n",
      "step:       59, time: 0.616\n",
      "step:       60, time: 0.639\n",
      "step:       61, time: 0.596\n",
      "step:       62, time: 0.587\n",
      "step:       63, time: 0.630\n",
      "step:       64, time: 0.628\n",
      "step:       65, time: 0.607\n",
      "step:       66, time: 0.616\n",
      "step:       67, time: 0.604\n",
      "step:       68, time: 0.611\n",
      "step:       69, time: 0.576\n",
      "step:       70, time: 0.608\n",
      "step:       71, time: 0.682\n",
      "step:       72, time: 0.593\n",
      "step:       73, time: 0.609\n",
      "step:       74, time: 0.581\n",
      "step:       75, time: 0.615\n",
      "step:       76, time: 0.593\n",
      "step:       77, time: 0.628\n",
      "step:       78, time: 0.642\n",
      "step:       79, time: 0.632\n",
      "step:       80, time: 0.629\n",
      "step:       81, time: 0.631\n",
      "step:       82, time: 0.619\n",
      "step:       83, time: 0.602\n",
      "step:       84, time: 0.637\n",
      "step:       85, time: 0.616\n",
      "step:       86, time: 0.615\n",
      "step:       87, time: 0.606\n",
      "step:       88, time: 0.610\n",
      "step:       89, time: 0.580\n",
      "step:       90, time: 0.596\n",
      "step:       91, time: 0.586\n",
      "step:       92, time: 0.598\n",
      "step:       93, time: 0.589\n",
      "step:       94, time: 0.628\n",
      "step:       95, time: 0.574\n",
      "step:       96, time: 0.609\n",
      "step:       97, time: 0.596\n",
      "step:       98, time: 0.622\n",
      "step:       99, time: 0.604\n",
      "step:      100, time: 0.642\n",
      "step:      101, time: 0.722\n",
      "step:      102, time: 0.652\n",
      "step:      103, time: 0.634\n",
      "step:      104, time: 0.599\n",
      "step:      105, time: 0.584\n",
      "step:      106, time: 0.616\n",
      "step:      107, time: 0.627\n",
      "step:      108, time: 0.586\n",
      "step:      109, time: 0.621\n",
      "step:      110, time: 0.633\n",
      "step:      111, time: 0.659\n",
      "step:      112, time: 0.641\n",
      "step:      113, time: 0.611\n",
      "step:      114, time: 0.625\n",
      "step:      115, time: 0.622\n",
      "step:      116, time: 0.653\n",
      "step:      117, time: 0.613\n",
      "step:      118, time: 0.602\n",
      "step:      119, time: 0.651\n",
      "step:      120, time: 0.568\n",
      "step:      121, time: 0.586\n",
      "step:      122, time: 0.583\n",
      "step:      123, time: 0.603\n",
      "step:      124, time: 0.599\n",
      "step:      125, time: 0.640\n",
      "step:      126, time: 0.624\n",
      "step:      127, time: 0.564\n",
      "step:      128, time: 0.605\n",
      "step:      129, time: 0.548\n",
      "step:      130, time: 0.583\n",
      "step:      131, time: 0.632\n",
      "step:      132, time: 0.621\n",
      "step:      133, time: 0.694\n",
      "step:      134, time: 0.673\n",
      "step:      135, time: 0.721\n",
      "step:      136, time: 0.710\n",
      "step:      137, time: 0.707\n",
      "step:      138, time: 0.611\n",
      "step:      139, time: 0.551\n",
      "step:      140, time: 0.588\n",
      "step:      141, time: 0.580\n",
      "step:      142, time: 0.570\n",
      "step:      143, time: 0.571\n",
      "step:      144, time: 0.565\n",
      "step:      145, time: 0.553\n",
      "step:      146, time: 0.550\n",
      "step:      147, time: 0.575\n",
      "step:      148, time: 0.595\n",
      "step:      149, time: 0.608\n",
      "step:      150, time: 0.588\n",
      "step:      151, time: 0.576\n",
      "step:      152, time: 0.557\n",
      "step:      153, time: 0.600\n",
      "step:      154, time: 0.610\n",
      "step:      155, time: 0.572\n",
      "step:      156, time: 0.591\n",
      "step:      157, time: 0.578\n",
      "step:      158, time: 0.561\n",
      "step:      159, time: 0.576\n",
      "step:      160, time: 0.570\n",
      "step:      161, time: 0.619\n",
      "step:      162, time: 0.597\n",
      "step:      163, time: 0.601\n",
      "step:      164, time: 0.643\n",
      "step:      165, time: 0.588\n",
      "step:      166, time: 0.596\n",
      "step:      167, time: 0.570\n",
      "step:      168, time: 0.584\n",
      "step:      169, time: 0.609\n",
      "step:      170, time: 0.594\n",
      "step:      171, time: 0.583\n",
      "step:      172, time: 0.600\n",
      "step:      173, time: 0.644\n",
      "step:      174, time: 0.600\n",
      "step:      175, time: 0.625\n",
      "step:      176, time: 0.574\n",
      "step:      177, time: 0.594\n",
      "step:      178, time: 0.595\n",
      "step:      179, time: 0.566\n",
      "step:      180, time: 0.578\n",
      "step:      181, time: 0.572\n",
      "step:      182, time: 0.554\n",
      "step:      183, time: 0.559\n",
      "step:      184, time: 0.571\n",
      "step:      185, time: 0.568\n",
      "step:      186, time: 0.580\n",
      "step:      187, time: 0.592\n",
      "step:      188, time: 0.578\n",
      "step:      189, time: 0.584\n",
      "step:      190, time: 0.571\n",
      "step:      191, time: 0.586\n",
      "step:      192, time: 0.565\n",
      "step:      193, time: 0.607\n",
      "step:      194, time: 0.560\n",
      "step:      195, time: 0.562\n",
      "step:      196, time: 0.584\n",
      "step:      197, time: 0.588\n",
      "step:      198, time: 0.592\n",
      "step:      199, time: 0.603\n",
      "step:      200, time: 0.584\n",
      "step:      201, time: 0.619\n",
      "step:      202, time: 0.599\n",
      "step:      203, time: 0.580\n",
      "step:      204, time: 0.590\n",
      "step:      205, time: 0.598\n",
      "step:      206, time: 0.565\n",
      "step:      207, time: 0.602\n",
      "step:      208, time: 0.585\n",
      "step:      209, time: 0.568\n",
      "step:      210, time: 0.563\n",
      "step:      211, time: 0.592\n",
      "step:      212, time: 0.603\n",
      "step:      213, time: 0.588\n",
      "step:      214, time: 0.587\n",
      "step:      215, time: 0.615\n",
      "step:      216, time: 0.565\n",
      "step:      217, time: 0.587\n",
      "step:      218, time: 0.562\n",
      "step:      219, time: 0.618\n",
      "step:      220, time: 0.563\n",
      "step:      221, time: 0.611\n",
      "step:      222, time: 0.594\n",
      "step:      223, time: 0.591\n",
      "step:      224, time: 0.576\n",
      "step:      225, time: 0.577\n",
      "step:      226, time: 0.591\n",
      "step:      227, time: 0.555\n",
      "step:      228, time: 0.562\n",
      "step:      229, time: 0.593\n",
      "step:      230, time: 0.625\n",
      "step:      231, time: 0.580\n",
      "step:      232, time: 0.558\n",
      "step:      233, time: 0.581\n",
      "step:      234, time: 0.561\n",
      "step:      235, time: 0.567\n",
      "step:      236, time: 0.557\n",
      "step:      237, time: 0.568\n",
      "step:      238, time: 0.584\n",
      "step:      239, time: 0.595\n",
      "step:      240, time: 0.597\n",
      "step:      241, time: 0.579\n",
      "step:      242, time: 0.575\n",
      "step:      243, time: 0.560\n",
      "step:      244, time: 0.600\n",
      "step:      245, time: 0.559\n",
      "step:      246, time: 0.600\n",
      "step:      247, time: 0.593\n",
      "step:      248, time: 0.596\n",
      "step:      249, time: 0.605\n",
      "step:      250, time: 0.556\n",
      "step:      251, time: 0.565\n",
      "step:      252, time: 0.575\n",
      "step:      253, time: 0.597\n",
      "step:      254, time: 0.556\n",
      "step:      255, time: 0.566\n",
      "step:      256, time: 0.606\n",
      "step:      257, time: 0.596\n",
      "step:      258, time: 0.592\n",
      "step:      259, time: 0.569\n",
      "step:      260, time: 0.615\n",
      "step:      261, time: 0.591\n",
      "step:      262, time: 0.593\n",
      "step:      263, time: 0.581\n",
      "step:      264, time: 0.592\n",
      "step:      265, time: 0.553\n",
      "step:      266, time: 0.574\n",
      "step:      267, time: 0.579\n",
      "step:      268, time: 0.570\n",
      "step:      269, time: 0.578\n",
      "step:      270, time: 0.575\n",
      "step:      271, time: 0.580\n",
      "step:      272, time: 0.570\n",
      "step:      273, time: 0.557\n",
      "step:      274, time: 0.604\n",
      "step:      275, time: 0.582\n",
      "step:      276, time: 0.603\n",
      "step:      277, time: 0.580\n",
      "step:      278, time: 0.544\n",
      "step:      279, time: 0.574\n",
      "step:      280, time: 0.616\n",
      "step:      281, time: 0.588\n",
      "step:      282, time: 0.602\n",
      "step:      283, time: 0.560\n",
      "step:      284, time: 0.576\n",
      "step:      285, time: 0.571\n",
      "step:      286, time: 0.612\n",
      "step:      287, time: 0.590\n",
      "step:      288, time: 0.580\n",
      "step:      289, time: 0.590\n",
      "step:      290, time: 0.550\n",
      "step:      291, time: 0.596\n",
      "step:      292, time: 0.570\n",
      "step:      293, time: 0.585\n",
      "step:      294, time: 0.570\n",
      "step:      295, time: 0.568\n",
      "step:      296, time: 0.588\n",
      "step:      297, time: 0.600\n",
      "step:      298, time: 0.586\n",
      "step:      299, time: 0.578\n",
      "step:      300, time: 0.597\n",
      "step:      301, time: 0.604\n",
      "step:      302, time: 0.605\n",
      "step:      303, time: 0.610\n",
      "step:      304, time: 0.599\n",
      "step:      305, time: 0.561\n",
      "step:      306, time: 0.565\n",
      "step:      307, time: 0.576\n",
      "step:      308, time: 0.585\n",
      "step:      309, time: 0.600\n",
      "step:      310, time: 0.578\n",
      "step:      311, time: 0.579\n",
      "step:      312, time: 0.567\n",
      "step:      313, time: 0.574\n",
      "step:      314, time: 0.579\n",
      "step:      315, time: 0.588\n",
      "step:      316, time: 0.580\n",
      "step:      317, time: 0.565\n",
      "step:      318, time: 0.591\n",
      "step:      319, time: 0.596\n",
      "step:      320, time: 0.587\n",
      "step:      321, time: 0.550\n",
      "step:      322, time: 0.576\n",
      "step:      323, time: 0.545\n",
      "step:      324, time: 0.588\n",
      "step:      325, time: 0.603\n",
      "step:      326, time: 0.592\n",
      "step:      327, time: 0.574\n",
      "step:      328, time: 0.587\n",
      "step:      329, time: 0.603\n",
      "step:      330, time: 0.574\n",
      "step:      331, time: 0.559\n",
      "step:      332, time: 0.584\n",
      "step:      333, time: 0.589\n",
      "step:      334, time: 0.581\n",
      "step:      335, time: 0.585\n",
      "step:      336, time: 0.602\n",
      "step:      337, time: 0.577\n",
      "step:      338, time: 0.591\n",
      "step:      339, time: 0.579\n",
      "step:      340, time: 0.573\n",
      "step:      341, time: 0.570\n",
      "step:      342, time: 0.553\n",
      "step:      343, time: 0.594\n",
      "step:      344, time: 0.554\n",
      "step:      345, time: 0.598\n",
      "step:      346, time: 0.589\n",
      "step:      347, time: 0.605\n",
      "step:      348, time: 0.559\n",
      "step:      349, time: 0.629\n",
      "step:      350, time: 0.598\n",
      "step:      351, time: 0.604\n",
      "step:      352, time: 0.576\n",
      "step:      353, time: 0.569\n",
      "step:      354, time: 0.554\n",
      "step:      355, time: 0.609\n",
      "step:      356, time: 0.615\n",
      "step:      357, time: 0.570\n",
      "step:      358, time: 0.573\n",
      "step:      359, time: 0.592\n",
      "step:      360, time: 0.600\n",
      "step:      361, time: 0.575\n",
      "step:      362, time: 0.579\n",
      "step:      363, time: 0.578\n",
      "step:      364, time: 0.623\n",
      "step:      365, time: 0.595\n",
      "step:      366, time: 0.540\n",
      "step:      367, time: 0.561\n",
      "step:      368, time: 0.588\n",
      "step:      369, time: 0.571\n",
      "step:      370, time: 0.599\n",
      "step:      371, time: 0.574\n",
      "step:      372, time: 0.589\n",
      "step:      373, time: 0.576\n",
      "step:      374, time: 0.574\n",
      "step:      375, time: 0.583\n",
      "step:      376, time: 0.565\n",
      "step:      377, time: 0.571\n",
      "step:      378, time: 0.584\n",
      "step:      379, time: 0.566\n",
      "step:      380, time: 0.566\n",
      "step:      381, time: 0.600\n",
      "step:      382, time: 0.585\n",
      "step:      383, time: 0.585\n",
      "step:      384, time: 0.590\n",
      "step:      385, time: 0.587\n",
      "step:      386, time: 0.578\n",
      "step:      387, time: 0.568\n",
      "step:      388, time: 0.534\n",
      "step:      389, time: 0.612\n",
      "step:      390, time: 0.576\n",
      "step:      391, time: 0.579\n",
      "step:      392, time: 0.587\n",
      "step:      393, time: 0.569\n",
      "step:      394, time: 0.594\n",
      "step:      395, time: 0.589\n",
      "step:      396, time: 0.610\n",
      "step:      397, time: 0.569\n",
      "step:      398, time: 0.592\n",
      "step:      399, time: 0.560\n",
      "step:      400, time: 0.598\n",
      "step:      401, time: 0.592\n",
      "step:      402, time: 0.576\n",
      "step:      403, time: 0.534\n",
      "step:      404, time: 0.585\n",
      "step:      405, time: 0.577\n",
      "step:      406, time: 0.575\n",
      "step:      407, time: 0.589\n",
      "step:      408, time: 0.571\n",
      "step:      409, time: 0.582\n",
      "step:      410, time: 0.578\n",
      "step:      411, time: 0.600\n",
      "step:      412, time: 0.568\n",
      "step:      413, time: 0.605\n",
      "step:      414, time: 0.612\n",
      "step:      415, time: 0.560\n",
      "step:      416, time: 0.587\n",
      "step:      417, time: 0.561\n",
      "step:      418, time: 0.534\n",
      "step:      419, time: 0.570\n",
      "step:      420, time: 0.598\n",
      "step:      421, time: 0.587\n",
      "step:      422, time: 0.589\n",
      "step:      423, time: 0.584\n",
      "step:      424, time: 0.575\n",
      "step:      425, time: 0.578\n",
      "step:      426, time: 0.576\n",
      "step:      427, time: 0.582\n",
      "step:      428, time: 0.587\n",
      "step:      429, time: 0.573\n",
      "step:      430, time: 0.580\n",
      "step:      431, time: 0.589\n",
      "step:      432, time: 0.554\n",
      "step:      433, time: 0.579\n",
      "step:      434, time: 0.592\n",
      "step:      435, time: 0.569\n",
      "step:      436, time: 0.572\n",
      "step:      437, time: 0.606\n",
      "step:      438, time: 0.574\n",
      "step:      439, time: 0.629\n",
      "step:      440, time: 0.569\n",
      "step:      441, time: 0.587\n",
      "step:      442, time: 0.572\n",
      "step:      443, time: 0.581\n",
      "step:      444, time: 0.592\n",
      "step:      445, time: 0.595\n",
      "step:      446, time: 0.636\n",
      "step:      447, time: 0.604\n",
      "step:      448, time: 0.590\n",
      "step:      449, time: 0.587\n",
      "step:      450, time: 0.593\n",
      "step:      451, time: 0.578\n",
      "step:      452, time: 0.612\n",
      "step:      453, time: 0.602\n",
      "step:      454, time: 0.567\n",
      "step:      455, time: 0.614\n",
      "step:      456, time: 0.587\n",
      "step:      457, time: 0.573\n",
      "step:      458, time: 0.601\n",
      "step:      459, time: 0.619\n",
      "step:      460, time: 0.565\n",
      "step:      461, time: 0.574\n",
      "step:      462, time: 0.590\n",
      "step:      463, time: 0.563\n",
      "step:      464, time: 0.574\n",
      "step:      465, time: 0.574\n",
      "step:      466, time: 0.573\n",
      "step:      467, time: 0.594\n",
      "step:      468, time: 0.565\n",
      "step:      469, time: 0.571\n",
      "step:      470, time: 0.596\n",
      "step:      471, time: 0.561\n",
      "step:      472, time: 0.611\n",
      "step:      473, time: 0.568\n",
      "step:      474, time: 0.581\n",
      "step:      475, time: 0.564\n",
      "step:      476, time: 0.579\n",
      "step:      477, time: 0.585\n",
      "step:      478, time: 0.587\n",
      "step:      479, time: 0.547\n",
      "step:      480, time: 0.588\n",
      "step:      481, time: 0.586\n",
      "step:      482, time: 0.574\n",
      "step:      483, time: 0.585\n",
      "step:      484, time: 0.551\n",
      "step:      485, time: 0.560\n",
      "step:      486, time: 0.593\n",
      "step:      487, time: 0.561\n",
      "step:      488, time: 0.564\n",
      "step:      489, time: 0.578\n",
      "step:      490, time: 0.591\n",
      "step:      491, time: 0.609\n",
      "step:      492, time: 0.571\n",
      "step:      493, time: 0.579\n",
      "step:      494, time: 0.577\n",
      "step:      495, time: 0.591\n",
      "step:      496, time: 0.580\n",
      "step:      497, time: 0.581\n",
      "step:      498, time: 0.607\n",
      "step:      499, time: 0.594\n",
      "step:      500, time: 0.561\n",
      "step:      501, time: 0.539\n",
      "step:      502, time: 0.555\n",
      "step:      503, time: 0.560\n",
      "step:      504, time: 0.557\n",
      "step:      505, time: 0.585\n",
      "step:      506, time: 0.581\n",
      "step:      507, time: 0.573\n",
      "step:      508, time: 0.558\n",
      "Finished test TOM, named: tom_test_new!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n",
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1614: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "C:\\Users\\ching\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:1625: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "!python test.py --name tom_test_new --stage TOM --workers 4 --datamode test --data_list test_pairs.txt --checkpoint checkpoints/tom_train_new/tom_final.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Cloth & Pose images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pairs = 'data/test_pairs.txt'\n",
    "test_pair = pd.read_table(test_pairs,names = ['pose-cloth'])\n",
    "test_pair['pose'] = test_pair['pose-cloth'].apply(lambda x : x.split()[0])\n",
    "test_pair['cloth'] = test_pair['pose-cloth'].apply(lambda x : x.split()[1])\n",
    "test_pair = test_pair.drop('pose-cloth',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Try on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = 'result/tom_final.pth/test/try-on/'\n",
    "try_on_path = glob(root+'*.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    input_cloth = Image.open('data/test/cloth/'+test_pair['cloth'][i])\n",
    "    input_pose = Image.open('data/test/image/'+test_pair['pose'][i])\n",
    "    output_try_on = Image.open(try_on_path[i])\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.title('Input cloth')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(input_cloth))\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    plt.title('Input pose')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(input_pose))\n",
    "    \n",
    "    plt.subplot(1,3,3)\n",
    "    plt.title('Final Output')\n",
    "    plt.axis('off')\n",
    "    plt.imshow(np.array(output_try_on))\n",
    "    plt.savefig('output_{}.png'.format(i+1))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
